{"eval/walltime": 227.34462976455688, "eval/episode_distance_from_origin": 341.96368408203125, "eval/episode_forward_reward": 168.7869873046875, "eval/episode_reward": 158.33026123046875, "eval/episode_reward_contact": 0.0, "eval/episode_reward_ctrl": -105.63672637939453, "eval/episode_reward_forward": 168.7869873046875, "eval/episode_reward_survive": 92.0, "eval/episode_x_position": 313.6747131347656, "eval/episode_x_velocity": 168.7869873046875, "eval/episode_y_position": -108.052734375, "eval/episode_y_velocity": -50.1572265625, "eval/avg_episode_length": 93.0, "eval/epoch_eval_time": 3.2823235988616943, "eval/sps": 304.6622217098883, "steps": 67000.0, "_timestamp": 1738159846.4281487, "_runtime": 2045.338710784912, "_step": 66, "training/sps": 27.44889698640285, "training/walltime": 1783.1203231811523, "training/model_train_time": 25.055099725723267, "training/other_time": 11.36210322380066, "training/model_horizon": 5, "training/hallucination_updates_per_training_step": 1000, "training/env_buffer_size": 67000, "model/train_total_loss": -29.076974868774414, "model/train_mean_loss": 0.8125792741775513, "model/test_total_loss": -27.440641403198242, "model/test_mean_loss": 0.9307333827018738, "model/train_epochs": 13, "model/sec_per_epoch": 1.7477041574624868, "sac/actor_loss": -49.68333053588867, "sac/alpha": 0.19999998807907104, "sac/alpha_loss": 0.7793558239936829, "sac/buffer_current_size": 1001999.0, "sac/critic_loss": 35.23221206665039, "_wandb": {"runtime": 2048}}