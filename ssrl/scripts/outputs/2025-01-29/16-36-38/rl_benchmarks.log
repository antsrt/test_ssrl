[2025-01-29 16:36:39,533][jax._src.xla_bridge][INFO] - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
[2025-01-29 16:36:39,534][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-01-29 16:37:10,295][absl][INFO] - {'eval/walltime': 10.618884801864624, 'eval/episode_distance_from_origin': Array(44.507618, dtype=float32), 'eval/episode_forward_reward': Array(-14.939314, dtype=float32), 'eval/episode_reward': Array(-90.88228, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-126.58382, dtype=float32), 'eval/episode_reward_forward': Array(-14.939314, dtype=float32), 'eval/episode_reward_survive': Array(55., dtype=float32), 'eval/episode_x_position': Array(-4.207349, dtype=float32), 'eval/episode_x_velocity': Array(-14.939314, dtype=float32), 'eval/episode_y_position': Array(-2.4676032, dtype=float32), 'eval/episode_y_velocity': Array(-9.95795, dtype=float32), 'eval/avg_episode_length': Array(56., dtype=float32), 'eval/epoch_eval_time': 10.618884801864624, 'eval/sps': 94.17184748293012}
[2025-01-29 16:37:25,473][absl][INFO] - env buffer size after init exploration 1000
[2025-01-29 16:38:31,716][absl][INFO] - {'eval/walltime': 13.88317084312439, 'training/sps': 15.879046386923362, 'training/walltime': 62.97607398033142, 'training/model_train_time': 36.14334797859192, 'training/other_time': 26.817777395248413, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 100, 'training/env_buffer_size': Array(2000, dtype=int32), 'model/train_total_loss': Array(105.13087, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(18.757011, dtype=float32), 'model/test_total_loss': Array(nan, dtype=float32), 'model/test_mean_loss': Array(nan, dtype=float32), 'model/train_epochs': 6, 'model/sec_per_epoch': 5.798494259516398, 'sac/actor_loss': Array(-0.29818133, dtype=float32), 'sac/alpha': Array(0.20000002, dtype=float32), 'sac/alpha_loss': Array(1.7752802, dtype=float32), 'sac/buffer_current_size': Array(21182., dtype=float32), 'sac/critic_loss': Array(1.0358174, dtype=float32), 'eval/episode_distance_from_origin': Array(17.450472, dtype=float32), 'eval/episode_forward_reward': Array(-7.075601, dtype=float32), 'eval/episode_reward': Array(-18.190481, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-35.562878, dtype=float32), 'eval/episode_reward_forward': Array(-7.075601, dtype=float32), 'eval/episode_reward_survive': Array(24., dtype=float32), 'eval/episode_x_position': Array(-4.201076, dtype=float32), 'eval/episode_x_velocity': Array(-7.075601, dtype=float32), 'eval/episode_y_position': Array(-4.5917087, dtype=float32), 'eval/episode_y_velocity': Array(-4.059867, dtype=float32), 'eval/avg_episode_length': Array(25., dtype=float32), 'eval/epoch_eval_time': 3.2642860412597656, 'eval/sps': 306.3457023558132}
[2025-01-29 16:39:04,927][absl][INFO] - {'eval/walltime': 17.159133672714233, 'training/sps': 33.45872799279852, 'training/walltime': 92.8636417388916, 'training/model_train_time': 7.095257997512817, 'training/other_time': 22.788010835647583, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 200, 'training/env_buffer_size': Array(3000, dtype=int32), 'model/train_total_loss': Array(39.3367, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(12.06475, dtype=float32), 'model/test_total_loss': Array(37.562122, dtype=float32), 'model/test_mean_loss': Array(11.648914, dtype=float32), 'model/train_epochs': 36, 'model/sec_per_epoch': 0.14721942610210842, 'sac/actor_loss': Array(-17.519108, dtype=float32), 'sac/alpha': Array(0.20000003, dtype=float32), 'sac/alpha_loss': Array(0.45199484, dtype=float32), 'sac/buffer_current_size': Array(41191., dtype=float32), 'sac/critic_loss': Array(14.399756, dtype=float32), 'eval/episode_distance_from_origin': Array(50.695217, dtype=float32), 'eval/episode_forward_reward': Array(-15.266896, dtype=float32), 'eval/episode_reward': Array(-128.51991, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-154.59996, dtype=float32), 'eval/episode_reward_forward': Array(-15.266896, dtype=float32), 'eval/episode_reward_survive': Array(45., dtype=float32), 'eval/episode_x_position': Array(7.5884457, dtype=float32), 'eval/episode_x_velocity': Array(-15.266896, dtype=float32), 'eval/episode_y_position': Array(31.280785, dtype=float32), 'eval/episode_y_velocity': Array(21.985239, dtype=float32), 'eval/avg_episode_length': Array(46., dtype=float32), 'eval/epoch_eval_time': 3.2759628295898438, 'eval/sps': 305.2537687447454}
[2025-01-29 16:39:36,747][absl][INFO] - {'eval/walltime': 20.43622922897339, 'training/sps': 35.08780911821725, 'training/walltime': 121.3635687828064, 'training/model_train_time': 4.846778154373169, 'training/other_time': 23.649479150772095, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 300, 'training/env_buffer_size': Array(4000, dtype=int32), 'model/train_total_loss': Array(35.737965, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(11.217013, dtype=float32), 'model/test_total_loss': Array(34.235916, dtype=float32), 'model/test_mean_loss': Array(10.906515, dtype=float32), 'model/train_epochs': 7, 'model/sec_per_epoch': 0.37964037486485075, 'sac/actor_loss': Array(-6485.4253, dtype=float32), 'sac/alpha': Array(0.2, dtype=float32), 'sac/alpha_loss': Array(-6.318407, dtype=float32), 'sac/buffer_current_size': Array(61194., dtype=float32), 'sac/critic_loss': Array(1884065.4, dtype=float32), 'eval/episode_distance_from_origin': Array(53.903107, dtype=float32), 'eval/episode_forward_reward': Array(3.5046506, dtype=float32), 'eval/episode_reward': Array(-191.51941, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-254.70016, dtype=float32), 'eval/episode_reward_forward': Array(3.5046506, dtype=float32), 'eval/episode_reward_survive': Array(64., dtype=float32), 'eval/episode_x_position': Array(23.603905, dtype=float32), 'eval/episode_x_velocity': Array(3.5046506, dtype=float32), 'eval/episode_y_position': Array(-5.2860923, dtype=float32), 'eval/episode_y_velocity': Array(-0.90491635, dtype=float32), 'eval/avg_episode_length': Array(65., dtype=float32), 'eval/epoch_eval_time': 3.2770955562591553, 'eval/sps': 305.1482579108899}
[2025-01-29 16:40:38,332][absl][INFO] - {'eval/walltime': 23.719568490982056, 'training/sps': 17.164491205994548, 'training/walltime': 179.6233789920807, 'training/model_train_time': 35.181999921798706, 'training/other_time': 23.073818922042847, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 400, 'training/env_buffer_size': Array(5000, dtype=int32), 'model/train_total_loss': Array(-15.59026, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.3127311, dtype=float32), 'model/test_total_loss': Array(1.4854969, dtype=float32), 'model/test_mean_loss': Array(3.2454324, dtype=float32), 'model/train_epochs': 222, 'model/sec_per_epoch': 0.1490693103085767, 'sac/actor_loss': Array(-38733.73, dtype=float32), 'sac/alpha': Array(0.20000003, dtype=float32), 'sac/alpha_loss': Array(-11.493571, dtype=float32), 'sac/buffer_current_size': Array(81195.5, dtype=float32), 'sac/critic_loss': Array(21792378., dtype=float32), 'eval/episode_distance_from_origin': Array(18.591118, dtype=float32), 'eval/episode_forward_reward': Array(5.006936, dtype=float32), 'eval/episode_reward': Array(-65.84973, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-94.171776, dtype=float32), 'eval/episode_reward_forward': Array(5.006936, dtype=float32), 'eval/episode_reward_survive': Array(26., dtype=float32), 'eval/episode_x_position': Array(0.11376083, dtype=float32), 'eval/episode_x_velocity': Array(5.006936, dtype=float32), 'eval/episode_y_position': Array(-0.43233496, dtype=float32), 'eval/episode_y_velocity': Array(-2.4461193, dtype=float32), 'eval/avg_episode_length': Array(27., dtype=float32), 'eval/epoch_eval_time': 3.283339262008667, 'eval/sps': 304.56797796406346}
[2025-01-29 16:41:12,567][absl][INFO] - {'eval/walltime': 26.99076223373413, 'training/sps': 32.343288653323846, 'training/walltime': 210.5416944026947, 'training/model_train_time': 8.054803609848022, 'training/other_time': 22.859325647354126, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 500, 'training/env_buffer_size': Array(6000, dtype=int32), 'model/train_total_loss': Array(-15.704923, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.3600757, dtype=float32), 'model/test_total_loss': Array(-9.713953, dtype=float32), 'model/test_mean_loss': Array(1.924782, dtype=float32), 'model/train_epochs': 28, 'model/sec_per_epoch': 0.22176629304885864, 'sac/actor_loss': Array(-25780.936, dtype=float32), 'sac/alpha': Array(0.20000002, dtype=float32), 'sac/alpha_loss': Array(-8.899195, dtype=float32), 'sac/buffer_current_size': Array(101196.41, dtype=float32), 'sac/critic_loss': Array(8702954., dtype=float32), 'eval/episode_distance_from_origin': Array(28.146091, dtype=float32), 'eval/episode_forward_reward': Array(-8.393208, dtype=float32), 'eval/episode_reward': Array(-75.57816, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-97.06573, dtype=float32), 'eval/episode_reward_forward': Array(-8.393208, dtype=float32), 'eval/episode_reward_survive': Array(32., dtype=float32), 'eval/episode_x_position': Array(-3.8268573, dtype=float32), 'eval/episode_x_velocity': Array(-8.393208, dtype=float32), 'eval/episode_y_position': Array(0.04886889, dtype=float32), 'eval/episode_y_velocity': Array(-12.575388, dtype=float32), 'eval/avg_episode_length': Array(33., dtype=float32), 'eval/epoch_eval_time': 3.271193742752075, 'eval/sps': 305.69879947211376}
[2025-01-29 16:41:47,101][absl][INFO] - {'eval/walltime': 30.268945693969727, 'training/sps': 32.03896976313368, 'training/walltime': 241.75368428230286, 'training/model_train_time': 6.391817569732666, 'training/other_time': 24.815496921539307, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 600, 'training/env_buffer_size': Array(7000, dtype=int32), 'model/train_total_loss': Array(-14.839908, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.4038924, dtype=float32), 'model/test_total_loss': Array(-12.088297, dtype=float32), 'model/test_mean_loss': Array(1.7169956, dtype=float32), 'model/train_epochs': 16, 'model/sec_per_epoch': 0.2815990597009659, 'sac/actor_loss': Array(-2210.4534, dtype=float32), 'sac/alpha': Array(0.2, dtype=float32), 'sac/alpha_loss': Array(-5.794001, dtype=float32), 'sac/buffer_current_size': Array(121197., dtype=float32), 'sac/critic_loss': Array(613735.56, dtype=float32), 'eval/episode_distance_from_origin': Array(13.9869375, dtype=float32), 'eval/episode_forward_reward': Array(2.6523323, dtype=float32), 'eval/episode_reward': Array(-26.58078, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-44.155685, dtype=float32), 'eval/episode_reward_forward': Array(2.6523323, dtype=float32), 'eval/episode_reward_survive': Array(18., dtype=float32), 'eval/episode_x_position': Array(3.6860735, dtype=float32), 'eval/episode_x_velocity': Array(2.6523323, dtype=float32), 'eval/episode_y_position': Array(4.356414, dtype=float32), 'eval/episode_y_velocity': Array(3.4419358, dtype=float32), 'eval/avg_episode_length': Array(19., dtype=float32), 'eval/epoch_eval_time': 3.2781834602355957, 'eval/sps': 305.04699085027175}
[2025-01-29 16:42:22,220][absl][INFO] - {'eval/walltime': 33.54872155189514, 'training/sps': 31.451130360480615, 'training/walltime': 273.5490438938141, 'training/model_train_time': 6.983920335769653, 'training/other_time': 24.808045148849487, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 700, 'training/env_buffer_size': Array(8000, dtype=int32), 'model/train_total_loss': Array(-15.330821, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.397968, dtype=float32), 'model/test_total_loss': Array(-11.612968, dtype=float32), 'model/test_mean_loss': Array(1.7883368, dtype=float32), 'model/train_epochs': 13, 'model/sec_per_epoch': 0.3798967691568228, 'sac/actor_loss': Array(2491.972, dtype=float32), 'sac/alpha': Array(0.20000002, dtype=float32), 'sac/alpha_loss': Array(-4.8582406, dtype=float32), 'sac/buffer_current_size': Array(141197.42, dtype=float32), 'sac/critic_loss': Array(71773.766, dtype=float32), 'eval/episode_distance_from_origin': Array(8.910715, dtype=float32), 'eval/episode_forward_reward': Array(-2.3755128, dtype=float32), 'eval/episode_reward': Array(-27.861135, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-33.520576, dtype=float32), 'eval/episode_reward_forward': Array(-2.3755128, dtype=float32), 'eval/episode_reward_survive': Array(13., dtype=float32), 'eval/episode_x_position': Array(0.95347524, dtype=float32), 'eval/episode_x_velocity': Array(-2.3755128, dtype=float32), 'eval/episode_y_position': Array(-3.2128315, dtype=float32), 'eval/episode_y_velocity': Array(-6.43261, dtype=float32), 'eval/avg_episode_length': Array(14., dtype=float32), 'eval/epoch_eval_time': 3.279775857925415, 'eval/sps': 304.8988843501454}
[2025-01-29 16:42:58,775][absl][INFO] - {'eval/walltime': 36.81963300704956, 'training/sps': 30.084987012605456, 'training/walltime': 306.788213968277, 'training/model_train_time': 6.187543153762817, 'training/other_time': 27.046292543411255, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 800, 'training/env_buffer_size': Array(9000, dtype=int32), 'model/train_total_loss': Array(-15.163156, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.3952268, dtype=float32), 'model/test_total_loss': Array(-11.106115, dtype=float32), 'model/test_mean_loss': Array(1.9582428, dtype=float32), 'model/train_epochs': 8, 'model/sec_per_epoch': 0.5045547485351562, 'sac/actor_loss': Array(2717.663, dtype=float32), 'sac/alpha': Array(0.20000003, dtype=float32), 'sac/alpha_loss': Array(-5.036258, dtype=float32), 'sac/buffer_current_size': Array(161197.75, dtype=float32), 'sac/critic_loss': Array(64704.5, dtype=float32), 'eval/episode_distance_from_origin': Array(221.71774, dtype=float32), 'eval/episode_forward_reward': Array(-94.45134, dtype=float32), 'eval/episode_reward': Array(-258.07767, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-254.746, dtype=float32), 'eval/episode_reward_forward': Array(-94.45134, dtype=float32), 'eval/episode_reward_survive': Array(96., dtype=float32), 'eval/episode_x_position': Array(-189.89946, dtype=float32), 'eval/episode_x_velocity': Array(-94.45134, dtype=float32), 'eval/episode_y_position': Array(-77.09086, dtype=float32), 'eval/episode_y_velocity': Array(-42.360184, dtype=float32), 'eval/avg_episode_length': Array(97., dtype=float32), 'eval/epoch_eval_time': 3.270911455154419, 'eval/sps': 305.72518202049287}
[2025-01-29 16:43:34,653][absl][INFO] - {'eval/walltime': 40.10497426986694, 'training/sps': 30.72218768078146, 'training/walltime': 339.3379793167114, 'training/model_train_time': 7.218359470367432, 'training/other_time': 25.32632875442505, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 900, 'training/env_buffer_size': Array(10000, dtype=int32), 'model/train_total_loss': Array(-14.830625, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.416881, dtype=float32), 'model/test_total_loss': Array(-10.747347, dtype=float32), 'model/test_mean_loss': Array(1.9387274, dtype=float32), 'model/train_epochs': 13, 'model/sec_per_epoch': 0.39512903873737043, 'sac/actor_loss': Array(3188.3303, dtype=float32), 'sac/alpha': Array(0.2, dtype=float32), 'sac/alpha_loss': Array(-5.307451, dtype=float32), 'sac/buffer_current_size': Array(181198.02, dtype=float32), 'sac/critic_loss': Array(80043.14, dtype=float32), 'eval/episode_distance_from_origin': Array(7.6475835, dtype=float32), 'eval/episode_forward_reward': Array(-0.87574863, dtype=float32), 'eval/episode_reward': Array(-20.880344, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-26.36132, dtype=float32), 'eval/episode_reward_forward': Array(-0.87574863, dtype=float32), 'eval/episode_reward_survive': Array(9., dtype=float32), 'eval/episode_x_position': Array(-0.21191448, dtype=float32), 'eval/episode_x_velocity': Array(-0.87574863, dtype=float32), 'eval/episode_y_position': Array(0.52189773, dtype=float32), 'eval/episode_y_velocity': Array(-0.6972982, dtype=float32), 'eval/avg_episode_length': Array(10., dtype=float32), 'eval/epoch_eval_time': 3.285341262817383, 'eval/sps': 304.38238222547335}
[2025-01-29 16:44:10,450][absl][INFO] - {'eval/walltime': 43.37683701515198, 'training/sps': 30.786979117517994, 'training/walltime': 371.8192434310913, 'training/model_train_time': 6.5822837352752686, 'training/other_time': 25.89344573020935, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(11000, dtype=int32), 'model/train_total_loss': Array(-14.379219, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.5737765, dtype=float32), 'model/test_total_loss': Array(-12.054277, dtype=float32), 'model/test_mean_loss': Array(1.7758901, dtype=float32), 'model/train_epochs': 9, 'model/sec_per_epoch': 0.5036327573988173, 'sac/actor_loss': Array(3538.146, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-6.2692633, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(110376.84, dtype=float32), 'eval/episode_distance_from_origin': Array(10.33184, dtype=float32), 'eval/episode_forward_reward': Array(-5.830557, dtype=float32), 'eval/episode_reward': Array(-28.744469, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-31.2646, dtype=float32), 'eval/episode_reward_forward': Array(-5.830557, dtype=float32), 'eval/episode_reward_survive': Array(11., dtype=float32), 'eval/episode_x_position': Array(-1.396122, dtype=float32), 'eval/episode_x_velocity': Array(-5.830557, dtype=float32), 'eval/episode_y_position': Array(-2.8473167, dtype=float32), 'eval/episode_y_velocity': Array(-9.087333, dtype=float32), 'eval/avg_episode_length': Array(12., dtype=float32), 'eval/epoch_eval_time': 3.271862745285034, 'eval/sps': 305.6362927940864}
[2025-01-29 16:44:27,888][absl][INFO] - {'eval/walltime': 46.65075492858887, 'training/sps': 70.64952425356793, 'training/walltime': 385.9736204147339, 'training/model_train_time': 5.617029428482056, 'training/other_time': 8.530169010162354, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(12000, dtype=int32), 'model/train_total_loss': Array(-15.664613, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.4264448, dtype=float32), 'model/test_total_loss': Array(-12.282657, dtype=float32), 'model/test_mean_loss': Array(1.8160766, dtype=float32), 'model/train_epochs': 7, 'model/sec_per_epoch': 0.5376785142081124, 'sac/actor_loss': Array(3755.9583, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-6.8524218, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(115870.7, dtype=float32), 'eval/episode_distance_from_origin': Array(3.0338166, dtype=float32), 'eval/episode_forward_reward': Array(5.2632656, dtype=float32), 'eval/episode_reward': Array(-2.181411, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-11.831751, dtype=float32), 'eval/episode_reward_forward': Array(5.2632656, dtype=float32), 'eval/episode_reward_survive': Array(4., dtype=float32), 'eval/episode_x_position': Array(0.5908003, dtype=float32), 'eval/episode_x_velocity': Array(5.2632656, dtype=float32), 'eval/episode_y_position': Array(0.4735046, dtype=float32), 'eval/episode_y_velocity': Array(-0.43368208, dtype=float32), 'eval/avg_episode_length': Array(5., dtype=float32), 'eval/epoch_eval_time': 3.2739179134368896, 'eval/sps': 305.4444327683895}
[2025-01-29 16:44:46,273][absl][INFO] - {'eval/walltime': 49.93855023384094, 'training/sps': 66.28331433449462, 'training/walltime': 401.060373544693, 'training/model_train_time': 6.531374931335449, 'training/other_time': 8.547792673110962, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(13000, dtype=int32), 'model/train_total_loss': Array(-16.050701, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.375719, dtype=float32), 'model/test_total_loss': Array(-12.063439, dtype=float32), 'model/test_mean_loss': Array(1.9636068, dtype=float32), 'model/train_epochs': 7, 'model/sec_per_epoch': 0.6404459135872977, 'sac/actor_loss': Array(3806.5864, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-7.209506, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(127700.195, dtype=float32), 'eval/episode_distance_from_origin': Array(14.872665, dtype=float32), 'eval/episode_forward_reward': Array(-3.0728593, dtype=float32), 'eval/episode_reward': Array(-46.936134, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-60.013256, dtype=float32), 'eval/episode_reward_forward': Array(-3.0728593, dtype=float32), 'eval/episode_reward_survive': Array(19., dtype=float32), 'eval/episode_x_position': Array(1.7529552, dtype=float32), 'eval/episode_x_velocity': Array(-3.0728593, dtype=float32), 'eval/episode_y_position': Array(5.073524, dtype=float32), 'eval/episode_y_velocity': Array(-1.3473657, dtype=float32), 'eval/avg_episode_length': Array(20., dtype=float32), 'eval/epoch_eval_time': 3.287795305252075, 'eval/sps': 304.15518825109154}
[2025-01-29 16:45:04,480][absl][INFO] - {'eval/walltime': 53.21919393539429, 'training/sps': 67.04412726342048, 'training/walltime': 415.97592306137085, 'training/model_train_time': 6.3603105545043945, 'training/other_time': 8.548458337783813, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(14000, dtype=int32), 'model/train_total_loss': Array(-15.486044, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.4546897, dtype=float32), 'model/test_total_loss': Array(-12.701877, dtype=float32), 'model/test_mean_loss': Array(1.8332162, dtype=float32), 'model/train_epochs': 7, 'model/sec_per_epoch': 0.6270309175763812, 'sac/actor_loss': Array(4035.239, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-7.3953943, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(147010.92, dtype=float32), 'eval/episode_distance_from_origin': Array(2.9953363, dtype=float32), 'eval/episode_forward_reward': Array(0.9930753, dtype=float32), 'eval/episode_reward': Array(-8.157174, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-11.865514, dtype=float32), 'eval/episode_reward_forward': Array(0.9930753, dtype=float32), 'eval/episode_reward_survive': Array(4., dtype=float32), 'eval/episode_x_position': Array(0.34947667, dtype=float32), 'eval/episode_x_velocity': Array(0.9930753, dtype=float32), 'eval/episode_y_position': Array(-0.18182707, dtype=float32), 'eval/episode_y_velocity': Array(1.1811136, dtype=float32), 'eval/avg_episode_length': Array(5., dtype=float32), 'eval/epoch_eval_time': 3.2806437015533447, 'eval/sps': 304.8182280588752}
[2025-01-29 16:45:23,176][absl][INFO] - {'eval/walltime': 56.5073344707489, 'training/sps': 64.94217986921308, 'training/walltime': 431.374235868454, 'training/model_train_time': 6.840149641036987, 'training/other_time': 8.551581382751465, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(15000, dtype=int32), 'model/train_total_loss': Array(-16.298553, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.4444278, dtype=float32), 'model/test_total_loss': Array(-13.687483, dtype=float32), 'model/test_mean_loss': Array(1.7419716, dtype=float32), 'model/train_epochs': 7, 'model/sec_per_epoch': 0.6787097113473075, 'sac/actor_loss': Array(4208.331, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-7.5760827, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(172196.3, dtype=float32), 'eval/episode_distance_from_origin': Array(3.9568436, dtype=float32), 'eval/episode_forward_reward': Array(-0.59760594, dtype=float32), 'eval/episode_reward': Array(-13.631995, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-17.107452, dtype=float32), 'eval/episode_reward_forward': Array(-0.59760594, dtype=float32), 'eval/episode_reward_survive': Array(5., dtype=float32), 'eval/episode_x_position': Array(-0.3372917, dtype=float32), 'eval/episode_x_velocity': Array(-0.59760594, dtype=float32), 'eval/episode_y_position': Array(-0.14239377, dtype=float32), 'eval/episode_y_velocity': Array(0.01332104, dtype=float32), 'eval/avg_episode_length': Array(6., dtype=float32), 'eval/epoch_eval_time': 3.2881405353546143, 'eval/sps': 304.12325423680636}
[2025-01-29 16:45:41,964][absl][INFO] - {'eval/walltime': 59.782713413238525, 'training/sps': 64.51127072024428, 'training/walltime': 446.87540316581726, 'training/model_train_time': 6.944274187088013, 'training/other_time': 8.54955768585205, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(16000, dtype=int32), 'model/train_total_loss': Array(-16.696108, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.4643387, dtype=float32), 'model/test_total_loss': Array(-12.241401, dtype=float32), 'model/test_mean_loss': Array(1.8660713, dtype=float32), 'model/train_epochs': 7, 'model/sec_per_epoch': 0.7007875442504883, 'sac/actor_loss': Array(4043.5298, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-7.669648, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(155118.48, dtype=float32), 'eval/episode_distance_from_origin': Array(8.654596, dtype=float32), 'eval/episode_forward_reward': Array(8.380749, dtype=float32), 'eval/episode_reward': Array(-16.326859, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-34.671883, dtype=float32), 'eval/episode_reward_forward': Array(8.380749, dtype=float32), 'eval/episode_reward_survive': Array(11., dtype=float32), 'eval/episode_x_position': Array(0.86020404, dtype=float32), 'eval/episode_x_velocity': Array(8.380749, dtype=float32), 'eval/episode_y_position': Array(0.6904291, dtype=float32), 'eval/episode_y_velocity': Array(2.8259, dtype=float32), 'eval/avg_episode_length': Array(12., dtype=float32), 'eval/epoch_eval_time': 3.275378942489624, 'eval/sps': 305.30818496375184}
[2025-01-29 16:46:00,319][absl][INFO] - {'eval/walltime': 63.07785987854004, 'training/sps': 66.44472189521083, 'training/walltime': 461.9255075454712, 'training/model_train_time': 6.441378831863403, 'training/other_time': 8.602113723754883, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(17000, dtype=int32), 'model/train_total_loss': Array(-17.945805, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.381554, dtype=float32), 'model/test_total_loss': Array(-14.4406, dtype=float32), 'model/test_mean_loss': Array(1.6472653, dtype=float32), 'model/train_epochs': 7, 'model/sec_per_epoch': 0.6616931983402797, 'sac/actor_loss': Array(4170.009, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-7.7970185, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(161879.95, dtype=float32), 'eval/episode_distance_from_origin': Array(12.859524, dtype=float32), 'eval/episode_forward_reward': Array(5.875473, dtype=float32), 'eval/episode_reward': Array(-32.867992, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-51.801876, dtype=float32), 'eval/episode_reward_forward': Array(5.875473, dtype=float32), 'eval/episode_reward_survive': Array(16., dtype=float32), 'eval/episode_x_position': Array(4.139454, dtype=float32), 'eval/episode_x_velocity': Array(5.875473, dtype=float32), 'eval/episode_y_position': Array(-0.6198507, dtype=float32), 'eval/episode_y_velocity': Array(4.886013, dtype=float32), 'eval/avg_episode_length': Array(17., dtype=float32), 'eval/epoch_eval_time': 3.2951464653015137, 'eval/sps': 303.47664679861134}
[2025-01-29 16:46:20,774][absl][INFO] - {'eval/walltime': 66.36574673652649, 'training/sps': 58.282501377578136, 'training/walltime': 479.0833160877228, 'training/model_train_time': 8.60389232635498, 'training/other_time': 8.547138452529907, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(18000, dtype=int32), 'model/train_total_loss': Array(-18.515354, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.4125953, dtype=float32), 'model/test_total_loss': Array(-14.545498, dtype=float32), 'model/test_mean_loss': Array(1.7937968, dtype=float32), 'model/train_epochs': 10, 'model/sec_per_epoch': 0.6502691030502319, 'sac/actor_loss': Array(4050.4424, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-8.013992, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(154285.67, dtype=float32), 'eval/episode_distance_from_origin': Array(3.0273392, dtype=float32), 'eval/episode_forward_reward': Array(0.99191284, dtype=float32), 'eval/episode_reward': Array(-10.3633585, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-13.751109, dtype=float32), 'eval/episode_reward_forward': Array(0.99191284, dtype=float32), 'eval/episode_reward_survive': Array(4., dtype=float32), 'eval/episode_x_position': Array(0.1735716, dtype=float32), 'eval/episode_x_velocity': Array(0.99191284, dtype=float32), 'eval/episode_y_position': Array(0.07530754, dtype=float32), 'eval/episode_y_velocity': Array(1.6124119, dtype=float32), 'eval/avg_episode_length': Array(5., dtype=float32), 'eval/epoch_eval_time': 3.28788685798645, 'eval/sps': 304.1467189088175}
[2025-01-29 16:46:42,708][absl][INFO] - {'eval/walltime': 69.65370011329651, 'training/sps': 53.65732881041062, 'training/walltime': 497.72009921073914, 'training/model_train_time': 10.08533263206482, 'training/other_time': 8.544795751571655, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(19000, dtype=int32), 'model/train_total_loss': Array(-19.865915, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.309133, dtype=float32), 'model/test_total_loss': Array(-15.7620945, dtype=float32), 'model/test_mean_loss': Array(1.743066, dtype=float32), 'model/train_epochs': 12, 'model/sec_per_epoch': 0.6509079734484354, 'sac/actor_loss': Array(3764.6655, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-8.137434, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(151467.08, dtype=float32), 'eval/episode_distance_from_origin': Array(4.2968974, dtype=float32), 'eval/episode_forward_reward': Array(2.6447222, dtype=float32), 'eval/episode_reward': Array(-11.38688, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-17.479092, dtype=float32), 'eval/episode_reward_forward': Array(2.6447222, dtype=float32), 'eval/episode_reward_survive': Array(5., dtype=float32), 'eval/episode_x_position': Array(0.26706246, dtype=float32), 'eval/episode_x_velocity': Array(2.6447222, dtype=float32), 'eval/episode_y_position': Array(1.1464078, dtype=float32), 'eval/episode_y_velocity': Array(6.34345, dtype=float32), 'eval/avg_episode_length': Array(6., dtype=float32), 'eval/epoch_eval_time': 3.2879533767700195, 'eval/sps': 304.1405656981572}
[2025-01-29 16:47:02,319][absl][INFO] - {'eval/walltime': 72.9268696308136, 'training/sps': 61.244500258466935, 'training/walltime': 514.0480959415436, 'training/model_train_time': 7.771981239318848, 'training/other_time': 8.549221992492676, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(20000, dtype=int32), 'model/train_total_loss': Array(-19.53773, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.4198135, dtype=float32), 'model/test_total_loss': Array(-16.738178, dtype=float32), 'model/test_mean_loss': Array(1.6495248, dtype=float32), 'model/train_epochs': 7, 'model/sec_per_epoch': 0.7932063170841762, 'sac/actor_loss': Array(3820.9104, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-7.98952, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(150840.86, dtype=float32), 'eval/episode_distance_from_origin': Array(10.384459, dtype=float32), 'eval/episode_forward_reward': Array(-5.0896215, dtype=float32), 'eval/episode_reward': Array(-41.774036, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-47.967846, dtype=float32), 'eval/episode_reward_forward': Array(-5.0896215, dtype=float32), 'eval/episode_reward_survive': Array(15., dtype=float32), 'eval/episode_x_position': Array(-1.4309367, dtype=float32), 'eval/episode_x_velocity': Array(-5.0896215, dtype=float32), 'eval/episode_y_position': Array(0.07157654, dtype=float32), 'eval/episode_y_velocity': Array(-1.1806313, dtype=float32), 'eval/avg_episode_length': Array(16., dtype=float32), 'eval/epoch_eval_time': 3.27316951751709, 'eval/sps': 305.5142713043975}
[2025-01-29 16:47:22,244][absl][INFO] - {'eval/walltime': 76.21446561813354, 'training/sps': 60.135984934461185, 'training/walltime': 530.677074432373, 'training/model_train_time': 8.07377314567566, 'training/other_time': 8.548313856124878, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(21000, dtype=int32), 'model/train_total_loss': Array(-20.267017, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.3321757, dtype=float32), 'model/test_total_loss': Array(-16.672478, dtype=float32), 'model/test_mean_loss': Array(1.6442912, dtype=float32), 'model/train_epochs': 8, 'model/sec_per_epoch': 0.7576989233493805, 'sac/actor_loss': Array(3791.7544, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-8.066328, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(152988.92, dtype=float32), 'eval/episode_distance_from_origin': Array(4.5823407, dtype=float32), 'eval/episode_forward_reward': Array(-5.7754745, dtype=float32), 'eval/episode_reward': Array(-25.99059, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-22.876314, dtype=float32), 'eval/episode_reward_forward': Array(-5.7754745, dtype=float32), 'eval/episode_reward_survive': Array(7., dtype=float32), 'eval/episode_x_position': Array(-0.8933455, dtype=float32), 'eval/episode_x_velocity': Array(-5.7754745, dtype=float32), 'eval/episode_y_position': Array(0.99676764, dtype=float32), 'eval/episode_y_velocity': Array(0.6976999, dtype=float32), 'eval/avg_episode_length': Array(8., dtype=float32), 'eval/epoch_eval_time': 3.2875959873199463, 'eval/sps': 304.1736283463473}
[2025-01-29 16:47:42,189][absl][INFO] - {'eval/walltime': 79.49874901771545, 'training/sps': 60.05674879822183, 'training/walltime': 547.32799243927, 'training/model_train_time': 8.097330808639526, 'training/other_time': 8.546391010284424, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(22000, dtype=int32), 'model/train_total_loss': Array(-21.009602, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.3351206, dtype=float32), 'model/test_total_loss': Array(-17.49641, dtype=float32), 'model/test_mean_loss': Array(1.6598675, dtype=float32), 'model/train_epochs': 8, 'model/sec_per_epoch': 0.7658686339855194, 'sac/actor_loss': Array(3523.9507, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-8.100229, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(136289.9, dtype=float32), 'eval/episode_distance_from_origin': Array(5.7919874, dtype=float32), 'eval/episode_forward_reward': Array(-6.2677402, dtype=float32), 'eval/episode_reward': Array(-32.045258, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-30.543884, dtype=float32), 'eval/episode_reward_forward': Array(-6.2677402, dtype=float32), 'eval/episode_reward_survive': Array(9., dtype=float32), 'eval/episode_x_position': Array(-1.4162114, dtype=float32), 'eval/episode_x_velocity': Array(-6.2677402, dtype=float32), 'eval/episode_y_position': Array(0.2343707, dtype=float32), 'eval/episode_y_velocity': Array(1.5215449, dtype=float32), 'eval/avg_episode_length': Array(10., dtype=float32), 'eval/epoch_eval_time': 3.284283399581909, 'eval/sps': 304.4804233785977}
[2025-01-29 16:48:02,364][absl][INFO] - {'eval/walltime': 82.78165197372437, 'training/sps': 59.23330431761415, 'training/walltime': 564.2103867530823, 'training/model_train_time': 8.328430652618408, 'training/other_time': 8.547162294387817, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(23000, dtype=int32), 'model/train_total_loss': Array(-20.45209, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.4152005, dtype=float32), 'model/test_total_loss': Array(-18.629145, dtype=float32), 'model/test_mean_loss': Array(1.5747607, dtype=float32), 'model/train_epochs': 7, 'model/sec_per_epoch': 0.8798649651663644, 'sac/actor_loss': Array(3514.3223, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-8.061401, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(131738.55, dtype=float32), 'eval/episode_distance_from_origin': Array(8.194859, dtype=float32), 'eval/episode_forward_reward': Array(-0.5247302, dtype=float32), 'eval/episode_reward': Array(-23.450817, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-30.815897, dtype=float32), 'eval/episode_reward_forward': Array(-0.5247302, dtype=float32), 'eval/episode_reward_survive': Array(10., dtype=float32), 'eval/episode_x_position': Array(-1.4291931, dtype=float32), 'eval/episode_x_velocity': Array(-0.5247302, dtype=float32), 'eval/episode_y_position': Array(1.7606994, dtype=float32), 'eval/episode_y_velocity': Array(1.4112962, dtype=float32), 'eval/avg_episode_length': Array(11., dtype=float32), 'eval/epoch_eval_time': 3.282902956008911, 'eval/sps': 304.60845580879413}
[2025-01-29 16:48:24,542][absl][INFO] - {'eval/walltime': 86.05869746208191, 'training/sps': 52.938053486933605, 'training/walltime': 583.100389957428, 'training/model_train_time': 10.330357789993286, 'training/other_time': 8.552665948867798, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(24000, dtype=int32), 'model/train_total_loss': Array(-22.239096, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.1933792, dtype=float32), 'model/test_total_loss': Array(-17.923275, dtype=float32), 'model/test_mean_loss': Array(1.7022396, dtype=float32), 'model/train_epochs': 10, 'model/sec_per_epoch': 0.8133739233016968, 'sac/actor_loss': Array(3217.698, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-8.188386, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(124085.84, dtype=float32), 'eval/episode_distance_from_origin': Array(13.947666, dtype=float32), 'eval/episode_forward_reward': Array(6.3477836, dtype=float32), 'eval/episode_reward': Array(-33.993927, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-54.514156, dtype=float32), 'eval/episode_reward_forward': Array(6.3477836, dtype=float32), 'eval/episode_reward_survive': Array(17., dtype=float32), 'eval/episode_x_position': Array(5.1422453, dtype=float32), 'eval/episode_x_velocity': Array(6.3477836, dtype=float32), 'eval/episode_y_position': Array(3.1406727, dtype=float32), 'eval/episode_y_velocity': Array(3.8091629, dtype=float32), 'eval/avg_episode_length': Array(18., dtype=float32), 'eval/epoch_eval_time': 3.277045488357544, 'eval/sps': 305.1529200777742}
[2025-01-29 16:48:45,922][absl][INFO] - {'eval/walltime': 89.34019064903259, 'training/sps': 55.28086052116953, 'training/walltime': 601.1898334026337, 'training/model_train_time': 9.533942222595215, 'training/other_time': 8.548727035522461, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(25000, dtype=int32), 'model/train_total_loss': Array(-21.03792, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.3363224, dtype=float32), 'model/test_total_loss': Array(-18.49842, dtype=float32), 'model/test_mean_loss': Array(1.6714004, dtype=float32), 'model/train_epochs': 8, 'model/sec_per_epoch': 0.8914667367935181, 'sac/actor_loss': Array(2864.8994, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-8.072344, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(101303.305, dtype=float32), 'eval/episode_distance_from_origin': Array(5.2415333, dtype=float32), 'eval/episode_forward_reward': Array(-3.0927417, dtype=float32), 'eval/episode_reward': Array(-24.649977, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-25.21671, dtype=float32), 'eval/episode_reward_forward': Array(-3.0927417, dtype=float32), 'eval/episode_reward_survive': Array(8., dtype=float32), 'eval/episode_x_position': Array(-0.77312946, dtype=float32), 'eval/episode_x_velocity': Array(-3.0927417, dtype=float32), 'eval/episode_y_position': Array(0.6695412, dtype=float32), 'eval/episode_y_velocity': Array(2.622969, dtype=float32), 'eval/avg_episode_length': Array(9., dtype=float32), 'eval/epoch_eval_time': 3.2814931869506836, 'eval/sps': 304.7393192759442}
[2025-01-29 16:49:06,866][absl][INFO] - {'eval/walltime': 92.62897729873657, 'training/sps': 56.670361187512825, 'training/walltime': 618.8357417583466, 'training/model_train_time': 9.089518547058105, 'training/other_time': 8.54959774017334, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(26000, dtype=int32), 'model/train_total_loss': Array(-21.499542, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.3111017, dtype=float32), 'model/test_total_loss': Array(-18.933973, dtype=float32), 'model/test_mean_loss': Array(1.6311444, dtype=float32), 'model/train_epochs': 8, 'model/sec_per_epoch': 0.88984614610672, 'sac/actor_loss': Array(2841.1428, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-7.8340898, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(100859.336, dtype=float32), 'eval/episode_distance_from_origin': Array(6.090193, dtype=float32), 'eval/episode_forward_reward': Array(-2.306536, dtype=float32), 'eval/episode_reward': Array(-25.066967, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-31.416386, dtype=float32), 'eval/episode_reward_forward': Array(-2.306536, dtype=float32), 'eval/episode_reward_survive': Array(10., dtype=float32), 'eval/episode_x_position': Array(-2.0055375, dtype=float32), 'eval/episode_x_velocity': Array(-2.306536, dtype=float32), 'eval/episode_y_position': Array(1.2335143, dtype=float32), 'eval/episode_y_velocity': Array(4.5551157, dtype=float32), 'eval/avg_episode_length': Array(11., dtype=float32), 'eval/epoch_eval_time': 3.2887866497039795, 'eval/sps': 304.0635062447754}
[2025-01-29 16:49:28,546][absl][INFO] - {'eval/walltime': 95.92068719863892, 'training/sps': 54.41193337156595, 'training/walltime': 637.214063167572, 'training/model_train_time': 9.829049110412598, 'training/other_time': 8.542279720306396, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(27000, dtype=int32), 'model/train_total_loss': Array(-22.106337, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.3126299, dtype=float32), 'model/test_total_loss': Array(-19.280916, dtype=float32), 'model/test_mean_loss': Array(1.5927428, dtype=float32), 'model/train_epochs': 9, 'model/sec_per_epoch': 0.8668011824289957, 'sac/actor_loss': Array(2627.1128, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-8.122439, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(87649.24, dtype=float32), 'eval/episode_distance_from_origin': Array(4.9347367, dtype=float32), 'eval/episode_forward_reward': Array(2.1258903, dtype=float32), 'eval/episode_reward': Array(-11.69914, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-18.155567, dtype=float32), 'eval/episode_reward_forward': Array(2.1258903, dtype=float32), 'eval/episode_reward_survive': Array(6., dtype=float32), 'eval/episode_x_position': Array(0.91334134, dtype=float32), 'eval/episode_x_velocity': Array(2.1258903, dtype=float32), 'eval/episode_y_position': Array(1.1026806, dtype=float32), 'eval/episode_y_velocity': Array(3.8600478, dtype=float32), 'eval/avg_episode_length': Array(7., dtype=float32), 'eval/epoch_eval_time': 3.2917098999023438, 'eval/sps': 303.7934782860626}
[2025-01-29 16:49:52,327][absl][INFO] - {'eval/walltime': 99.2080774307251, 'training/sps': 48.81854473945968, 'training/walltime': 657.6980822086334, 'training/model_train_time': 11.926324129104614, 'training/other_time': 8.551082611083984, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(28000, dtype=int32), 'model/train_total_loss': Array(-21.593494, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.3650358, dtype=float32), 'model/test_total_loss': Array(36.707485, dtype=float32), 'model/test_mean_loss': Array(1.571926, dtype=float32), 'model/train_epochs': 11, 'model/sec_per_epoch': 0.8859648704528809, 'sac/actor_loss': Array(2402.994, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-8.001889, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(74984.64, dtype=float32), 'eval/episode_distance_from_origin': Array(13.451198, dtype=float32), 'eval/episode_forward_reward': Array(0.7228191, dtype=float32), 'eval/episode_reward': Array(-42.117996, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-56.144615, dtype=float32), 'eval/episode_reward_forward': Array(0.7228191, dtype=float32), 'eval/episode_reward_survive': Array(17., dtype=float32), 'eval/episode_x_position': Array(4.1319175, dtype=float32), 'eval/episode_x_velocity': Array(0.7228191, dtype=float32), 'eval/episode_y_position': Array(1.4444292, dtype=float32), 'eval/episode_y_velocity': Array(8.522891, dtype=float32), 'eval/avg_episode_length': Array(18., dtype=float32), 'eval/epoch_eval_time': 3.2873902320861816, 'eval/sps': 304.1926663404967}
[2025-01-29 16:50:17,371][absl][INFO] - {'eval/walltime': 102.5007643699646, 'training/sps': 45.99361184727113, 'training/walltime': 679.4402320384979, 'training/model_train_time': 13.191572427749634, 'training/other_time': 8.543647527694702, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(29000, dtype=int32), 'model/train_total_loss': Array(-22.503721, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.25893, dtype=float32), 'model/test_total_loss': Array(-19.078295, dtype=float32), 'model/test_mean_loss': Array(1.5932984, dtype=float32), 'model/train_epochs': 12, 'model/sec_per_epoch': 0.9020755688349406, 'sac/actor_loss': Array(2007.5555, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-7.7621374, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(57824.125, dtype=float32), 'eval/episode_distance_from_origin': Array(4.748786, dtype=float32), 'eval/episode_forward_reward': Array(-5.960439, dtype=float32), 'eval/episode_reward': Array(-31.142262, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-27.982073, dtype=float32), 'eval/episode_reward_forward': Array(-5.960439, dtype=float32), 'eval/episode_reward_survive': Array(8., dtype=float32), 'eval/episode_x_position': Array(-0.29706994, dtype=float32), 'eval/episode_x_velocity': Array(-5.960439, dtype=float32), 'eval/episode_y_position': Array(-0.87535566, dtype=float32), 'eval/episode_y_velocity': Array(-1.3031988, dtype=float32), 'eval/avg_episode_length': Array(9., dtype=float32), 'eval/epoch_eval_time': 3.292686939239502, 'eval/sps': 303.70333361572654}
[2025-01-29 16:50:40,844][absl][INFO] - {'eval/walltime': 105.7812864780426, 'training/sps': 49.54860640055441, 'training/walltime': 699.6224343776703, 'training/model_train_time': 11.626214981079102, 'training/other_time': 8.549216032028198, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(30000, dtype=int32), 'model/train_total_loss': Array(-23.302837, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.2496475, dtype=float32), 'model/test_total_loss': Array(-19.984636, dtype=float32), 'model/test_mean_loss': Array(1.5081842, dtype=float32), 'model/train_epochs': 10, 'model/sec_per_epoch': 0.9440724372863769, 'sac/actor_loss': Array(1850.2439, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-7.463292, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(50326.684, dtype=float32), 'eval/episode_distance_from_origin': Array(6.9868507, dtype=float32), 'eval/episode_forward_reward': Array(-6.3059416, dtype=float32), 'eval/episode_reward': Array(-35.64679, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-36.466545, dtype=float32), 'eval/episode_reward_forward': Array(-6.3059416, dtype=float32), 'eval/episode_reward_survive': Array(11., dtype=float32), 'eval/episode_x_position': Array(0.8484758, dtype=float32), 'eval/episode_x_velocity': Array(-6.3059416, dtype=float32), 'eval/episode_y_position': Array(-1.4478844, dtype=float32), 'eval/episode_y_velocity': Array(-2.305924, dtype=float32), 'eval/avg_episode_length': Array(12., dtype=float32), 'eval/epoch_eval_time': 3.280522108078003, 'eval/sps': 304.82952623229886}
[2025-01-29 16:51:04,824][absl][INFO] - {'eval/walltime': 109.07654523849487, 'training/sps': 48.36929226923529, 'training/walltime': 720.2967083454132, 'training/model_train_time': 12.10099458694458, 'training/other_time': 8.566024780273438, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(31000, dtype=int32), 'model/train_total_loss': Array(-22.578413, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.2941071, dtype=float32), 'model/test_total_loss': Array(-20.087101, dtype=float32), 'model/test_mean_loss': Array(1.5289742, dtype=float32), 'model/train_epochs': 10, 'model/sec_per_epoch': 0.9824001550674438, 'sac/actor_loss': Array(1736.3944, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-7.114242, dtype=float32), 'sac/buffer_current_size': Array(201198.22, dtype=float32), 'sac/critic_loss': Array(44237.51, dtype=float32), 'eval/episode_distance_from_origin': Array(9.843204, dtype=float32), 'eval/episode_forward_reward': Array(-12.8761635, dtype=float32), 'eval/episode_reward': Array(-47.83819, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-44.953777, dtype=float32), 'eval/episode_reward_forward': Array(-12.8761635, dtype=float32), 'eval/episode_reward_survive': Array(14., dtype=float32), 'eval/episode_x_position': Array(-1.2771323, dtype=float32), 'eval/episode_x_velocity': Array(-12.8761635, dtype=float32), 'eval/episode_y_position': Array(-1.2853146, dtype=float32), 'eval/episode_y_velocity': Array(-11.508696, dtype=float32), 'eval/avg_episode_length': Array(15., dtype=float32), 'eval/epoch_eval_time': 3.2952587604522705, 'eval/sps': 303.4663049838159}
[2025-01-29 16:51:46,081][absl][INFO] - {'eval/walltime': 112.35948276519775, 'training/sps': 26.362495602955136, 'training/walltime': 758.2293841838837, 'training/model_train_time': 10.105802536010742, 'training/other_time': 27.819827795028687, 'training/model_horizon': 2, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(32000, dtype=int32), 'model/train_total_loss': Array(-22.913565, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.2410418, dtype=float32), 'model/test_total_loss': Array(-20.773472, dtype=float32), 'model/test_mean_loss': Array(1.4334899, dtype=float32), 'model/train_epochs': 8, 'model/sec_per_epoch': 1.0089214444160461, 'sac/actor_loss': Array(987.22296, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-5.943366, dtype=float32), 'sac/buffer_current_size': Array(401398.8, dtype=float32), 'sac/critic_loss': Array(25476.523, dtype=float32), 'eval/episode_distance_from_origin': Array(24.439405, dtype=float32), 'eval/episode_forward_reward': Array(-8.772045, dtype=float32), 'eval/episode_reward': Array(-62.876514, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-79.09241, dtype=float32), 'eval/episode_reward_forward': Array(-8.772045, dtype=float32), 'eval/episode_reward_survive': Array(27., dtype=float32), 'eval/episode_x_position': Array(-9.780548, dtype=float32), 'eval/episode_x_velocity': Array(-8.772045, dtype=float32), 'eval/episode_y_position': Array(-1.416141, dtype=float32), 'eval/episode_y_velocity': Array(-21.551449, dtype=float32), 'eval/avg_episode_length': Array(28., dtype=float32), 'eval/epoch_eval_time': 3.282937526702881, 'eval/sps': 304.60524815539816}
[2025-01-29 16:52:10,128][absl][INFO] - {'eval/walltime': 115.6365339756012, 'training/sps': 48.16893230286393, 'training/walltime': 778.9896533489227, 'training/model_train_time': 11.480134725570679, 'training/other_time': 9.271507740020752, 'training/model_horizon': 2, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(33000, dtype=int32), 'model/train_total_loss': Array(-23.02836, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.3085886, dtype=float32), 'model/test_total_loss': Array(-20.64791, dtype=float32), 'model/test_mean_loss': Array(1.5233781, dtype=float32), 'model/train_epochs': 8, 'model/sec_per_epoch': 1.1195329129695892, 'sac/actor_loss': Array(412.89325, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-3.4148543, dtype=float32), 'sac/buffer_current_size': Array(401398.8, dtype=float32), 'sac/critic_loss': Array(4792.943, dtype=float32), 'eval/episode_distance_from_origin': Array(55.657616, dtype=float32), 'eval/episode_forward_reward': Array(-21.143848, dtype=float32), 'eval/episode_reward': Array(-102.32939, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-123.693436, dtype=float32), 'eval/episode_reward_forward': Array(-21.143848, dtype=float32), 'eval/episode_reward_survive': Array(45., dtype=float32), 'eval/episode_x_position': Array(-39.37164, dtype=float32), 'eval/episode_x_velocity': Array(-21.143848, dtype=float32), 'eval/episode_y_position': Array(-3.3934188, dtype=float32), 'eval/episode_y_velocity': Array(3.419982, dtype=float32), 'eval/avg_episode_length': Array(46., dtype=float32), 'eval/epoch_eval_time': 3.2770512104034424, 'eval/sps': 305.15238725149146}
[2025-01-29 16:52:33,681][absl][INFO] - {'eval/walltime': 118.9242012500763, 'training/sps': 49.37080853058675, 'training/walltime': 799.2445373535156, 'training/model_train_time': 10.972108602523804, 'training/other_time': 9.274041414260864, 'training/model_horizon': 2, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(34000, dtype=int32), 'model/train_total_loss': Array(-23.188213, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.2117289, dtype=float32), 'model/test_total_loss': Array(-20.491297, dtype=float32), 'model/test_mean_loss': Array(1.5288465, dtype=float32), 'model/train_epochs': 8, 'model/sec_per_epoch': 1.0812232196331024, 'sac/actor_loss': Array(206.56548, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-1.7803253, dtype=float32), 'sac/buffer_current_size': Array(401398.8, dtype=float32), 'sac/critic_loss': Array(1156.3416, dtype=float32), 'eval/episode_distance_from_origin': Array(4.068637, dtype=float32), 'eval/episode_forward_reward': Array(-5.8872156, dtype=float32), 'eval/episode_reward': Array(-21.2275, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-18.131626, dtype=float32), 'eval/episode_reward_forward': Array(-5.8872156, dtype=float32), 'eval/episode_reward_survive': Array(6., dtype=float32), 'eval/episode_x_position': Array(-0.13825037, dtype=float32), 'eval/episode_x_velocity': Array(-5.8872156, dtype=float32), 'eval/episode_y_position': Array(0.260553, dtype=float32), 'eval/episode_y_velocity': Array(-0.52257764, dtype=float32), 'eval/avg_episode_length': Array(7., dtype=float32), 'eval/epoch_eval_time': 3.2876672744750977, 'eval/sps': 304.1670328879792}
[2025-01-29 16:52:58,463][absl][INFO] - {'eval/walltime': 122.20947170257568, 'training/sps': 46.54004453384131, 'training/walltime': 820.7314097881317, 'training/model_train_time': 12.209853649139404, 'training/other_time': 9.267935276031494, 'training/model_horizon': 2, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(35000, dtype=int32), 'model/train_total_loss': Array(-21.743639, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.4712309, dtype=float32), 'model/test_total_loss': Array(-20.526234, dtype=float32), 'model/test_mean_loss': Array(1.5285933, dtype=float32), 'model/train_epochs': 9, 'model/sec_per_epoch': 1.0972852971818712, 'sac/actor_loss': Array(128.97401, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-0.8685244, dtype=float32), 'sac/buffer_current_size': Array(401398.8, dtype=float32), 'sac/critic_loss': Array(427.33054, dtype=float32), 'eval/episode_distance_from_origin': Array(8.717533, dtype=float32), 'eval/episode_forward_reward': Array(-4.371718, dtype=float32), 'eval/episode_reward': Array(-26.990412, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-30.546906, dtype=float32), 'eval/episode_reward_forward': Array(-4.371718, dtype=float32), 'eval/episode_reward_survive': Array(12., dtype=float32), 'eval/episode_x_position': Array(-1.0266154, dtype=float32), 'eval/episode_x_velocity': Array(-4.371718, dtype=float32), 'eval/episode_y_position': Array(-4.246406, dtype=float32), 'eval/episode_y_velocity': Array(-12.082933, dtype=float32), 'eval/avg_episode_length': Array(13., dtype=float32), 'eval/epoch_eval_time': 3.2852704524993896, 'eval/sps': 304.3889428461555}
[2025-01-29 16:53:25,733][absl][INFO] - {'eval/walltime': 125.49307918548584, 'training/sps': 41.709067563324744, 'training/walltime': 844.7070116996765, 'training/model_train_time': 14.694733619689941, 'training/other_time': 9.272357940673828, 'training/model_horizon': 2, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(36000, dtype=int32), 'model/train_total_loss': Array(-23.226315, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.2647222, dtype=float32), 'model/test_total_loss': Array(-20.413736, dtype=float32), 'model/test_mean_loss': Array(1.5287054, dtype=float32), 'model/train_epochs': 12, 'model/sec_per_epoch': 1.0503642161687214, 'sac/actor_loss': Array(101.02241, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(-0.42812172, dtype=float32), 'sac/buffer_current_size': Array(401398.8, dtype=float32), 'sac/critic_loss': Array(243.39879, dtype=float32), 'eval/episode_distance_from_origin': Array(15.732128, dtype=float32), 'eval/episode_forward_reward': Array(-22.359682, dtype=float32), 'eval/episode_reward': Array(-52.218945, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-41.46091, dtype=float32), 'eval/episode_reward_forward': Array(-22.359682, dtype=float32), 'eval/episode_reward_survive': Array(16., dtype=float32), 'eval/episode_x_position': Array(-6.71538, dtype=float32), 'eval/episode_x_velocity': Array(-22.359682, dtype=float32), 'eval/episode_y_position': Array(5.807416, dtype=float32), 'eval/episode_y_velocity': Array(8.269146, dtype=float32), 'eval/avg_episode_length': Array(17., dtype=float32), 'eval/epoch_eval_time': 3.2836074829101562, 'eval/sps': 304.5430993821868}
[2025-01-29 16:53:50,284][absl][INFO] - {'eval/walltime': 128.77940154075623, 'training/sps': 47.04732416986532, 'training/walltime': 865.9622056484222, 'training/model_train_time': 11.961548089981079, 'training/other_time': 9.285221815109253, 'training/model_horizon': 2, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(37000, dtype=int32), 'model/train_total_loss': Array(-23.42977, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.2557354, dtype=float32), 'model/test_total_loss': Array(-21.284101, dtype=float32), 'model/test_mean_loss': Array(1.457351, dtype=float32), 'model/train_epochs': 9, 'model/sec_per_epoch': 1.0845377975040011, 'sac/actor_loss': Array(72.45024, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(0.09428748, dtype=float32), 'sac/buffer_current_size': Array(401398.8, dtype=float32), 'sac/critic_loss': Array(115.09597, dtype=float32), 'eval/episode_distance_from_origin': Array(11.771346, dtype=float32), 'eval/episode_forward_reward': Array(-2.2318988, dtype=float32), 'eval/episode_reward': Array(-20.618452, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-29.674095, dtype=float32), 'eval/episode_reward_forward': Array(-2.2318988, dtype=float32), 'eval/episode_reward_survive': Array(15., dtype=float32), 'eval/episode_x_position': Array(1.129786, dtype=float32), 'eval/episode_x_velocity': Array(-2.2318988, dtype=float32), 'eval/episode_y_position': Array(-2.7984786, dtype=float32), 'eval/episode_y_velocity': Array(-0.46756727, dtype=float32), 'eval/avg_episode_length': Array(16., dtype=float32), 'eval/epoch_eval_time': 3.2863223552703857, 'eval/sps': 304.2915124854585}
[2025-01-29 16:54:16,299][absl][INFO] - {'eval/walltime': 132.06468796730042, 'training/sps': 44.01620409310954, 'training/walltime': 888.681111574173, 'training/model_train_time': 13.430138111114502, 'training/other_time': 9.279455661773682, 'training/model_horizon': 2, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(38000, dtype=int32), 'model/train_total_loss': Array(-23.37672, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.3419341, dtype=float32), 'model/test_total_loss': Array(-20.812786, dtype=float32), 'model/test_mean_loss': Array(1.5102766, dtype=float32), 'model/train_epochs': 10, 'model/sec_per_epoch': 1.1201212882995606, 'sac/actor_loss': Array(55.73665, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(0.30141407, dtype=float32), 'sac/buffer_current_size': Array(401398.8, dtype=float32), 'sac/critic_loss': Array(75.4215, dtype=float32), 'eval/episode_distance_from_origin': Array(4.0385604, dtype=float32), 'eval/episode_forward_reward': Array(-1.4263937, dtype=float32), 'eval/episode_reward': Array(-12.129648, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-14.138342, dtype=float32), 'eval/episode_reward_forward': Array(-1.4263937, dtype=float32), 'eval/episode_reward_survive': Array(5., dtype=float32), 'eval/episode_x_position': Array(0.00503931, dtype=float32), 'eval/episode_x_velocity': Array(-1.4263937, dtype=float32), 'eval/episode_y_position': Array(0.6859556, dtype=float32), 'eval/episode_y_velocity': Array(4.19442, dtype=float32), 'eval/avg_episode_length': Array(6., dtype=float32), 'eval/epoch_eval_time': 3.2852864265441895, 'eval/sps': 304.38746281611293}
[2025-01-29 16:54:41,927][absl][INFO] - {'eval/walltime': 135.34231328964233, 'training/sps': 44.76237299623925, 'training/walltime': 911.0213034152985, 'training/model_train_time': 13.060631036758423, 'training/other_time': 9.270779848098755, 'training/model_horizon': 2, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(39000, dtype=int32), 'model/train_total_loss': Array(-24.197659, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.1005273, dtype=float32), 'model/test_total_loss': Array(-20.965237, dtype=float32), 'model/test_mean_loss': Array(1.4666246, dtype=float32), 'model/train_epochs': 9, 'model/sec_per_epoch': 1.186802281273736, 'sac/actor_loss': Array(44.239372, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(0.58679783, dtype=float32), 'sac/buffer_current_size': Array(401398.8, dtype=float32), 'sac/critic_loss': Array(50.887882, dtype=float32), 'eval/episode_distance_from_origin': Array(3.1312256, dtype=float32), 'eval/episode_forward_reward': Array(0.7967359, dtype=float32), 'eval/episode_reward': Array(-5.3653736, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-8.463304, dtype=float32), 'eval/episode_reward_forward': Array(0.7967359, dtype=float32), 'eval/episode_reward_survive': Array(4., dtype=float32), 'eval/episode_x_position': Array(-0.02592516, dtype=float32), 'eval/episode_x_velocity': Array(0.7967359, dtype=float32), 'eval/episode_y_position': Array(-0.20724155, dtype=float32), 'eval/episode_y_velocity': Array(-1.667074, dtype=float32), 'eval/avg_episode_length': Array(5., dtype=float32), 'eval/epoch_eval_time': 3.277625322341919, 'eval/sps': 305.0989364719342}
[2025-01-29 16:55:09,634][absl][INFO] - {'eval/walltime': 138.6294503211975, 'training/sps': 40.96713244176926, 'training/walltime': 935.4311153888702, 'training/model_train_time': 15.145468950271606, 'training/other_time': 9.255237102508545, 'training/model_horizon': 2, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(40000, dtype=int32), 'model/train_total_loss': Array(-22.289734, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.3855251, dtype=float32), 'model/test_total_loss': Array(-20.588533, dtype=float32), 'model/test_mean_loss': Array(1.4767269, dtype=float32), 'model/train_epochs': 11, 'model/sec_per_epoch': 1.1626885370774702, 'sac/actor_loss': Array(31.176193, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(0.93657535, dtype=float32), 'sac/buffer_current_size': Array(401398.8, dtype=float32), 'sac/critic_loss': Array(30.275677, dtype=float32), 'eval/episode_distance_from_origin': Array(30.738909, dtype=float32), 'eval/episode_forward_reward': Array(19.360462, dtype=float32), 'eval/episode_reward': Array(-0.5609262, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-52.451523, dtype=float32), 'eval/episode_reward_forward': Array(19.360462, dtype=float32), 'eval/episode_reward_survive': Array(33., dtype=float32), 'eval/episode_x_position': Array(10.751708, dtype=float32), 'eval/episode_x_velocity': Array(19.360462, dtype=float32), 'eval/episode_y_position': Array(-13.51685, dtype=float32), 'eval/episode_y_velocity': Array(-10.983906, dtype=float32), 'eval/avg_episode_length': Array(34., dtype=float32), 'eval/epoch_eval_time': 3.287137031555176, 'eval/sps': 304.2160975950828}
[2025-01-29 16:55:52,034][absl][INFO] - {'eval/walltime': 141.89979815483093, 'training/sps': 25.582604484754437, 'training/walltime': 974.5201768875122, 'training/model_train_time': 12.83526611328125, 'training/other_time': 26.244460821151733, 'training/model_horizon': 3, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(41000, dtype=int32), 'model/train_total_loss': Array(-24.797012, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.1299183, dtype=float32), 'model/test_total_loss': Array(-21.671925, dtype=float32), 'model/test_mean_loss': Array(1.4172845, dtype=float32), 'model/train_epochs': 9, 'model/sec_per_epoch': 1.202122449874878, 'sac/actor_loss': Array(19.982056, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.246456, dtype=float32), 'sac/buffer_current_size': Array(601599., dtype=float32), 'sac/critic_loss': Array(21.197561, dtype=float32), 'eval/episode_distance_from_origin': Array(10.615776, dtype=float32), 'eval/episode_forward_reward': Array(1.8885583, dtype=float32), 'eval/episode_reward': Array(-5.888341, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-21.537516, dtype=float32), 'eval/episode_reward_forward': Array(1.8885583, dtype=float32), 'eval/episode_reward_survive': Array(15., dtype=float32), 'eval/episode_x_position': Array(1.992528, dtype=float32), 'eval/episode_x_velocity': Array(1.8885583, dtype=float32), 'eval/episode_y_position': Array(3.179192, dtype=float32), 'eval/episode_y_velocity': Array(7.72533, dtype=float32), 'eval/avg_episode_length': Array(16., dtype=float32), 'eval/epoch_eval_time': 3.270347833633423, 'eval/sps': 305.77787161220084}
[2025-01-29 16:56:17,793][absl][INFO] - {'eval/walltime': 145.17680382728577, 'training/sps': 44.50056536766935, 'training/walltime': 996.9918015003204, 'training/model_train_time': 12.484788179397583, 'training/other_time': 9.976248979568481, 'training/model_horizon': 3, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(42000, dtype=int32), 'model/train_total_loss': Array(-23.713503, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.1736834, dtype=float32), 'model/test_total_loss': Array(-22.103619, dtype=float32), 'model/test_mean_loss': Array(1.3333681, dtype=float32), 'model/train_epochs': 8, 'model/sec_per_epoch': 1.2907492518424988, 'sac/actor_loss': Array(11.655908, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.4417737, dtype=float32), 'sac/buffer_current_size': Array(601599., dtype=float32), 'sac/critic_loss': Array(13.922128, dtype=float32), 'eval/episode_distance_from_origin': Array(65.76485, dtype=float32), 'eval/episode_forward_reward': Array(26.779907, dtype=float32), 'eval/episode_reward': Array(17.881674, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-59.49176, dtype=float32), 'eval/episode_reward_forward': Array(26.779907, dtype=float32), 'eval/episode_reward_survive': Array(51., dtype=float32), 'eval/episode_x_position': Array(29.101416, dtype=float32), 'eval/episode_x_velocity': Array(26.779907, dtype=float32), 'eval/episode_y_position': Array(36.80913, dtype=float32), 'eval/episode_y_velocity': Array(32.94295, dtype=float32), 'eval/avg_episode_length': Array(52., dtype=float32), 'eval/epoch_eval_time': 3.277005672454834, 'eval/sps': 305.15662771217944}
[2025-01-29 16:56:48,246][absl][INFO] - {'eval/walltime': 148.47045516967773, 'training/sps': 36.83342059926336, 'training/walltime': 1024.1410584449768, 'training/model_train_time': 17.180332899093628, 'training/other_time': 9.95868706703186, 'training/model_horizon': 3, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(43000, dtype=int32), 'model/train_total_loss': Array(-24.389612, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.0999956, dtype=float32), 'model/test_total_loss': Array(-21.428694, dtype=float32), 'model/test_mean_loss': Array(1.4162805, dtype=float32), 'model/train_epochs': 12, 'model/sec_per_epoch': 1.2311004002888997, 'sac/actor_loss': Array(5.896205, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.4602381, dtype=float32), 'sac/buffer_current_size': Array(601599., dtype=float32), 'sac/critic_loss': Array(12.196053, dtype=float32), 'eval/episode_distance_from_origin': Array(103.710205, dtype=float32), 'eval/episode_forward_reward': Array(51.0945, dtype=float32), 'eval/episode_reward': Array(56.40681, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-78.50325, dtype=float32), 'eval/episode_reward_forward': Array(51.0945, dtype=float32), 'eval/episode_reward_survive': Array(83., dtype=float32), 'eval/episode_x_position': Array(74.34538, dtype=float32), 'eval/episode_x_velocity': Array(51.0945, dtype=float32), 'eval/episode_y_position': Array(-16.49536, dtype=float32), 'eval/episode_y_velocity': Array(-3.886624, dtype=float32), 'eval/avg_episode_length': Array(84., dtype=float32), 'eval/epoch_eval_time': 3.2936513423919678, 'eval/sps': 303.61440724741806}
[2025-01-29 16:57:16,518][absl][INFO] - {'eval/walltime': 151.76191902160645, 'training/sps': 40.04916504641151, 'training/walltime': 1049.110368013382, 'training/model_train_time': 14.988624095916748, 'training/other_time': 9.970012664794922, 'training/model_horizon': 3, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(44000, dtype=int32), 'model/train_total_loss': Array(-24.60816, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.0700237, dtype=float32), 'model/test_total_loss': Array(-21.656572, dtype=float32), 'model/test_mean_loss': Array(1.3863815, dtype=float32), 'model/train_epochs': 9, 'model/sec_per_epoch': 1.3700623247358534, 'sac/actor_loss': Array(0.7588774, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.3945307, dtype=float32), 'sac/buffer_current_size': Array(601599., dtype=float32), 'sac/critic_loss': Array(11.079837, dtype=float32), 'eval/episode_distance_from_origin': Array(5.8514314, dtype=float32), 'eval/episode_forward_reward': Array(4.7271624, dtype=float32), 'eval/episode_reward': Array(5.176335, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-9.916438, dtype=float32), 'eval/episode_reward_forward': Array(4.7271624, dtype=float32), 'eval/episode_reward_survive': Array(10., dtype=float32), 'eval/episode_x_position': Array(1.5635455, dtype=float32), 'eval/episode_x_velocity': Array(4.7271624, dtype=float32), 'eval/episode_y_position': Array(-0.27523363, dtype=float32), 'eval/episode_y_velocity': Array(2.1156259, dtype=float32), 'eval/avg_episode_length': Array(11., dtype=float32), 'eval/epoch_eval_time': 3.291463851928711, 'eval/sps': 303.8161878685152}
[2025-01-29 16:57:47,684][absl][INFO] - {'eval/walltime': 155.0565755367279, 'training/sps': 35.890650636899494, 'training/walltime': 1076.9727773666382, 'training/model_train_time': 17.880243062973022, 'training/other_time': 9.971814155578613, 'training/model_horizon': 3, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(45000, dtype=int32), 'model/train_total_loss': Array(-24.726088, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.0514091, dtype=float32), 'model/test_total_loss': Array(-22.21372, dtype=float32), 'model/test_mean_loss': Array(1.3349329, dtype=float32), 'model/train_epochs': 12, 'model/sec_per_epoch': 1.2790419459342957, 'sac/actor_loss': Array(-0.646759, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.3632346, dtype=float32), 'sac/buffer_current_size': Array(601599., dtype=float32), 'sac/critic_loss': Array(11.697111, dtype=float32), 'eval/episode_distance_from_origin': Array(39.924862, dtype=float32), 'eval/episode_forward_reward': Array(23.211065, dtype=float32), 'eval/episode_reward': Array(23.76832, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-40.869144, dtype=float32), 'eval/episode_reward_forward': Array(23.211065, dtype=float32), 'eval/episode_reward_survive': Array(41., dtype=float32), 'eval/episode_x_position': Array(25.238735, dtype=float32), 'eval/episode_x_velocity': Array(23.211065, dtype=float32), 'eval/episode_y_position': Array(0.19367255, dtype=float32), 'eval/episode_y_velocity': Array(1.7368002, dtype=float32), 'eval/avg_episode_length': Array(42., dtype=float32), 'eval/epoch_eval_time': 3.29465651512146, 'eval/sps': 303.5217769774505}
[2025-01-29 16:58:17,645][absl][INFO] - {'eval/walltime': 158.33748364448547, 'training/sps': 37.49464495220767, 'training/walltime': 1103.6432526111603, 'training/model_train_time': 16.69323754310608, 'training/other_time': 9.966736793518066, 'training/model_horizon': 3, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(46000, dtype=int32), 'model/train_total_loss': Array(-25.389135, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.0111799, dtype=float32), 'model/test_total_loss': Array(-21.86876, dtype=float32), 'model/test_mean_loss': Array(1.316632, dtype=float32), 'model/train_epochs': 11, 'model/sec_per_epoch': 1.3113788474689831, 'sac/actor_loss': Array(-2.051798, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.3234451, dtype=float32), 'sac/buffer_current_size': Array(601599., dtype=float32), 'sac/critic_loss': Array(11.864953, dtype=float32), 'eval/episode_distance_from_origin': Array(70.19056, dtype=float32), 'eval/episode_forward_reward': Array(24.040384, dtype=float32), 'eval/episode_reward': Array(38.812443, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-58.33032, dtype=float32), 'eval/episode_reward_forward': Array(24.040384, dtype=float32), 'eval/episode_reward_survive': Array(74., dtype=float32), 'eval/episode_x_position': Array(41.772297, dtype=float32), 'eval/episode_x_velocity': Array(24.040384, dtype=float32), 'eval/episode_y_position': Array(-30.538176, dtype=float32), 'eval/episode_y_velocity': Array(-11.1941395, dtype=float32), 'eval/avg_episode_length': Array(75., dtype=float32), 'eval/epoch_eval_time': 3.2809081077575684, 'eval/sps': 304.79366296042923}
[2025-01-29 16:58:44,979][absl][INFO] - {'eval/walltime': 161.62980103492737, 'training/sps': 41.61128116144323, 'training/walltime': 1127.6751971244812, 'training/model_train_time': 14.058405876159668, 'training/other_time': 9.963257789611816, 'training/model_horizon': 3, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(47000, dtype=int32), 'model/train_total_loss': Array(-25.161234, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.0756179, dtype=float32), 'model/test_total_loss': Array(-22.861061, dtype=float32), 'model/test_mean_loss': Array(1.25456, dtype=float32), 'model/train_epochs': 9, 'model/sec_per_epoch': 1.3290229108598497, 'sac/actor_loss': Array(-3.367294, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.2953998, dtype=float32), 'sac/buffer_current_size': Array(601599., dtype=float32), 'sac/critic_loss': Array(12.725415, dtype=float32), 'eval/episode_distance_from_origin': Array(199.821, dtype=float32), 'eval/episode_forward_reward': Array(34.768284, dtype=float32), 'eval/episode_reward': Array(54.342117, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-95.91103, dtype=float32), 'eval/episode_reward_forward': Array(34.768284, dtype=float32), 'eval/episode_reward_survive': Array(116., dtype=float32), 'eval/episode_x_position': Array(103.44092, dtype=float32), 'eval/episode_x_velocity': Array(34.768284, dtype=float32), 'eval/episode_y_position': Array(-146.01224, dtype=float32), 'eval/episode_y_velocity': Array(-53.266712, dtype=float32), 'eval/avg_episode_length': Array(117., dtype=float32), 'eval/epoch_eval_time': 3.2923173904418945, 'eval/sps': 303.73742303921074}
[2025-01-29 16:59:16,910][absl][INFO] - {'eval/walltime': 164.90905237197876, 'training/sps': 34.91320651562736, 'training/walltime': 1156.3176536560059, 'training/model_train_time': 18.675980806350708, 'training/other_time': 9.955122470855713, 'training/model_horizon': 3, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(48000, dtype=int32), 'model/train_total_loss': Array(-25.781504, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.9988175, dtype=float32), 'model/test_total_loss': Array(-23.574543, dtype=float32), 'model/test_mean_loss': Array(1.2126671, dtype=float32), 'model/train_epochs': 12, 'model/sec_per_epoch': 1.3523132999738057, 'sac/actor_loss': Array(-4.7479653, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.266751, dtype=float32), 'sac/buffer_current_size': Array(601599., dtype=float32), 'sac/critic_loss': Array(13.34444, dtype=float32), 'eval/episode_distance_from_origin': Array(1075.5321, dtype=float32), 'eval/episode_forward_reward': Array(99.40405, dtype=float32), 'eval/episode_reward': Array(113.27986, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-300.32907, dtype=float32), 'eval/episode_reward_forward': Array(99.40405, dtype=float32), 'eval/episode_reward_survive': Array(314., dtype=float32), 'eval/episode_x_position': Array(892.14026, dtype=float32), 'eval/episode_x_velocity': Array(99.40405, dtype=float32), 'eval/episode_y_position': Array(-396.90958, dtype=float32), 'eval/episode_y_velocity': Array(1.4338329, dtype=float32), 'eval/avg_episode_length': Array(315., dtype=float32), 'eval/epoch_eval_time': 3.2792513370513916, 'eval/sps': 304.94765335650396}
[2025-01-29 16:59:47,989][absl][INFO] - {'eval/walltime': 168.1953582763672, 'training/sps': 35.994478706423706, 'training/walltime': 1184.0996923446655, 'training/model_train_time': 17.81067991256714, 'training/other_time': 9.960902690887451, 'training/model_horizon': 3, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(49000, dtype=int32), 'model/train_total_loss': Array(-25.604002, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.0602915, dtype=float32), 'model/test_total_loss': Array(-23.522362, dtype=float32), 'model/test_mean_loss': Array(1.2136921, dtype=float32), 'model/train_epochs': 11, 'model/sec_per_epoch': 1.3956576260653408, 'sac/actor_loss': Array(-6.27379, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.2510219, dtype=float32), 'sac/buffer_current_size': Array(601599., dtype=float32), 'sac/critic_loss': Array(13.330218, dtype=float32), 'eval/episode_distance_from_origin': Array(7.3138504, dtype=float32), 'eval/episode_forward_reward': Array(0.89935815, dtype=float32), 'eval/episode_reward': Array(-0.15087646, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-13.20832, dtype=float32), 'eval/episode_reward_forward': Array(0.89935815, dtype=float32), 'eval/episode_reward_survive': Array(12., dtype=float32), 'eval/episode_x_position': Array(-0.715028, dtype=float32), 'eval/episode_x_velocity': Array(0.89935815, dtype=float32), 'eval/episode_y_position': Array(-0.10335898, dtype=float32), 'eval/episode_y_velocity': Array(-1.2446016, dtype=float32), 'eval/avg_episode_length': Array(13., dtype=float32), 'eval/epoch_eval_time': 3.2863059043884277, 'eval/sps': 304.2930357349363}
[2025-01-29 17:00:37,121][absl][INFO] - {'eval/walltime': 171.47943592071533, 'training/sps': 21.831241607988527, 'training/walltime': 1229.9056074619293, 'training/model_train_time': 16.428722381591797, 'training/other_time': 29.366607189178467, 'training/model_horizon': 4, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(50000, dtype=int32), 'model/train_total_loss': Array(-25.693094, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.021509, dtype=float32), 'model/test_total_loss': Array(-23.58481, dtype=float32), 'model/test_mean_loss': Array(1.2149873, dtype=float32), 'model/train_epochs': 10, 'model/sec_per_epoch': 1.4116641759872437, 'sac/actor_loss': Array(-8.4492855, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.2536443, dtype=float32), 'sac/buffer_current_size': Array(801799.06, dtype=float32), 'sac/critic_loss': Array(14.789486, dtype=float32), 'eval/episode_distance_from_origin': Array(619.7584, dtype=float32), 'eval/episode_forward_reward': Array(13.003908, dtype=float32), 'eval/episode_reward': Array(20.194828, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-178.67294, dtype=float32), 'eval/episode_reward_forward': Array(13.003908, dtype=float32), 'eval/episode_reward_survive': Array(182., dtype=float32), 'eval/episode_x_position': Array(233.8595, dtype=float32), 'eval/episode_x_velocity': Array(13.003908, dtype=float32), 'eval/episode_y_position': Array(-520.9349, dtype=float32), 'eval/episode_y_velocity': Array(-140.21901, dtype=float32), 'eval/avg_episode_length': Array(183., dtype=float32), 'eval/epoch_eval_time': 3.2840776443481445, 'eval/sps': 304.49949979745065}
[2025-01-29 17:01:06,816][absl][INFO] - {'eval/walltime': 174.76376867294312, 'training/sps': 37.8789950457432, 'training/walltime': 1256.3054630756378, 'training/model_train_time': 15.723246097564697, 'training/other_time': 10.664389848709106, 'training/model_horizon': 4, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(51000, dtype=int32), 'model/train_total_loss': Array(-27.375109, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.8841833, dtype=float32), 'model/test_total_loss': Array(-24.142733, dtype=float32), 'model/test_mean_loss': Array(1.1661181, dtype=float32), 'model/train_epochs': 9, 'model/sec_per_epoch': 1.4820300738016765, 'sac/actor_loss': Array(-9.4723835, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.2169353, dtype=float32), 'sac/buffer_current_size': Array(801799.06, dtype=float32), 'sac/critic_loss': Array(16.211452, dtype=float32), 'eval/episode_distance_from_origin': Array(7.1243925, dtype=float32), 'eval/episode_forward_reward': Array(-0.55550957, dtype=float32), 'eval/episode_reward': Array(-3.0147965, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-12.414078, dtype=float32), 'eval/episode_reward_forward': Array(-0.55550957, dtype=float32), 'eval/episode_reward_survive': Array(10., dtype=float32), 'eval/episode_x_position': Array(-0.7248948, dtype=float32), 'eval/episode_x_velocity': Array(-0.55550957, dtype=float32), 'eval/episode_y_position': Array(1.7511597, dtype=float32), 'eval/episode_y_velocity': Array(4.490697, dtype=float32), 'eval/avg_episode_length': Array(11., dtype=float32), 'eval/epoch_eval_time': 3.284332752227783, 'eval/sps': 304.4758480460586}
[2025-01-29 17:01:34,810][absl][INFO] - {'eval/walltime': 178.05088686943054, 'training/sps': 40.492454115812244, 'training/walltime': 1281.001422405243, 'training/model_train_time': 14.03319525718689, 'training/other_time': 10.650647640228271, 'training/model_horizon': 4, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(52000, dtype=int32), 'model/train_total_loss': Array(-25.635921, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(1.0642756, dtype=float32), 'model/test_total_loss': Array(-24.60166, dtype=float32), 'model/test_mean_loss': Array(1.1305441, dtype=float32), 'model/train_epochs': 8, 'model/sec_per_epoch': 1.483540117740631, 'sac/actor_loss': Array(-12.405878, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.1511828, dtype=float32), 'sac/buffer_current_size': Array(801799.06, dtype=float32), 'sac/critic_loss': Array(17.601948, dtype=float32), 'eval/episode_distance_from_origin': Array(4633.9, dtype=float32), 'eval/episode_forward_reward': Array(189.47363, dtype=float32), 'eval/episode_reward': Array(232.56992, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-440.42178, dtype=float32), 'eval/episode_reward_forward': Array(189.47363, dtype=float32), 'eval/episode_reward_survive': Array(484., dtype=float32), 'eval/episode_x_position': Array(1966.1405, dtype=float32), 'eval/episode_x_velocity': Array(189.47363, dtype=float32), 'eval/episode_y_position': Array(-4158.4575, dtype=float32), 'eval/episode_y_velocity': Array(-316.16077, dtype=float32), 'eval/avg_episode_length': Array(485., dtype=float32), 'eval/epoch_eval_time': 3.2871181964874268, 'eval/sps': 304.21784074226093}
[2025-01-29 17:02:04,863][absl][INFO] - {'eval/walltime': 181.33859825134277, 'training/sps': 37.37577154789637, 'training/walltime': 1307.7567229270935, 'training/model_train_time': 16.087090730667114, 'training/other_time': 10.65561580657959, 'training/model_horizon': 4, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(53000, dtype=int32), 'model/train_total_loss': Array(-27.608147, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.8896595, dtype=float32), 'model/test_total_loss': Array(-24.86838, dtype=float32), 'model/test_mean_loss': Array(1.1336247, dtype=float32), 'model/train_epochs': 9, 'model/sec_per_epoch': 1.5300317605336506, 'sac/actor_loss': Array(-10.996413, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.1538064, dtype=float32), 'sac/buffer_current_size': Array(801799.06, dtype=float32), 'sac/critic_loss': Array(20.519968, dtype=float32), 'eval/episode_distance_from_origin': Array(281.15546, dtype=float32), 'eval/episode_forward_reward': Array(40.998245, dtype=float32), 'eval/episode_reward': Array(43.103558, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-141.53679, dtype=float32), 'eval/episode_reward_forward': Array(40.998245, dtype=float32), 'eval/episode_reward_survive': Array(144., dtype=float32), 'eval/episode_x_position': Array(239.27054, dtype=float32), 'eval/episode_x_velocity': Array(40.998245, dtype=float32), 'eval/episode_y_position': Array(-19.182756, dtype=float32), 'eval/episode_y_velocity': Array(35.193512, dtype=float32), 'eval/avg_episode_length': Array(145., dtype=float32), 'eval/epoch_eval_time': 3.2877113819122314, 'eval/sps': 304.16295222920996}
[2025-01-29 17:02:38,809][absl][INFO] - {'eval/walltime': 184.62340450286865, 'training/sps': 32.624675721471114, 'training/walltime': 1338.408368587494, 'training/model_train_time': 19.98490309715271, 'training/other_time': 10.654537916183472, 'training/model_horizon': 4, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(54000, dtype=int32), 'model/train_total_loss': Array(-27.26302, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.924122, dtype=float32), 'model/test_total_loss': Array(-24.405338, dtype=float32), 'model/test_mean_loss': Array(1.1637844, dtype=float32), 'model/train_epochs': 12, 'model/sec_per_epoch': 1.4716932773590088, 'sac/actor_loss': Array(-11.932056, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.1454334, dtype=float32), 'sac/buffer_current_size': Array(801799.06, dtype=float32), 'sac/critic_loss': Array(18.447088, dtype=float32), 'eval/episode_distance_from_origin': Array(1501.9081, dtype=float32), 'eval/episode_forward_reward': Array(196.88284, dtype=float32), 'eval/episode_reward': Array(203.50378, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-327.19495, dtype=float32), 'eval/episode_reward_forward': Array(196.88284, dtype=float32), 'eval/episode_reward_survive': Array(334., dtype=float32), 'eval/episode_x_position': Array(1389.5181, dtype=float32), 'eval/episode_x_velocity': Array(196.88284, dtype=float32), 'eval/episode_y_position': Array(-477.74802, dtype=float32), 'eval/episode_y_velocity': Array(-86.27895, dtype=float32), 'eval/avg_episode_length': Array(335., dtype=float32), 'eval/epoch_eval_time': 3.284806251525879, 'eval/sps': 304.4319583645074}
[2025-01-29 17:03:12,020][absl][INFO] - {'eval/walltime': 187.90549540519714, 'training/sps': 33.423393580065735, 'training/walltime': 1368.3275327682495, 'training/model_train_time': 19.25937032699585, 'training/other_time': 10.647529602050781, 'training/model_horizon': 4, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(55000, dtype=int32), 'model/train_total_loss': Array(-27.056728, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.9083935, dtype=float32), 'model/test_total_loss': Array(-24.964779, dtype=float32), 'model/test_mean_loss': Array(1.1227802, dtype=float32), 'model/train_epochs': 11, 'model/sec_per_epoch': 1.5299706675789573, 'sac/actor_loss': Array(-14.446977, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.0993011, dtype=float32), 'sac/buffer_current_size': Array(801799.06, dtype=float32), 'sac/critic_loss': Array(20.042303, dtype=float32), 'eval/episode_distance_from_origin': Array(700.7542, dtype=float32), 'eval/episode_forward_reward': Array(140.81125, dtype=float32), 'eval/episode_reward': Array(155.3183, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-194.566, dtype=float32), 'eval/episode_reward_forward': Array(140.81125, dtype=float32), 'eval/episode_reward_survive': Array(208., dtype=float32), 'eval/episode_x_position': Array(644.13104, dtype=float32), 'eval/episode_x_velocity': Array(140.81125, dtype=float32), 'eval/episode_y_position': Array(-224.50787, dtype=float32), 'eval/episode_y_velocity': Array(-45.906105, dtype=float32), 'eval/avg_episode_length': Array(209., dtype=float32), 'eval/epoch_eval_time': 3.282090902328491, 'eval/sps': 304.68382191685987}
[2025-01-29 17:03:45,261][absl][INFO] - {'eval/walltime': 191.20454263687134, 'training/sps': 33.40861701743464, 'training/walltime': 1398.2599301338196, 'training/model_train_time': 19.251688241958618, 'training/other_time': 10.668731212615967, 'training/model_horizon': 4, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(56000, dtype=int32), 'model/train_total_loss': Array(-26.349567, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.96803916, dtype=float32), 'model/test_total_loss': Array(-24.851257, dtype=float32), 'model/test_mean_loss': Array(1.1015267, dtype=float32), 'model/train_epochs': 11, 'model/sec_per_epoch': 1.5440179651433772, 'sac/actor_loss': Array(-15.485567, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.0665696, dtype=float32), 'sac/buffer_current_size': Array(801799.06, dtype=float32), 'sac/critic_loss': Array(21.004969, dtype=float32), 'eval/episode_distance_from_origin': Array(1961.5695, dtype=float32), 'eval/episode_forward_reward': Array(264.19885, dtype=float32), 'eval/episode_reward': Array(302.78384, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-220.11566, dtype=float32), 'eval/episode_reward_forward': Array(264.19885, dtype=float32), 'eval/episode_reward_survive': Array(257., dtype=float32), 'eval/episode_x_position': Array(1836.9253, dtype=float32), 'eval/episode_x_velocity': Array(264.19885, dtype=float32), 'eval/episode_y_position': Array(-631.8295, dtype=float32), 'eval/episode_y_velocity': Array(-143.7363, dtype=float32), 'eval/avg_episode_length': Array(258., dtype=float32), 'eval/epoch_eval_time': 3.2990472316741943, 'eval/sps': 303.1178185019564}
[2025-01-29 17:04:16,887][absl][INFO] - {'eval/walltime': 194.48860430717468, 'training/sps': 35.29400459246567, 'training/walltime': 1426.5933542251587, 'training/model_train_time': 17.657975435256958, 'training/other_time': 10.66319227218628, 'training/model_horizon': 4, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(57000, dtype=int32), 'model/train_total_loss': Array(-26.957, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.89816386, dtype=float32), 'model/test_total_loss': Array(-25.04605, dtype=float32), 'model/test_mean_loss': Array(1.1251142, dtype=float32), 'model/train_epochs': 10, 'model/sec_per_epoch': 1.5534077405929565, 'sac/actor_loss': Array(-17.480453, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(1.0286889, dtype=float32), 'sac/buffer_current_size': Array(801799.06, dtype=float32), 'sac/critic_loss': Array(23.136694, dtype=float32), 'eval/episode_distance_from_origin': Array(107.08521, dtype=float32), 'eval/episode_forward_reward': Array(56.173054, dtype=float32), 'eval/episode_reward': Array(58.558666, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-66.21546, dtype=float32), 'eval/episode_reward_forward': Array(56.173054, dtype=float32), 'eval/episode_reward_survive': Array(68., dtype=float32), 'eval/episode_x_position': Array(89.47974, dtype=float32), 'eval/episode_x_velocity': Array(56.173054, dtype=float32), 'eval/episode_y_position': Array(17.660402, dtype=float32), 'eval/episode_y_velocity': Array(-2.2680743, dtype=float32), 'eval/avg_episode_length': Array(69., dtype=float32), 'eval/epoch_eval_time': 3.2840616703033447, 'eval/sps': 304.5009809172162}
[2025-01-29 17:04:49,152][absl][INFO] - {'eval/walltime': 197.78241324424744, 'training/sps': 34.52910436521538, 'training/walltime': 1455.554429769516, 'training/model_train_time': 18.264551639556885, 'training/other_time': 10.684226274490356, 'training/model_horizon': 4, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(58000, dtype=int32), 'model/train_total_loss': Array(-26.390764, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.8893393, dtype=float32), 'model/test_total_loss': Array(-24.277529, dtype=float32), 'model/test_mean_loss': Array(1.1413444, dtype=float32), 'model/train_epochs': 10, 'model/sec_per_epoch': 1.6061277389526367, 'sac/actor_loss': Array(-22.58987, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(0.9900984, dtype=float32), 'sac/buffer_current_size': Array(801799.06, dtype=float32), 'sac/critic_loss': Array(24.14322, dtype=float32), 'eval/episode_distance_from_origin': Array(4366.679, dtype=float32), 'eval/episode_forward_reward': Array(415.47925, dtype=float32), 'eval/episode_reward': Array(444.66492, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-381.71402, dtype=float32), 'eval/episode_reward_forward': Array(415.47925, dtype=float32), 'eval/episode_reward_survive': Array(411., dtype=float32), 'eval/episode_x_position': Array(4267.1353, dtype=float32), 'eval/episode_x_velocity': Array(415.47925, dtype=float32), 'eval/episode_y_position': Array(551.5797, dtype=float32), 'eval/episode_y_velocity': Array(45.830063, dtype=float32), 'eval/avg_episode_length': Array(412., dtype=float32), 'eval/epoch_eval_time': 3.293808937072754, 'eval/sps': 303.5998805955975}
[2025-01-29 17:05:20,767][absl][INFO] - {'eval/walltime': 201.05553221702576, 'training/sps': 35.295162297845074, 'training/walltime': 1483.8869245052338, 'training/model_train_time': 17.66033697128296, 'training/other_time': 10.659777879714966, 'training/model_horizon': 4, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(59000, dtype=int32), 'model/train_total_loss': Array(-28.092134, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.8546909, dtype=float32), 'model/test_total_loss': Array(-26.006863, dtype=float32), 'model/test_mean_loss': Array(1.0240564, dtype=float32), 'model/train_epochs': 9, 'model/sec_per_epoch': 1.699984868367513, 'sac/actor_loss': Array(-25.160202, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(0.9481904, dtype=float32), 'sac/buffer_current_size': Array(801799.06, dtype=float32), 'sac/critic_loss': Array(25.266754, dtype=float32), 'eval/episode_distance_from_origin': Array(13129.673, dtype=float32), 'eval/episode_forward_reward': Array(808.59265, dtype=float32), 'eval/episode_reward': Array(847.8512, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-560.8917, dtype=float32), 'eval/episode_reward_forward': Array(808.59265, dtype=float32), 'eval/episode_reward_survive': Array(600., dtype=float32), 'eval/episode_x_position': Array(11285.159, dtype=float32), 'eval/episode_x_velocity': Array(808.59265, dtype=float32), 'eval/episode_y_position': Array(-6670.763, dtype=float32), 'eval/episode_y_velocity': Array(-432.1889, dtype=float32), 'eval/avg_episode_length': Array(601., dtype=float32), 'eval/epoch_eval_time': 3.2731189727783203, 'eval/sps': 305.5189891711056}
[2025-01-29 17:06:12,355][absl][INFO] - {'eval/walltime': 204.3374001979828, 'training/sps': 20.718968618303425, 'training/walltime': 1532.151875257492, 'training/model_train_time': 20.659245491027832, 'training/other_time': 27.5921528339386, 'training/model_horizon': 5, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(60000, dtype=int32), 'model/train_total_loss': Array(-27.12997, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.9772106, dtype=float32), 'model/test_total_loss': Array(-25.61859, dtype=float32), 'model/test_mean_loss': Array(1.0848446, dtype=float32), 'model/train_epochs': 11, 'model/sec_per_epoch': 1.650750918821855, 'sac/actor_loss': Array(-29.6794, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(0.90391755, dtype=float32), 'sac/buffer_current_size': Array(1001999., dtype=float32), 'sac/critic_loss': Array(28.591143, dtype=float32), 'eval/episode_distance_from_origin': Array(3009.018, dtype=float32), 'eval/episode_forward_reward': Array(348.8601, dtype=float32), 'eval/episode_reward': Array(340.83072, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-314.49515, dtype=float32), 'eval/episode_reward_forward': Array(348.8601, dtype=float32), 'eval/episode_reward_survive': Array(308., dtype=float32), 'eval/episode_x_position': Array(2985.9705, dtype=float32), 'eval/episode_x_velocity': Array(348.8601, dtype=float32), 'eval/episode_y_position': Array(-0.04523575, dtype=float32), 'eval/episode_y_velocity': Array(19.95521, dtype=float32), 'eval/avg_episode_length': Array(309., dtype=float32), 'eval/epoch_eval_time': 3.2818679809570312, 'eval/sps': 304.70451761084803}
[2025-01-29 17:06:44,456][absl][INFO] - {'eval/walltime': 207.62604975700378, 'training/sps': 34.72154679653825, 'training/walltime': 1560.9524354934692, 'training/model_train_time': 17.431150674819946, 'training/other_time': 11.353823184967041, 'training/model_horizon': 5, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(61000, dtype=int32), 'model/train_total_loss': Array(-27.82397, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.8447452, dtype=float32), 'model/test_total_loss': Array(-26.335312, dtype=float32), 'model/test_mean_loss': Array(0.99787444, dtype=float32), 'model/train_epochs': 9, 'model/sec_per_epoch': 1.6913139820098877, 'sac/actor_loss': Array(-30.635042, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(0.8903463, dtype=float32), 'sac/buffer_current_size': Array(1001999., dtype=float32), 'sac/critic_loss': Array(29.688843, dtype=float32), 'eval/episode_distance_from_origin': Array(45170.758, dtype=float32), 'eval/episode_forward_reward': Array(1826.0482, dtype=float32), 'eval/episode_reward': Array(1807.6819, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-1019.50977, dtype=float32), 'eval/episode_reward_forward': Array(1826.0482, dtype=float32), 'eval/episode_reward_survive': Array(999., dtype=float32), 'eval/episode_x_position': Array(44368.945, dtype=float32), 'eval/episode_x_velocity': Array(1826.0482, dtype=float32), 'eval/episode_y_position': Array(-8191.84, dtype=float32), 'eval/episode_y_velocity': Array(-272.33636, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 3.288649559020996, 'eval/sps': 304.0761814395608}
[2025-01-29 17:07:25,456][absl][INFO] - {'eval/walltime': 210.91599464416504, 'training/sps': 26.52440799712763, 'training/walltime': 1598.6535596847534, 'training/model_train_time': 26.325434923171997, 'training/other_time': 11.361738681793213, 'training/model_horizon': 5, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(62000, dtype=int32), 'model/train_total_loss': Array(-28.559124, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.815687, dtype=float32), 'model/test_total_loss': Array(-26.193012, dtype=float32), 'model/test_mean_loss': Array(1.0027677, dtype=float32), 'model/train_epochs': 15, 'model/sec_per_epoch': 1.6125421365102133, 'sac/actor_loss': Array(-35.9817, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(0.85952204, dtype=float32), 'sac/buffer_current_size': Array(1001999., dtype=float32), 'sac/critic_loss': Array(30.403217, dtype=float32), 'eval/episode_distance_from_origin': Array(3131.7266, dtype=float32), 'eval/episode_forward_reward': Array(479.1332, dtype=float32), 'eval/episode_reward': Array(455.95132, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-279.79398, dtype=float32), 'eval/episode_reward_forward': Array(479.1332, dtype=float32), 'eval/episode_reward_survive': Array(257., dtype=float32), 'eval/episode_x_position': Array(3081.3218, dtype=float32), 'eval/episode_x_velocity': Array(479.1332, dtype=float32), 'eval/episode_y_position': Array(-441.71582, dtype=float32), 'eval/episode_y_velocity': Array(-19.535975, dtype=float32), 'eval/avg_episode_length': Array(258., dtype=float32), 'eval/epoch_eval_time': 3.289944887161255, 'eval/sps': 303.9564595450883}
[2025-01-29 17:08:03,420][absl][INFO] - {'eval/walltime': 214.20677495002747, 'training/sps': 28.849843678059024, 'training/walltime': 1633.3157925605774, 'training/model_train_time': 23.28962779045105, 'training/other_time': 11.3577721118927, 'training/model_horizon': 5, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(63000, dtype=int32), 'model/train_total_loss': Array(-28.277298, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.77744204, dtype=float32), 'model/test_total_loss': Array(-26.069445, dtype=float32), 'model/test_mean_loss': Array(0.99866986, dtype=float32), 'model/train_epochs': 12, 'model/sec_per_epoch': 1.7075148622194927, 'sac/actor_loss': Array(-42.406857, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(0.8153261, dtype=float32), 'sac/buffer_current_size': Array(1001999., dtype=float32), 'sac/critic_loss': Array(33.32893, dtype=float32), 'eval/episode_distance_from_origin': Array(42898.973, dtype=float32), 'eval/episode_forward_reward': Array(1749.2095, dtype=float32), 'eval/episode_reward': Array(1665.53, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-1082.9208, dtype=float32), 'eval/episode_reward_forward': Array(1749.2095, dtype=float32), 'eval/episode_reward_survive': Array(999., dtype=float32), 'eval/episode_x_position': Array(42474.938, dtype=float32), 'eval/episode_x_velocity': Array(1749.2095, dtype=float32), 'eval/episode_y_position': Array(-5793.662, dtype=float32), 'eval/episode_y_velocity': Array(-189.63504, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 3.2907803058624268, 'eval/sps': 303.87929519893197}
[2025-01-29 17:08:44,270][absl][INFO] - {'eval/walltime': 217.49575114250183, 'training/sps': 26.630600162792984, 'training/walltime': 1670.8665797710419, 'training/model_train_time': 26.190387964248657, 'training/other_time': 11.345591068267822, 'training/model_horizon': 5, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(64000, dtype=int32), 'model/train_total_loss': Array(-29.476742, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.75733835, dtype=float32), 'model/test_total_loss': Array(-27.283535, dtype=float32), 'model/test_mean_loss': Array(0.9446718, dtype=float32), 'model/train_epochs': 14, 'model/sec_per_epoch': 1.7010619129453386, 'sac/actor_loss': Array(-43.99929, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(0.81475216, dtype=float32), 'sac/buffer_current_size': Array(1001999., dtype=float32), 'sac/critic_loss': Array(34.129894, dtype=float32), 'eval/episode_distance_from_origin': Array(43789.598, dtype=float32), 'eval/episode_forward_reward': Array(1770.8378, dtype=float32), 'eval/episode_reward': Array(1713.5076, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-1056.522, dtype=float32), 'eval/episode_reward_forward': Array(1770.8378, dtype=float32), 'eval/episode_reward_survive': Array(999., dtype=float32), 'eval/episode_x_position': Array(42555.297, dtype=float32), 'eval/episode_x_velocity': Array(1770.8378, dtype=float32), 'eval/episode_y_position': Array(9801.453, dtype=float32), 'eval/episode_y_velocity': Array(289.19327, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 3.2889761924743652, 'eval/sps': 304.0459831506652}
[2025-01-29 17:09:22,226][absl][INFO] - {'eval/walltime': 220.77614092826843, 'training/sps': 28.862012523925642, 'training/walltime': 1705.5141983032227, 'training/model_train_time': 23.274035215377808, 'training/other_time': 11.359488487243652, 'training/model_horizon': 5, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(65000, dtype=int32), 'model/train_total_loss': Array(-29.172005, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.7620538, dtype=float32), 'model/test_total_loss': Array(-27.026167, dtype=float32), 'model/test_mean_loss': Array(0.93210953, dtype=float32), 'model/train_epochs': 12, 'model/sec_per_epoch': 1.74655948082606, 'sac/actor_loss': Array(-49.33542, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(0.78630555, dtype=float32), 'sac/buffer_current_size': Array(1001999., dtype=float32), 'sac/critic_loss': Array(35.20235, dtype=float32), 'eval/episode_distance_from_origin': Array(154.31204, dtype=float32), 'eval/episode_forward_reward': Array(109.30128, dtype=float32), 'eval/episode_reward': Array(92.23024, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-72.53958, dtype=float32), 'eval/episode_reward_forward': Array(109.30128, dtype=float32), 'eval/episode_reward_survive': Array(55., dtype=float32), 'eval/episode_x_position': Array(144.32632, dtype=float32), 'eval/episode_x_velocity': Array(109.30128, dtype=float32), 'eval/episode_y_position': Array(-6.297086, dtype=float32), 'eval/episode_y_velocity': Array(5.8207464, dtype=float32), 'eval/avg_episode_length': Array(56., dtype=float32), 'eval/epoch_eval_time': 3.2803897857666016, 'eval/sps': 304.8418222550671}
[2025-01-29 17:10:06,697][absl][INFO] - {'eval/walltime': 224.0623061656952, 'training/sps': 24.28670642974349, 'training/walltime': 1746.6889867782593, 'training/model_train_time': 29.81504988670349, 'training/other_time': 11.345587253570557, 'training/model_horizon': 5, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(66000, dtype=int32), 'model/train_total_loss': Array(-28.822771, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.7943326, dtype=float32), 'model/test_total_loss': Array(-26.260359, dtype=float32), 'model/test_mean_loss': Array(0.99187326, dtype=float32), 'model/train_epochs': 16, 'model/sec_per_epoch': 1.7152621746063232, 'sac/actor_loss': Array(-49.487263, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(0.7886201, dtype=float32), 'sac/buffer_current_size': Array(1001999., dtype=float32), 'sac/critic_loss': Array(33.20386, dtype=float32), 'eval/episode_distance_from_origin': Array(3944.1018, dtype=float32), 'eval/episode_forward_reward': Array(632.89746, dtype=float32), 'eval/episode_reward': Array(591.9691, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-302.01892, dtype=float32), 'eval/episode_reward_forward': Array(632.89746, dtype=float32), 'eval/episode_reward_survive': Array(259., dtype=float32), 'eval/episode_x_position': Array(3929.5952, dtype=float32), 'eval/episode_x_velocity': Array(632.89746, dtype=float32), 'eval/episode_y_position': Array(65.593544, dtype=float32), 'eval/episode_y_velocity': Array(-19.78022, dtype=float32), 'eval/avg_episode_length': Array(260., dtype=float32), 'eval/epoch_eval_time': 3.286165237426758, 'eval/sps': 304.30606124452015}
[2025-01-29 17:10:46,420][absl][INFO] - {'eval/walltime': 227.34462976455688, 'training/sps': 27.44889698640285, 'training/walltime': 1783.1203231811523, 'training/model_train_time': 25.055099725723267, 'training/other_time': 11.36210322380066, 'training/model_horizon': 5, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(67000, dtype=int32), 'model/train_total_loss': Array(-29.076975, dtype=float32, weak_type=True), 'model/train_mean_loss': Array(0.8125793, dtype=float32), 'model/test_total_loss': Array(-27.440641, dtype=float32), 'model/test_mean_loss': Array(0.9307334, dtype=float32), 'model/train_epochs': 13, 'model/sec_per_epoch': 1.7477041574624868, 'sac/actor_loss': Array(-49.68333, dtype=float32), 'sac/alpha': Array(0.19999999, dtype=float32), 'sac/alpha_loss': Array(0.7793558, dtype=float32), 'sac/buffer_current_size': Array(1001999., dtype=float32), 'sac/critic_loss': Array(35.232212, dtype=float32), 'eval/episode_distance_from_origin': Array(341.96368, dtype=float32), 'eval/episode_forward_reward': Array(168.78699, dtype=float32), 'eval/episode_reward': Array(158.33026, dtype=float32), 'eval/episode_reward_contact': Array(0., dtype=float32), 'eval/episode_reward_ctrl': Array(-105.63673, dtype=float32), 'eval/episode_reward_forward': Array(168.78699, dtype=float32), 'eval/episode_reward_survive': Array(92., dtype=float32), 'eval/episode_x_position': Array(313.6747, dtype=float32), 'eval/episode_x_velocity': Array(168.78699, dtype=float32), 'eval/episode_y_position': Array(-108.052734, dtype=float32), 'eval/episode_y_velocity': Array(-50.157227, dtype=float32), 'eval/avg_episode_length': Array(93., dtype=float32), 'eval/epoch_eval_time': 3.2823235988616943, 'eval/sps': 304.6622217098883}
