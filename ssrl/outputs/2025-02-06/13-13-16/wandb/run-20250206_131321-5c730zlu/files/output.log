run_name: null
sweep_name: null
env: Go1GoFast
algo: ssrl
gpus: '0'
num_seeds: 1
ssrl_dynamics_fn: contact_integrate_only
render_during_training: true
render_epoch_interval: 1
render_seed: 0
common:
  action_repeat: 1
  obs_history_length: 5
  normalize_observations: false
  forces_in_q_coords: true
actor_network:
  hidden_layers: 2
  hidden_size: 512
  activation: swish
  max_std: null
critic_network:
  hidden_layers: 5
  hidden_size: 256
env_common:
  policy_repeat: 4
  forward_vel_rew_weight: 2.0
  turn_rew_weight: 0.5
  pitch_rew_weight: 0.25
  roll_rew_weight: 0.25
  yaw_rew_weight: 0.5
  side_motion_rew_weight: 0.5
  z_vel_change_rew_weight: 0.15
  ang_vel_rew_weight: 0.0
  ang_change_rew_weight: 0.25
  joint_lim_rew_weight: 0.0
  torque_lim_rew_weight: 0.0
  joint_acc_rew_weight: 0.0
  action_rew_weight: 0.0
  cosmetic_rew_weight: 0.0
  energy_rew_weight: 0.25
  foot_z_rew_weight: 0.0
  torque_lim_penalty_weight: 0.1
  fallen_roll: 0.785
  fallen_pitch: 0.785
  include_height_in_obs: false
  gains_in_action_space: false
  reward_type: normalized
env_sac:
  policy_repeat: ${env_common.policy_repeat}
  forward_cmd_vel_type: constant
  forward_cmd_vel_range: 0.0
  forward_cmd_vel_period_range:
  - 40.0
  - 40.0
  turn_cmd_rate_range:
  - -0.0
  - 0.0
  initial_yaw_range:
  - -0.0
  - 0.0
  contact_time_const: 0.02
  contact_damping_ratio: 1.0
  friction_range:
  - 0.6
  - 0.6
  ground_roll_range:
  - 0.0
  - 0.0
  ground_pitch_range:
  - 0.0
  - 0.0
  joint_damping_perc_range:
  - 1.0
  - 1.0
  joint_gain_range:
  - 1.0
  - 1.0
  link_mass_perc_range:
  - 1.0
  - 1.0
  forward_vel_rew_weight: ${env_common.forward_vel_rew_weight}
  turn_rew_weight: ${env_common.turn_rew_weight}
  pitch_rew_weight: ${env_common.pitch_rew_weight}
  roll_rew_weight: ${env_common.roll_rew_weight}
  yaw_rew_weight: ${env_common.yaw_rew_weight}
  side_motion_rew_weight: ${env_common.side_motion_rew_weight}
  z_vel_change_rew_weight: ${env_common.z_vel_change_rew_weight}
  ang_vel_rew_weight: ${env_common.ang_vel_rew_weight}
  ang_change_rew_weight: ${env_common.ang_change_rew_weight}
  joint_lim_rew_weight: ${env_common.joint_lim_rew_weight}
  torque_lim_rew_weight: ${env_common.torque_lim_rew_weight}
  joint_acc_rew_weight: ${env_common.joint_acc_rew_weight}
  action_rew_weight: ${env_common.action_rew_weight}
  cosmetic_rew_weight: ${env_common.cosmetic_rew_weight}
  energy_rew_weight: ${env_common.energy_rew_weight}
  foot_z_rew_weight: ${env_common.foot_z_rew_weight}
  torque_lim_penalty_weight: ${env_common.torque_lim_penalty_weight}
  fallen_roll: ${env_common.fallen_roll}
  fallen_pitch: ${env_common.fallen_pitch}
  forces_in_q_coords: ${common.forces_in_q_coords}
  include_height_in_obs: ${env_common.include_height_in_obs}
  gains_in_action_space: ${env_common.gains_in_action_space}
  reward_type: ${env_common.reward_type}
sac:
  num_timesteps: 10000000
  episode_length: 1000
  action_repeat: ${common.action_repeat}
  obs_history_length: ${common.obs_history_length}
  num_envs: 1
  num_eval_envs: 500
  learning_rate: 0.0001
  discounting: 0.99
  seed: 0
  batch_size: 200
  num_evals: 10
  normalize_observations: ${common.normalize_observations}
  reward_scaling: 1
  tau: 0.001
  min_replay_size: 10000
  max_replay_size: 200000
  grad_updates_per_step: 20
  deterministic_eval: true
env_ssrl:
  policy_repeat: ${env_common.policy_repeat}
  forward_cmd_vel_type: constant
  forward_cmd_vel_range: 0.0
  forward_cmd_vel_period_range:
  - 40.0
  - 40.0
  turn_cmd_rate_range:
  - -0.0
  - 0.0
  initial_yaw_range:
  - -0.0
  - 0.0
  contact_time_const: 0.02
  contact_damping_ratio: 1.0
  friction_range:
  - 0.6
  - 0.6
  ground_roll_range:
  - 0.0
  - 0.0
  ground_pitch_range:
  - 0.0
  - 0.0
  joint_damping_perc_range:
  - 1.0
  - 1.0
  joint_gain_range:
  - 1.0
  - 1.0
  link_mass_perc_range:
  - 1.0
  - 1.0
  forward_vel_rew_weight: ${env_common.forward_vel_rew_weight}
  turn_rew_weight: ${env_common.turn_rew_weight}
  pitch_rew_weight: ${env_common.pitch_rew_weight}
  roll_rew_weight: ${env_common.roll_rew_weight}
  yaw_rew_weight: ${env_common.yaw_rew_weight}
  side_motion_rew_weight: ${env_common.side_motion_rew_weight}
  z_vel_change_rew_weight: ${env_common.z_vel_change_rew_weight}
  ang_vel_rew_weight: ${env_common.ang_vel_rew_weight}
  ang_change_rew_weight: ${env_common.ang_change_rew_weight}
  joint_lim_rew_weight: ${env_common.joint_lim_rew_weight}
  torque_lim_rew_weight: ${env_common.torque_lim_rew_weight}
  joint_acc_rew_weight: ${env_common.joint_acc_rew_weight}
  action_rew_weight: ${env_common.action_rew_weight}
  cosmetic_rew_weight: ${env_common.cosmetic_rew_weight}
  energy_rew_weight: ${env_common.energy_rew_weight}
  foot_z_rew_weight: ${env_common.foot_z_rew_weight}
  torque_lim_penalty_weight: ${env_common.torque_lim_penalty_weight}
  fallen_roll: ${env_common.fallen_roll}
  fallen_pitch: ${env_common.fallen_pitch}
  forces_in_q_coords: ${common.forces_in_q_coords}
  include_height_in_obs: ${env_common.include_height_in_obs}
  body_height_in_action_space: true
  gains_in_action_space: ${env_common.gains_in_action_space}
  reward_type: ${env_common.reward_type}
  healthy_delta_radius: 2.0
  healthy_delta_yaw: 1.57
ssrl_start_with_sac: false
ssrl:
  episode_length: 1000
  policy_repeat: 1
  num_epochs: 40
  model_trains_per_epoch: 1
  training_steps_per_model_train: 1
  env_steps_per_training_step: 1000
  model_rollouts_per_hallucination_update: 400
  sac_grad_updates_per_hallucination_update: 60
  init_exploration_steps: 1000
  clear_model_buffer_after_model_train: false
  action_repeat: ${common.action_repeat}
  obs_history_length: ${common.obs_history_length}
  num_envs: 1
  num_evals: 41
  num_eval_envs: 1
  policy_normalize_observations: ${common.normalize_observations}
  model_learning_rate: 0.001
  model_training_batch_size: 200
  model_training_max_sgd_steps_per_epoch: null
  model_training_max_epochs: 1000
  model_training_convergence_criteria: 0.01
  model_training_consec_converged_epochs: 6
  model_training_abs_criteria: null
  model_training_test_ratio: 0.2
  model_training_weight_decay: true
  model_training_stop_gradient: false
  model_loss_horizon: 4
  model_check_done_condition: true
  max_env_buffer_size: 15000
  max_model_buffer_size: 400000
  sac_learning_rate: 0.0002
  sac_discounting: 0.99
  sac_batch_size: 256
  real_ratio: 0.06
  sac_reward_scaling: 1.0
  sac_tau: 0.001
  sac_fixed_alpha: None
  seed: 2
  deterministic_in_env: true
  deterministic_eval: true
  hallucination_max_std: -1.0
  zero_final_layer_of_policy: false
ssrl_model:
  hidden_size: 400
  ensemble_size: 7
  num_elites: 5
  probabilistic: true
ssrl_linear_threshold_fn:
  start_epoch: 0
  end_epoch: 10
  start_model_horizon: 1
  end_model_horizon: 20
ssrl_hupts_fn:
  start_epoch: 0
  end_epoch: 4
  start_hupts: 10
  end_hupts: 1000
render:
  policy: ssrl
wandb:
  entity: an-tsaritsin-itmo-university
  log_sac: true
  log_ssrl: true
save_policy:
  sac: true
  sac_all: true
  ssrl: true
  ssrl_all: true
torque_validate:
  hardware_data: true
Running on GPU 0
[2025-02-06 13:13:23,998][root][INFO] - Converting mesh (-4727597157440148521, -3234457570207681910) into convex hull.
[2025-02-06 13:13:27,473][root][INFO] - Converting mesh (5466102744222878978, 1016926561687441101) into convex hull.
[2025-02-06 13:13:27,838][root][INFO] - Converting mesh (-1582683505712166574, 6055050898466525703) into convex hull.
[2025-02-06 13:13:28,971][root][INFO] - Converting mesh (-8292992290705196147, -6327403989860275673) into convex hull.
[2025-02-06 13:13:29,818][root][INFO] - Converting mesh (790835530283589702, 1524563741799366687) into convex hull.
[2025-02-06 13:14:30,114][absl][INFO] - {'eval/walltime': 53.85934615135193, 'eval/episode_forward_vel': Array(-53.85287801, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-7.63774057e-06, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(9.72727785, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.33477471, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-23.16252818, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(8.06192478, dtype=float64), 'eval/episode_rew_roll': Array(9.8011583, dtype=float64), 'eval/episode_rew_side_motion': Array(13.18476162, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(5.93992367, dtype=float64), 'eval/episode_rew_yaw': Array(13.88444286, dtype=float64), 'eval/episode_rew_z_vel_change': Array(5.75307719, dtype=float64), 'eval/episode_reward': Array(42.46158172, dtype=float64), 'eval/episode_step_count': Array(17205., dtype=float64), 'eval/avg_episode_length': Array(186., dtype=float64), 'eval/epoch_eval_time': 53.85934615135193, 'eval/sps': 18.566879686765358}
Steps / Eval:  0
Reward is  42.461581721084585
Total reward is  233.40142895861757
[2025-02-06 13:17:03,270][absl][INFO] - env buffer size after init exploration 1000
Model epoch 0: train total loss -2.1448406503238115, train mean loss 0.10295771463884945, test mean loss [0.10309776 0.10308314 0.10311622 0.10308953 0.10310609 0.1030941
 0.10312661]
Model epoch 1: train total loss -3.4894226191449276, train mean loss 0.10046141016926519, test mean loss [0.09916297 0.09901631 0.09930866 0.09907992 0.09929259 0.09859033
 0.09882801]
Model epoch 2: train total loss -11.987119612126206, train mean loss 0.08714916407262144, test mean loss [0.08679685 0.08498465 0.08591349 0.08586318 0.08302678 0.08379988
 0.08412251]
Model epoch 3: train total loss -23.90206385004409, train mean loss 0.07778221800705261, test mean loss [0.08060321 0.07409053 0.07482136 0.0754479  0.07450784 0.0734113
 0.07241916]
Model epoch 4: train total loss -33.30845119466348, train mean loss 0.0669191697364466, test mean loss [0.07219724 0.06592881 0.0661935  0.06840346 0.06611632 0.06420626
 0.06478259]
Model epoch 5: train total loss -35.668300735616064, train mean loss 0.06252182431592379, test mean loss [0.06578828 0.06309907 0.06245592 0.06358033 0.06172939 0.06366742
 0.05984097]
Model epoch 6: train total loss -36.497582654766106, train mean loss 0.059339433628125056, test mean loss [0.06140137 0.06059269 0.05774747 0.05878071 0.05834934 0.06048304
 0.05608771]
Model epoch 7: train total loss -37.1527277386348, train mean loss 0.056552348966711616, test mean loss [0.05932203 0.05663282 0.05503    0.05625648 0.05606925 0.05583712
 0.05464132]
Model epoch 8: train total loss -37.5987338759176, train mean loss 0.05565738166128725, test mean loss [0.05792577 0.05561595 0.0548386  0.05502785 0.05435887 0.05577305
 0.05384571]
Model epoch 9: train total loss -38.069859135290606, train mean loss 0.05372011458281543, test mean loss [0.05666377 0.05531711 0.05420862 0.0532906  0.05355468 0.05514576
 0.05091758]
Model epoch 10: train total loss -38.5000777173727, train mean loss 0.05176804129703424, test mean loss [0.05592732 0.05354467 0.05141955 0.05266839 0.05184574 0.05316808
 0.04729399]
Model epoch 11: train total loss -39.10368136545819, train mean loss 0.04972020587325383, test mean loss [0.05402166 0.05246854 0.04823082 0.05016673 0.04988035 0.05074923
 0.04398853]
Model epoch 12: train total loss -39.69626142599455, train mean loss 0.04752452053636575, test mean loss [0.05183536 0.05069436 0.04497001 0.04739453 0.04690025 0.0479532
 0.04185249]
Model epoch 13: train total loss -40.131069019873415, train mean loss 0.044418440136664565, test mean loss [0.0495653  0.04818216 0.04119984 0.04469247 0.04420252 0.044685
 0.03985787]
Model epoch 14: train total loss -40.49940839809851, train mean loss 0.04225791291626343, test mean loss [0.04685496 0.04553646 0.03830946 0.04115594 0.04198731 0.04252039
 0.03878483]
Model epoch 15: train total loss -41.15246462056753, train mean loss 0.040045452955862273, test mean loss [0.04469187 0.04286627 0.03672707 0.03796094 0.04071862 0.04074742
 0.03733283]
Model epoch 16: train total loss -41.706375402837764, train mean loss 0.03755433680676225, test mean loss [0.04268933 0.04047622 0.03492966 0.03585368 0.03960976 0.03865133
 0.03553441]
Model epoch 17: train total loss -42.10724778966448, train mean loss 0.03595781980727591, test mean loss [0.04113043 0.03850944 0.03410619 0.0348896  0.03793954 0.03646858
 0.03443489]
Model epoch 18: train total loss -42.47867684679658, train mean loss 0.03410690172828964, test mean loss [0.03890652 0.03712983 0.03250075 0.03386039 0.03599599 0.03468629
 0.03226686]
Model epoch 19: train total loss -42.98250094923561, train mean loss 0.032496892165174256, test mean loss [0.03749594 0.0351056  0.0306775  0.03186278 0.03410604 0.03336199
 0.03081661]
Model epoch 20: train total loss -43.42028686190565, train mean loss 0.03112079350573597, test mean loss [0.0361494  0.03344975 0.02882918 0.02996328 0.03265084 0.03178016
 0.02928289]
Model epoch 21: train total loss -43.7189555247678, train mean loss 0.029689000939498104, test mean loss [0.03461816 0.03201451 0.02715583 0.02854033 0.03132462 0.03035675
 0.0274383 ]
Model epoch 22: train total loss -44.26731574451755, train mean loss 0.028028035517078158, test mean loss [0.03314089 0.03015004 0.02516093 0.02692594 0.0301706  0.02893214
 0.02637113]
Model epoch 23: train total loss -44.69347537994176, train mean loss 0.027029422516278618, test mean loss [0.03182041 0.02820348 0.02315783 0.02580242 0.02907573 0.02760508
 0.02542574]
Model epoch 24: train total loss -45.14390651850282, train mean loss 0.025731931349032264, test mean loss [0.03081658 0.02665655 0.02189863 0.02402687 0.02810379 0.02644948
 0.02377829]
Model epoch 25: train total loss -45.80702091356568, train mean loss 0.024295497849573022, test mean loss [0.02914952 0.02534901 0.02089516 0.02236844 0.02676019 0.02495721
 0.02243327]
Model epoch 26: train total loss -46.09279286853308, train mean loss 0.02292794509732951, test mean loss [0.02774382 0.02379082 0.01985453 0.02107818 0.02594174 0.02358441
 0.02150593]
Model epoch 27: train total loss -46.61614785713688, train mean loss 0.022185562919665235, test mean loss [0.02662935 0.02283909 0.01957988 0.02078773 0.02502732 0.02198683
 0.0213233 ]
Model epoch 28: train total loss -46.94462559192115, train mean loss 0.021498242547726042, test mean loss [0.02527714 0.02235721 0.01931099 0.02080917 0.02397513 0.02066432
 0.02038489]
Model epoch 29: train total loss -47.286313807903184, train mean loss 0.02068348828823954, test mean loss [0.02432945 0.02084612 0.01831614 0.01974012 0.02322129 0.01942028
 0.01923141]
Model epoch 30: train total loss -47.844721237678364, train mean loss 0.01942616309671126, test mean loss [0.0234152  0.02052626 0.01820032 0.01911657 0.02275927 0.01837603
 0.01862895]
Model epoch 31: train total loss -48.27893197701855, train mean loss 0.018518692134496792, test mean loss [0.0224856  0.01930138 0.0180328  0.01872658 0.02161306 0.01759225
 0.01830664]
Model epoch 32: train total loss -48.47308918721969, train mean loss 0.018081021285006434, test mean loss [0.02175433 0.01840946 0.01749968 0.01812091 0.0203973  0.01710638
 0.01825976]
Model epoch 33: train total loss -48.831438611030705, train mean loss 0.018132799075487722, test mean loss [0.02147543 0.01763178 0.01667706 0.01776662 0.01945831 0.01646992
 0.01719692]
Model epoch 34: train total loss -49.194953536806445, train mean loss 0.017271369645487377, test mean loss [0.02116442 0.0171822  0.01630811 0.01740907 0.0186651  0.01585426
 0.01651919]
Model epoch 35: train total loss -49.590271745068975, train mean loss 0.01648211665245833, test mean loss [0.02028402 0.01637121 0.01586184 0.01671424 0.01748952 0.01495301
 0.01616646]
Model epoch 36: train total loss -49.81781730440583, train mean loss 0.01589425940142084, test mean loss [0.02005522 0.01592012 0.01506156 0.0158743  0.01695844 0.01443022
 0.01554327]
Model epoch 37: train total loss -49.972890482817405, train mean loss 0.015740195080018907, test mean loss [0.01925376 0.01542143 0.01451292 0.0153879  0.01588103 0.0158123
 0.01519309]
Model epoch 38: train total loss -49.875704847083334, train mean loss 0.015358324024685756, test mean loss [0.01932356 0.01544557 0.01472443 0.01498987 0.0156738  0.01500887
 0.01497047]
Model epoch 39: train total loss -50.42570735985867, train mean loss 0.014773880250498686, test mean loss [0.01799302 0.01474654 0.01410445 0.0142556  0.01516701 0.01349964
 0.01415785]
Model epoch 40: train total loss -50.70278214694665, train mean loss 0.014719623958632093, test mean loss [0.01772467 0.01452852 0.01299077 0.01371956 0.01567455 0.01288696
 0.01374072]
Model epoch 41: train total loss -50.97124765943106, train mean loss 0.014075151223492068, test mean loss [0.01728428 0.01365641 0.01258598 0.01312247 0.01527752 0.0123393
 0.01319225]
Model epoch 42: train total loss -51.38161317455703, train mean loss 0.013268046102987699, test mean loss [0.01686287 0.01293984 0.01238752 0.01268137 0.01448729 0.01188952
 0.01303538]
Model epoch 43: train total loss -51.692461159262585, train mean loss 0.012948994503108763, test mean loss [0.01643198 0.01273466 0.0116516  0.01236371 0.01363839 0.01136576
 0.01224182]
Model epoch 44: train total loss -51.91860766904993, train mean loss 0.012475561026910786, test mean loss [0.01616365 0.01216788 0.01134706 0.01242122 0.01329628 0.0111648
 0.01221579]
Model epoch 45: train total loss -51.803241312651075, train mean loss 0.012407575815950325, test mean loss [0.01555784 0.01190467 0.01069312 0.0115915  0.01304295 0.01058525
 0.01201286]
Model epoch 46: train total loss -52.26857086626885, train mean loss 0.011703512804116117, test mean loss [0.01501649 0.01139219 0.01076569 0.01051387 0.0127681  0.01017702
 0.01165921]
Model epoch 47: train total loss -52.593103065253, train mean loss 0.01141132453887677, test mean loss [0.01489024 0.01147847 0.01032073 0.01013556 0.0124574  0.01010561
 0.01110844]
Model epoch 48: train total loss -52.57403370048013, train mean loss 0.01078379278255104, test mean loss [0.0141306  0.01089685 0.00979236 0.01081409 0.01197037 0.00954958
 0.0108452 ]
Model epoch 49: train total loss -53.14228495794952, train mean loss 0.010574201827951907, test mean loss [0.01368263 0.01011387 0.00974199 0.0101515  0.01148648 0.00907532
 0.0104168 ]
Model epoch 50: train total loss -52.73408826639388, train mean loss 0.010092930761590091, test mean loss [0.01443377 0.00999825 0.00931456 0.0095726  0.0111576  0.00945613
 0.0110518 ]
Model epoch 51: train total loss -52.659160803927556, train mean loss 0.010541525390857377, test mean loss [0.01493776 0.00963615 0.00892408 0.00967026 0.01129974 0.00947022
 0.00994942]
Model epoch 52: train total loss -52.54169340019006, train mean loss 0.010364409275781215, test mean loss [0.01376216 0.00945214 0.00936151 0.00930993 0.01063761 0.00908368
 0.00976317]
Model epoch 53: train total loss -53.39594441493454, train mean loss 0.009575859081540142, test mean loss [0.01227803 0.00901461 0.00931415 0.00890379 0.01015125 0.00823672
 0.00903318]
Model epoch 54: train total loss -53.054160486035485, train mean loss 0.009226369891866567, test mean loss [0.0113817  0.00873287 0.00870845 0.00829825 0.01029996 0.01017365
 0.00877821]
Model epoch 55: train total loss -53.01096663948586, train mean loss 0.010227906210493068, test mean loss [0.01087777 0.00861727 0.00807473 0.00797435 0.00968682 0.01672888
 0.00886921]
Model epoch 56: train total loss -53.43211781867405, train mean loss 0.009840229746019127, test mean loss [0.01032747 0.00858705 0.0082598  0.00786818 0.00921778 0.01560399
 0.00857152]
Model epoch 57: train total loss -53.61150953133661, train mean loss 0.009398724218703183, test mean loss [0.01075023 0.00773389 0.00830884 0.00764673 0.00902379 0.01387419
 0.00821337]
Model epoch 58: train total loss -53.299304259886, train mean loss 0.009017677699943313, test mean loss [0.01007971 0.00783263 0.00794775 0.00729735 0.00966207 0.01340957
 0.00806488]
Model epoch 59: train total loss -52.88735150197242, train mean loss 0.009723706335838567, test mean loss [0.01001301 0.00745661 0.00908675 0.00786295 0.00945382 0.01500435
 0.00750489]
Model epoch 60: train total loss -53.079872142521495, train mean loss 0.009088423567086527, test mean loss [0.00923132 0.00749645 0.00822714 0.00890942 0.00887036 0.01301208
 0.00762177]
Model epoch 61: train total loss -53.67504418952448, train mean loss 0.008437902582047047, test mean loss [0.00937113 0.00694148 0.00803471 0.00819371 0.00848784 0.0114431
 0.0070703 ]
Model epoch 62: train total loss -53.92442967747222, train mean loss 0.008052826775471915, test mean loss [0.00922398 0.00657446 0.00751705 0.00752131 0.00937531 0.01013955
 0.00683133]
Model epoch 63: train total loss -54.3603545460529, train mean loss 0.00783383824050747, test mean loss [0.00915197 0.00669734 0.00741708 0.00729446 0.00877384 0.00933586
 0.00670868]
Model epoch 64: train total loss -54.49931733930236, train mean loss 0.007721790609630452, test mean loss [0.00896392 0.00660044 0.00745594 0.00696574 0.00847995 0.00856481
 0.0068206 ]
Model epoch 65: train total loss -55.05691258717237, train mean loss 0.007400318200879876, test mean loss [0.00876764 0.00594004 0.00740761 0.00666835 0.00803135 0.00795246
 0.00635365]
Model epoch 66: train total loss -55.592931601786304, train mean loss 0.007093563661761415, test mean loss [0.00873841 0.0059517  0.00714671 0.00631469 0.00777757 0.00752575
 0.00620946]
Model epoch 67: train total loss -55.57243873013446, train mean loss 0.006760135763850888, test mean loss [0.00871957 0.00597197 0.00655757 0.00651205 0.00752822 0.00725661
 0.00601126]
Model epoch 68: train total loss -55.77570986168068, train mean loss 0.006954688836232963, test mean loss [0.00875255 0.00564909 0.00614331 0.00645133 0.007067   0.00681409
 0.00588396]
Model epoch 69: train total loss -55.45252894563097, train mean loss 0.006466072729143246, test mean loss [0.00832325 0.00552741 0.00699628 0.00618838 0.00770128 0.00656444
 0.00559481]
Model epoch 70: train total loss -55.22722312164638, train mean loss 0.00643845847140313, test mean loss [0.00811812 0.00587193 0.00715837 0.00580495 0.00797937 0.00611209
 0.00551572]
Model epoch 71: train total loss -55.43882699062289, train mean loss 0.006357775653983405, test mean loss [0.00796777 0.00557319 0.00698446 0.00625708 0.00749793 0.00592363
 0.00556564]
Model epoch 72: train total loss -55.65593271960992, train mean loss 0.006322894921743705, test mean loss [0.00767468 0.00535269 0.00659283 0.00608266 0.00727085 0.00574501
 0.00545352]
Model epoch 73: train total loss -55.760248784318655, train mean loss 0.0062118390973976935, test mean loss [0.00766305 0.0054998  0.00613381 0.00582384 0.00697091 0.00558356
 0.00507655]
Model epoch 74: train total loss -56.07064719589519, train mean loss 0.006050222098024088, test mean loss [0.00762863 0.00576865 0.00598733 0.00560626 0.00670458 0.0055292
 0.0053658 ]
Model epoch 75: train total loss -56.12334584300128, train mean loss 0.005968718167946712, test mean loss [0.00736874 0.005766   0.00581548 0.00567495 0.00633405 0.00547352
 0.00580721]
Model epoch 76: train total loss -56.38465398809511, train mean loss 0.005906528403079499, test mean loss [0.00718773 0.00513063 0.00587046 0.005542   0.00592619 0.00563664
 0.00537677]
Model epoch 77: train total loss -56.63230827924756, train mean loss 0.005809736156165814, test mean loss [0.00741956 0.00499989 0.00574247 0.00538151 0.00595246 0.00557719
 0.00512194]
Model epoch 78: train total loss -56.41931429451, train mean loss 0.005762313853937817, test mean loss [0.00716569 0.0049449  0.00558321 0.00543311 0.00579072 0.00556093
 0.00491791]
Model epoch 79: train total loss -56.86597394200594, train mean loss 0.005473221746929812, test mean loss [0.00691775 0.00512728 0.00571203 0.00514986 0.00558823 0.00557769
 0.00479378]
Model epoch 80: train total loss -56.783697590030044, train mean loss 0.005438986755318767, test mean loss [0.00673096 0.00497365 0.0055816  0.00523457 0.00548729 0.00533864
 0.00463121]
Model epoch 81: train total loss -56.92161598696788, train mean loss 0.005395091296740086, test mean loss [0.00659283 0.00495616 0.00527297 0.00558044 0.005411   0.00497272
 0.00492579]
Model epoch 82: train total loss -57.16476684682323, train mean loss 0.005131308688544345, test mean loss [0.00638621 0.00457058 0.00496754 0.00546693 0.00520462 0.00478125
 0.00467231]
Model epoch 83: train total loss -57.35843725418499, train mean loss 0.005144556845757241, test mean loss [0.00642835 0.00456845 0.00512756 0.00528045 0.00522834 0.00495077
 0.00440001]
Model epoch 84: train total loss -57.55979866153727, train mean loss 0.00512454873302463, test mean loss [0.00617448 0.004595   0.00511129 0.00529618 0.0051131  0.00501613
 0.0044287 ]
Model epoch 85: train total loss -57.52376834902565, train mean loss 0.004894657628236519, test mean loss [0.00599402 0.00438193 0.00473876 0.00526478 0.00523848 0.00489591
 0.00466493]
Model epoch 86: train total loss -57.84305794312096, train mean loss 0.004890947082023055, test mean loss [0.00608587 0.0043789  0.00456381 0.005087   0.00497324 0.00473192
 0.00448631]
Model epoch 87: train total loss -57.832862616810026, train mean loss 0.004882808549095065, test mean loss [0.00598492 0.0045304  0.00456349 0.00497714 0.00470918 0.00476858
 0.0041501 ]
Model epoch 88: train total loss -57.88704541957166, train mean loss 0.004822778447540081, test mean loss [0.00584856 0.00460897 0.00450474 0.0046929  0.00473088 0.00481444
 0.00416484]
Model epoch 89: train total loss -58.009812100873624, train mean loss 0.004648370153250844, test mean loss [0.00587445 0.00439428 0.00444785 0.00469417 0.00490962 0.00463899
 0.00408795]
Model epoch 90: train total loss -58.14551305047129, train mean loss 0.004767348559612093, test mean loss [0.00572398 0.00433882 0.00429082 0.00450368 0.00503807 0.00440511
 0.00428344]
Model epoch 91: train total loss -58.1699731923863, train mean loss 0.00468719750137104, test mean loss [0.00548582 0.00411693 0.00430413 0.00450384 0.00475386 0.00453328
 0.00411416]
Model epoch 92: train total loss -58.41897445085422, train mean loss 0.004459793293056015, test mean loss [0.00560212 0.00409411 0.00438454 0.00443707 0.00461094 0.00456989
 0.00394933]
Model epoch 93: train total loss -58.14949810857892, train mean loss 0.004535147696465232, test mean loss [0.00560585 0.00468805 0.00437092 0.00419185 0.00466619 0.00435015
 0.00388669]
Model epoch 94: train total loss -58.2471623608809, train mean loss 0.004520704275228046, test mean loss [0.00545974 0.00499554 0.00413922 0.0040786  0.00460089 0.00406124
 0.00399892]
Model epoch 95: train total loss -58.21129753927157, train mean loss 0.004449041666845519, test mean loss [0.00578139 0.00463755 0.00389411 0.00435966 0.00451272 0.00407085
 0.00379983]
Model epoch 96: train total loss -58.29603543596349, train mean loss 0.0043430724557376775, test mean loss [0.00549646 0.00424449 0.00376062 0.00411239 0.00438167 0.00403162
 0.00373065]
Traceback (most recent call last):
  File "/home/ant/ssrl/ssrl/scripts/aliengo_train.py", line 248, in <module>
    train_go1()
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/ant/ssrl/ssrl/scripts/aliengo_train.py", line 199, in train_go1
    state = train_fn(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 263, in train
    env_state) = sim_training_epoch_with_timing(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 947, in sim_training_epoch_with_timing
    training_state, model_metrics = train_model(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 661, in train_model
    test_total_loss, test_mean_loss) = model_training_epoch(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 745, in model_training_epoch
    test_total_losses, test_mean_losses) = model_training_epoch_jit(
  File "<string>", line 1, in <lambda>
KeyboardInterrupt