run_name: null
sweep_name: null
env: Go1GoFast
algo: ssrl
gpus: '0'
num_seeds: 1
ssrl_dynamics_fn: contact_integrate_only
render_during_training: true
render_epoch_interval: 10
render_seed: 0
common:
  action_repeat: 1
  obs_history_length: 5
  normalize_observations: false
  forces_in_q_coords: true
actor_network:
  hidden_layers: 2
  hidden_size: 512
  activation: swish
  max_std: null
critic_network:
  hidden_layers: 5
  hidden_size: 256
env_common:
  policy_repeat: 4
  forward_vel_rew_weight: 2.0
  turn_rew_weight: 0.5
  pitch_rew_weight: 0.25
  roll_rew_weight: 0.25
  yaw_rew_weight: 0.5
  side_motion_rew_weight: 0.5
  z_vel_change_rew_weight: 0.15
  ang_vel_rew_weight: 0.0
  ang_change_rew_weight: 0.25
  joint_lim_rew_weight: 0.0
  torque_lim_rew_weight: 0.0
  joint_acc_rew_weight: 0.0
  action_rew_weight: 0.0
  cosmetic_rew_weight: 0.0
  energy_rew_weight: 0.25
  foot_z_rew_weight: 0.0
  torque_lim_penalty_weight: 0.1
  fallen_roll: 0.785
  fallen_pitch: 0.785
  include_height_in_obs: false
  gains_in_action_space: false
  reward_type: normalized
env_sac:
  policy_repeat: ${env_common.policy_repeat}
  forward_cmd_vel_type: constant
  forward_cmd_vel_range: 0.0
  forward_cmd_vel_period_range:
  - 40.0
  - 40.0
  turn_cmd_rate_range:
  - -0.0
  - 0.0
  initial_yaw_range:
  - -0.0
  - 0.0
  contact_time_const: 0.02
  contact_damping_ratio: 1.0
  friction_range:
  - 0.6
  - 0.6
  ground_roll_range:
  - 0.0
  - 0.0
  ground_pitch_range:
  - 0.0
  - 0.0
  joint_damping_perc_range:
  - 1.0
  - 1.0
  joint_gain_range:
  - 1.0
  - 1.0
  link_mass_perc_range:
  - 1.0
  - 1.0
  forward_vel_rew_weight: ${env_common.forward_vel_rew_weight}
  turn_rew_weight: ${env_common.turn_rew_weight}
  pitch_rew_weight: ${env_common.pitch_rew_weight}
  roll_rew_weight: ${env_common.roll_rew_weight}
  yaw_rew_weight: ${env_common.yaw_rew_weight}
  side_motion_rew_weight: ${env_common.side_motion_rew_weight}
  z_vel_change_rew_weight: ${env_common.z_vel_change_rew_weight}
  ang_vel_rew_weight: ${env_common.ang_vel_rew_weight}
  ang_change_rew_weight: ${env_common.ang_change_rew_weight}
  joint_lim_rew_weight: ${env_common.joint_lim_rew_weight}
  torque_lim_rew_weight: ${env_common.torque_lim_rew_weight}
  joint_acc_rew_weight: ${env_common.joint_acc_rew_weight}
  action_rew_weight: ${env_common.action_rew_weight}
  cosmetic_rew_weight: ${env_common.cosmetic_rew_weight}
  energy_rew_weight: ${env_common.energy_rew_weight}
  foot_z_rew_weight: ${env_common.foot_z_rew_weight}
  torque_lim_penalty_weight: ${env_common.torque_lim_penalty_weight}
  fallen_roll: ${env_common.fallen_roll}
  fallen_pitch: ${env_common.fallen_pitch}
  forces_in_q_coords: ${common.forces_in_q_coords}
  include_height_in_obs: ${env_common.include_height_in_obs}
  gains_in_action_space: ${env_common.gains_in_action_space}
  reward_type: ${env_common.reward_type}
sac:
  num_timesteps: 10000000
  episode_length: 1000
  action_repeat: ${common.action_repeat}
  obs_history_length: ${common.obs_history_length}
  num_envs: 1
  num_eval_envs: 500
  learning_rate: 0.0001
  discounting: 0.99
  seed: 0
  batch_size: 200
  num_evals: 10
  normalize_observations: ${common.normalize_observations}
  reward_scaling: 1
  tau: 0.001
  min_replay_size: 10000
  max_replay_size: 200000
  grad_updates_per_step: 20
  deterministic_eval: true
env_ssrl:
  policy_repeat: ${env_common.policy_repeat}
  forward_cmd_vel_type: constant
  forward_cmd_vel_range: 0.0
  forward_cmd_vel_period_range:
  - 40.0
  - 40.0
  turn_cmd_rate_range:
  - -0.0
  - 0.0
  initial_yaw_range:
  - -0.0
  - 0.0
  contact_time_const: 0.02
  contact_damping_ratio: 1.0
  friction_range:
  - 0.6
  - 0.6
  ground_roll_range:
  - 0.0
  - 0.0
  ground_pitch_range:
  - 0.0
  - 0.0
  joint_damping_perc_range:
  - 1.0
  - 1.0
  joint_gain_range:
  - 1.0
  - 1.0
  link_mass_perc_range:
  - 1.0
  - 1.0
  forward_vel_rew_weight: ${env_common.forward_vel_rew_weight}
  turn_rew_weight: ${env_common.turn_rew_weight}
  pitch_rew_weight: ${env_common.pitch_rew_weight}
  roll_rew_weight: ${env_common.roll_rew_weight}
  yaw_rew_weight: ${env_common.yaw_rew_weight}
  side_motion_rew_weight: ${env_common.side_motion_rew_weight}
  z_vel_change_rew_weight: ${env_common.z_vel_change_rew_weight}
  ang_vel_rew_weight: ${env_common.ang_vel_rew_weight}
  ang_change_rew_weight: ${env_common.ang_change_rew_weight}
  joint_lim_rew_weight: ${env_common.joint_lim_rew_weight}
  torque_lim_rew_weight: ${env_common.torque_lim_rew_weight}
  joint_acc_rew_weight: ${env_common.joint_acc_rew_weight}
  action_rew_weight: ${env_common.action_rew_weight}
  cosmetic_rew_weight: ${env_common.cosmetic_rew_weight}
  energy_rew_weight: ${env_common.energy_rew_weight}
  foot_z_rew_weight: ${env_common.foot_z_rew_weight}
  torque_lim_penalty_weight: ${env_common.torque_lim_penalty_weight}
  fallen_roll: ${env_common.fallen_roll}
  fallen_pitch: ${env_common.fallen_pitch}
  forces_in_q_coords: ${common.forces_in_q_coords}
  include_height_in_obs: ${env_common.include_height_in_obs}
  body_height_in_action_space: true
  gains_in_action_space: ${env_common.gains_in_action_space}
  reward_type: ${env_common.reward_type}
  healthy_delta_radius: 2.0
  healthy_delta_yaw: 1.57
ssrl_start_with_sac: false
ssrl:
  episode_length: 1000
  policy_repeat: 1
  num_epochs: 40
  model_trains_per_epoch: 1
  training_steps_per_model_train: 1
  env_steps_per_training_step: 1000
  model_rollouts_per_hallucination_update: 400
  sac_grad_updates_per_hallucination_update: 60
  init_exploration_steps: 1000
  clear_model_buffer_after_model_train: false
  action_repeat: ${common.action_repeat}
  obs_history_length: ${common.obs_history_length}
  num_envs: 1
  num_evals: 41
  num_eval_envs: 1
  policy_normalize_observations: ${common.normalize_observations}
  model_learning_rate: 0.001
  model_training_batch_size: 200
  model_training_max_sgd_steps_per_epoch: null
  model_training_max_epochs: 1000
  model_training_convergence_criteria: 0.01
  model_training_consec_converged_epochs: 6
  model_training_abs_criteria: null
  model_training_test_ratio: 0.2
  model_training_weight_decay: true
  model_training_stop_gradient: false
  model_loss_horizon: 4
  model_check_done_condition: true
  max_env_buffer_size: 15000
  max_model_buffer_size: 400000
  sac_learning_rate: 0.0002
  sac_discounting: 0.99
  sac_batch_size: 256
  real_ratio: 0.06
  sac_reward_scaling: 1.0
  sac_tau: 0.001
  sac_fixed_alpha: None
  seed: 2
  deterministic_in_env: true
  deterministic_eval: true
  hallucination_max_std: -1.0
  zero_final_layer_of_policy: false
ssrl_model:
  hidden_size: 400
  ensemble_size: 7
  num_elites: 5
  probabilistic: true
ssrl_linear_threshold_fn:
  start_epoch: 0
  end_epoch: 10
  start_model_horizon: 1
  end_model_horizon: 20
ssrl_hupts_fn:
  start_epoch: 0
  end_epoch: 4
  start_hupts: 10
  end_hupts: 1000
render:
  policy: ssrl
wandb:
  entity: an-tsaritsin-itmo-university
  log_sac: false
  log_ssrl: true
save_policy:
  sac: false
  sac_all: false
  ssrl: true
  ssrl_all: true
torque_validate:
  hardware_data: true
Running on GPU 0
[2025-01-24 16:50:35,208][root][INFO] - Converting mesh (-794479370041538276, 9215531194246729595) into convex hull.
[2025-01-24 16:50:43,470][root][INFO] - Converting mesh (3768656487993901711, -9101843950356169874) into convex hull.
[2025-01-24 16:50:46,362][root][INFO] - Converting mesh (3832421531282480037, -9043800777252305120) into convex hull.
[2025-01-24 16:50:51,609][root][INFO] - Converting mesh (-1005330490923646212, 3123352237682281068) into convex hull.
[2025-01-24 16:50:55,973][root][INFO] - Converting mesh (-5250690474180786663, -3390023931332099214) into convex hull.
[2025-01-24 16:51:48,320][absl][INFO] - {'eval/walltime': 43.135085344314575, 'eval/episode_forward_vel': Array(-108.60923714, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-0.10797279, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(52.49267436, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.4366862, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-46.71365038, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(53.27323164, dtype=float64), 'eval/episode_rew_roll': Array(52.95435189, dtype=float64), 'eval/episode_rew_side_motion': Array(60.45251734, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(65.55468316, dtype=float64), 'eval/episode_rew_yaw': Array(6.67671905, dtype=float64), 'eval/episode_rew_z_vel_change': Array(26.43004902, dtype=float64), 'eval/episode_reward': Array(271.56760586, dtype=float64), 'eval/episode_step_count': Array(499500., dtype=float64), 'eval/avg_episode_length': Array(1000., dtype=float64), 'eval/epoch_eval_time': 43.135085344314575, 'eval/sps': 23.182984153566885}
Steps / Eval:  0
Reward is  271.56760586399474
Total reward is  273.29554575457934
[2025-01-24 16:54:02,911][absl][INFO] - env buffer size after init exploration 1000
Model epoch 0: train total loss -2.433030696166185, train mean loss 0.08022555609505085, test mean loss [0.09032431 0.09035206 0.09033741 0.09029995 0.09033865 0.09033664
 0.09031725]
Model epoch 1: train total loss -3.5116417766649626, train mean loss 0.0783273790956046, test mean loss [0.08783237 0.08862202 0.08787606 0.08733863 0.08818419 0.08801171
 0.08743748]
Model epoch 2: train total loss -10.36094151238542, train mean loss 0.07165521504416651, test mean loss [0.08060349 0.07970682 0.07818074 0.07896752 0.07969765 0.0796728
 0.07893755]
Model epoch 3: train total loss -23.19979282260816, train mean loss 0.07140440420083492, test mean loss [0.08001599 0.0783972  0.07792717 0.08112816 0.0767287  0.07804427
 0.08203095]
Model epoch 4: train total loss -32.07740710375042, train mean loss 0.07041869090580388, test mean loss [0.07700295 0.07871353 0.0776455  0.08039485 0.07839404 0.07703025
 0.08099034]
Model epoch 5: train total loss -34.7644936043428, train mean loss 0.07083978544744518, test mean loss [0.07753515 0.07847852 0.07762597 0.07841327 0.07781392 0.07782656
 0.07867845]
Model epoch 6: train total loss -35.539779740893096, train mean loss 0.0690318841336398, test mean loss [0.07653183 0.07777744 0.07547972 0.07707271 0.07563764 0.07636436
 0.07779823]
Model epoch 7: train total loss -36.60653838173046, train mean loss 0.06818740530729053, test mean loss [0.0748518  0.07645038 0.07404208 0.075706   0.07573951 0.07590809
 0.07751473]
Model epoch 8: train total loss -37.46233557997256, train mean loss 0.06628951160369585, test mean loss [0.07335667 0.0754175  0.07361219 0.0747071  0.07639888 0.074584
 0.07646168]
Model epoch 9: train total loss -38.03681497173527, train mean loss 0.06537115801455491, test mean loss [0.07282687 0.07407883 0.07365027 0.07489238 0.0759189  0.07233161
 0.07581091]
Model epoch 10: train total loss -38.44096115168685, train mean loss 0.06428811388355203, test mean loss [0.07170673 0.07161134 0.07039811 0.07534275 0.07235227 0.06850149
 0.07471132]
Model epoch 11: train total loss -39.03950764602959, train mean loss 0.06236814965747296, test mean loss [0.06772349 0.06817478 0.06697574 0.07510683 0.06906839 0.06461813
 0.07391542]
Model epoch 12: train total loss -39.53494225643966, train mean loss 0.060344235634691996, test mean loss [0.06412832 0.06530356 0.06318687 0.07314248 0.06561126 0.06103944
 0.07242043]
Model epoch 13: train total loss -40.188433294914596, train mean loss 0.05821089901831442, test mean loss [0.06138993 0.06049876 0.05886143 0.07020219 0.06108008 0.05627882
 0.07063572]
Model epoch 14: train total loss -40.993456681033095, train mean loss 0.05331764277654024, test mean loss [0.05956854 0.05637248 0.05385292 0.06654467 0.0572705  0.05189573
 0.06904605]
Model epoch 15: train total loss -41.7339663980766, train mean loss 0.05146463313348294, test mean loss [0.05801486 0.05264636 0.04937495 0.06266374 0.05498717 0.04899094
 0.06736647]
Model epoch 16: train total loss -42.39120751853818, train mean loss 0.04899806048207919, test mean loss [0.05655282 0.04941161 0.04625846 0.05964109 0.04971461 0.04355197
 0.06436531]
Model epoch 17: train total loss -43.05942762706137, train mean loss 0.04585203868594269, test mean loss [0.05278129 0.04692901 0.04180382 0.05713809 0.04855693 0.03986679
 0.06058757]
Model epoch 18: train total loss -43.5921495127978, train mean loss 0.043632067599346396, test mean loss [0.04866897 0.04510196 0.03970635 0.053751   0.04661671 0.04026857
 0.05583891]
Model epoch 19: train total loss -44.08721498527179, train mean loss 0.04161612294442185, test mean loss [0.04591174 0.04352275 0.03801626 0.05116465 0.04474613 0.03853003
 0.05167187]
Model epoch 20: train total loss -44.69371176741973, train mean loss 0.03931733987071586, test mean loss [0.04350722 0.04201948 0.03591335 0.04834382 0.04307694 0.03629027
 0.04859273]
Model epoch 21: train total loss -44.914222278333234, train mean loss 0.03791839655228657, test mean loss [0.04130096 0.04107921 0.03435189 0.04615323 0.04051858 0.0362847
 0.04598187]
Model epoch 22: train total loss -45.38449021883211, train mean loss 0.036586859202684854, test mean loss [0.03939584 0.0385777  0.03314787 0.04407799 0.03914531 0.03624375
 0.0433468 ]
Model epoch 23: train total loss -45.85033551547323, train mean loss 0.034580211947851, test mean loss [0.03773507 0.03601086 0.0337863  0.0430529  0.03734135 0.0348133
 0.04169995]
Model epoch 24: train total loss -46.18136308220281, train mean loss 0.03388224955841951, test mean loss [0.03646007 0.0349138  0.03235113 0.04162706 0.03540823 0.03262099
 0.0392119 ]
Model epoch 25: train total loss -46.36840186183971, train mean loss 0.03320653037792158, test mean loss [0.03494328 0.03405891 0.0312916  0.04012717 0.0345694  0.03394536
 0.03753883]
Model epoch 26: train total loss -46.82212600590449, train mean loss 0.03191053343495607, test mean loss [0.03361253 0.03279073 0.03048803 0.04064703 0.03307466 0.0323366
 0.03577565]
Model epoch 27: train total loss -46.96847097862468, train mean loss 0.031404656035067195, test mean loss [0.03327048 0.03204006 0.02971555 0.0409764  0.03247443 0.03149027
 0.0342224 ]
Model epoch 28: train total loss -47.37816638101896, train mean loss 0.030612886452242666, test mean loss [0.03174801 0.0304701  0.02981307 0.03908592 0.03146513 0.03140679
 0.03307892]
Model epoch 29: train total loss -47.61913969238808, train mean loss 0.029931167249982776, test mean loss [0.03075416 0.02988528 0.02996773 0.03798841 0.03083313 0.0301035
 0.03247072]
Model epoch 30: train total loss -48.07928085169434, train mean loss 0.029223459062238465, test mean loss [0.03013171 0.02920766 0.02904998 0.0369348  0.03018114 0.02889668
 0.03154609]
Model epoch 31: train total loss -48.29366875578339, train mean loss 0.028535550064222162, test mean loss [0.02902416 0.02831683 0.02858643 0.03583291 0.02950507 0.02802011
 0.03082588]
Model epoch 32: train total loss -48.54064722754817, train mean loss 0.027959490137817455, test mean loss [0.02821585 0.02768033 0.02878141 0.03486874 0.02928687 0.02727603
 0.03008664]
Model epoch 33: train total loss -48.8193837392165, train mean loss 0.027130381166358672, test mean loss [0.02826333 0.02675036 0.0278565  0.0340904  0.02909295 0.02634927
 0.02863252]
Model epoch 34: train total loss -49.100118534201485, train mean loss 0.02648529227148358, test mean loss [0.02739994 0.02666076 0.02730394 0.03337152 0.0276609  0.02569375
 0.02799877]
Model epoch 35: train total loss -49.37779906184321, train mean loss 0.026457712087668804, test mean loss [0.02609523 0.02601254 0.0266598  0.03277146 0.02754009 0.02502786
 0.02722805]
Model epoch 36: train total loss -49.70425705762469, train mean loss 0.025064983176518875, test mean loss [0.02550087 0.02559334 0.02584496 0.03178248 0.02727346 0.0243724
 0.02650062]
Model epoch 37: train total loss -49.84848112535601, train mean loss 0.02483335515796393, test mean loss [0.02485586 0.02500655 0.02521284 0.03119563 0.02659191 0.02372384
 0.02614908]
Model epoch 38: train total loss -49.972183620336054, train mean loss 0.02452206438915212, test mean loss [0.02433557 0.02467607 0.02510764 0.03063841 0.02563573 0.02374508
 0.02586698]
Model epoch 39: train total loss -50.139754440113336, train mean loss 0.023737714756763235, test mean loss [0.02382119 0.02426415 0.02451156 0.03028056 0.02505195 0.02353517
 0.02558491]
Model epoch 40: train total loss -50.39039764381678, train mean loss 0.023434696376430093, test mean loss [0.02435526 0.02391167 0.02368629 0.03017833 0.02445031 0.02293715
 0.02479797]
Model epoch 41: train total loss -50.610072295253055, train mean loss 0.02290116617597604, test mean loss [0.02371843 0.02426035 0.02400074 0.02881899 0.02417426 0.0227636
 0.02416454]
Model epoch 42: train total loss -50.64483185740919, train mean loss 0.022836910428167795, test mean loss [0.02352197 0.02431589 0.02374159 0.02833131 0.02422755 0.02217605
 0.02363929]
Model epoch 43: train total loss -50.93063109123446, train mean loss 0.022714691066247676, test mean loss [0.02335426 0.02384563 0.02327447 0.02782935 0.02380981 0.02156373
 0.02269882]
Model epoch 44: train total loss -51.1816705286061, train mean loss 0.022066689241152015, test mean loss [0.02281442 0.02354332 0.02312917 0.0273009  0.02386717 0.02130857
 0.0221395 ]
Model epoch 45: train total loss -51.43259932144987, train mean loss 0.021655803128913947, test mean loss [0.02254935 0.02314302 0.02259015 0.02682153 0.02330215 0.02120805
 0.02147887]
Model epoch 46: train total loss -51.40984081796694, train mean loss 0.02207291985427315, test mean loss [0.02210753 0.02303642 0.02268117 0.0265204  0.02322744 0.02104968
 0.02115672]
Model epoch 47: train total loss -51.526837868019086, train mean loss 0.02121601985895187, test mean loss [0.02203984 0.02278879 0.02169134 0.02615497 0.02271335 0.02068309
 0.02148093]
Model epoch 48: train total loss -51.6251365780696, train mean loss 0.020986592192898668, test mean loss [0.02146072 0.02212908 0.02157461 0.02566291 0.02253607 0.02046771
 0.0208937 ]
Model epoch 49: train total loss -51.98866665693827, train mean loss 0.020489059574418725, test mean loss [0.02104478 0.02215494 0.02139281 0.02511047 0.02230634 0.02031782
 0.02051038]
Model epoch 50: train total loss -52.06400290481498, train mean loss 0.020627318766150166, test mean loss [0.02107509 0.02154536 0.0208952  0.02471045 0.0219949  0.01982787
 0.02034821]
Model epoch 51: train total loss -52.18758238697209, train mean loss 0.02017396990802758, test mean loss [0.02094593 0.02106856 0.02045367 0.02458482 0.02109247 0.01940184
 0.0199083 ]
Model epoch 52: train total loss -52.473386633817455, train mean loss 0.019571968473811565, test mean loss [0.02057122 0.02112398 0.02013271 0.02383461 0.02115613 0.01955373
 0.01926215]
Model epoch 53: train total loss -52.49794291308153, train mean loss 0.019694270860496268, test mean loss [0.02073552 0.02048786 0.0200247  0.02342348 0.02057687 0.01941176
 0.01960352]
Model epoch 54: train total loss -52.63201550809345, train mean loss 0.019335413870543258, test mean loss [0.02021773 0.02025109 0.01986026 0.02318457 0.02052264 0.01911025
 0.01910709]
Model epoch 55: train total loss -52.726269838578936, train mean loss 0.019241254566762456, test mean loss [0.01956516 0.01994616 0.01960017 0.02307684 0.02050062 0.01874168
 0.01894367]
Model epoch 56: train total loss -52.83720949187103, train mean loss 0.019228596883487974, test mean loss [0.01911892 0.01940231 0.01963547 0.02319841 0.02027986 0.01829542
 0.01849476]
Model epoch 57: train total loss -53.003193333850554, train mean loss 0.018773093237713492, test mean loss [0.01888852 0.0192086  0.0194533  0.02297776 0.02004021 0.01796202
 0.01842596]
Model epoch 58: train total loss -53.04130179890217, train mean loss 0.018719529934308796, test mean loss [0.01885327 0.01854151 0.01938166 0.02260614 0.01970139 0.01748171
 0.0178424 ]
Model epoch 59: train total loss -53.22314732422901, train mean loss 0.018269594810510006, test mean loss [0.01865139 0.01828241 0.01908719 0.02253736 0.01944015 0.01742596
 0.01764147]
Model epoch 60: train total loss -53.3308282861806, train mean loss 0.017978969358859277, test mean loss [0.01828949 0.01767098 0.01881701 0.02232698 0.019121   0.01695126
 0.0172269 ]
Model epoch 61: train total loss -53.39927658009426, train mean loss 0.017783575430364365, test mean loss [0.01780353 0.01760533 0.01875925 0.02187085 0.01878055 0.01692478
 0.0169473 ]
Model epoch 62: train total loss -53.562801707308324, train mean loss 0.017491559338859045, test mean loss [0.01741199 0.01724527 0.01850636 0.02147042 0.01867251 0.01642754
 0.0169804 ]
Model epoch 63: train total loss -53.64974813937734, train mean loss 0.016944163260010955, test mean loss [0.01744572 0.01682671 0.01828668 0.02104759 0.01802178 0.0158828
 0.01686845]
Model epoch 64: train total loss -53.55274082767591, train mean loss 0.017010384571268657, test mean loss [0.01718236 0.01630597 0.01790334 0.02110794 0.01806129 0.01588271
 0.01741994]
Model epoch 65: train total loss -53.54753153907591, train mean loss 0.016595558802170646, test mean loss [0.0169718  0.01621613 0.01764214 0.02088768 0.01776351 0.01555817
 0.01716257]
Model epoch 66: train total loss -53.84997208147982, train mean loss 0.01651314188314861, test mean loss [0.01674229 0.01597185 0.01751128 0.02072147 0.01751318 0.01550657
 0.01689792]
Model epoch 67: train total loss -53.87733987140108, train mean loss 0.01653124599154497, test mean loss [0.01638297 0.01589508 0.01724713 0.02022878 0.01717879 0.01502999
 0.01662285]
Model epoch 68: train total loss -54.01358633070104, train mean loss 0.015690004818593603, test mean loss [0.01631984 0.01557669 0.01711446 0.02016204 0.01709684 0.01492459
 0.01600796]
Model epoch 69: train total loss -54.05544920456875, train mean loss 0.01591415946091282, test mean loss [0.01649261 0.01523187 0.01670629 0.01973415 0.01724269 0.01468506
 0.01547071]
Model epoch 70: train total loss -54.113053222161895, train mean loss 0.015455722065450391, test mean loss [0.01616007 0.01525339 0.01695644 0.01956986 0.01741601 0.01447696
 0.01519583]
Model epoch 71: train total loss -54.30516790631019, train mean loss 0.01511884268059096, test mean loss [0.01576828 0.01493511 0.01692486 0.0192156  0.0166642  0.01405815
 0.01505144]
Model epoch 72: train total loss -54.333879116325704, train mean loss 0.015668287740220204, test mean loss [0.01549344 0.01457311 0.0168276  0.01899354 0.01623632 0.01367733
 0.01470849]
Model epoch 73: train total loss -54.39568665582761, train mean loss 0.015108712097149826, test mean loss [0.01511576 0.01469122 0.0168911  0.01898802 0.01602612 0.013428
 0.0145806 ]
Model epoch 74: train total loss -54.61025402709014, train mean loss 0.014748511550436433, test mean loss [0.01504923 0.01480648 0.0162171  0.01916172 0.0156237  0.0131024
 0.01410816]
Model epoch 75: train total loss -54.50180495044892, train mean loss 0.015241698077019035, test mean loss [0.0145115  0.01456568 0.01591371 0.01888499 0.01563392 0.01310029
 0.0140572 ]
Model epoch 76: train total loss -54.72686602754968, train mean loss 0.014698257836807713, test mean loss [0.01456099 0.01419309 0.01581466 0.01880746 0.01569951 0.01258809
 0.01415011]
Model epoch 77: train total loss -54.88649155825313, train mean loss 0.01398998046994659, test mean loss [0.01407438 0.01364555 0.01544702 0.018786   0.01533004 0.01208365
 0.0139842 ]
Model epoch 78: train total loss -54.943678210536724, train mean loss 0.01425566426347952, test mean loss [0.01382359 0.01350562 0.01513299 0.01875646 0.01518376 0.01228302
 0.01356261]
Model epoch 79: train total loss -54.9480705997205, train mean loss 0.013816439683125455, test mean loss [0.0141125  0.01311843 0.0147657  0.0181941  0.01512254 0.01179632
 0.01329279]
Model epoch 80: train total loss -55.13068744054525, train mean loss 0.013818783581911784, test mean loss [0.01335828 0.0128873  0.01469857 0.01798213 0.01507623 0.01173716
 0.01320601]
Model epoch 81: train total loss -55.31580515484457, train mean loss 0.01363310378397656, test mean loss [0.01299987 0.01287755 0.01433637 0.01781385 0.01490289 0.01134052
 0.01291567]
Model epoch 82: train total loss -55.466644811868974, train mean loss 0.01311227410704369, test mean loss [0.01275622 0.01252516 0.01414663 0.01759377 0.01451349 0.01113492
 0.01268201]
Model epoch 83: train total loss -55.43145615063617, train mean loss 0.013055971394586557, test mean loss [0.01281695 0.0121564  0.01449984 0.01741469 0.0142821  0.010645
 0.01249765]
Model epoch 84: train total loss -55.356034871729555, train mean loss 0.012893631511119183, test mean loss [0.01248863 0.01197912 0.0136986  0.01718333 0.01403133 0.01079847
 0.01217094]
Model epoch 85: train total loss -55.54064757809518, train mean loss 0.012517825802178821, test mean loss [0.0122155  0.01158856 0.01416279 0.01734948 0.01363747 0.01057355
 0.0117506 ]
Model epoch 86: train total loss -55.63933785379701, train mean loss 0.01250736077720399, test mean loss [0.01204962 0.0115901  0.01387659 0.01679933 0.01389217 0.01025251
 0.01157037]
Model epoch 87: train total loss -55.726201612161276, train mean loss 0.012234982589533983, test mean loss [0.01168425 0.01144215 0.01330186 0.01651189 0.01343975 0.01025606
 0.01155958]
Model epoch 88: train total loss -55.75243127478171, train mean loss 0.012307763568552545, test mean loss [0.01166035 0.01136083 0.01355245 0.01667206 0.01335728 0.0101211
 0.01114609]
Model epoch 89: train total loss -55.942255529878786, train mean loss 0.011960480138502682, test mean loss [0.01128895 0.01109925 0.01339561 0.0165572  0.01307154 0.01003321
 0.0107418 ]
Model epoch 90: train total loss -55.911196003503846, train mean loss 0.011577670936355597, test mean loss [0.01125673 0.01100737 0.01305963 0.01612989 0.01261457 0.00950905
 0.0109199 ]
Model epoch 91: train total loss -55.972650201679095, train mean loss 0.011645398755481958, test mean loss [0.01125877 0.0108002  0.01273174 0.01609175 0.01275018 0.00930459
 0.01097991]
Model epoch 92: train total loss -56.04956224940965, train mean loss 0.011436183727586232, test mean loss [0.01106737 0.01068509 0.01250104 0.015734   0.01262043 0.00938123
 0.01048057]
Model epoch 93: train total loss -56.08544243814929, train mean loss 0.011414988326277815, test mean loss [0.01097848 0.0104363  0.01238236 0.01545759 0.0123258  0.00896554
 0.01009709]
Model epoch 94: train total loss -56.28765843335248, train mean loss 0.011355185233691618, test mean loss [0.0105147  0.01023391 0.01217999 0.01545867 0.01213651 0.00904567
 0.00991083]
Model epoch 95: train total loss -56.35582832080255, train mean loss 0.01100417868934254, test mean loss [0.01048991 0.01008539 0.01177476 0.01542753 0.01194711 0.00853006
 0.01002368]
Model epoch 96: train total loss -56.37324503098896, train mean loss 0.010821080497102682, test mean loss [0.01035537 0.00975236 0.01177371 0.01505544 0.01199818 0.00848961
 0.00973271]
Model epoch 97: train total loss -56.55664679964738, train mean loss 0.010624761922780253, test mean loss [0.01000845 0.00965115 0.01160194 0.01482519 0.01180837 0.00836326
 0.0091994 ]
Model epoch 98: train total loss -56.52924025738006, train mean loss 0.010100365175665933, test mean loss [0.00997273 0.00941675 0.0113861  0.01461942 0.01165865 0.00780353
 0.00922342]
Model epoch 99: train total loss -56.49112576222422, train mean loss 0.010229803217329296, test mean loss [0.01009635 0.00907914 0.01116709 0.01470758 0.01135235 0.00808406
 0.00894687]
Model epoch 100: train total loss -56.54066350733317, train mean loss 0.010205696729027151, test mean loss [0.00989797 0.00895391 0.0111309  0.01426499 0.01131359 0.00787903
 0.00879413]
Model epoch 101: train total loss -56.643470665363125, train mean loss 0.010124682263103557, test mean loss [0.00953592 0.00861819 0.01109667 0.0141115  0.01108034 0.00768118
 0.00864567]
Model epoch 102: train total loss -56.753582986904746, train mean loss 0.009841345057017163, test mean loss [0.00925899 0.00847659 0.01097344 0.01418619 0.01108875 0.00768012
 0.00814976]
Model epoch 103: train total loss -56.98767789788689, train mean loss 0.009409365174642696, test mean loss [0.00922993 0.00834031 0.01053684 0.01403646 0.01070174 0.00736052
 0.00797197]
Model epoch 104: train total loss -56.75895724443212, train mean loss 0.009270849602390656, test mean loss [0.00896352 0.00847698 0.01093638 0.01392259 0.01069637 0.00728453
 0.00812459]
Model epoch 105: train total loss -56.96553752006794, train mean loss 0.009543003982387104, test mean loss [0.0088986  0.00829957 0.01031311 0.01376551 0.01025056 0.00695272
 0.00787148]
Model epoch 106: train total loss -57.05870009378014, train mean loss 0.009102927580598871, test mean loss [0.00871104 0.0078576  0.01033327 0.01347977 0.01040174 0.00688881
 0.00782799]
Model epoch 107: train total loss -57.03733726314075, train mean loss 0.009125000734721918, test mean loss [0.0085992  0.00771412 0.01001995 0.01347825 0.01015248 0.00691332
 0.00766731]
Model epoch 108: train total loss -57.175597524990884, train mean loss 0.008766277588474748, test mean loss [0.00865132 0.00759554 0.01022102 0.01323366 0.00988041 0.00662169
 0.00720359]
Model epoch 109: train total loss -56.99170490844916, train mean loss 0.008956723176436658, test mean loss [0.00844631 0.00758858 0.00998529 0.01301909 0.00976971 0.00650347
 0.00718818]
Model epoch 110: train total loss -57.06521562401107, train mean loss 0.008762981765407898, test mean loss [0.00840882 0.00744779 0.00981992 0.01296183 0.00959182 0.00641271
 0.00731988]
Model epoch 111: train total loss -57.24350574260764, train mean loss 0.008522625676672292, test mean loss [0.00819152 0.00764304 0.00948692 0.01286532 0.00940547 0.00668734
 0.00717844]
Model epoch 112: train total loss -57.328272343228164, train mean loss 0.00825787472526805, test mean loss [0.00824938 0.00734699 0.00939203 0.01256777 0.00932744 0.00620451
 0.00710614]
Model epoch 113: train total loss -57.29457232238527, train mean loss 0.008178681513354517, test mean loss [0.00827881 0.00687357 0.0089595  0.01253583 0.00920641 0.00603251
 0.00688569]
Model epoch 114: train total loss -57.49448209902069, train mean loss 0.0081980722103613, test mean loss [0.00810024 0.0069667  0.00904412 0.01237635 0.00909442 0.00579799
 0.00673293]
Model epoch 115: train total loss -57.35232270734278, train mean loss 0.008020366989163037, test mean loss [0.00790682 0.0067384  0.00893681 0.01270965 0.00893941 0.00562599
 0.00659043]
Model epoch 116: train total loss -57.57996376380332, train mean loss 0.007919138847086971, test mean loss [0.00730837 0.00656148 0.0086369  0.01233879 0.00878655 0.00556621
 0.00645122]
Model epoch 117: train total loss -57.63765202681813, train mean loss 0.007656431532294876, test mean loss [0.00739182 0.00626573 0.00870439 0.01213251 0.00861142 0.00574416
 0.006389  ]
Model epoch 118: train total loss -57.71835682532665, train mean loss 0.007673089677925425, test mean loss [0.00746085 0.00604365 0.00841496 0.01217399 0.00834278 0.00532314
 0.0061211 ]
Model epoch 119: train total loss -57.72556498010245, train mean loss 0.0073493138233844384, test mean loss [0.00718431 0.00609228 0.00841796 0.0117517  0.00835202 0.00529482
 0.0060104 ]
Model epoch 120: train total loss -57.59519354962377, train mean loss 0.007311154580802103, test mean loss [0.0069998  0.00594274 0.00827517 0.01181219 0.00792422 0.00542217
 0.00588337]
Model epoch 121: train total loss -57.72571870918999, train mean loss 0.007235716003693366, test mean loss [0.0070903  0.00586381 0.00794795 0.01152628 0.00788218 0.00540575
 0.00556065]
Model epoch 122: train total loss -57.62286867303191, train mean loss 0.0072870546581193865, test mean loss [0.00675579 0.005667   0.00847147 0.01143857 0.00778175 0.00513744
 0.00579898]
Model epoch 123: train total loss -57.82154007948486, train mean loss 0.007010537786231633, test mean loss [0.00658743 0.00575272 0.00810159 0.01149445 0.00813592 0.00518098
 0.005561  ]
Model epoch 124: train total loss -57.85821949043192, train mean loss 0.0071273170561581955, test mean loss [0.00660154 0.00531243 0.0080097  0.01139989 0.00762101 0.00486854
 0.00563393]
Model epoch 125: train total loss -58.067982160375166, train mean loss 0.006573665254203412, test mean loss [0.00633873 0.00534181 0.00765798 0.01121654 0.00754906 0.0048134
 0.00533451]
Model epoch 126: train total loss -57.887487328186424, train mean loss 0.006862437803573154, test mean loss [0.00607609 0.00514459 0.0076088  0.01114762 0.00725211 0.00469847
 0.00526036]
Model epoch 127: train total loss -58.010068266051626, train mean loss 0.006669955417500662, test mean loss [0.00645182 0.00493565 0.00728759 0.01085844 0.00761275 0.00459363
 0.00505513]
Model epoch 128: train total loss -58.1038891550229, train mean loss 0.006523116628652307, test mean loss [0.00622142 0.00479644 0.007273   0.01083296 0.00750515 0.00449872
 0.00497082]
Model epoch 129: train total loss -57.85084484440492, train mean loss 0.006523240513796867, test mean loss [0.00599076 0.00460566 0.00711291 0.01047411 0.0072385  0.00446459
 0.00501817]
Model epoch 130: train total loss -58.20557739996004, train mean loss 0.006286312798275035, test mean loss [0.00622777 0.00451143 0.00705077 0.01052106 0.00718075 0.00443067
 0.00476833]
Model epoch 131: train total loss -58.283029673768446, train mean loss 0.00621604788555074, test mean loss [0.00573513 0.00444569 0.00680006 0.01028996 0.00699646 0.00408537
 0.00471577]
Model epoch 132: train total loss -58.26353917966557, train mean loss 0.0061636229103685155, test mean loss [0.00573783 0.0043216  0.00659666 0.01032143 0.00668267 0.00403773
 0.00474916]
Model epoch 133: train total loss -58.28348014054752, train mean loss 0.005901626938543577, test mean loss [0.00592123 0.00411458 0.00677095 0.01002276 0.0067579  0.00389988
 0.00460537]
Model epoch 134: train total loss -58.30870224309008, train mean loss 0.005797656451388485, test mean loss [0.00575787 0.00456698 0.00642424 0.00998298 0.00663171 0.00389886
 0.00438054]
Model epoch 135: train total loss -58.25771048172928, train mean loss 0.005881775102970978, test mean loss [0.00551765 0.00459857 0.00632432 0.00990457 0.00637016 0.00386805
 0.00427252]
Model epoch 136: train total loss -58.57172312948801, train mean loss 0.0056283409883783, test mean loss [0.00551644 0.00430019 0.00609408 0.00945379 0.00627797 0.00382547
 0.00425751]
Model epoch 137: train total loss -58.562335239214704, train mean loss 0.005598072214150369, test mean loss [0.0052761  0.0041617  0.0061574  0.00972936 0.00633378 0.00348825
 0.00417642]
Model epoch 138: train total loss -58.78199727182474, train mean loss 0.005474486226521381, test mean loss [0.00514781 0.00416648 0.00610109 0.00935941 0.00600852 0.00340458
 0.00386524]
Model epoch 139: train total loss -58.79675469537815, train mean loss 0.005329580385043377, test mean loss [0.00511859 0.00395066 0.00588235 0.0093045  0.00621728 0.00336044
 0.00389662]
Model epoch 140: train total loss -58.85262275025639, train mean loss 0.0051498451648620165, test mean loss [0.00493357 0.00370886 0.00602295 0.00919605 0.0057579  0.00332227
 0.00381959]
Model epoch 141: train total loss -58.78615157490327, train mean loss 0.0052110298848513275, test mean loss [0.00485282 0.00364421 0.00605026 0.00921681 0.00588659 0.00325389
 0.0037651 ]
Model epoch 142: train total loss -58.744868457363644, train mean loss 0.005035707315992227, test mean loss [0.00468126 0.00347516 0.00550845 0.00883103 0.00555809 0.00322809
 0.00368723]
Model epoch 143: train total loss -58.89239097390715, train mean loss 0.005117145718249346, test mean loss [0.00443203 0.0033692  0.00551836 0.00874018 0.00541622 0.00317573
 0.00373102]
Model epoch 144: train total loss -58.81915586376473, train mean loss 0.004952738419523668, test mean loss [0.00461094 0.00344044 0.00530525 0.00852216 0.00532397 0.00305662
 0.00357686]
Model epoch 145: train total loss -58.87300211928782, train mean loss 0.004864259319183059, test mean loss [0.00464854 0.00329292 0.00529604 0.00842802 0.00530536 0.0029539
 0.00362143]
Model epoch 146: train total loss -59.08226283677132, train mean loss 0.0046211005942493775, test mean loss [0.0044447  0.00307101 0.00527514 0.00837114 0.00529959 0.00294631
 0.00337344]
Model epoch 147: train total loss -58.984318805882296, train mean loss 0.004623687220951248, test mean loss [0.00439845 0.00315657 0.00510698 0.00819219 0.00506657 0.00282664
 0.00337297]
Model epoch 148: train total loss -59.010723123409385, train mean loss 0.004717143242515549, test mean loss [0.0042646  0.00283762 0.005038   0.0082292  0.00496179 0.0027928
 0.00315537]
Model epoch 149: train total loss -59.13226296153936, train mean loss 0.004526716089938921, test mean loss [0.00406635 0.00291676 0.0049408  0.00824651 0.00478479 0.00263344
 0.00318065]
Model epoch 150: train total loss -59.038936591272524, train mean loss 0.004478521190851641, test mean loss [0.0046209  0.00271745 0.00482909 0.00796188 0.00476968 0.00286292
 0.0030585 ]
Model epoch 151: train total loss -58.99795801118746, train mean loss 0.004323728998176123, test mean loss [0.00416078 0.0028763  0.00499523 0.007789   0.00444991 0.00261257
 0.00322537]
Model epoch 152: train total loss -59.19319220609189, train mean loss 0.004184037875635603, test mean loss [0.00398526 0.00285959 0.00493586 0.00780993 0.00458217 0.00272909
 0.00298243]
Model epoch 153: train total loss -59.12857213386123, train mean loss 0.0043400324429826815, test mean loss [0.00400527 0.00262201 0.00474162 0.00774308 0.00441202 0.00248823
 0.0030085 ]
Model epoch 154: train total loss -59.20810450954133, train mean loss 0.004303420911517653, test mean loss [0.0038983  0.00255574 0.00467703 0.00748096 0.00428757 0.00233973
 0.00298524]
Model epoch 155: train total loss -59.33013103247511, train mean loss 0.004076621009320186, test mean loss [0.00384867 0.00238499 0.00460144 0.0073129  0.00406218 0.00238125
 0.00291495]
Model epoch 156: train total loss -59.253626076269605, train mean loss 0.003984104306832794, test mean loss [0.00371955 0.00245759 0.00447183 0.00734318 0.00425528 0.00233456
 0.00288483]
Model epoch 157: train total loss -59.434619149631985, train mean loss 0.0039214907029351785, test mean loss [0.00364472 0.00237743 0.0044494  0.00715078 0.00418179 0.00220757
 0.00277426]
Model epoch 158: train total loss -59.393003167639435, train mean loss 0.0039530664072239645, test mean loss [0.00393389 0.00224907 0.00437837 0.00713835 0.00396237 0.00210348
 0.0028561 ]
Model epoch 159: train total loss -59.26545342530536, train mean loss 0.0037396379892399865, test mean loss [0.00372632 0.00238047 0.00430829 0.00687115 0.00400624 0.00210988
 0.00282617]
Model epoch 160: train total loss -59.321741094346926, train mean loss 0.00372230257342879, test mean loss [0.00353818 0.00217237 0.00410039 0.0067064  0.00382218 0.00213408
 0.00268847]
Model epoch 161: train total loss -59.39884880317841, train mean loss 0.00376562179684333, test mean loss [0.00345982 0.00227099 0.00417489 0.00694966 0.00382411 0.00206078
 0.0025923 ]
Model epoch 162: train total loss -59.36806036237265, train mean loss 0.003739414011337137, test mean loss [0.0033391  0.00219594 0.00402057 0.00692547 0.00360841 0.00202212
 0.00258386]
Model epoch 163: train total loss -59.54100264562321, train mean loss 0.003630852511698166, test mean loss [0.00321558 0.00207664 0.00387204 0.00690265 0.00362487 0.00198899
 0.00282073]
Model epoch 164: train total loss -59.683373213727734, train mean loss 0.003566898978445917, test mean loss [0.00313682 0.00197318 0.00385218 0.00665655 0.00356727 0.00194236
 0.00274016]
Model epoch 165: train total loss -59.5896876913673, train mean loss 0.003639264920229808, test mean loss [0.00304469 0.0019857  0.00386744 0.00643663 0.00350071 0.00184527
 0.00261753]
Model epoch 166: train total loss -59.749562410793914, train mean loss 0.003326643954060992, test mean loss [0.00299058 0.00198954 0.0037316  0.0064766  0.00342533 0.00185458
 0.00262054]
Model epoch 167: train total loss -59.70619310211074, train mean loss 0.003546097270298273, test mean loss [0.00309059 0.00195277 0.0035844  0.00635115 0.00331071 0.00182591
 0.00255329]
Model epoch 168: train total loss -59.82868616060008, train mean loss 0.003425111767865578, test mean loss [0.00298404 0.00198159 0.00343756 0.00610427 0.00322616 0.00176109
 0.00249199]
Model epoch 169: train total loss -59.72414427644297, train mean loss 0.0032207360957815408, test mean loss [0.00287905 0.00196214 0.00342832 0.00609684 0.00326283 0.00174673
 0.00244141]
Model epoch 170: train total loss -59.903900061276836, train mean loss 0.0030458798414586047, test mean loss [0.0028175  0.00180422 0.00341464 0.00600231 0.00315729 0.00172088
 0.00227684]
Model epoch 171: train total loss -59.91866770385297, train mean loss 0.0032147560741149694, test mean loss [0.00285211 0.00176318 0.00338328 0.00607845 0.00299014 0.00167839
 0.00236571]
Model epoch 172: train total loss -59.95211960249644, train mean loss 0.003088188383056854, test mean loss [0.00279208 0.00176064 0.00339898 0.00584022 0.00290029 0.00167963
 0.00222704]
Model epoch 173: train total loss -59.92284265252646, train mean loss 0.0029421096287615594, test mean loss [0.00273575 0.0016788  0.00332731 0.00586889 0.00304616 0.00158392
 0.00240525]
Model epoch 174: train total loss -59.954313439549765, train mean loss 0.0031606469276364885, test mean loss [0.0026732  0.00167466 0.00337482 0.00571819 0.00283302 0.0016171
 0.00225966]
Model epoch 175: train total loss -59.921563629340895, train mean loss 0.0029952047128403076, test mean loss [0.00272324 0.00178718 0.00337905 0.00560094 0.00277671 0.00156225
 0.00222068]
Model epoch 176: train total loss -59.946024706399164, train mean loss 0.002905782600534264, test mean loss [0.00262618 0.00157529 0.0031857  0.00560514 0.00274172 0.00152669
 0.00233715]
Model epoch 177: train total loss -59.77680949198235, train mean loss 0.0029264722664595275, test mean loss [0.00266733 0.00159612 0.00305176 0.00541435 0.00290206 0.00144137
 0.0022453 ]
Model epoch 178: train total loss -59.943105122444585, train mean loss 0.002776551135332883, test mean loss [0.00246343 0.00152795 0.00318697 0.00514937 0.00287704 0.00142925
 0.00222975]
Model epoch 179: train total loss -59.99680016805699, train mean loss 0.0026421028530101017, test mean loss [0.00259007 0.00151204 0.00305653 0.00539619 0.0028539  0.00135347
 0.00225897]
Model epoch 180: train total loss -59.95303314263518, train mean loss 0.002899369921634301, test mean loss [0.00258731 0.00145761 0.00296806 0.00532922 0.00268753 0.00141477
 0.00212442]
Model epoch 181: train total loss -60.16178721091933, train mean loss 0.0025559186949085317, test mean loss [0.00263875 0.00146635 0.00302909 0.00506817 0.00276077 0.00136225
 0.00208985]
Model epoch 182: train total loss -60.1093316558047, train mean loss 0.0026740982497702463, test mean loss [0.00243611 0.00137488 0.00290678 0.00496305 0.00276684 0.00137233
 0.00211797]
Model epoch 183: train total loss -59.93379045227054, train mean loss 0.002663332489384624, test mean loss [0.00250686 0.00138947 0.00281796 0.00507054 0.0029188  0.00132792
 0.00204648]
Model epoch 184: train total loss -60.08508959789508, train mean loss 0.002902476983038327, test mean loss [0.00240808 0.00144281 0.00287321 0.0047765  0.00281659 0.00133551
 0.00194231]
Model epoch 185: train total loss -60.15920524891132, train mean loss 0.0027688002013258545, test mean loss [0.00230253 0.00131187 0.00283222 0.00477084 0.00272209 0.0013601
 0.00201169]
Model epoch 186: train total loss -60.198547945852866, train mean loss 0.0025759262933727507, test mean loss [0.00231048 0.00140193 0.00272196 0.0048652  0.00257024 0.00121597
 0.00195146]
Model epoch 187: train total loss -60.258187617185364, train mean loss 0.0026818439680384525, test mean loss [0.00234241 0.00133929 0.00272763 0.00490285 0.00248506 0.00119406
 0.00198656]
Model epoch 188: train total loss -60.24206623707229, train mean loss 0.0025865682753716045, test mean loss [0.00232026 0.00134239 0.00259681 0.00490046 0.0025865  0.00114105
 0.00197662]
Model epoch 189: train total loss -60.144032909277335, train mean loss 0.0024765011862124906, test mean loss [0.00230273 0.00131295 0.00254991 0.00457906 0.00245147 0.00138679
 0.00184989]
Model epoch 190: train total loss -59.94723089680259, train mean loss 0.0025818552807653204, test mean loss [0.00225668 0.00129302 0.00315811 0.00444426 0.00249586 0.00142704
 0.00185367]
Model epoch 191: train total loss -60.19095865164168, train mean loss 0.0023119555597052254, test mean loss [0.00221932 0.00125563 0.00268593 0.00444751 0.00242688 0.00127852
 0.00193333]
Model epoch 192: train total loss -60.26413987116669, train mean loss 0.0024759096304955786, test mean loss [0.00212277 0.0011819  0.00257218 0.00436133 0.00237243 0.00130756
 0.00179581]
Model epoch 193: train total loss -60.407467867994946, train mean loss 0.0023556579948380394, test mean loss [0.00212962 0.00128082 0.00256501 0.00437166 0.00236114 0.00123978
 0.00174914]
Model epoch 194: train total loss -60.41686437240126, train mean loss 0.0023447310882669515, test mean loss [0.00213197 0.00120119 0.00257074 0.00428725 0.00237842 0.0011234
 0.00176293]
Model epoch 195: train total loss -60.61935776110151, train mean loss 0.002443140172402148, test mean loss [0.00208503 0.00118369 0.00241912 0.00434813 0.0023319  0.00107349
 0.00174863]
Model epoch 196: train total loss -60.72312554589599, train mean loss 0.002312197386722517, test mean loss [0.00207029 0.00117804 0.00247975 0.00412194 0.00225158 0.00110624
 0.00168446]
Model epoch 197: train total loss -60.65633094658504, train mean loss 0.0022697669286012635, test mean loss [0.00202225 0.00117574 0.00239284 0.00401701 0.00212305 0.00111206
 0.0017147 ]
Model epoch 198: train total loss -60.699194322735245, train mean loss 0.0021414339400514146, test mean loss [0.00188857 0.00114757 0.00240771 0.00399469 0.00208249 0.00104232
 0.00159296]
Model epoch 199: train total loss -60.611209654373916, train mean loss 0.0021565802368925364, test mean loss [0.00209977 0.00112385 0.00230257 0.00406287 0.00210941 0.00098999
 0.00169953]
Model epoch 200: train total loss -60.68687581035381, train mean loss 0.0021773260098601225, test mean loss [0.002076   0.00111264 0.00235012 0.00393326 0.00212983 0.00098215
 0.0016613 ]
Model epoch 201: train total loss -60.77238904196702, train mean loss 0.0022152261411071622, test mean loss [0.00196052 0.00108503 0.00221613 0.00396856 0.002028   0.00100679
 0.00165007]
Model epoch 202: train total loss -60.76067579252654, train mean loss 0.00215397151259398, test mean loss [0.00186615 0.00105973 0.00228372 0.00389212 0.00192346 0.0010188
 0.0015558 ]
Model epoch 203: train total loss -60.883227951471696, train mean loss 0.0020497413904551924, test mean loss [0.00187749 0.00109514 0.00221156 0.00385952 0.00197315 0.00093879
 0.00167208]
Model epoch 204: train total loss -60.78159296305854, train mean loss 0.0021096753198634683, test mean loss [0.00192677 0.00106476 0.00220008 0.00370447 0.00193276 0.0009474
 0.0015745 ]
Model epoch 205: train total loss -60.86679398749805, train mean loss 0.0019962934517793033, test mean loss [0.00183527 0.00099552 0.00215452 0.00356433 0.0018582  0.00092404
 0.00155194]
Model epoch 206: train total loss -60.753228375867124, train mean loss 0.0018846475538121495, test mean loss [0.00183034 0.00100451 0.00215903 0.00354687 0.00192323 0.00103936
 0.00158283]
Model epoch 207: train total loss -60.86567400424379, train mean loss 0.0018689586377874008, test mean loss [0.00187109 0.00096842 0.00209358 0.00350205 0.00182591 0.00096194
 0.00159802]
Model epoch 208: train total loss -60.703761492998794, train mean loss 0.002055423569676369, test mean loss [0.00234307 0.00098624 0.00209362 0.00346054 0.00183237 0.00087083
 0.00153073]
Model epoch 209: train total loss -60.798446391970195, train mean loss 0.002001666401571825, test mean loss [0.00189855 0.00094485 0.00210978 0.00342279 0.00177847 0.00084993
 0.00146084]
Model epoch 210: train total loss -61.00818538288421, train mean loss 0.0018636543666474064, test mean loss [0.00195548 0.00096406 0.00210864 0.00334819 0.0016859  0.00083809
 0.00146758]
Model epoch 211: train total loss -60.966832349138244, train mean loss 0.001920869864519076, test mean loss [0.00183995 0.00093934 0.00220253 0.0034046  0.00169667 0.00083267
 0.00147542]
Model epoch 212: train total loss -61.07070142995966, train mean loss 0.0018727508128521461, test mean loss [0.00195485 0.0009628  0.00203399 0.00335937 0.00164299 0.00079279
 0.00138554]
Model epoch 213: train total loss -61.113935334602274, train mean loss 0.0018517796566862466, test mean loss [0.00173627 0.00091782 0.00194138 0.00333523 0.00170654 0.00085591
 0.00138183]
Model epoch 214: train total loss -61.03593527900906, train mean loss 0.001841356735788938, test mean loss [0.00173921 0.00087125 0.00193772 0.0032419  0.0015971  0.00082473
 0.00137282]
Model epoch 215: train total loss -61.26037151248254, train mean loss 0.0017442138428331998, test mean loss [0.00170639 0.00085406 0.00200943 0.00322897 0.00159197 0.00078433
 0.00133209]
Model epoch 216: train total loss -61.277788924326174, train mean loss 0.001877783413574839, test mean loss [0.00167351 0.00081963 0.00192754 0.00318095 0.00158206 0.00079934
 0.001312  ]
Model epoch 217: train total loss -61.30411477178702, train mean loss 0.0016128727843090166, test mean loss [0.00163162 0.0008177  0.0018486  0.00308226 0.00161999 0.00078108
 0.00125514]
Model epoch 218: train total loss -61.120925433105704, train mean loss 0.0017140503044032313, test mean loss [0.00166066 0.00079938 0.0018338  0.00314316 0.00160659 0.00072968
 0.0013096 ]
Model epoch 219: train total loss -61.06450399636151, train mean loss 0.0017155836016991253, test mean loss [0.00161001 0.00088382 0.00178374 0.00305195 0.00164931 0.00076072
 0.00132866]
Model epoch 220: train total loss -61.13653558647766, train mean loss 0.001690671485759906, test mean loss [0.0016112  0.00080893 0.00183486 0.0029916  0.00155858 0.00070392
 0.0012225 ]
Model epoch 221: train total loss -61.245467464744685, train mean loss 0.0016210616569500126, test mean loss [0.00157171 0.00081206 0.00179478 0.00309843 0.00158179 0.00067265
 0.00126879]
Model epoch 222: train total loss -61.45009023863816, train mean loss 0.0016741667099322312, test mean loss [0.00152873 0.00081039 0.00172129 0.0029791  0.00154838 0.00069856
 0.00123392]
Model epoch 223: train total loss -61.24726588353466, train mean loss 0.001595416085925733, test mean loss [0.0016145  0.00082748 0.00166757 0.00287946 0.00145041 0.00063587
 0.00122535]
Model epoch 224: train total loss -61.25721656552731, train mean loss 0.0016337601488339115, test mean loss [0.00155195 0.00082782 0.00170173 0.00289194 0.00148046 0.0006465
 0.00122292]
Model epoch 225: train total loss -61.22913010018067, train mean loss 0.0016076996112247945, test mean loss [0.00154751 0.00079595 0.00165571 0.0027549  0.00156631 0.0006239
 0.00121985]
Model epoch 226: train total loss -61.10500620592693, train mean loss 0.0016299089677370814, test mean loss [0.00161389 0.00079493 0.00157016 0.0026988  0.00151562 0.00072781
 0.0011847 ]
Model epoch 227: train total loss -61.21183834291085, train mean loss 0.0015719513825510234, test mean loss [0.00156496 0.00075623 0.00162469 0.00270772 0.0014596  0.00070398
 0.00117971]
Model epoch 228: train total loss -61.25796677028609, train mean loss 0.0015114925368207833, test mean loss [0.00155606 0.0007682  0.00169021 0.00268191 0.00145802 0.00061393
 0.00109797]
Model epoch 229: train total loss -61.386684256679736, train mean loss 0.0015108511976654544, test mean loss [0.00151024 0.00072309 0.00174545 0.00255292 0.00141666 0.00060485
 0.00114822]
Model epoch 230: train total loss -61.31708530619383, train mean loss 0.0014929551823484792, test mean loss [0.00142174 0.00073367 0.00160963 0.00257312 0.00145621 0.00059248
 0.00111441]
Model epoch 231: train total loss -61.49627219011518, train mean loss 0.0013906651634838858, test mean loss [0.00137789 0.00072819 0.00163435 0.00255466 0.00134909 0.00059209
 0.00111653]
Model epoch 232: train total loss -61.51593748275439, train mean loss 0.0013926539733850564, test mean loss [0.00146755 0.00069041 0.00156079 0.00261821 0.00133487 0.00057401
 0.00111046]
Model epoch 233: train total loss -61.578148480636, train mean loss 0.0014489394663989715, test mean loss [0.00146439 0.00069036 0.00158857 0.00248862 0.00134796 0.00054287
 0.00113812]
Model epoch 234: train total loss -61.71874758634975, train mean loss 0.0013179387129903745, test mean loss [0.00144002 0.00067007 0.00155793 0.00241262 0.00130256 0.00053839
 0.00104296]
Model epoch 235: train total loss -61.55373978287325, train mean loss 0.001403038270995684, test mean loss [0.00154118 0.00065804 0.00151736 0.00234696 0.00122778 0.00054096
 0.00117052]
Model epoch 236: train total loss -61.40804763756623, train mean loss 0.0013453549695870042, test mean loss [0.00136621 0.00065459 0.0015499  0.00241098 0.00124451 0.00051786
 0.00121078]
Model epoch 237: train total loss -61.4660156382114, train mean loss 0.0014590374482187042, test mean loss [0.00135175 0.00062364 0.00155568 0.00241258 0.00124258 0.00051334
 0.001103  ]
Model epoch 238: train total loss -61.59236516719468, train mean loss 0.001421257649378337, test mean loss [0.0012995  0.00061083 0.00150916 0.00230965 0.00123543 0.00049975
 0.00108068]
Model epoch 239: train total loss -61.610445484975024, train mean loss 0.0013418236986230407, test mean loss [0.00136923 0.00060105 0.00141527 0.00231479 0.00126133 0.00048859
 0.00100733]
Model epoch 240: train total loss -61.757236350631615, train mean loss 0.0012926699059942705, test mean loss [0.00124642 0.00066273 0.0013472  0.0023584  0.00125359 0.00050739
 0.00101794]
Model epoch 241: train total loss -61.5513184326586, train mean loss 0.0013106081165518172, test mean loss [0.00124654 0.00068124 0.00142381 0.00224062 0.00123293 0.00050963
 0.00096648]
Model epoch 242: train total loss -61.60327166253954, train mean loss 0.0013095619623180099, test mean loss [0.00134608 0.00062339 0.00140894 0.00223394 0.00116907 0.00047121
 0.00100237]
Model epoch 243: train total loss -61.73063615834877, train mean loss 0.0013192870165269317, test mean loss [0.00129624 0.00058556 0.0013671  0.00231024 0.0012558  0.00047957
 0.00094397]
Model epoch 244: train total loss -61.81564633370223, train mean loss 0.0013070414920830326, test mean loss [0.00134392 0.000577   0.00139765 0.00225314 0.00115672 0.00047328
 0.00092253]
Model epoch 245: train total loss -61.8088215604289, train mean loss 0.0013166094855452729, test mean loss [0.00132694 0.00054991 0.00140319 0.0021171  0.0011032  0.0004642
 0.00091791]
Model epoch 246: train total loss -61.806629842497586, train mean loss 0.0012064104802917183, test mean loss [0.0012512  0.00057779 0.00135206 0.00210579 0.00108582 0.00046473
 0.00090571]
Model epoch 247: train total loss -61.75585626652011, train mean loss 0.0011373136512596031, test mean loss [0.00121672 0.00058288 0.00127346 0.00209168 0.00112194 0.00047291
 0.00088703]
Model epoch 248: train total loss -61.68538389385384, train mean loss 0.0011122910368813858, test mean loss [0.00120746 0.00059059 0.00126728 0.00207978 0.00109091 0.00047241
 0.00095035]
Model epoch 249: train total loss -61.963663946520235, train mean loss 0.001094837270339642, test mean loss [0.00116908 0.00054328 0.00128979 0.00212911 0.00106981 0.00046214
 0.00089383]
Model epoch 250: train total loss -61.90710716199034, train mean loss 0.0011789018945247804, test mean loss [0.00122453 0.0005552  0.00125699 0.00204787 0.00106775 0.00046295
 0.0008555 ]
Model epoch 251: train total loss -61.496004244183176, train mean loss 0.0011542535785371332, test mean loss [0.00122286 0.00057272 0.00141531 0.00196842 0.00104171 0.00044836
 0.00083503]
Model epoch 252: train total loss -61.784464354964776, train mean loss 0.0011782131844083603, test mean loss [0.00117984 0.00052802 0.00135704 0.00197942 0.00100771 0.00044699
 0.00085893]
Model epoch 253: train total loss -61.98248866071346, train mean loss 0.0010901060282077124, test mean loss [0.00117166 0.00052952 0.00127413 0.00191201 0.00093611 0.00044234
 0.00080467]
Model epoch 254: train total loss -61.85129022010969, train mean loss 0.0012472071862189165, test mean loss [0.00115141 0.00055442 0.0012779  0.00195617 0.00096075 0.00044053
 0.00085674]
Model epoch 255: train total loss -62.06670753770706, train mean loss 0.0011367905339449533, test mean loss [0.00112746 0.00052317 0.00123295 0.00192943 0.00095531 0.00042996
 0.0008971 ]
Model epoch 256: train total loss -61.92733480795676, train mean loss 0.0011086030835680497, test mean loss [0.00114767 0.00050325 0.00123731 0.00190788 0.00090878 0.00043804
 0.00081486]
Model epoch 257: train total loss -61.38393629589829, train mean loss 0.0011464377296992877, test mean loss [0.00115226 0.00050477 0.00122272 0.00200154 0.00091779 0.0004553
 0.00092851]
Model epoch 258: train total loss -61.62287993214198, train mean loss 0.0012190825013451872, test mean loss [0.0011522  0.00050726 0.00112303 0.00187022 0.0009131  0.00041589
 0.00092737]
Model epoch 259: train total loss -61.57575545257108, train mean loss 0.0011285427712823682, test mean loss [0.00107701 0.00050284 0.00116928 0.00185656 0.00094725 0.00040469
 0.00091168]
Model epoch 260: train total loss -61.994487771711846, train mean loss 0.0009976795184462415, test mean loss [0.00104984 0.00049511 0.00114775 0.00180052 0.00087808 0.00042854
 0.00078678]
Model epoch 261: train total loss -61.97813650975104, train mean loss 0.0010766825583165525, test mean loss [0.00102027 0.00047053 0.00122326 0.0018367  0.00086546 0.00070917
 0.00082375]
Model epoch 262: train total loss -61.69543480098638, train mean loss 0.0010538354558008896, test mean loss [0.00098111 0.00049927 0.00110845 0.00174736 0.00088942 0.00057705
 0.00079505]
Model epoch 263: train total loss -61.88783831167521, train mean loss 0.0010875213476673588, test mean loss [0.0010004  0.00048071 0.00103734 0.00172047 0.00093438 0.00049179
 0.00076424]
Model epoch 264: train total loss -62.030782491246185, train mean loss 0.0011175860710160434, test mean loss [0.00099024 0.00049381 0.00110265 0.00169997 0.00087464 0.00046304
 0.00074446]
Model epoch 265: train total loss -62.178569255817976, train mean loss 0.0010488228940984754, test mean loss [0.0009653  0.00050864 0.00109425 0.00170814 0.000806   0.00044505
 0.00073811]
Model epoch 266: train total loss -62.01914135589862, train mean loss 0.001076977144483352, test mean loss [0.00094542 0.00087218 0.00108517 0.00164408 0.00077478 0.0004299
 0.00072157]
Model epoch 267: train total loss -61.928864452024555, train mean loss 0.000981414900623443, test mean loss [0.00100222 0.00076671 0.00102525 0.00165617 0.00074732 0.00044945
 0.00072821]
Model epoch 268: train total loss -61.86098060691113, train mean loss 0.0010843494152847114, test mean loss [0.00101877 0.00071237 0.00101797 0.00170456 0.00073203 0.00045807
 0.0007075 ]
Model epoch 269: train total loss -62.103533426230626, train mean loss 0.001012470568443287, test mean loss [0.00102513 0.00069601 0.00106007 0.00163585 0.0006906  0.00042582
 0.00073951]
Model epoch 270: train total loss -62.11128284922146, train mean loss 0.0011040357251295829, test mean loss [0.00097966 0.0006748  0.00103102 0.00166539 0.00070156 0.00040786
 0.00069939]
Model epoch 271: train total loss -62.1062706016743, train mean loss 0.0010594339684775334, test mean loss [0.00093055 0.00086554 0.00096298 0.00165876 0.00069877 0.00038938
 0.00067535]
Model epoch 272: train total loss -61.9834749490699, train mean loss 0.0010532025774574124, test mean loss [0.00090193 0.00076379 0.00102249 0.00167635 0.00066631 0.00038369
 0.00075079]
Model epoch 273: train total loss -62.038838940055555, train mean loss 0.0010611434923447278, test mean loss [0.00088268 0.0007798  0.0009221  0.00164712 0.00069617 0.00038987
 0.00072221]
Model epoch 274: train total loss -62.025135573597105, train mean loss 0.0010580901734797159, test mean loss [0.00089176 0.00076094 0.00103831 0.00160238 0.00064455 0.00037259
 0.00067478]
Model epoch 275: train total loss -62.30086746732017, train mean loss 0.0009832573584917955, test mean loss [0.00088285 0.00075034 0.00102625 0.00160788 0.00063533 0.00036596
 0.00066816]
Model epoch 276: train total loss -62.306076749481264, train mean loss 0.0009447420649822239, test mean loss [0.0008654  0.00067635 0.00097374 0.00160805 0.00060153 0.00037228
 0.00066696]
Model epoch 277: train total loss -62.464282388176734, train mean loss 0.0009833437634167675, test mean loss [0.00080797 0.00062478 0.0009703  0.00161952 0.00060513 0.00035728
 0.00067803]
Model epoch 278: train total loss -62.50018052540229, train mean loss 0.0009487683118780681, test mean loss [0.0008379  0.00057822 0.00092409 0.00155897 0.00059114 0.00036656
 0.00065297]
Model epoch 279: train total loss -62.42028465416259, train mean loss 0.000970462974296404, test mean loss [0.00082673 0.00061184 0.00095102 0.00149418 0.00056912 0.00035904
 0.00077684]
Model epoch 280: train total loss -62.2173835435427, train mean loss 0.0008270807867477165, test mean loss [0.00081732 0.00057839 0.00090701 0.00154832 0.00057502 0.00039522
 0.00065193]
Model epoch 281: train total loss -61.899640411776744, train mean loss 0.0009535672830401662, test mean loss [0.00083076 0.00051487 0.0008466  0.00157913 0.00073558 0.00037137
 0.00062291]
Model epoch 282: train total loss -61.991711560293886, train mean loss 0.000880670054633738, test mean loss [0.00080755 0.00051496 0.00087179 0.00151298 0.00066547 0.00035625
 0.00062635]
Model epoch 283: train total loss -62.164751861726444, train mean loss 0.0009283155494057497, test mean loss [0.00077025 0.00048996 0.00087868 0.00152071 0.00060199 0.00034411
 0.00061703]
Model epoch 284: train total loss -62.51182082335099, train mean loss 0.0008837477851360248, test mean loss [0.00077581 0.0004562  0.00087501 0.0015949  0.00056414 0.00034792
 0.00063866]
Model epoch 285: train total loss -62.44586508294582, train mean loss 0.0008827161577821881, test mean loss [0.00079383 0.00045078 0.00089833 0.0014899  0.00057998 0.00034864
 0.00061843]
Model epoch 286: train total loss -62.51164429596171, train mean loss 0.0007797987460212665, test mean loss [0.00073964 0.00041097 0.00086782 0.00147436 0.00053903 0.00037343
 0.00060526]
Model epoch 287: train total loss -62.319873079762836, train mean loss 0.0008318907715127284, test mean loss [0.00074054 0.00044013 0.00081718 0.00150021 0.00054265 0.00033181
 0.0006881 ]
Model epoch 288: train total loss -62.249999875615245, train mean loss 0.0009331652407635752, test mean loss [0.00073877 0.00040723 0.00079253 0.00142323 0.00056506 0.00033857
 0.00064125]
Model epoch 289: train total loss -62.69763714774062, train mean loss 0.000828849424551029, test mean loss [0.00072338 0.00039959 0.00078729 0.00141523 0.00056153 0.00033402
 0.00063156]
Model epoch 290: train total loss -62.491094273066885, train mean loss 0.0007763009990628556, test mean loss [0.00071932 0.00041697 0.00078074 0.00138122 0.00053291 0.00033528
 0.00063554]
Model epoch 291: train total loss -62.313726673046155, train mean loss 0.0008561770243775426, test mean loss [0.00069308 0.00040007 0.00072744 0.00139911 0.00051675 0.00036553
 0.00085372]
Model epoch 292: train total loss -62.21917120841621, train mean loss 0.0007878323922844274, test mean loss [0.00067325 0.00038879 0.00071981 0.0013282  0.00051749 0.00035842
 0.00073496]
Model epoch 293: train total loss -62.35663870493877, train mean loss 0.0008066630860792033, test mean loss [0.00068317 0.00039185 0.00076652 0.00136443 0.00047728 0.00034277
 0.00069055]
Model epoch 294: train total loss -62.350840079893565, train mean loss 0.0007601669646724365, test mean loss [0.00064977 0.00038902 0.00073778 0.00138015 0.00050434 0.00035033
 0.00068354]
Model epoch 295: train total loss -62.47698315890506, train mean loss 0.000722970346260125, test mean loss [0.00064569 0.0003914  0.00074142 0.0013362  0.00050125 0.00032496
 0.00068878]
Model epoch 296: train total loss -62.718095754640814, train mean loss 0.0008081234583605371, test mean loss [0.00071711 0.00040198 0.00073307 0.00131388 0.00046744 0.00033117
 0.00066477]
Model epoch 297: train total loss -62.495222982875056, train mean loss 0.0007800115873433086, test mean loss [0.0006688  0.00040749 0.00073093 0.00132116 0.00046678 0.00031667
 0.00063229]
Model epoch 298: train total loss -62.614573130822755, train mean loss 0.0007440488875324764, test mean loss [0.00063152 0.00037264 0.00070077 0.00125819 0.00043204 0.00031528
 0.00061373]
Model epoch 299: train total loss -62.747101142373815, train mean loss 0.0007425760032323316, test mean loss [0.00062359 0.00037901 0.00070685 0.00126962 0.000415   0.00031808
 0.00060443]
Model epoch 300: train total loss -62.46829728179666, train mean loss 0.0007897398944476942, test mean loss [0.00062794 0.00036364 0.00072946 0.00124113 0.00041069 0.00069615
 0.00064088]
Model epoch 301: train total loss -62.41961304348014, train mean loss 0.0008200006523982016, test mean loss [0.00065356 0.00036433 0.00068497 0.00126253 0.00045015 0.00079974
 0.00062588]
Model epoch 302: train total loss -62.41285632842543, train mean loss 0.0008117362105692846, test mean loss [0.00061927 0.00038573 0.00066646 0.00126812 0.00043553 0.00056053
 0.00058199]
Model epoch 303: train total loss -62.490112342925116, train mean loss 0.0007959079893243016, test mean loss [0.00058043 0.00035667 0.00076389 0.00118105 0.00041799 0.00046446
 0.00057994]
Model epoch 304: train total loss -62.55231613231355, train mean loss 0.0007365518693540825, test mean loss [0.00058032 0.00037126 0.00072511 0.00113484 0.00042575 0.00042518
 0.00058503]
Model epoch 305: train total loss -62.55021750354046, train mean loss 0.0007208719950807193, test mean loss [0.00061353 0.00036513 0.00069601 0.00116001 0.00042012 0.0006176
 0.00055872]
Model epoch 306: train total loss -62.57763133522887, train mean loss 0.0007529747082540169, test mean loss [0.00058214 0.00034773 0.00068105 0.00115411 0.00040433 0.00054206
 0.00056933]
Model epoch 307: train total loss -62.64770175958835, train mean loss 0.0007306952979857866, test mean loss [0.00061259 0.00033985 0.00060213 0.00115992 0.00039003 0.00050521
 0.00055121]
Model epoch 308: train total loss -62.68672133247064, train mean loss 0.0006914317982605772, test mean loss [0.00057149 0.00036581 0.00063742 0.00111691 0.00041623 0.00045654
 0.00055207]
Model epoch 309: train total loss -62.60527548503646, train mean loss 0.0007820996025589468, test mean loss [0.00057051 0.00035159 0.00058835 0.00108142 0.00039482 0.00047923
 0.00055004]
Model epoch 310: train total loss -62.73652072539711, train mean loss 0.0007273187414372897, test mean loss [0.00058365 0.00034169 0.00056239 0.00110267 0.00039421 0.0004261
 0.00054288]
Model epoch 311: train total loss -62.813215602223494, train mean loss 0.0006811672330497895, test mean loss [0.0005806  0.00033942 0.00055623 0.0010662  0.00039822 0.00037971
 0.00054542]
Model epoch 312: train total loss -62.804942543560564, train mean loss 0.0006813787532672263, test mean loss [0.00054696 0.00033527 0.00056467 0.00106613 0.00038521 0.00037972
 0.00053849]
Model epoch 313: train total loss -62.90068572865012, train mean loss 0.0007321747864808188, test mean loss [0.00053847 0.00034481 0.00055327 0.00109449 0.00039516 0.00036163
 0.00053195]
Model epoch 314: train total loss -62.69189061990491, train mean loss 0.0007427883829325673, test mean loss [0.00052487 0.00036613 0.00056745 0.00103513 0.00037159 0.00036082
 0.00052551]
Model epoch 315: train total loss -62.782459321891686, train mean loss 0.0006998444133676372, test mean loss [0.00052512 0.0003477  0.00053917 0.00109494 0.00037188 0.0003445
 0.00053235]
Model epoch 316: train total loss -62.96574588841342, train mean loss 0.0006038065611718989, test mean loss [0.00053307 0.00034178 0.00050182 0.00102624 0.00037228 0.00033882
 0.00054657]
Model epoch 317: train total loss -62.98291053205919, train mean loss 0.0006309892115137237, test mean loss [0.00052962 0.00032545 0.00052202 0.00101162 0.00035951 0.00033414
 0.00052332]
Model epoch 318: train total loss -63.153931400808055, train mean loss 0.000635418837329355, test mean loss [0.00056776 0.00032006 0.0004952  0.00100031 0.00036499 0.00030295
 0.0005179 ]
Model epoch 319: train total loss -62.35150022695391, train mean loss 0.0005800713757740938, test mean loss [0.00053604 0.0003894  0.0004852  0.00097461 0.00036514 0.00029632
 0.00053033]
Model epoch 320: train total loss -62.93586574412873, train mean loss 0.0006370877727039245, test mean loss [0.00049281 0.0003813  0.00050024 0.00095151 0.00037527 0.0002866
 0.00050869]
Model epoch 321: train total loss -62.80840838033969, train mean loss 0.000651187843317694, test mean loss [0.00049937 0.00036801 0.00050093 0.00097552 0.00035472 0.00028785
 0.00050855]
Model epoch 322: train total loss -62.830472620374515, train mean loss 0.0006035488304754286, test mean loss [0.00051576 0.00034466 0.00051577 0.00096736 0.00035928 0.00029189
 0.00050959]
Model epoch 323: train total loss -62.873301505766214, train mean loss 0.000641843720886325, test mean loss [0.00050812 0.00033501 0.00048904 0.00101074 0.00035621 0.00027722
 0.00051002]
Model epoch 324: train total loss -63.067865189299944, train mean loss 0.0005870639782985931, test mean loss [0.00048821 0.00033619 0.00043745 0.00094391 0.00034721 0.00027763
 0.00051406]
Model epoch 325: train total loss -63.14943846490247, train mean loss 0.0005452896651406365, test mean loss [0.00048669 0.00037581 0.00040536 0.00094666 0.00034373 0.00027202
 0.00049482]
Model epoch 326: train total loss -62.92495825690294, train mean loss 0.0006059237417707168, test mean loss [0.00050391 0.00033466 0.00041371 0.00087291 0.00034612 0.00027722
 0.00053594]
Model epoch 327: train total loss -62.878605468564785, train mean loss 0.0006128032470122763, test mean loss [0.00048639 0.00031557 0.00045756 0.00084963 0.00034541 0.00028785
 0.00052391]
Model epoch 328: train total loss -62.8898256920371, train mean loss 0.0006278839289408395, test mean loss [0.00047921 0.00031242 0.00043823 0.00090794 0.00034183 0.00030978
 0.00049906]
Model epoch 329: train total loss -62.89746393851079, train mean loss 0.0006586716803195114, test mean loss [0.00047347 0.00030601 0.00041171 0.00086192 0.00037874 0.00028881
 0.00047719]
Model epoch 330: train total loss -62.903238060079495, train mean loss 0.0005849890722859618, test mean loss [0.00050924 0.00030918 0.00040953 0.00080936 0.00036094 0.00028343
 0.00050474]
Model epoch 331: train total loss -63.000769477712915, train mean loss 0.0005768524873781488, test mean loss [0.00049333 0.00031229 0.00038374 0.00084441 0.00036538 0.00028608
 0.00048709]
Model epoch 332: train total loss -63.20174284027477, train mean loss 0.0005834387765331368, test mean loss [0.00046146 0.00031288 0.00037967 0.00083116 0.00037288 0.0002767
 0.00047618]
Model epoch 333: train total loss -63.28150863979855, train mean loss 0.0006314813797399036, test mean loss [0.00046188 0.00031976 0.0003667  0.00079852 0.00034286 0.00026998
 0.00048354]
Model epoch 334: train total loss -63.293571618395106, train mean loss 0.0005896384700985755, test mean loss [0.00046697 0.00029593 0.00036371 0.00085401 0.00033486 0.00026605
 0.00048715]
Model epoch 335: train total loss -62.92978875930315, train mean loss 0.0005897901703133632, test mean loss [0.00046607 0.00030029 0.00037314 0.00079122 0.00034178 0.00026723
 0.00050087]
Model epoch 336: train total loss -63.0053599328691, train mean loss 0.0005631951890210841, test mean loss [0.00046027 0.00028869 0.00034683 0.00085005 0.00034768 0.00025716
 0.00049254]
Model epoch 337: train total loss -63.01065046587666, train mean loss 0.0005464809856315635, test mean loss [0.00044678 0.00030183 0.00034066 0.00081026 0.00034115 0.00025765
 0.00047159]
Model epoch 338: train total loss -63.39345706246038, train mean loss 0.00045193404524318927, test mean loss [0.00046743 0.00030687 0.00038375 0.00075692 0.00033364 0.00026679
 0.00047208]
Model epoch 339: train total loss -63.120635915892144, train mean loss 0.0005253781115173375, test mean loss [0.00045053 0.00032045 0.00034515 0.00073968 0.00033707 0.00026167
 0.00046257]
Model epoch 340: train total loss -63.25888390780714, train mean loss 0.0006495500177823721, test mean loss [0.00043496 0.00030406 0.00031749 0.00077423 0.0003483  0.00025487
 0.00044987]
Model epoch 341: train total loss -63.26756219597029, train mean loss 0.0005266950246405555, test mean loss [0.0004621  0.00028635 0.00033456 0.0007422  0.00033838 0.00025829
 0.00047489]
Model epoch 342: train total loss -63.12322079425912, train mean loss 0.0004879952827515278, test mean loss [0.00046347 0.00028842 0.00032465 0.00072682 0.00031392 0.00027399
 0.00047389]
Model epoch 343: train total loss -63.32783627240556, train mean loss 0.0005001711121855198, test mean loss [0.00045939 0.00029949 0.00034089 0.00073098 0.00031924 0.00026714
 0.00046524]
Model epoch 344: train total loss -63.35920771257613, train mean loss 0.0005255782672368738, test mean loss [0.00043773 0.00029059 0.00031507 0.00073895 0.00039027 0.00025781
 0.00044499]
Model epoch 345: train total loss -63.47017377608107, train mean loss 0.0004787985794525455, test mean loss [0.00043158 0.00027562 0.00030365 0.00072459 0.00033133 0.00025846
 0.00044267]
Model epoch 346: train total loss -63.21854086838926, train mean loss 0.0005002845841707936, test mean loss [0.00043439 0.00032597 0.00030401 0.00070639 0.00032619 0.00025274
 0.00046767]
Model epoch 347: train total loss -63.3952167921521, train mean loss 0.0004781964464205256, test mean loss [0.00043161 0.00027919 0.00029527 0.00068433 0.00032301 0.00026919
 0.0004489 ]
Model epoch 348: train total loss -63.493657234064536, train mean loss 0.00048641255841713673, test mean loss [0.00043092 0.00028353 0.00028374 0.00064892 0.00031779 0.00024944
 0.0004452 ]
Model epoch 349: train total loss -63.405211662688224, train mean loss 0.0004968609844669644, test mean loss [0.00049793 0.00027431 0.00029505 0.00065745 0.0003516  0.00024607
 0.00043292]
Model epoch 350: train total loss -62.356215765314, train mean loss 0.0012669153126511517, test mean loss [0.01241344 0.00027216 0.00027603 0.00061776 0.00032796 0.00026944
 0.00044849]
Model epoch 351: train total loss -61.92589168413378, train mean loss 0.002360380668234943, test mean loss [0.01730726 0.00026739 0.00027826 0.00063145 0.00031214 0.00024628
 0.00043648]
Model epoch 352: train total loss -61.89079231729628, train mean loss 0.002519300084408973, test mean loss [0.01637119 0.00026109 0.00027803 0.00078696 0.00032234 0.00025143
 0.00043031]
Model epoch 353: train total loss -62.12132019929769, train mean loss 0.0027580829306426283, test mean loss [0.01445189 0.00026557 0.00028    0.00070968 0.00032746 0.00026741
 0.00044772]
Model epoch 354: train total loss -62.34445892311353, train mean loss 0.0019353140765957116, test mean loss [0.01319482 0.0002753  0.00027464 0.0006939  0.00031404 0.00026167
 0.00043336]
Model epoch 355: train total loss -62.5189093826768, train mean loss 0.0020194406763274636, test mean loss [0.01176565 0.00025733 0.00026787 0.00064029 0.00030592 0.00024895
 0.00043046]
Model epoch 356: train total loss -62.63628448338998, train mean loss 0.0017914148875077922, test mean loss [0.01059856 0.00025837 0.00027283 0.00062184 0.00032071 0.00025398
 0.00041812]
Model epoch 357: train total loss -62.891114233964345, train mean loss 0.0015511106997924515, test mean loss [0.00961707 0.00028246 0.00026233 0.00057786 0.00032834 0.00024963
 0.00041999]
Model epoch 358: train total loss -62.981546158318295, train mean loss 0.0013048729251346916, test mean loss [0.00871486 0.00025731 0.00026506 0.00056301 0.00031214 0.00032893
 0.00044665]
Model epoch 359: train total loss -62.93569502467494, train mean loss 0.001497973060048154, test mean loss [0.00805047 0.00025107 0.00025852 0.00058628 0.00030146 0.00025558
 0.00041708]
Model epoch 360: train total loss -62.93658233915298, train mean loss 0.0012708232562330102, test mean loss [0.00727607 0.00024832 0.00025938 0.00056576 0.00032512 0.00025051
 0.00042963]
Model epoch 361: train total loss -62.92256284388522, train mean loss 0.001220347733314007, test mean loss [0.00676111 0.00025031 0.00029912 0.00054995 0.00031094 0.00025098
 0.00040654]
Model epoch 362: train total loss -63.09651928056383, train mean loss 0.0011351106597330908, test mean loss [0.00626896 0.00025671 0.00026777 0.00056464 0.00030808 0.00024284
 0.00046058]
Model epoch 363: train total loss -62.628268367067854, train mean loss 0.00124238945226674, test mean loss [0.00576116 0.00024692 0.00026494 0.00053576 0.00031288 0.00025478
 0.00166864]
Model epoch 364: train total loss -62.31461707948716, train mean loss 0.001626568092199444, test mean loss [0.00522731 0.00024858 0.00025197 0.00054831 0.00039472 0.00026449
 0.00199025]
Model epoch 365: train total loss -61.90286652450301, train mean loss 0.001403016273439393, test mean loss [0.00483891 0.00024216 0.00024487 0.00053167 0.00035738 0.00202492
 0.00175397]
Model epoch 366: train total loss -62.01115307468656, train mean loss 0.001284404616818435, test mean loss [0.00444909 0.00025111 0.00025132 0.00050372 0.000342   0.00300162
 0.00140923]
Model epoch 367: train total loss -62.2660268384089, train mean loss 0.0011642215441273807, test mean loss [0.00409246 0.00024837 0.00027011 0.00051984 0.00033936 0.00271366
 0.00116757]
Model epoch 368: train total loss -62.6461499453643, train mean loss 0.0010331168025172921, test mean loss [0.00368344 0.0002582  0.00025699 0.00051725 0.00032743 0.00223525
 0.00100084]
Model epoch 369: train total loss -62.66723849083525, train mean loss 0.001018723717890667, test mean loss [0.00332659 0.00025183 0.00025142 0.00048697 0.00048787 0.00177922
 0.00087872]
Model epoch 370: train total loss -62.67845816740297, train mean loss 0.001077740468622939, test mean loss [0.00304182 0.00024667 0.00024407 0.00047635 0.00034758 0.00144389
 0.00095961]
Model epoch 371: train total loss -62.47384417783611, train mean loss 0.0010172411375048386, test mean loss [0.00269544 0.00024681 0.0002996  0.00046909 0.00034183 0.00118114
 0.00084254]
Model epoch 372: train total loss -62.828501536763234, train mean loss 0.0007119737586429513, test mean loss [0.0024295  0.00024342 0.00025715 0.00049122 0.0003314  0.00099568
 0.00075624]
Model epoch 373: train total loss -62.926940855110296, train mean loss 0.0008224383816016542, test mean loss [0.00215802 0.00025106 0.00025621 0.00046745 0.0003291  0.0008319
 0.00072378]
Model epoch 374: train total loss -63.26727880138594, train mean loss 0.0006997364237809379, test mean loss [0.00185148 0.00023907 0.00024292 0.00045072 0.00030648 0.00076153
 0.00068353]
Model epoch 375: train total loss -63.12572795978576, train mean loss 0.0006668922521478096, test mean loss [0.00167904 0.00024341 0.00024774 0.00043585 0.00033189 0.00071777
 0.00069348]
Model epoch 376: train total loss -62.83976327831899, train mean loss 0.0007345282996652515, test mean loss [0.00156012 0.00023984 0.00025658 0.00043184 0.00045777 0.00071153
 0.00065458]
Model epoch 377: train total loss -62.8514297449491, train mean loss 0.0007162158547241146, test mean loss [0.00149227 0.00024816 0.00024203 0.00044198 0.00039452 0.00061564
 0.00064989]
Model epoch 378: train total loss -62.92507062038282, train mean loss 0.0005692158058435891, test mean loss [0.00139207 0.00022876 0.00024505 0.00041298 0.00037144 0.00059311
 0.00064242]
Model epoch 379: train total loss -63.19154885665149, train mean loss 0.0007532686782572647, test mean loss [0.00129717 0.00022367 0.00024165 0.00042209 0.00033177 0.00062847
 0.00061521]
Model epoch 380: train total loss -63.10901891526564, train mean loss 0.0006569640508141615, test mean loss [0.00126679 0.00024408 0.00023432 0.00041879 0.00033796 0.00060972
 0.00059895]
Model epoch 381: train total loss -63.39143526774178, train mean loss 0.0006908581254541837, test mean loss [0.00122431 0.0002528  0.00023639 0.0004411  0.00033159 0.00057158
 0.00059517]
Model epoch 382: train total loss -63.273311454358954, train mean loss 0.0006023468138117541, test mean loss [0.00118367 0.00023881 0.00024064 0.00042498 0.00032184 0.00057514
 0.00056912]
Model epoch 383: train total loss -63.50257433095456, train mean loss 0.0006234938376921879, test mean loss [0.00110786 0.00022856 0.00024395 0.00039074 0.0003073  0.00055303
 0.00057782]
Model epoch 384: train total loss -63.61827641356909, train mean loss 0.0005530957767530715, test mean loss [0.00114182 0.00023391 0.00023333 0.0003742  0.00029808 0.00053901
 0.0005605 ]
Model epoch 385: train total loss -63.66099590388221, train mean loss 0.000527919393918976, test mean loss [0.00110552 0.00022041 0.00023411 0.00037207 0.00029088 0.00051923
 0.00055109]
Model epoch 386: train total loss -63.687713157205266, train mean loss 0.0005364602566074212, test mean loss [0.00108694 0.00022995 0.00023412 0.00037154 0.00030383 0.00054402
 0.00054228]
Model epoch 387: train total loss -63.47226502700028, train mean loss 0.0006250133585286452, test mean loss [0.00104117 0.00022859 0.00023122 0.00038103 0.00030197 0.00059034
 0.0005539 ]
Model epoch 388: train total loss -63.33154875861619, train mean loss 0.0004844838238512743, test mean loss [0.00103105 0.0002339  0.00024369 0.0003671  0.00029512 0.00061704
 0.00051301]
Model epoch 389: train total loss -63.603737080385585, train mean loss 0.000547678009453, test mean loss [0.00102774 0.00023787 0.00022954 0.0003551  0.00028185 0.00057207
 0.00052397]
Model epoch 390: train total loss -63.60651851220406, train mean loss 0.0004601301584612804, test mean loss [0.00096332 0.00024057 0.00022439 0.00034294 0.00029068 0.00053911
 0.00050622]
Model epoch 391: train total loss -63.53134839430939, train mean loss 0.0005695442336042766, test mean loss [0.00092704 0.0002285  0.00022564 0.00034802 0.00029008 0.00057277
 0.00050239]
Model epoch 392: train total loss -63.72027947216044, train mean loss 0.000498800912670782, test mean loss [0.00089163 0.00022328 0.00023496 0.00034558 0.00028106 0.00057709
 0.0004747 ]
Model epoch 393: train total loss -63.83152810694075, train mean loss 0.0005001498609722604, test mean loss [0.00082029 0.00021585 0.00022344 0.00036185 0.00027889 0.000564
 0.00045429]
Model epoch 394: train total loss -63.762344503719206, train mean loss 0.000544781204406898, test mean loss [0.00083187 0.00022526 0.00023098 0.00034431 0.00027002 0.0005435
 0.00044813]
Model epoch 395: train total loss -63.94595902083221, train mean loss 0.00044532047844760063, test mean loss [0.00078111 0.00021252 0.00022537 0.00033542 0.00026966 0.0004916
 0.00044798]
Model epoch 396: train total loss -63.316556191534666, train mean loss 0.0005117931278242334, test mean loss [0.00076946 0.00024318 0.00028249 0.00033031 0.00027325 0.00050512
 0.00042154]
Model epoch 397: train total loss -63.69420598108298, train mean loss 0.0005136375701950613, test mean loss [0.00073574 0.00021249 0.0002411  0.00032441 0.00026553 0.00047514
 0.00039924]
Model epoch 398: train total loss -63.747611469888746, train mean loss 0.00048314507155693625, test mean loss [0.00072191 0.00022443 0.00023574 0.00032245 0.0002801  0.00048153
 0.00040944]
Model epoch 399: train total loss -63.85041039888765, train mean loss 0.00045269749721441044, test mean loss [0.00065883 0.00022115 0.00023004 0.00034055 0.00027589 0.00047068
 0.00038479]
Model epoch 400: train total loss -63.76246342806705, train mean loss 0.0005196484030876483, test mean loss [0.00065736 0.00021959 0.00022238 0.00033656 0.0002737  0.00046704
 0.00036397]
Model epoch 401: train total loss -63.8261852727415, train mean loss 0.00045109397399551826, test mean loss [0.00064724 0.00021102 0.00023474 0.0003168  0.00027036 0.00046216
 0.00037348]
Model epoch 402: train total loss -63.97043774348125, train mean loss 0.00043895621686511257, test mean loss [0.0005816  0.00022601 0.00022039 0.0003233  0.00026739 0.00044371
 0.00036879]
Model epoch 403: train total loss -63.83956061372806, train mean loss 0.0004628858829891805, test mean loss [0.00058062 0.00021999 0.00021361 0.00032348 0.00028079 0.0004351
 0.0003669 ]
Model epoch 404: train total loss -63.71167901787736, train mean loss 0.00045213762730680765, test mean loss [0.00056077 0.00021653 0.00022972 0.0003177  0.00030739 0.00041281
 0.00036223]
Model epoch 405: train total loss -63.71315212628224, train mean loss 0.0004231926541435208, test mean loss [0.00054336 0.00019993 0.00023708 0.00031666 0.00030586 0.00041218
 0.00035744]
Model epoch 406: train total loss -63.866809087143714, train mean loss 0.0004442559457505248, test mean loss [0.00053045 0.00019937 0.00023456 0.00032179 0.00028791 0.00042855
 0.00036215]
Model epoch 407: train total loss -62.952901271364276, train mean loss 0.0004563536635146689, test mean loss [0.00049781 0.00025229 0.00022574 0.00032543 0.00028568 0.00041128
 0.00034808]
Model epoch 408: train total loss -63.69283672319229, train mean loss 0.00042080986357328766, test mean loss [0.00046225 0.00029243 0.00023552 0.00031155 0.00028957 0.0003879
 0.00035307]
Model epoch 409: train total loss -63.571438690497295, train mean loss 0.00039791763252302334, test mean loss [0.00044333 0.00026413 0.00023033 0.0003156  0.00028075 0.00038391
 0.00034251]
Model epoch 410: train total loss -63.799308225343836, train mean loss 0.0004262257747674993, test mean loss [0.0004301  0.00026543 0.00021448 0.00033716 0.00028443 0.00037553
 0.00034305]
Model epoch 411: train total loss -63.56311496300501, train mean loss 0.0004109720392798942, test mean loss [0.00043272 0.00026685 0.00026784 0.0003138  0.00026827 0.00035285
 0.00034728]
Model epoch 412: train total loss -63.5457007718588, train mean loss 0.0004301146959523938, test mean loss [0.00038653 0.00025862 0.00042896 0.00032301 0.00026985 0.00034674
 0.00036607]
Model epoch 413: train total loss -63.74626615689944, train mean loss 0.00041788986826388154, test mean loss [0.00038806 0.00025421 0.0003423  0.00031403 0.00027245 0.00033009
 0.00034033]
Model epoch 414: train total loss -63.560611839090946, train mean loss 0.00039191321226127233, test mean loss [0.00040409 0.00023759 0.00030609 0.00039156 0.00027063 0.00031313
 0.00034324]
Model epoch 415: train total loss -63.74706978136195, train mean loss 0.000449661797973383, test mean loss [0.00038431 0.00023579 0.00030385 0.00047191 0.00027245 0.00033107
 0.00034547]
Model epoch 416: train total loss -62.86551019590615, train mean loss 0.0004198261459930947, test mean loss [0.0003558  0.00039302 0.00029255 0.00044551 0.0002634  0.0003197
 0.00034501]
Model epoch 417: train total loss -63.47194703387891, train mean loss 0.000402491084856508, test mean loss [0.00034419 0.00033547 0.00030656 0.0004215  0.00026002 0.0003028
 0.00033828]
Model epoch 418: train total loss -63.606061361098206, train mean loss 0.0004549586246984591, test mean loss [0.00033775 0.00032509 0.00030496 0.00045439 0.00027521 0.00029059
 0.00033934]
Model epoch 419: train total loss -62.958121389994666, train mean loss 0.0004972610171551131, test mean loss [0.00034303 0.00027795 0.00029218 0.00172989 0.00026188 0.00028333
 0.00034024]
Model epoch 420: train total loss -63.05732398955765, train mean loss 0.0005851496599120672, test mean loss [0.00034564 0.00025439 0.00029201 0.00219855 0.00026646 0.00027792
 0.00033698]
Model epoch 421: train total loss -62.99417186297426, train mean loss 0.0006392950508839249, test mean loss [0.00032941 0.00024071 0.00026747 0.00214265 0.00025546 0.0002587
 0.00032951]
Model epoch 422: train total loss -63.228925419385575, train mean loss 0.0006172247082777906, test mean loss [0.00036189 0.00024184 0.00030974 0.00201218 0.0002556  0.00024485
 0.00033166]
Model epoch 423: train total loss -63.31494040002727, train mean loss 0.0005266067640433689, test mean loss [0.00035418 0.00022629 0.0002281  0.00182553 0.00025841 0.00023576
 0.00033722]
Model epoch 424: train total loss -63.3808885462254, train mean loss 0.0005126236658441236, test mean loss [0.00036478 0.00021874 0.00023087 0.00179506 0.00025107 0.00022626
 0.00033365]
Model epoch 425: train total loss -63.55569788742441, train mean loss 0.0005185862676484833, test mean loss [0.00032736 0.00021779 0.00022257 0.00157415 0.00025937 0.00022921
 0.00031953]
Model epoch 426: train total loss -63.62469785404676, train mean loss 0.0005369300209167232, test mean loss [0.0003361  0.00020534 0.00021422 0.00153356 0.0002601  0.00023307
 0.0003147 ]
Model epoch 427: train total loss -63.55356304413144, train mean loss 0.0005093281292850215, test mean loss [0.00033456 0.00021703 0.00021559 0.00149427 0.00025309 0.00021616
 0.00033896]
Model epoch 428: train total loss -63.79527685645506, train mean loss 0.0005050561708757278, test mean loss [0.00032939 0.00019408 0.00022    0.00139707 0.00024718 0.00020393
 0.00032272]
Model epoch 429: train total loss -63.71874755283066, train mean loss 0.000457385798924049, test mean loss [0.00032265 0.00020105 0.0003683  0.00142029 0.00025238 0.00020221
 0.00031433]
Model epoch 430: train total loss -63.76289142011207, train mean loss 0.0005162239194985766, test mean loss [0.00031308 0.00020275 0.00026107 0.00140777 0.00024837 0.00019791
 0.00031019]
Model epoch 431: train total loss -63.67622782809533, train mean loss 0.00045001959411711, test mean loss [0.00041176 0.00021309 0.00023858 0.00136013 0.00024267 0.0001916
 0.00034096]
Model epoch 432: train total loss -63.45553735176185, train mean loss 0.000519560828767177, test mean loss [0.00032644 0.00021012 0.0002546  0.0013523  0.00026265 0.00018925
 0.00032448]
Model epoch 433: train total loss -63.54172667440426, train mean loss 0.00045493084635378863, test mean loss [0.000326   0.00019372 0.00025868 0.00128632 0.00025486 0.000197
 0.0003095 ]
Model epoch 434: train total loss -63.7999819038078, train mean loss 0.00045358348804239233, test mean loss [0.00031753 0.00019501 0.00026149 0.00125479 0.00024981 0.00019253
 0.00032541]
Model epoch 435: train total loss -64.0272930603557, train mean loss 0.0004894478200141553, test mean loss [0.00031878 0.00019472 0.00025292 0.00120419 0.00025664 0.00018963
 0.00030739]
Model epoch 436: train total loss -63.86094990521578, train mean loss 0.00047232758702829916, test mean loss [0.00032168 0.00020087 0.00025153 0.00116943 0.00025214 0.00021006
 0.00030724]
Model epoch 437: train total loss -63.81870061727885, train mean loss 0.0004534904341446688, test mean loss [0.00030671 0.00019556 0.00026269 0.00114868 0.00026265 0.00019499
 0.00030397]
Model epoch 438: train total loss -64.12528669563548, train mean loss 0.0003928217311457694, test mean loss [0.00030285 0.00019312 0.00023999 0.0011159  0.00024539 0.00018732
 0.00030665]
Model epoch 439: train total loss -64.08323280015729, train mean loss 0.00040652852873416357, test mean loss [0.00030484 0.0001825  0.00024225 0.00114547 0.00023983 0.00018232
 0.0003051 ]
Model epoch 440: train total loss -63.62367758536409, train mean loss 0.00039658553405862233, test mean loss [0.00042595 0.00018564 0.00023837 0.00110792 0.00024289 0.00017994
 0.00031546]
Model epoch 441: train total loss -64.05322791903649, train mean loss 0.00040489633920668197, test mean loss [0.00035424 0.00018665 0.00021681 0.00109105 0.00024527 0.00018603
 0.00029692]
Model epoch 442: train total loss -63.774026179756696, train mean loss 0.00042441056388848306, test mean loss [0.00035183 0.00018659 0.00020855 0.00105459 0.00024865 0.00021568
 0.00030052]
Model epoch 443: train total loss -63.85916385792083, train mean loss 0.0004048891432156715, test mean loss [0.00032182 0.00018974 0.00021108 0.0009628  0.00024241 0.00023861
 0.00030644]
Model epoch 444: train total loss -63.78148343286055, train mean loss 0.00041865284860377085, test mean loss [0.00030938 0.00019211 0.00025154 0.00089794 0.00023879 0.00021398
 0.00029863]
Model epoch 445: train total loss -63.89157144301, train mean loss 0.00037698078152977266, test mean loss [0.00032163 0.00018386 0.00021409 0.00087242 0.00024076 0.00020329
 0.00031439]
Model epoch 446: train total loss -63.97487509975409, train mean loss 0.0004305225719985203, test mean loss [0.00040426 0.00018316 0.00022503 0.00085183 0.00024736 0.00018975
 0.00029721]
Model epoch 447: train total loss -63.9119716480859, train mean loss 0.0003994870475310798, test mean loss [0.0005251  0.00017683 0.00022231 0.00082347 0.00024229 0.00018642
 0.00029245]
Model epoch 448: train total loss -63.86186183015566, train mean loss 0.00036884827114126, test mean loss [0.0006503  0.0001788  0.0002045  0.00077448 0.00023494 0.0002378
 0.00029486]
Model epoch 449: train total loss -64.08583884312495, train mean loss 0.00039079200035192524, test mean loss [0.00056065 0.00017966 0.00021121 0.0007069  0.00023039 0.00020793
 0.00027971]
Model epoch 450: train total loss -63.90204027908344, train mean loss 0.000364544199466428, test mean loss [0.00046867 0.00017529 0.00019932 0.00072038 0.00026608 0.00019408
 0.00030312]
Model epoch 451: train total loss -63.934276704090756, train mean loss 0.0003750265911188879, test mean loss [0.0003914  0.00018248 0.00025471 0.00073574 0.00024564 0.00018461
 0.00031168]
Model epoch 452: train total loss -63.46065447070704, train mean loss 0.0004650774867896325, test mean loss [0.00037374 0.00020163 0.00105424 0.00069015 0.00024164 0.00019095
 0.00029616]
Model epoch 453: train total loss -63.56158849566888, train mean loss 0.0004964517829248805, test mean loss [0.00038448 0.00017884 0.0008475  0.00063407 0.00023386 0.00018341
 0.00029677]
Model epoch 454: train total loss -63.269294482116884, train mean loss 0.0004763624118871433, test mean loss [0.00041298 0.00018159 0.00069593 0.00063748 0.00022968 0.00019679
 0.0002947 ]
Model epoch 455: train total loss -63.1454562592908, train mean loss 0.00040329135520433856, test mean loss [0.00039904 0.00017285 0.00057049 0.00060639 0.0002521  0.00018577
 0.00028193]
Model epoch 456: train total loss -63.629927015249265, train mean loss 0.00041252821383967546, test mean loss [0.0003948  0.00017609 0.00050401 0.00060674 0.00027647 0.00018191
 0.00028712]
Model epoch 457: train total loss -63.84254696686669, train mean loss 0.00040434518383821935, test mean loss [0.00037288 0.00017313 0.00047824 0.00060259 0.00026684 0.00017845
 0.0002867 ]
Model epoch 458: train total loss -64.03915976537384, train mean loss 0.0003732908562292897, test mean loss [0.00037284 0.00018029 0.0004702  0.0005903  0.00025892 0.00018441
 0.00028834]
Model epoch 459: train total loss -64.03264201235386, train mean loss 0.00040043770172877276, test mean loss [0.00037204 0.00018767 0.00040818 0.00055302 0.00024449 0.00018831
 0.00028463]
Model epoch 460: train total loss -63.979155338144444, train mean loss 0.0003404091746333348, test mean loss [0.00036495 0.00017107 0.00041365 0.00054955 0.00024692 0.00019138
 0.00027564]
Model epoch 461: train total loss -64.35485955021558, train mean loss 0.00038910035964597936, test mean loss [0.00034201 0.0001676  0.00038524 0.00052568 0.00024164 0.00018045
 0.00027262]
Model epoch 462: train total loss -64.36353782970784, train mean loss 0.00037647234582603825, test mean loss [0.00033054 0.00017059 0.00037575 0.0005711  0.00023401 0.00018191
 0.00027208]
Model epoch 463: train total loss -64.17490667080193, train mean loss 0.0003695018456322724, test mean loss [0.00033375 0.00016934 0.00035098 0.00057147 0.00023954 0.0001903
 0.00027936]
Model epoch 464: train total loss -64.14240122479039, train mean loss 0.0003512141943286267, test mean loss [0.00031765 0.00018035 0.00031363 0.00054415 0.00023618 0.00019278
 0.00026962]
Model epoch 465: train total loss -64.28161963096453, train mean loss 0.00035515169865441855, test mean loss [0.00030875 0.00018089 0.00032011 0.00053656 0.00023115 0.00018865
 0.00026742]
Model epoch 466: train total loss -64.41385715635322, train mean loss 0.0003461550110650074, test mean loss [0.00031724 0.00017118 0.000307   0.00053518 0.0002348  0.00018259
 0.00026721]
Model epoch 467: train total loss -64.13687351074853, train mean loss 0.0003748038514047435, test mean loss [0.00032365 0.00018097 0.00028651 0.0005031  0.00023452 0.00017837
 0.0002727 ]
Model epoch 468: train total loss -64.26786935584816, train mean loss 0.00031812164568944764, test mean loss [0.00030276 0.00018572 0.00027525 0.00049946 0.00024052 0.00018551
 0.00026524]
Model epoch 469: train total loss -64.33138325635804, train mean loss 0.00035308444570217155, test mean loss [0.0002957  0.00017054 0.0002719  0.00049215 0.0002294  0.00018051
 0.00029404]
Model epoch 470: train total loss -64.30859976868734, train mean loss 0.0003603680854775795, test mean loss [0.0002928  0.00018121 0.000276   0.00046227 0.00023612 0.00018796
 0.00027058]
Model epoch 471: train total loss -64.26764779633254, train mean loss 0.00030987597142267964, test mean loss [0.00029996 0.00016974 0.0002659  0.00047218 0.00022953 0.00018131
 0.00026631]
Model epoch 472: train total loss -64.13226379767787, train mean loss 0.00033325347528675824, test mean loss [0.00029145 0.00021577 0.00026357 0.00049902 0.00022871 0.00017993
 0.00026305]
Model epoch 473: train total loss -64.23739752844408, train mean loss 0.00032480452825086546, test mean loss [0.00027785 0.00019709 0.00027501 0.00050846 0.00023232 0.00018606
 0.00026293]
Model epoch 474: train total loss -64.24315715716465, train mean loss 0.0003231036431245818, test mean loss [0.0002781  0.00021136 0.00026125 0.00048945 0.00022987 0.00017726
 0.00025894]
Model epoch 475: train total loss -64.04876926198553, train mean loss 0.0003076048727365484, test mean loss [0.00029391 0.00019896 0.00027064 0.00044857 0.00024032 0.00017922
 0.00027447]
Model epoch 476: train total loss -64.09516721020117, train mean loss 0.0003583133444533576, test mean loss [0.00026098 0.00019388 0.00025454 0.00045996 0.00023087 0.00018165
 0.00026109]
Model epoch 477: train total loss -64.16957669517207, train mean loss 0.00031319834734238743, test mean loss [0.00025636 0.00024917 0.0002395  0.00046987 0.00022942 0.00018136
 0.00026642]
Model epoch 478: train total loss -64.31548252869862, train mean loss 0.0003172464584724193, test mean loss [0.00024623 0.0002     0.00023165 0.00045799 0.000233   0.00018383
 0.00026015]
Model epoch 479: train total loss -64.33315100254661, train mean loss 0.00031222979408803103, test mean loss [0.00025244 0.00019333 0.00022931 0.00042291 0.00023151 0.00017454
 0.00025084]
Model epoch 480: train total loss -64.24503239128519, train mean loss 0.0003052075576969859, test mean loss [0.00025839 0.00018948 0.00023    0.00043328 0.00021887 0.00016911
 0.00025511]
Model epoch 481: train total loss -64.39148219235898, train mean loss 0.00031362554407050885, test mean loss [0.00025258 0.00018298 0.0002344  0.00041357 0.00022068 0.00016935
 0.00026196]
Model epoch 482: train total loss -64.28930613391725, train mean loss 0.00029514844020099904, test mean loss [0.00025877 0.00018036 0.00022335 0.00039015 0.00022828 0.00017605
 0.00027134]
Model epoch 483: train total loss -64.17455601963518, train mean loss 0.00030569234996241266, test mean loss [0.00028486 0.00016827 0.00021674 0.00038159 0.00023473 0.00021581
 0.00025023]
Model epoch 484: train total loss -64.17114829028195, train mean loss 0.00030689077099306966, test mean loss [0.00026182 0.00016553 0.00021212 0.00036302 0.00022104 0.00021354
 0.00025679]
Model epoch 485: train total loss -64.16345683751302, train mean loss 0.00027970157922884467, test mean loss [0.00025256 0.00018381 0.00021611 0.00034068 0.00022728 0.0001922
 0.00024717]
Model epoch 486: train total loss -64.22399767508983, train mean loss 0.000303496627236495, test mean loss [0.00025348 0.00017773 0.00022307 0.00033627 0.00021221 0.00018062
 0.0002496 ]
Model epoch 487: train total loss -64.27139765061524, train mean loss 0.00026238628776359207, test mean loss [0.00024734 0.00017893 0.00020575 0.00032905 0.00027373 0.00017711
 0.00032705]
Model epoch 488: train total loss -64.16178668470793, train mean loss 0.00025566964351261275, test mean loss [0.00024671 0.00016498 0.00021695 0.00030669 0.00026115 0.00017231
 0.00026388]
Model epoch 489: train total loss -64.24842020539971, train mean loss 0.0002540605183456201, test mean loss [0.00024447 0.00016207 0.00020115 0.00028122 0.00025515 0.00019097
 0.00027192]
Model epoch 490: train total loss -64.28232634968113, train mean loss 0.0002876845960442711, test mean loss [0.00025606 0.00017043 0.00020085 0.00029254 0.00023616 0.0001909
 0.00025259]
Model epoch 491: train total loss -64.31617173070146, train mean loss 0.0002601710319402717, test mean loss [0.00026364 0.00017415 0.00020549 0.00029304 0.00023126 0.00018635
 0.00025119]
Model epoch 492: train total loss -64.46425982804982, train mean loss 0.0002592357574418064, test mean loss [0.0002363  0.00016944 0.00019893 0.00027566 0.0002248  0.00017792
 0.0002423 ]
Model epoch 493: train total loss -64.40546945754086, train mean loss 0.0002639229409844011, test mean loss [0.00024203 0.0001585  0.00020923 0.00026479 0.00024461 0.00017993
 0.00024351]
Model epoch 494: train total loss -64.59719676547428, train mean loss 0.0002602957941123761, test mean loss [0.00023954 0.00015849 0.00020521 0.00027189 0.00024978 0.00017042
 0.0002572 ]
Model epoch 495: train total loss -64.11314460677532, train mean loss 0.00029195252495795585, test mean loss [0.00023609 0.00016234 0.00020158 0.00026508 0.00023712 0.00017364
 0.00036303]
Model epoch 496: train total loss -64.23363675299444, train mean loss 0.00024434398358147446, test mean loss [0.00024075 0.00015645 0.00019641 0.00026323 0.00023298 0.00017435
 0.00032266]
Model epoch 497: train total loss -64.36714468836449, train mean loss 0.00026469335715238176, test mean loss [0.0002432  0.00015633 0.00020454 0.00025663 0.00022321 0.00017319
 0.00032076]
Model epoch 498: train total loss -64.44101433062978, train mean loss 0.00024473713828050437, test mean loss [0.00023324 0.0001542  0.00020463 0.00026088 0.00021565 0.00016738
 0.00033105]
Model epoch 499: train total loss -64.40257940990907, train mean loss 0.00024052865676519092, test mean loss [0.00024049 0.00015567 0.00019436 0.00025346 0.00030742 0.00017057
 0.00034334]
Model epoch 500: train total loss -64.23170364554288, train mean loss 0.0003120632866837686, test mean loss [0.00023077 0.00015927 0.00019078 0.00028101 0.00023909 0.00016532
 0.00032714]
Model epoch 501: train total loss -64.38214837220596, train mean loss 0.0003129020973247688, test mean loss [0.00023676 0.00017069 0.00018394 0.0002669  0.00024634 0.00016803
 0.00031008]
Model epoch 502: train total loss -64.48825276699642, train mean loss 0.00027578492674030516, test mean loss [0.00023741 0.00015508 0.00019686 0.0002596  0.0002243  0.00017049
 0.00029145]
Model epoch 503: train total loss -64.69085412722585, train mean loss 0.0002488832640140642, test mean loss [0.00023427 0.00015623 0.00018882 0.00025672 0.00022752 0.00016585
 0.00028424]
Model epoch 504: train total loss -64.5201635914572, train mean loss 0.000272214082615584, test mean loss [0.00025297 0.00015886 0.00019404 0.00024845 0.00022204 0.00018713
 0.00030239]
Model epoch 505: train total loss -64.56071751147815, train mean loss 0.00025737286768681765, test mean loss [0.00022668 0.00015857 0.00018388 0.00027306 0.00021922 0.00018227
 0.00029033]
Model epoch 506: train total loss -64.58627497928799, train mean loss 0.00026491486037016497, test mean loss [0.00022815 0.00015659 0.00020874 0.00028964 0.00021758 0.00017005
 0.00026656]
Model epoch 507: train total loss -64.34799119490572, train mean loss 0.0002476126984304378, test mean loss [0.00022886 0.00015606 0.0001932  0.00027082 0.00022433 0.00017081
 0.00026565]
Model epoch 508: train total loss -64.53279226008674, train mean loss 0.0002662618071681782, test mean loss [0.00021999 0.00015812 0.00019726 0.00025784 0.00022528 0.00017219
 0.00025507]
Model epoch 509: train total loss -64.40375547259488, train mean loss 0.0002363065700265368, test mean loss [0.00023893 0.00015343 0.00018998 0.00025075 0.0002208  0.00017338
 0.0002427 ]
Model epoch 510: train total loss -64.60613476133264, train mean loss 0.00025352910781976007, test mean loss [0.00023282 0.0001667  0.0001838  0.00026823 0.00021045 0.00017371
 0.00024467]
Model epoch 511: train total loss -64.52950726767139, train mean loss 0.0002624307190985547, test mean loss [0.00023363 0.0001515  0.00018657 0.00025181 0.00021376 0.00017358
 0.00023918]
Model epoch 512: train total loss -64.73500377106846, train mean loss 0.0002269202817276386, test mean loss [0.000242   0.00015494 0.00019338 0.00024677 0.00021135 0.000178
 0.0002378 ]
Model epoch 513: train total loss -64.69538516140584, train mean loss 0.00027154486394565766, test mean loss [0.00022987 0.00015078 0.00017752 0.00024278 0.00021541 0.00016741
 0.00023733]
Model epoch 514: train total loss -64.49495650926366, train mean loss 0.0002807449087940615, test mean loss [0.00022646 0.00021074 0.00018159 0.00025151 0.00021671 0.00017012
 0.00023841]
Model epoch 515: train total loss -64.59733979942669, train mean loss 0.00025778745517105253, test mean loss [0.0002315  0.00016258 0.00019232 0.0002437  0.00021276 0.00016847
 0.00023473]
Model epoch 516: train total loss -64.67705312009309, train mean loss 0.0002511660874718696, test mean loss [0.00023455 0.00015544 0.00018993 0.00025278 0.00021551 0.00016518
 0.00022906]
Model epoch 517: train total loss -64.7557548323401, train mean loss 0.0002488885253794281, test mean loss [0.00022871 0.00015043 0.00020043 0.00023936 0.00021358 0.00016683
 0.00023227]
Model epoch 518: train total loss -64.72757920204587, train mean loss 0.00025549942682529545, test mean loss [0.00022793 0.00015586 0.00019557 0.00024014 0.00021677 0.0001702
 0.00022886]
Model epoch 519: train total loss -64.53504598317065, train mean loss 0.00022301866967624822, test mean loss [0.00023332 0.00017522 0.00018345 0.00024301 0.00021486 0.00018855
 0.00022766]
Model epoch 520: train total loss -64.53430979534075, train mean loss 0.00021418736902263543, test mean loss [0.00022366 0.00015694 0.00017558 0.00024852 0.00021842 0.00016732
 0.00023066]
Model epoch 521: train total loss -64.81684039394698, train mean loss 0.0002422304289111155, test mean loss [0.00022093 0.00015625 0.00017423 0.00023437 0.00020943 0.000174
 0.00022272]
Model epoch 522: train total loss -64.94773348007499, train mean loss 0.0002569714368156912, test mean loss [0.00022047 0.00015275 0.00018436 0.00024255 0.00020159 0.00016267
 0.00022741]
Model epoch 523: train total loss -64.38868607899121, train mean loss 0.0002597289560505651, test mean loss [0.00023923 0.00015318 0.0001912  0.00025068 0.00020002 0.00016798
 0.0002197 ]
Model epoch 524: train total loss -64.63304341983837, train mean loss 0.0002329880838893855, test mean loss [0.00023635 0.000152   0.00018844 0.00023453 0.00020885 0.0001794
 0.00021551]
Model epoch 525: train total loss -64.45856788602998, train mean loss 0.0002609524569849281, test mean loss [0.00022181 0.00014777 0.00018191 0.00022895 0.00020206 0.00022213
 0.00021152]
Model epoch 526: train total loss -64.60691789426005, train mean loss 0.00024571859946435274, test mean loss [0.00022172 0.00015001 0.00017674 0.00023554 0.00020951 0.00024182
 0.00021463]
Model epoch 527: train total loss -64.5315979863034, train mean loss 0.00023017489411591126, test mean loss [0.00022542 0.00014365 0.00017807 0.00023343 0.0001982  0.00024347
 0.00023122]
Model epoch 528: train total loss -64.49433800639972, train mean loss 0.0002527929315930344, test mean loss [0.00021945 0.00014383 0.00018575 0.00024107 0.00020262 0.00020318
 0.00027149]
Model epoch 529: train total loss -64.4338007467391, train mean loss 0.00024232398118040148, test mean loss [0.00021263 0.00014976 0.00017249 0.00023551 0.00021898 0.00020638
 0.00025389]
Model epoch 530: train total loss -63.58782968458373, train mean loss 0.00026744359766619493, test mean loss [0.00021529 0.00024599 0.00017431 0.00024218 0.00020251 0.000201
 0.00025804]
Model epoch 531: train total loss -64.0534689843139, train mean loss 0.0002717389740493485, test mean loss [0.00022539 0.00023311 0.00018029 0.00022268 0.00020204 0.00019623
 0.00024103]
Model epoch 532: train total loss -64.2422117076801, train mean loss 0.0002518657516602441, test mean loss [0.00022632 0.00024328 0.00017555 0.00022388 0.00019346 0.00018308
 0.00023415]
Model epoch 533: train total loss -64.40883122998888, train mean loss 0.00024336746278164404, test mean loss [0.00022509 0.00021481 0.00017104 0.00022626 0.00019618 0.0001772
 0.00023919]
Model epoch 534: train total loss -64.3656605569409, train mean loss 0.00023712410316712723, test mean loss [0.00022144 0.00019051 0.00017687 0.00026725 0.00019479 0.00017624
 0.0002433 ]
Model epoch 535: train total loss -64.47673243819114, train mean loss 0.00024252482071929597, test mean loss [0.00021509 0.00017891 0.0001742  0.00023113 0.00024238 0.0001689
 0.00021916]
Model epoch 536: train total loss -63.6037752398719, train mean loss 0.0006810080192759474, test mean loss [0.00020553 0.00016311 0.00017631 0.00022819 0.00355479 0.00017539
 0.0002289 ]
Model epoch 537: train total loss -63.316251829608895, train mean loss 0.0009085107500145388, test mean loss [0.00021445 0.00016337 0.00017369 0.00023366 0.005015   0.00016004
 0.00023426]
Model epoch 538: train total loss -63.60962869717265, train mean loss 0.0008538276535414628, test mean loss [0.00021556 0.00015903 0.00017351 0.00022743 0.00524265 0.00015408
 0.00022507]
Model epoch 539: train total loss -63.7447553806156, train mean loss 0.0007319724229899596, test mean loss [0.00022206 0.00015204 0.00017219 0.00022557 0.00497609 0.00015678
 0.0002155 ]
Model epoch 540: train total loss -63.9755514784268, train mean loss 0.0007484785313619027, test mean loss [0.00023103 0.00023616 0.00017521 0.0002369  0.0044546  0.00014924
 0.00021622]
Model epoch 541: train total loss -63.08685125116125, train mean loss 0.0009780325544528651, test mean loss [0.00021298 0.0052851  0.00016932 0.00022508 0.0041362  0.00015791
 0.00021188]
Model epoch 542: train total loss -63.33760291052822, train mean loss 0.0018177643603727704, test mean loss [0.00021165 0.01051108 0.00017186 0.00022395 0.00387171 0.00015264
 0.00021339]
Model epoch 543: train total loss -63.01345875516077, train mean loss 0.0021840918987943033, test mean loss [0.00021452 0.01200768 0.00017574 0.00022237 0.00357679 0.0001933
 0.00021818]
Model epoch 544: train total loss -63.25126303507705, train mean loss 0.002034914349960098, test mean loss [0.00021068 0.01171042 0.00017076 0.0002259  0.00330488 0.00018021
 0.00023384]
Model epoch 545: train total loss -63.41071394278443, train mean loss 0.0019611686435711184, test mean loss [0.00021009 0.01128989 0.00016539 0.00021942 0.00297996 0.00016987
 0.00023091]
Model epoch 546: train total loss -63.71767321180619, train mean loss 0.0018999944749089426, test mean loss [0.00021227 0.01071975 0.0001699  0.00022106 0.00263853 0.00016665
 0.00021704]
Model epoch 547: train total loss -63.968194556343605, train mean loss 0.00164164838973276, test mean loss [0.0002242  0.01005835 0.00016959 0.00022178 0.00234315 0.00015698
 0.00021366]
Model epoch 548: train total loss -64.01179407929332, train mean loss 0.0017758757960855205, test mean loss [0.00020478 0.00932569 0.00016964 0.00021651 0.00203689 0.00015783
 0.00020641]
Model epoch 549: train total loss -64.3040558821762, train mean loss 0.00133174064645643, test mean loss [0.00020494 0.00863293 0.00016667 0.00021333 0.00175977 0.00015223
 0.00021049]
Model epoch 550: train total loss -64.41297652322535, train mean loss 0.00120245507513183, test mean loss [0.00020829 0.00791691 0.00017793 0.00021279 0.00154664 0.0001553
 0.00021049]
Model epoch 551: train total loss -64.45405197111745, train mean loss 0.0011320031955090052, test mean loss [0.00020659 0.00723962 0.00018135 0.00020617 0.00138917 0.00015591
 0.00021849]
Model epoch 552: train total loss -64.17270164332552, train mean loss 0.0012666929985141345, test mean loss [0.00023384 0.00663337 0.00018429 0.00020696 0.001374   0.00016713
 0.00021604]
Model epoch 553: train total loss -64.01941503524074, train mean loss 0.00121616472031646, test mean loss [0.00020003 0.00608758 0.00018172 0.00024288 0.00121125 0.0001672
 0.00021456]
Model epoch 554: train total loss -64.10610075272773, train mean loss 0.0009520329962819213, test mean loss [0.00020892 0.00555991 0.00017314 0.00022778 0.00110906 0.00016442
 0.0002052 ]
Model epoch 555: train total loss -64.28442329781213, train mean loss 0.0008649830039944518, test mean loss [0.00020286 0.00507106 0.00017329 0.00021855 0.0010305  0.00016144
 0.00020203]
Model epoch 556: train total loss -64.43926480564022, train mean loss 0.0007907447680545747, test mean loss [0.00019938 0.00470045 0.00016867 0.00020772 0.00095443 0.00015375
 0.00020636]
Model epoch 557: train total loss -64.56558739271745, train mean loss 0.0008649735665297718, test mean loss [0.00019765 0.00430295 0.00018382 0.00020843 0.00091983 0.00015051
 0.00020721]
Model epoch 558: train total loss -64.72511041622062, train mean loss 0.0008107301756581572, test mean loss [0.00019867 0.00389795 0.0001728  0.00020308 0.00091461 0.00014631
 0.00020773]
Model epoch 559: train total loss -63.48345205493329, train mean loss 0.0007133667783797658, test mean loss [0.00031477 0.00352231 0.00017547 0.00020509 0.00090551 0.0001461
 0.00032932]
Model epoch 560: train total loss -64.12457378304035, train mean loss 0.0006950208537292284, test mean loss [0.00026159 0.00319134 0.00016452 0.00020357 0.00087855 0.0002089
 0.00025424]
Model epoch 561: train total loss -63.97023866813404, train mean loss 0.0006294887806562242, test mean loss [0.0002549  0.00291439 0.00017128 0.00021257 0.00087678 0.0001742
 0.00023637]
Model epoch 562: train total loss -64.25143215300335, train mean loss 0.0006225409793915112, test mean loss [0.0002449  0.00268737 0.00016293 0.00021008 0.00083562 0.00016155
 0.00021782]
Model epoch 563: train total loss -64.50742134277746, train mean loss 0.0006154381579526806, test mean loss [0.00022504 0.00249497 0.00016564 0.0002134  0.00080604 0.0001571
 0.00021378]
Model epoch 564: train total loss -64.5383828009804, train mean loss 0.0005698050272338132, test mean loss [0.00022193 0.00236392 0.00017338 0.00027635 0.0007871  0.00015158
 0.00021329]
Model epoch 565: train total loss -64.69522318134432, train mean loss 0.0005167475526158253, test mean loss [0.00022181 0.00226187 0.00016418 0.00021658 0.00075676 0.00014716
 0.00020608]
Model epoch 566: train total loss -64.6918206455632, train mean loss 0.0004386563178707118, test mean loss [0.00021332 0.00214725 0.00016011 0.00021616 0.00077116 0.00015172
 0.00020852]
Model epoch 567: train total loss -64.87679265736007, train mean loss 0.0005683217267768884, test mean loss [0.00021493 0.00213292 0.0001635  0.00020566 0.0007355  0.00014595
 0.00020431]
Model epoch 568: train total loss -64.83240967167987, train mean loss 0.0004704493942313038, test mean loss [0.00026461 0.0021015  0.00016272 0.0002103  0.00072631 0.00015394
 0.00020653]
Model epoch 569: train total loss -64.23423008907913, train mean loss 0.0005263813959649522, test mean loss [0.00022738 0.00201293 0.00017485 0.00022418 0.00070364 0.00019734
 0.00023582]
Model epoch 570: train total loss -64.26383894901689, train mean loss 0.0005418460970485137, test mean loss [0.0002172  0.00195933 0.0001704  0.00026887 0.00069476 0.00019507
 0.00023075]
Model epoch 571: train total loss -64.41280960019122, train mean loss 0.0004584192639660846, test mean loss [0.00020523 0.00192589 0.00017791 0.00022352 0.00067026 0.00018333
 0.0002739 ]
Model epoch 572: train total loss -64.45661523401868, train mean loss 0.00042156740625296673, test mean loss [0.00019966 0.00187049 0.00016184 0.00021145 0.00066287 0.00016329
 0.00022339]
Model trained in 573 epochs with 1000 transitions.
[2025-01-24 17:11:00,904][absl][INFO] - {'eval/walltime': 73.12700366973877, 'training/sps': 1.0121487097379793, 'training/walltime': 987.9971098899841, 'training/model_train_time': 917.0158998966217, 'training/other_time': 70.14949917793274, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 10, 'training/env_buffer_size': Array(2000, dtype=int32), 'model/train_total_loss': Array(-64.45661523, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00042157, dtype=float64), 'model/test_total_loss': Array(-63.4185985, dtype=float64), 'model/test_mean_loss': Array(0.000499, dtype=float64), 'model/train_epochs': 573, 'model/sec_per_epoch': 1.5974198303089508, 'sac/actor_loss': Array(-11.74320243, dtype=float64), 'sac/alpha': Array(0.9169324, dtype=float32), 'sac/alpha_loss': Array(9.71430101, dtype=float64), 'sac/buffer_current_size': Array(3600., dtype=float32), 'sac/critic_loss': Array(0.69297133, dtype=float64), 'eval/episode_forward_vel': Array(-196.0344278, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-0.11680721, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(51.58010855, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.92082143, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-84.31588292, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(52.55790843, dtype=float64), 'eval/episode_rew_roll': Array(52.16821391, dtype=float64), 'eval/episode_rew_side_motion': Array(63.45014528, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(56.8258035, dtype=float64), 'eval/episode_rew_yaw': Array(80.63553618, dtype=float64), 'eval/episode_rew_z_vel_change': Array(25.5853409, dtype=float64), 'eval/episode_reward': Array(299.58982243, dtype=float64), 'eval/episode_step_count': Array(499500., dtype=float64), 'eval/avg_episode_length': Array(1000., dtype=float64), 'eval/epoch_eval_time': 29.991918325424194, 'eval/sps': 33.34231539141991}
Steps / Eval:  2000.0
Reward is  299.5898224312598
Model horizon updated to 2.
Hallucination updates per training step updated to 257.
SAC buffer resized to 205600 samples.
Model epoch 0: train total loss -62.03739352170109, train mean loss 0.0005612350772872693, test mean loss [0.00033354 0.00185956 0.00029731 0.00032413 0.00065985 0.00034111
 0.00033127]
Model epoch 1: train total loss -63.081902054382475, train mean loss 0.0005758306205719482, test mean loss [0.00031202 0.00178014 0.00027015 0.00031304 0.00063963 0.00027017
 0.00027195]
Model epoch 2: train total loss -63.631786574838756, train mean loss 0.0004052149995734235, test mean loss [0.00028905 0.00170508 0.00024783 0.00028865 0.00065022 0.0002462
 0.0002559 ]
Model epoch 3: train total loss -63.72016096626102, train mean loss 0.0004942674118166867, test mean loss [0.00027262 0.00158396 0.00024063 0.00027367 0.00066376 0.00022481
 0.0002469 ]
Model epoch 4: train total loss -64.14843319434607, train mean loss 0.0004980693927956362, test mean loss [0.00026166 0.0015191  0.00022753 0.00026255 0.00061905 0.00022368
 0.00023246]
Model epoch 5: train total loss -63.970189586187, train mean loss 0.000515871325654604, test mean loss [0.00028057 0.00147599 0.00023711 0.00025878 0.00057863 0.00022541
 0.00022836]
Model epoch 6: train total loss -64.23740335275915, train mean loss 0.00040665134058578273, test mean loss [0.0002658  0.00142666 0.00022607 0.0002621  0.00056322 0.00022326
 0.00022427]
Model epoch 7: train total loss -64.44615445084443, train mean loss 0.00039964984844794566, test mean loss [0.00025084 0.00138603 0.0002274  0.00025759 0.00051786 0.00021503
 0.00022515]
Model epoch 8: train total loss -64.25804378972714, train mean loss 0.00048140328209366753, test mean loss [0.00025091 0.00132169 0.0002384  0.00024918 0.00047761 0.00021634
 0.00023114]
Model epoch 9: train total loss -64.27792598250227, train mean loss 0.0004233646838635933, test mean loss [0.00025401 0.00127355 0.00022599 0.00025064 0.00044205 0.00020522
 0.00022225]
Model epoch 10: train total loss -64.31640702355737, train mean loss 0.0003943242581017191, test mean loss [0.00024526 0.00126881 0.0002263  0.000243   0.00040885 0.00021392
 0.00021927]
Model epoch 11: train total loss -64.47191972476138, train mean loss 0.00039666495767252925, test mean loss [0.00024087 0.00120062 0.0002198  0.00023521 0.0003666  0.00021288
 0.0002212 ]
Model epoch 12: train total loss -64.48539961604126, train mean loss 0.0003753931575210613, test mean loss [0.00024051 0.00113721 0.00022311 0.00023809 0.00034049 0.00020248
 0.00021389]
Model epoch 13: train total loss -64.46488989015978, train mean loss 0.0003741808811974407, test mean loss [0.00023993 0.00111074 0.00021764 0.00024133 0.00030998 0.00019738
 0.00021215]
Model epoch 14: train total loss -64.57657838170329, train mean loss 0.0003209037301897494, test mean loss [0.00023575 0.0010581  0.00021427 0.00023389 0.00028354 0.00019712
 0.00020751]
Model epoch 15: train total loss -64.4576622428472, train mean loss 0.00032694859155007306, test mean loss [0.00023534 0.00107808 0.00021665 0.0002364  0.00027717 0.00019607
 0.00020702]
Model epoch 16: train total loss -64.43880516686201, train mean loss 0.00034899650797616587, test mean loss [0.00022435 0.00100649 0.00021196 0.00024218 0.00026073 0.00019918
 0.00020569]
Model epoch 17: train total loss -64.49889470115059, train mean loss 0.0003063520961724103, test mean loss [0.00023639 0.00097729 0.00020972 0.00022672 0.00025942 0.00019341
 0.00020615]
Model epoch 18: train total loss -64.57541901449427, train mean loss 0.00028872330018201245, test mean loss [0.00022866 0.00094495 0.0002108  0.00023108 0.00025262 0.00019238
 0.0002102 ]
Model epoch 19: train total loss -64.62180829220175, train mean loss 0.0003068893858948348, test mean loss [0.00022547 0.00088404 0.00020544 0.00022517 0.00024113 0.00019672
 0.00019653]
Model epoch 20: train total loss -64.54007652769624, train mean loss 0.0002813659372846148, test mean loss [0.00021985 0.00081381 0.00021007 0.00022806 0.00023618 0.00018953
 0.00019906]
Model epoch 21: train total loss -64.55659672307591, train mean loss 0.00026804924861841597, test mean loss [0.0002175  0.00076255 0.00021118 0.00023182 0.00023237 0.00018989
 0.0002027 ]
Model epoch 22: train total loss -64.59278949701898, train mean loss 0.0002939198328880809, test mean loss [0.00022511 0.00075476 0.00021048 0.00022905 0.00023753 0.00019743
 0.0001997 ]
Model epoch 23: train total loss -64.43535157771801, train mean loss 0.0002738069042383542, test mean loss [0.00022246 0.00073356 0.00021473 0.00022124 0.00023791 0.0001863
 0.00019844]
Model epoch 24: train total loss -64.65234747878345, train mean loss 0.0003016073643430319, test mean loss [0.0002189  0.00068376 0.00020572 0.00021834 0.00023618 0.00018516
 0.000199  ]
Model epoch 25: train total loss -64.74857661530693, train mean loss 0.0002699433301507943, test mean loss [0.00021388 0.00064617 0.00020467 0.00021937 0.00023506 0.00018508
 0.00019674]
Model epoch 26: train total loss -64.53968487261886, train mean loss 0.00026636634444482865, test mean loss [0.00021729 0.00065876 0.00020684 0.00022981 0.00023029 0.00018859
 0.00020586]
Model epoch 27: train total loss -64.50107388280523, train mean loss 0.00023989738511832298, test mean loss [0.00020774 0.00058364 0.00020959 0.00021878 0.00023065 0.00018256
 0.0002002 ]
Model epoch 28: train total loss -64.6499729297697, train mean loss 0.00026103848758198705, test mean loss [0.00021178 0.00055742 0.00020374 0.00021553 0.00022865 0.00018037
 0.00019814]
Model epoch 29: train total loss -64.73528858843584, train mean loss 0.00025298387379629706, test mean loss [0.00021316 0.0005338  0.00020341 0.00023384 0.00023264 0.0001781
 0.00019191]
Model epoch 30: train total loss -64.30825642143377, train mean loss 0.0002648382261517355, test mean loss [0.00021517 0.0005205  0.00020815 0.00022303 0.00023673 0.00040723
 0.00019386]
Model epoch 31: train total loss -64.43370556705484, train mean loss 0.00024456093603543157, test mean loss [0.00021064 0.00050023 0.00020244 0.00022909 0.00023101 0.00030231
 0.00019564]
Model epoch 32: train total loss -64.45279825130731, train mean loss 0.00023934053893974173, test mean loss [0.00022619 0.00048292 0.00020379 0.00020888 0.0002285  0.00023246
 0.00019266]
Model epoch 33: train total loss -64.56979478534424, train mean loss 0.00023859172623524877, test mean loss [0.00021508 0.00043816 0.00019994 0.00021541 0.0002277  0.00020828
 0.00018772]
Model epoch 34: train total loss -64.68384090509218, train mean loss 0.000225708423166761, test mean loss [0.00021514 0.00043997 0.00020008 0.00021004 0.00023057 0.00020103
 0.00018517]
Model epoch 35: train total loss -64.5522776040751, train mean loss 0.00023521168046383107, test mean loss [0.00021161 0.00042967 0.00020234 0.00021041 0.00021988 0.00021561
 0.00018897]
Model epoch 36: train total loss -64.63641036820498, train mean loss 0.00021192302023388356, test mean loss [0.00020754 0.00039127 0.00020255 0.00020918 0.00023101 0.00020174
 0.00018738]
Model epoch 37: train total loss -64.74587028448232, train mean loss 0.00023074062095713549, test mean loss [0.00020552 0.00037771 0.00020494 0.00020252 0.00022432 0.00020227
 0.00018528]
Model epoch 38: train total loss -64.62299968064542, train mean loss 0.0002114216277171571, test mean loss [0.00021881 0.00036168 0.00019533 0.00021152 0.00022838 0.00019803
 0.00018804]
Model epoch 39: train total loss -64.76286461980294, train mean loss 0.00020331138924703913, test mean loss [0.00020741 0.00035936 0.00019406 0.00020434 0.00022576 0.00018244
 0.00018929]
Model epoch 40: train total loss -64.69558661479252, train mean loss 0.000215703015225523, test mean loss [0.00019801 0.00031817 0.00020132 0.00020746 0.00022446 0.00018593
 0.00018301]
Model epoch 41: train total loss -64.58893856799988, train mean loss 0.00019759378939061822, test mean loss [0.00020952 0.00031058 0.00019857 0.00023135 0.00021841 0.0001738
 0.00019375]
Model epoch 42: train total loss -64.4722545811555, train mean loss 0.0001929850245568545, test mean loss [0.00021147 0.00030868 0.00019867 0.00022269 0.00021466 0.00016974
 0.0001809 ]
Model epoch 43: train total loss -64.72274577553284, train mean loss 0.0002022542048344963, test mean loss [0.00020049 0.00029005 0.00019685 0.00021617 0.00021641 0.00017119
 0.00018387]
Model epoch 44: train total loss -64.75861753244165, train mean loss 0.00018984640571352947, test mean loss [0.00020614 0.00025523 0.00019215 0.00021639 0.00021997 0.00016656
 0.0001915 ]
Model epoch 45: train total loss -64.80991478517433, train mean loss 0.00018557545278627548, test mean loss [0.00020405 0.00024835 0.00021115 0.00020455 0.00021716 0.00016947
 0.00019178]
Model epoch 46: train total loss -64.73029344268441, train mean loss 0.00018453035033667097, test mean loss [0.00019789 0.00022801 0.00020186 0.00020452 0.00022264 0.00017072
 0.00018248]
Model epoch 47: train total loss -64.74695377671966, train mean loss 0.00018169741037491548, test mean loss [0.00020062 0.00022638 0.00019342 0.00020244 0.00020865 0.0001807
 0.00018841]
Model epoch 48: train total loss -64.7924984811088, train mean loss 0.000183270408258704, test mean loss [0.00019476 0.00020846 0.0001904  0.00020415 0.00021927 0.00017288
 0.00018641]
Model epoch 49: train total loss -64.89052210905623, train mean loss 0.00018704050032144025, test mean loss [0.00019915 0.00020609 0.00020266 0.00020373 0.00021776 0.00016711
 0.00018043]
Model epoch 50: train total loss -64.68031101346588, train mean loss 0.00018187451227785214, test mean loss [0.00020154 0.00019117 0.00019233 0.00019567 0.00021301 0.00017179
 0.0001795 ]
Model epoch 51: train total loss -64.80533728718386, train mean loss 0.00016959612802268473, test mean loss [0.00019523 0.00018614 0.00018596 0.00019271 0.00021978 0.00018054
 0.0001799 ]
Model epoch 52: train total loss -64.77748909103502, train mean loss 0.00018524220462204637, test mean loss [0.00019503 0.00018559 0.00018859 0.0001949  0.0002091  0.00017267
 0.00018005]
Model epoch 53: train total loss -65.02906894746741, train mean loss 0.00017625448341831532, test mean loss [0.00019844 0.00018076 0.00018769 0.00019744 0.00020919 0.00017536
 0.00018242]
Model epoch 54: train total loss -64.88721175509201, train mean loss 0.00017434005309895597, test mean loss [0.00019673 0.00017617 0.00019916 0.00019184 0.00020597 0.00019008
 0.00017517]
Model epoch 55: train total loss -64.87635580839328, train mean loss 0.0001639560670766576, test mean loss [0.00018961 0.00017638 0.00018959 0.00019158 0.00021108 0.00016839
 0.00017211]
Model epoch 56: train total loss -64.93860374720037, train mean loss 0.0001697977616983204, test mean loss [0.00018923 0.00018027 0.00018652 0.00019272 0.00020372 0.00017339
 0.00017551]
Model epoch 57: train total loss -65.02253218349213, train mean loss 0.00016671975541794157, test mean loss [0.0001855  0.00017431 0.000185   0.0001933  0.00019907 0.00016794
 0.00017952]
Model epoch 58: train total loss -65.1178039865751, train mean loss 0.00016236935163994675, test mean loss [0.00018585 0.00017669 0.00018386 0.00018963 0.00019868 0.00016009
 0.00017809]
Model epoch 59: train total loss -64.99518345950435, train mean loss 0.00018105545889704255, test mean loss [0.00019061 0.00016912 0.00018524 0.00018142 0.00020053 0.00016686
 0.00018126]
Model epoch 60: train total loss -65.02412707453175, train mean loss 0.00017005304656691244, test mean loss [0.00018761 0.00017275 0.00019288 0.0001872  0.00020481 0.00016373
 0.00016859]
Model epoch 61: train total loss -65.02092204105759, train mean loss 0.00015912139555774172, test mean loss [0.00018984 0.00017049 0.00018636 0.00019305 0.00020382 0.00016196
 0.00017549]
Model epoch 62: train total loss -64.85118296054894, train mean loss 0.00017625659339997444, test mean loss [0.00018404 0.00018036 0.0001961  0.00018653 0.00021093 0.00016255
 0.00018431]
Model epoch 63: train total loss -64.87143095063092, train mean loss 0.00017016395168346451, test mean loss [0.00018575 0.00016719 0.00019125 0.00018581 0.00020151 0.00016411
 0.00017374]
Model epoch 64: train total loss -64.90406684517069, train mean loss 0.0001645304998339172, test mean loss [0.00019804 0.00017193 0.0001893  0.00018201 0.00019839 0.00016096
 0.00017047]
Model epoch 65: train total loss -64.93423564427916, train mean loss 0.00016702965358193596, test mean loss [0.00018911 0.00017916 0.00018289 0.00017734 0.0002082  0.00016714
 0.00017957]
Model epoch 66: train total loss -64.74517753321967, train mean loss 0.00016845405327521945, test mean loss [0.00018945 0.00017705 0.00017614 0.00019579 0.00019958 0.0001633
 0.00017229]
Model epoch 67: train total loss -64.82204794958565, train mean loss 0.0001613448520044912, test mean loss [0.00018913 0.00017147 0.00017907 0.00018878 0.00019424 0.00015818
 0.00017202]
Model epoch 68: train total loss -64.95051158516422, train mean loss 0.00016001479412464383, test mean loss [0.00018536 0.00016892 0.00018548 0.00018385 0.00019357 0.00017281
 0.00017957]
Model epoch 69: train total loss -64.78569752599451, train mean loss 0.00015706060673339596, test mean loss [0.00018377 0.00016806 0.00018598 0.00019493 0.00019312 0.00015523
 0.00016878]
Model epoch 70: train total loss -64.9368462377006, train mean loss 0.000170938966150088, test mean loss [0.00020489 0.0001656  0.00017974 0.00018655 0.00019411 0.00017491
 0.00016424]
Model epoch 71: train total loss -64.98218059928894, train mean loss 0.00016178815759023798, test mean loss [0.00018899 0.00017021 0.00018006 0.00018594 0.00019344 0.00017059
 0.00017019]
Model epoch 72: train total loss -64.96920260068812, train mean loss 0.00015347600894562776, test mean loss [0.00018654 0.00016901 0.00018613 0.00019355 0.00019198 0.00015846
 0.00017037]
Model epoch 73: train total loss -64.81863910121993, train mean loss 0.00016664700186580104, test mean loss [0.00017571 0.00016871 0.00017186 0.00021304 0.00018815 0.00015255
 0.00016248]
Model epoch 74: train total loss -64.97267779363413, train mean loss 0.0001542808844630985, test mean loss [0.00019639 0.00016587 0.00017709 0.00018917 0.00020402 0.00015711
 0.00016286]
Model epoch 75: train total loss -64.93862112784272, train mean loss 0.0001593784200155799, test mean loss [0.00018786 0.00016253 0.00018042 0.00018022 0.00020124 0.00016001
 0.00016013]
Model epoch 76: train total loss -64.78382618400569, train mean loss 0.0001663776334822832, test mean loss [0.00017794 0.00024969 0.00018623 0.00018421 0.0001955  0.00016201
 0.00015812]
Model epoch 77: train total loss -64.66547718243233, train mean loss 0.0001768020501001981, test mean loss [0.00018824 0.00025872 0.00017939 0.00020185 0.00020717 0.00015673
 0.00016238]
Model epoch 78: train total loss -64.56930153270206, train mean loss 0.000176595142479547, test mean loss [0.00019401 0.00021807 0.00017717 0.0001872  0.00020991 0.00020195
 0.00016096]
Model epoch 79: train total loss -64.7298216291893, train mean loss 0.00017888860082941382, test mean loss [0.00018891 0.00018087 0.0001711  0.00017983 0.00018648 0.00017927
 0.00016464]
Model epoch 80: train total loss -64.87855199365264, train mean loss 0.0001736801873368693, test mean loss [0.00017432 0.00021839 0.00017421 0.00018253 0.00019    0.00018969
 0.0001575 ]
Model epoch 81: train total loss -64.85313176575315, train mean loss 0.0001831562039438143, test mean loss [0.00019052 0.00017661 0.00017514 0.00017973 0.00018576 0.00017789
 0.00016009]
Model epoch 82: train total loss -64.77730151513101, train mean loss 0.00016000695218529025, test mean loss [0.0001765  0.00016808 0.00019371 0.00018269 0.00020322 0.0001616
 0.00016249]
Model epoch 83: train total loss -64.82582507982845, train mean loss 0.0001538546260688334, test mean loss [0.00017057 0.00016299 0.00017543 0.00017603 0.00018609 0.00017644
 0.00016974]
Model epoch 84: train total loss -64.93219597876512, train mean loss 0.00015260184643271183, test mean loss [0.00019282 0.00016199 0.00017204 0.0001753  0.00018974 0.00016002
 0.00017374]
Model epoch 85: train total loss -64.46711811897005, train mean loss 0.0001855009029540709, test mean loss [0.0003885  0.00016751 0.00017456 0.000178   0.00019272 0.0001506
 0.00017192]
Model epoch 86: train total loss -64.71953244851248, train mean loss 0.00016802818114885015, test mean loss [0.00027398 0.00016348 0.00017643 0.00017391 0.00018279 0.00015882
 0.00015676]
Model epoch 87: train total loss -64.8308570405213, train mean loss 0.0001648673227790569, test mean loss [0.00025578 0.00015753 0.00017265 0.00017396 0.00018657 0.00016287
 0.00016483]
Model epoch 88: train total loss -64.88535177679987, train mean loss 0.00017074708965018608, test mean loss [0.00023695 0.00015732 0.00017512 0.00017142 0.00018666 0.00015208
 0.00016704]
Model epoch 89: train total loss -65.20363264108171, train mean loss 0.00015617975829792187, test mean loss [0.00021802 0.00015455 0.00016952 0.00017245 0.00019127 0.00015339
 0.00015776]
Model epoch 90: train total loss -65.1856850204, train mean loss 0.0001568033416426697, test mean loss [0.00020071 0.0001517  0.00016885 0.00017925 0.00018693 0.00015388
 0.00015346]
Model epoch 91: train total loss -65.13093899589539, train mean loss 0.00014462478301590877, test mean loss [0.00019152 0.00015419 0.00016605 0.00017685 0.00018278 0.00015723
 0.00017014]
Model epoch 92: train total loss -65.04518420858177, train mean loss 0.00014339740381951973, test mean loss [0.00019002 0.00015832 0.00016996 0.00017389 0.00017664 0.00014976
 0.00015731]
Model epoch 93: train total loss -64.87169412764113, train mean loss 0.00015166436121609775, test mean loss [0.00018739 0.00016098 0.00017593 0.00016945 0.00020446 0.00015834
 0.00015873]
Model epoch 94: train total loss -64.99208148512851, train mean loss 0.00014680136011089185, test mean loss [0.00018418 0.00017096 0.00019541 0.0001747  0.00018003 0.00015224
 0.00015438]
Model epoch 95: train total loss -64.81793247850446, train mean loss 0.0001562791948891253, test mean loss [0.00018387 0.00016368 0.0001781  0.00021196 0.00017987 0.00014966
 0.00016424]
Model epoch 96: train total loss -65.01454280818476, train mean loss 0.00014382372197259738, test mean loss [0.00017404 0.00015411 0.00016823 0.000183   0.00018546 0.00015529
 0.00015398]
Model epoch 97: train total loss -65.1199906461128, train mean loss 0.00014461717046034586, test mean loss [0.00017405 0.00015291 0.00018074 0.00018027 0.00018986 0.0001584
 0.00015293]
Model epoch 98: train total loss -65.09783622440234, train mean loss 0.00013909799515035597, test mean loss [0.0001766  0.0001503  0.00018267 0.00017305 0.00017703 0.00015012
 0.00015928]
Model epoch 99: train total loss -65.24849667454073, train mean loss 0.00014056078064600882, test mean loss [0.00017453 0.00015654 0.00016633 0.00018479 0.00018244 0.00015165
 0.0001517 ]
Model epoch 100: train total loss -65.163157324244, train mean loss 0.00014469080036463635, test mean loss [0.00017706 0.00015538 0.00016574 0.00017648 0.00017877 0.00014659
 0.0001635 ]
Model epoch 101: train total loss -65.03776852961457, train mean loss 0.00014204246899099482, test mean loss [0.0001691  0.00016435 0.00018984 0.00017122 0.000175   0.0001601
 0.00015985]
Model epoch 102: train total loss -65.15996506381516, train mean loss 0.00014151798729777296, test mean loss [0.00017028 0.00015318 0.00017437 0.00017003 0.00017886 0.00014988
 0.00015593]
Model epoch 103: train total loss -65.40280722378354, train mean loss 0.0001393293481802022, test mean loss [0.00018969 0.00015286 0.00016614 0.00016839 0.00017703 0.00014629
 0.00015792]
Model epoch 104: train total loss -65.09718261560151, train mean loss 0.00014699264163065004, test mean loss [0.00017891 0.00015256 0.00016384 0.000158   0.00018015 0.00014836
 0.00015436]
Model epoch 105: train total loss -64.91347357708523, train mean loss 0.00016542475887589635, test mean loss [0.00017314 0.00015787 0.00031313 0.00016437 0.00017388 0.00014845
 0.00015533]
Model epoch 106: train total loss -64.94592400516827, train mean loss 0.00015780425263731994, test mean loss [0.00016472 0.0001574  0.00027766 0.00016643 0.00017204 0.00016447
 0.00015059]
Model epoch 107: train total loss -65.21896890533277, train mean loss 0.00015885511517176151, test mean loss [0.00017138 0.00015789 0.0002687  0.00017023 0.00016317 0.00015647
 0.00015359]
Model epoch 108: train total loss -65.24811789723704, train mean loss 0.0001624858823259523, test mean loss [0.00016453 0.00014872 0.00025145 0.00016399 0.00016675 0.00015174
 0.00015865]
Model epoch 109: train total loss -65.03150271001874, train mean loss 0.0001610051702485643, test mean loss [0.00017261 0.00015021 0.0002749  0.0001625  0.00016839 0.00014601
 0.00015638]
Model epoch 110: train total loss -64.25970754650407, train mean loss 0.00016646987200576665, test mean loss [0.0001792  0.00015168 0.00023195 0.00016629 0.00017145 0.00022297
 0.00015092]
Model epoch 111: train total loss -64.6906677475123, train mean loss 0.00023117875213455078, test mean loss [0.00016561 0.00015685 0.00020808 0.00016434 0.0001708  0.00068666
 0.00015045]
Model epoch 112: train total loss -64.78901971587375, train mean loss 0.00018559288380400337, test mean loss [0.0001649  0.00017042 0.0001852  0.00016367 0.00018177 0.0003483
 0.00015651]
Model epoch 113: train total loss -65.05365934393252, train mean loss 0.00014667714447127523, test mean loss [0.00015671 0.0001483  0.00017994 0.00016684 0.00016978 0.00024699
 0.00014288]
Model epoch 114: train total loss -65.11881509195173, train mean loss 0.00015637586695162235, test mean loss [0.0001622  0.00015522 0.00017774 0.00016088 0.0001682  0.00024296
 0.00014798]
Model epoch 115: train total loss -65.13152644837966, train mean loss 0.00014791134979371784, test mean loss [0.00016835 0.0001471  0.00016837 0.00016176 0.00017248 0.00021991
 0.00015211]
Model epoch 116: train total loss -65.16476349424404, train mean loss 0.0001445731738547463, test mean loss [0.00016246 0.00015082 0.00016779 0.00017262 0.00016982 0.00023105
 0.0001511 ]
Model epoch 117: train total loss -65.29758057035241, train mean loss 0.00015249226717666586, test mean loss [0.00016016 0.00014624 0.00016311 0.00016707 0.00016719 0.00023393
 0.0001476 ]
Model epoch 118: train total loss -65.33151004865532, train mean loss 0.00015379559623823148, test mean loss [0.00016151 0.00015237 0.00015955 0.00016598 0.00016619 0.00022105
 0.00014812]
Model epoch 119: train total loss -64.81949488642991, train mean loss 0.000156476049402097, test mean loss [0.00019313 0.00015748 0.00016465 0.00015775 0.00015848 0.00023696
 0.00015584]
Model epoch 120: train total loss -65.17341621111815, train mean loss 0.0001451997158484435, test mean loss [0.00016911 0.00014258 0.00016369 0.00016358 0.00016936 0.00022608
 0.00014424]
Model epoch 121: train total loss -65.34549795210468, train mean loss 0.00014577742088255205, test mean loss [0.00016367 0.0001454  0.00015695 0.00016531 0.00017389 0.00022425
 0.00015468]
Model epoch 122: train total loss -65.33245718475402, train mean loss 0.0001514656434224085, test mean loss [0.00015777 0.00014748 0.00015411 0.00017027 0.00016064 0.00022619
 0.0001601 ]
Model epoch 123: train total loss -65.39819957163256, train mean loss 0.00015251477886171722, test mean loss [0.00016134 0.0001435  0.00015843 0.00015803 0.00016376 0.00022809
 0.00017258]
Model epoch 124: train total loss -64.74754009685576, train mean loss 0.00015194233811925714, test mean loss [0.00022041 0.00015306 0.00016112 0.00016581 0.00016208 0.00023545
 0.00015626]
Model epoch 125: train total loss -64.88131048182187, train mean loss 0.0001520831594324687, test mean loss [0.00018266 0.00014725 0.00016258 0.00015966 0.00016576 0.00022196
 0.00014308]
Model epoch 126: train total loss -65.17187874768774, train mean loss 0.00014825655763532183, test mean loss [0.00016319 0.00014678 0.00015529 0.00017158 0.0001547  0.00023234
 0.00014943]
Model epoch 127: train total loss -65.18579298294247, train mean loss 0.00015102615779512518, test mean loss [0.00017263 0.00014798 0.00016277 0.00015692 0.00016772 0.00021611
 0.0001449 ]
Model epoch 128: train total loss -64.96478584556105, train mean loss 0.00016388172408130395, test mean loss [0.000164   0.00014182 0.00015459 0.00016442 0.00027763 0.00021427
 0.00014428]
Model epoch 129: train total loss -65.11078590643649, train mean loss 0.00014784848133007626, test mean loss [0.00016431 0.00014504 0.00016125 0.00016638 0.00020402 0.00021673
 0.00014389]
Model epoch 130: train total loss -64.6801942406994, train mean loss 0.00015654391093331859, test mean loss [0.00016704 0.00014649 0.00015885 0.00016855 0.00018955 0.00025669
 0.00014779]
Model epoch 131: train total loss -65.01224087810357, train mean loss 0.00015100093767224734, test mean loss [0.00015577 0.00014565 0.00015651 0.00016586 0.00018425 0.00021089
 0.00015128]
Model epoch 132: train total loss -65.03858668678146, train mean loss 0.00016173514930666285, test mean loss [0.00016256 0.00014714 0.00015967 0.00016115 0.00026232 0.00021038
 0.00015826]
Model trained in 133 epochs with 2000 transitions.
[2025-01-24 17:23:56,369][absl][INFO] - {'eval/walltime': 103.34820365905762, 'training/sps': 1.3420894948924436, 'training/walltime': 1733.1039032936096, 'training/model_train_time': 382.41318798065186, 'training/other_time': 361.8626766204834, 'training/model_horizon': 2, 'training/hallucination_updates_per_training_step': 257, 'training/env_buffer_size': Array(3000, dtype=int32), 'model/train_total_loss': Array(-65.03858669, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00016174, dtype=float64), 'model/test_total_loss': Array(-64.65758615, dtype=float64), 'model/test_mean_loss': Array(0.00018021, dtype=float64), 'model/train_epochs': 133, 'model/sec_per_epoch': 2.8608374183339285, 'sac/actor_loss': Array(-12.32185724, dtype=float64), 'sac/alpha': Array(0.23557527, dtype=float32), 'sac/alpha_loss': Array(1.98647087, dtype=float64), 'sac/buffer_current_size': Array(108129.18, dtype=float32), 'sac/critic_loss': Array(0.08233389, dtype=float64), 'eval/episode_forward_vel': Array(-32.80732702, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-7.41933057, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(4.26363295, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.04680879, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-14.11067829, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(3.71094706, dtype=float64), 'eval/episode_rew_roll': Array(3.5569748, dtype=float64), 'eval/episode_rew_side_motion': Array(3.26542459, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(6.20092554, dtype=float64), 'eval/episode_rew_yaw': Array(8.87126196, dtype=float64), 'eval/episode_rew_z_vel_change': Array(2.26980931, dtype=float64), 'eval/episode_reward': Array(9.78753491, dtype=float64), 'eval/episode_step_count': Array(4005., dtype=float64), 'eval/avg_episode_length': Array(90., dtype=float64), 'eval/epoch_eval_time': 30.221199989318848, 'eval/sps': 33.0893545045674}
Steps / Eval:  3000.0
Reward is  9.787534914662029
Model horizon updated to 4.
Hallucination updates per training step updated to 505.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -30.029120561402003, train mean loss 0.03023144027982396, test mean loss [0.02483195 0.02864132 0.01794619 0.03148406 0.02416905 0.03630953
 0.03290313]
Model epoch 1: train total loss -36.726683253264554, train mean loss 0.02580872331362861, test mean loss [0.01983623 0.02470528 0.01493491 0.0279583  0.02176315 0.0345538
 0.02591007]
Model epoch 2: train total loss -40.966674680168865, train mean loss 0.022560033312913053, test mean loss [0.01743368 0.02244724 0.01264027 0.02625883 0.01952863 0.03334204
 0.02099754]
Model epoch 3: train total loss -44.620959367879, train mean loss 0.02093597875535009, test mean loss [0.01449309 0.02036069 0.01079511 0.02410219 0.01619872 0.03121728
 0.01809791]
Model epoch 4: train total loss -46.93104382725781, train mean loss 0.0178094548691894, test mean loss [0.01232048 0.0177337  0.00918017 0.02303288 0.01367832 0.02574807
 0.01554572]
Model epoch 5: train total loss -49.23980323299992, train mean loss 0.015728253363669422, test mean loss [0.01062121 0.01427051 0.00834938 0.02131081 0.01205698 0.02066965
 0.01413489]
Model epoch 6: train total loss -51.31960152924638, train mean loss 0.012614527763835483, test mean loss [0.00945966 0.01050316 0.00747959 0.01934573 0.01073507 0.01702686
 0.01289853]
Model epoch 7: train total loss -52.702077091853845, train mean loss 0.011402931316660333, test mean loss [0.00837256 0.00785837 0.00678117 0.01712701 0.00948313 0.01474475
 0.01173159]
Model epoch 8: train total loss -54.07863119466852, train mean loss 0.009732015162060228, test mean loss [0.00770237 0.00632968 0.00629058 0.01491133 0.00826469 0.01336348
 0.01065622]
Model epoch 9: train total loss -55.07462529342197, train mean loss 0.008850006328033275, test mean loss [0.00690192 0.00513373 0.0057709  0.01255714 0.00717399 0.01240002
 0.00962549]
Model epoch 10: train total loss -55.806692419965444, train mean loss 0.007762263502019642, test mean loss [0.00597582 0.00427668 0.00527151 0.01079824 0.00638055 0.01151466
 0.00891668]
Model epoch 11: train total loss -56.490394250214486, train mean loss 0.007143099608947757, test mean loss [0.00532191 0.00355825 0.00482302 0.00985122 0.00571599 0.01086528
 0.00804298]
Model epoch 12: train total loss -57.154953342210845, train mean loss 0.0065006291915081895, test mean loss [0.00461133 0.00306939 0.00435696 0.00902226 0.00502831 0.0100931
 0.00708012]
Model epoch 13: train total loss -57.621459577936406, train mean loss 0.005821000278194613, test mean loss [0.00416361 0.00265486 0.00403082 0.00852199 0.00454978 0.009468
 0.00621436]
Model epoch 14: train total loss -58.01557718717841, train mean loss 0.005203238562203203, test mean loss [0.0035765  0.00230048 0.00366779 0.00801243 0.00400029 0.00872644
 0.00540969]
Model epoch 15: train total loss -58.35286983393917, train mean loss 0.005020669338785901, test mean loss [0.00318291 0.00200667 0.0034325  0.00767885 0.00351607 0.00813616
 0.00486732]
Model epoch 16: train total loss -58.76080800265796, train mean loss 0.004264227720281339, test mean loss [0.00275704 0.00170538 0.00313723 0.00720898 0.00306924 0.00762931
 0.00435045]
Model epoch 17: train total loss -58.90270834221088, train mean loss 0.003820763561451647, test mean loss [0.00239676 0.00155808 0.00277971 0.00674934 0.00269686 0.00699345
 0.00379294]
Model epoch 18: train total loss -59.12792015165101, train mean loss 0.0036520386900504133, test mean loss [0.00215357 0.00141581 0.00255739 0.0062438  0.00233627 0.00627896
 0.00337724]
Model epoch 19: train total loss -59.53416352432019, train mean loss 0.003272843167949522, test mean loss [0.00186501 0.00127831 0.00220049 0.00573551 0.00207709 0.0058622
 0.00300535]
Model epoch 20: train total loss -59.72940189203415, train mean loss 0.0030825478457225685, test mean loss [0.00171721 0.0011898  0.00188429 0.00544213 0.00178751 0.00541462
 0.00280809]
Model epoch 21: train total loss -59.98352322744135, train mean loss 0.0027698608758096846, test mean loss [0.00149004 0.0011218  0.00159976 0.00511048 0.00153506 0.00496322
 0.00247499]
Model epoch 22: train total loss -60.215116404304936, train mean loss 0.002460916828708124, test mean loss [0.00126824 0.00105797 0.00138089 0.00474949 0.00135526 0.00449086
 0.00223495]
Model epoch 23: train total loss -60.58054834623406, train mean loss 0.0019424275499104256, test mean loss [0.00116761 0.00099924 0.00122071 0.00441377 0.00119369 0.0040231
 0.00196967]
Model epoch 24: train total loss -60.53232816261277, train mean loss 0.001902771582369691, test mean loss [0.0010468  0.00095324 0.00109987 0.00420818 0.00103515 0.00356323
 0.00180041]
Model epoch 25: train total loss -60.73529489680967, train mean loss 0.0017366032333504782, test mean loss [0.000975   0.00091215 0.0010121  0.0038593  0.00094293 0.00331041
 0.00159369]
Model epoch 26: train total loss -61.00061436181133, train mean loss 0.001625946130146703, test mean loss [0.00092994 0.00088188 0.00093565 0.00376023 0.00087008 0.00295012
 0.00145839]
Model epoch 27: train total loss -61.054067450217396, train mean loss 0.0014401997381056867, test mean loss [0.00083828 0.00085485 0.00089371 0.00348513 0.00083347 0.00260199
 0.00129246]
Model epoch 28: train total loss -61.187211432022515, train mean loss 0.0015104540779348583, test mean loss [0.00078034 0.00080214 0.00083616 0.0033239  0.00079564 0.00227876
 0.00115711]
Model epoch 29: train total loss -61.37594722464598, train mean loss 0.001312999570443284, test mean loss [0.00075251 0.00079548 0.00079607 0.00316944 0.00076479 0.00202774
 0.00106939]
Model epoch 30: train total loss -61.38878676138885, train mean loss 0.001167460814465208, test mean loss [0.00073668 0.00077529 0.00075715 0.00306425 0.00075211 0.00180295
 0.00102038]
Model epoch 31: train total loss -61.603558288298174, train mean loss 0.0011895528551822002, test mean loss [0.00069799 0.00074112 0.0007355  0.00292169 0.00073843 0.00154975
 0.00098501]
Model epoch 32: train total loss -61.65301939444039, train mean loss 0.0010950923625599035, test mean loss [0.00069543 0.00073264 0.0007089  0.0028434  0.00070827 0.00136339
 0.00095816]
Model epoch 33: train total loss -61.8303298364709, train mean loss 0.0010469968309342863, test mean loss [0.00066201 0.00071304 0.00069425 0.00273267 0.00069144 0.00120668
 0.00093067]
Model epoch 34: train total loss -61.96089434401006, train mean loss 0.000979915531379686, test mean loss [0.00064471 0.00068468 0.00067519 0.00258664 0.00066671 0.00111125
 0.00087944]
Model epoch 35: train total loss -62.04567236252493, train mean loss 0.0009303897946244755, test mean loss [0.00061007 0.00068456 0.00065913 0.00246693 0.00064235 0.00103456
 0.00085727]
Model epoch 36: train total loss -61.99965854068817, train mean loss 0.0008684540321634073, test mean loss [0.00060582 0.00065828 0.00065178 0.00236131 0.0006369  0.00095929
 0.00084554]
Model epoch 37: train total loss -62.144595484017344, train mean loss 0.0008744774718308996, test mean loss [0.00058471 0.00066248 0.00062525 0.00219156 0.00060512 0.00090883
 0.00079472]
Model epoch 38: train total loss -61.93415012653091, train mean loss 0.0008619510154135611, test mean loss [0.0005899  0.0006271  0.00060812 0.00220187 0.00061328 0.00083194
 0.00079245]
Model epoch 39: train total loss -62.2501415410921, train mean loss 0.0007406529857332878, test mean loss [0.00056937 0.00064492 0.0005942  0.00212437 0.00058913 0.00080104
 0.00077877]
Model epoch 40: train total loss -62.275877928305505, train mean loss 0.0007451395506260876, test mean loss [0.00055268 0.00064347 0.00058122 0.00199313 0.00057942 0.00077817
 0.00075618]
Model epoch 41: train total loss -62.31693262718212, train mean loss 0.0006834022571641113, test mean loss [0.00054452 0.00060057 0.00057009 0.00193227 0.00056432 0.00074441
 0.00072621]
Model epoch 42: train total loss -62.476774110667236, train mean loss 0.0006936871626971719, test mean loss [0.00053819 0.00060691 0.00056035 0.00188533 0.00054398 0.00072022
 0.00071469]
Model epoch 43: train total loss -62.65823552400848, train mean loss 0.0007218436777793579, test mean loss [0.00052325 0.00058838 0.00054269 0.00177694 0.000537   0.00069067
 0.00068959]
Model epoch 44: train total loss -62.78145446182495, train mean loss 0.000694276012121083, test mean loss [0.00051622 0.00057164 0.00053897 0.00169084 0.0005391  0.00067728
 0.00070555]
Model epoch 45: train total loss -62.64575787304455, train mean loss 0.0006617558106447388, test mean loss [0.0005058  0.00055196 0.00052686 0.00169575 0.00051113 0.00065655
 0.00065667]
Model epoch 46: train total loss -62.93276252443748, train mean loss 0.0006023768006781561, test mean loss [0.00049933 0.00055063 0.00053337 0.00158998 0.00051099 0.00064114
 0.0006484 ]
Model epoch 47: train total loss -62.593849869806164, train mean loss 0.0005408120195957528, test mean loss [0.00049138 0.00054472 0.00051059 0.0015451  0.00050435 0.00063696
 0.00063111]
Model epoch 48: train total loss -62.632700992338556, train mean loss 0.0006375650702884661, test mean loss [0.00048887 0.00052815 0.00050027 0.00145104 0.00049481 0.00063165
 0.00062614]
Model epoch 49: train total loss -62.88377981469912, train mean loss 0.0005403889862492972, test mean loss [0.00047458 0.00051368 0.00048842 0.00139856 0.00047936 0.00062047
 0.00061767]
Model epoch 50: train total loss -62.76324927013987, train mean loss 0.0005326200814713515, test mean loss [0.00046838 0.00052244 0.00054432 0.0013099  0.00047732 0.0005881
 0.00059094]
Model epoch 51: train total loss -63.19955165459068, train mean loss 0.0005025819039297572, test mean loss [0.00046092 0.0005155  0.00049815 0.00131318 0.00047467 0.00058066
 0.00058957]
Model epoch 52: train total loss -62.90221372462956, train mean loss 0.0005098683813527087, test mean loss [0.00047081 0.0005054  0.00048687 0.00123838 0.00046439 0.00057339
 0.00058835]
Model epoch 53: train total loss -63.12495316113312, train mean loss 0.0004948768523262893, test mean loss [0.00045588 0.00049644 0.00046717 0.00113332 0.00045842 0.00057712
 0.0005725 ]
Model epoch 54: train total loss -62.869561052293946, train mean loss 0.0005391730966196489, test mean loss [0.00044967 0.00050578 0.00046347 0.00114319 0.00044504 0.00055615
 0.0005495 ]
Model epoch 55: train total loss -63.13967835792269, train mean loss 0.0005146431865604279, test mean loss [0.0004452  0.00048526 0.00045263 0.00102995 0.00044193 0.00052527
 0.00054071]
Model epoch 56: train total loss -63.30272262561719, train mean loss 0.00042379579690647096, test mean loss [0.0004404  0.00048504 0.00043964 0.00103242 0.00044609 0.00052746
 0.00053938]
Model epoch 57: train total loss -63.17390924809959, train mean loss 0.00041596032673484496, test mean loss [0.00043026 0.0004766  0.00043582 0.00098371 0.00043055 0.00054129
 0.00052795]
Model epoch 58: train total loss -63.200337475078605, train mean loss 0.000483189246538686, test mean loss [0.00042648 0.00046102 0.00043416 0.00093533 0.00045576 0.00052337
 0.00051636]
Model epoch 59: train total loss -63.23369308611454, train mean loss 0.00045746689067539397, test mean loss [0.00041236 0.0004728  0.00043968 0.00092024 0.00042862 0.00049595
 0.00050493]
Model epoch 60: train total loss -63.307492486611615, train mean loss 0.0004085352347962338, test mean loss [0.00041929 0.00046521 0.00041251 0.00085368 0.00041891 0.00049143
 0.00049972]
Model epoch 61: train total loss -63.18007462312441, train mean loss 0.0003929622007390992, test mean loss [0.00041939 0.00045592 0.00041676 0.00084722 0.00040444 0.00048828
 0.00049419]
Model epoch 62: train total loss -63.39894421264983, train mean loss 0.0004077025038837993, test mean loss [0.00040377 0.00046367 0.00040078 0.00079204 0.00040803 0.00047364
 0.00049838]
Model epoch 63: train total loss -63.300918654934804, train mean loss 0.00036830036259774643, test mean loss [0.00040675 0.00045028 0.00040073 0.00076678 0.00040514 0.00049225
 0.00048491]
Model epoch 64: train total loss -63.34241828801252, train mean loss 0.0003980282487029368, test mean loss [0.00039065 0.00043236 0.00039237 0.00074864 0.00039337 0.00046969
 0.00047241]
Model epoch 65: train total loss -63.493724879459656, train mean loss 0.0003435794037742417, test mean loss [0.0004099  0.00042425 0.00038345 0.00072801 0.00038926 0.00045531
 0.00047286]
Model epoch 66: train total loss -63.441944100910376, train mean loss 0.0003731878202458137, test mean loss [0.0004001  0.00042196 0.00038414 0.00068975 0.00037474 0.00045052
 0.00046193]
Model epoch 67: train total loss -63.47382733414595, train mean loss 0.00043055520363732385, test mean loss [0.00039391 0.00042212 0.00038503 0.00065376 0.00038273 0.00043625
 0.00045954]
Model epoch 68: train total loss -63.527867099437394, train mean loss 0.0003918223728413306, test mean loss [0.00037879 0.00043113 0.00037726 0.00061433 0.00037253 0.00043982
 0.00043771]
Model epoch 69: train total loss -63.50261954088843, train mean loss 0.0003701620350078865, test mean loss [0.00037864 0.00041407 0.00036448 0.00057597 0.00037265 0.00043104
 0.00044951]
Model epoch 70: train total loss -63.709886923644824, train mean loss 0.0003278477185655893, test mean loss [0.00038632 0.00040688 0.00035835 0.00054932 0.0003745  0.00042529
 0.00043394]
Model epoch 71: train total loss -63.674262988022925, train mean loss 0.000363106778884086, test mean loss [0.00037119 0.00041033 0.0003686  0.00050784 0.00036372 0.00042226
 0.00042181]
Model epoch 72: train total loss -63.70757331039747, train mean loss 0.00033371083731617996, test mean loss [0.00036572 0.00040703 0.00036157 0.00049301 0.00035306 0.00040964
 0.00042178]
Model epoch 73: train total loss -63.77740260861927, train mean loss 0.0002958787334513818, test mean loss [0.00035876 0.00040626 0.00035361 0.00047162 0.00035588 0.00040339
 0.00041081]
Model epoch 74: train total loss -63.80770479494402, train mean loss 0.0003080810588766337, test mean loss [0.00036668 0.00039611 0.00035226 0.00047971 0.00034631 0.0003913
 0.00041032]
Model epoch 75: train total loss -63.784851326921405, train mean loss 0.00026069582402980963, test mean loss [0.00035757 0.00040359 0.00034181 0.00046472 0.00035497 0.00040441
 0.00040198]
Model epoch 76: train total loss -63.84749970645615, train mean loss 0.0003254814288860412, test mean loss [0.00034714 0.00039071 0.00034629 0.0004549  0.00034519 0.00038078
 0.00040043]
Model epoch 77: train total loss -63.864622561198054, train mean loss 0.00031796517442368515, test mean loss [0.00034534 0.00039948 0.00035213 0.00045561 0.00034277 0.00038703
 0.00038789]
Model epoch 78: train total loss -63.86819040160881, train mean loss 0.00027387182036367957, test mean loss [0.00034793 0.00038659 0.0003239  0.00044356 0.00034313 0.00038393
 0.00038403]
Model epoch 79: train total loss -63.8964544865282, train mean loss 0.0003131917395448136, test mean loss [0.00033965 0.00039794 0.00033294 0.00043209 0.00033082 0.0003757
 0.00038485]
Model epoch 80: train total loss -63.83426016851303, train mean loss 0.0003071813481344261, test mean loss [0.00033086 0.00038092 0.00032397 0.00043308 0.000335   0.00037335
 0.00039174]
Model epoch 81: train total loss -63.92001780193969, train mean loss 0.00025172516251700366, test mean loss [0.00033327 0.00038174 0.00033235 0.00041976 0.00031692 0.00036403
 0.00037503]
Model epoch 82: train total loss -63.799647125285475, train mean loss 0.0003259332103028756, test mean loss [0.00033554 0.00037922 0.00032162 0.00042541 0.00034504 0.00036497
 0.00038764]
Model epoch 83: train total loss -63.959832324384124, train mean loss 0.0003039084777881258, test mean loss [0.00032783 0.00037333 0.0003205  0.00041779 0.0003368  0.00034889
 0.00037368]
Model epoch 84: train total loss -64.09276425226375, train mean loss 0.0002752585996848044, test mean loss [0.00033164 0.00037804 0.00031677 0.00041754 0.00032345 0.00034907
 0.00036394]
Model epoch 85: train total loss -64.04377326341918, train mean loss 0.0002716443306424765, test mean loss [0.00032406 0.00037222 0.00031645 0.00040579 0.00031705 0.00034357
 0.00035549]
Model epoch 86: train total loss -64.05524559976409, train mean loss 0.0002350122608011461, test mean loss [0.00032211 0.00037206 0.00030806 0.00039679 0.0003179  0.0003421
 0.00034856]
Model epoch 87: train total loss -64.00677973725846, train mean loss 0.0002836047696740637, test mean loss [0.00032592 0.00036619 0.00030024 0.0003955  0.00030142 0.0003642
 0.00035334]
Model epoch 88: train total loss -64.11294569346168, train mean loss 0.00023383389692423648, test mean loss [0.00031769 0.00036823 0.0003037  0.00038824 0.00029658 0.00033504
 0.0003482 ]
Model epoch 89: train total loss -63.970604230544964, train mean loss 0.0002729713334794554, test mean loss [0.00031765 0.00035906 0.00032551 0.00039241 0.00029292 0.00032838
 0.00034627]
Model epoch 90: train total loss -64.01551870083664, train mean loss 0.0002806291312025323, test mean loss [0.00030752 0.00036108 0.00030311 0.00039401 0.00029132 0.00033255
 0.00033141]
Model epoch 91: train total loss -64.02100537177598, train mean loss 0.0002464851971041562, test mean loss [0.00031991 0.00035154 0.00030286 0.0003821  0.00030818 0.00032793
 0.00032899]
Model epoch 92: train total loss -64.14016233231614, train mean loss 0.0002484022204180065, test mean loss [0.00031082 0.000354   0.00030908 0.00037852 0.00029541 0.00032307
 0.00033268]
Model epoch 93: train total loss -64.15310271934625, train mean loss 0.0002882270469035512, test mean loss [0.00031218 0.00034683 0.00029482 0.00038134 0.00028628 0.00031679
 0.00032973]
Model epoch 94: train total loss -64.00930985585623, train mean loss 0.0002366101870561395, test mean loss [0.00029786 0.00040729 0.00029498 0.00037097 0.00029819 0.00031246
 0.00033167]
Model epoch 95: train total loss -64.29198890373134, train mean loss 0.0002346341761241772, test mean loss [0.00030156 0.00037589 0.00028622 0.00036572 0.00028618 0.00030663
 0.00032789]
Model epoch 96: train total loss -64.20939194641832, train mean loss 0.000257155731390449, test mean loss [0.0002963  0.00034927 0.00028222 0.00036353 0.00027358 0.0003023
 0.00032   ]
Model epoch 97: train total loss -64.24931473301767, train mean loss 0.0002576031804590158, test mean loss [0.00030014 0.00035097 0.00028321 0.00035846 0.00027884 0.00030511
 0.00031921]
Model epoch 98: train total loss -64.30002912940054, train mean loss 0.0002213485160787451, test mean loss [0.00029432 0.00033823 0.00028805 0.00035754 0.000275   0.00030892
 0.00032938]
Model epoch 99: train total loss -63.774947661303386, train mean loss 0.00027463932019267513, test mean loss [0.00029398 0.00052412 0.00028562 0.00035288 0.00028218 0.00029881
 0.00030928]
Model epoch 100: train total loss -64.01397325701392, train mean loss 0.00027718256104038424, test mean loss [0.00029479 0.00040282 0.00028486 0.00035464 0.00027587 0.00030734
 0.00030949]
Model epoch 101: train total loss -63.94188593114306, train mean loss 0.0002175010032993079, test mean loss [0.0002823  0.0003583  0.00027919 0.00033862 0.00028837 0.00029393
 0.00032349]
Model epoch 102: train total loss -64.05108793325617, train mean loss 0.00027754820188321237, test mean loss [0.00029369 0.00034221 0.00027721 0.00033983 0.00027795 0.00028946
 0.0003048 ]
Model epoch 103: train total loss -64.32912497294743, train mean loss 0.00024022237608582102, test mean loss [0.00028576 0.00034746 0.00027515 0.00034345 0.00027667 0.00029126
 0.00030627]
Model epoch 104: train total loss -64.31647159816498, train mean loss 0.00022952597587500828, test mean loss [0.00028706 0.00033639 0.00027417 0.00033602 0.00026752 0.00028556
 0.00030123]
Model epoch 105: train total loss -64.20287514580386, train mean loss 0.0002533509921208511, test mean loss [0.00028451 0.00032836 0.00027422 0.00033002 0.00027112 0.00027332
 0.0003022 ]
Model epoch 106: train total loss -64.2947850071637, train mean loss 0.00022593542364509063, test mean loss [0.00028984 0.0003295  0.00027264 0.00034008 0.00025702 0.00027549
 0.00029257]
Model epoch 107: train total loss -64.31553234610632, train mean loss 0.00023771672416017715, test mean loss [0.00028677 0.00032255 0.00027689 0.00034717 0.00025672 0.00027012
 0.00030712]
Model epoch 108: train total loss -64.26899089924528, train mean loss 0.00020903220718601105, test mean loss [0.0002764  0.0003229  0.00028526 0.00032692 0.00026035 0.00027165
 0.00029101]
Model epoch 109: train total loss -64.29788975334722, train mean loss 0.0002610582950967759, test mean loss [0.00026904 0.00032204 0.00026448 0.00032785 0.00026682 0.00027159
 0.00028934]
Model epoch 110: train total loss -64.54396520909745, train mean loss 0.00022775995996093923, test mean loss [0.00028309 0.0003181  0.00025835 0.00031786 0.0002581  0.00026917
 0.00028614]
Model epoch 111: train total loss -64.5113706709525, train mean loss 0.00022545086812363193, test mean loss [0.00027241 0.0003093  0.00025563 0.00032075 0.00025051 0.00026232
 0.0002952 ]
Model epoch 112: train total loss -64.15973855138152, train mean loss 0.00024782059964919564, test mean loss [0.00026736 0.00031171 0.00026131 0.00033542 0.00024397 0.00026276
 0.00029228]
Model epoch 113: train total loss -64.67008628445156, train mean loss 0.0002362821021292248, test mean loss [0.00026256 0.0003046  0.00025607 0.00031477 0.00024031 0.00026245
 0.0002876 ]
Model epoch 114: train total loss -64.54978258113807, train mean loss 0.00023812855498600666, test mean loss [0.00026729 0.00030815 0.00025909 0.00031331 0.00023394 0.00025684
 0.00028838]
Model epoch 115: train total loss -64.3784619226899, train mean loss 0.00021483512232329944, test mean loss [0.00027719 0.00030618 0.00026377 0.00031673 0.00024016 0.00026179
 0.00027026]
Model epoch 116: train total loss -64.50741649761865, train mean loss 0.00022685485307064775, test mean loss [0.00026539 0.00030732 0.00024892 0.00030248 0.00025467 0.00025225
 0.00027208]
Model epoch 117: train total loss -64.60049995308748, train mean loss 0.00023478925688556637, test mean loss [0.00025499 0.00030037 0.00025512 0.00030427 0.00025132 0.00025325
 0.00028082]
Model epoch 118: train total loss -64.50408436902893, train mean loss 0.00022297099698939283, test mean loss [0.00025873 0.00030291 0.00024797 0.00029516 0.00024381 0.00025717
 0.00027104]
Model epoch 119: train total loss -64.45015125581797, train mean loss 0.00023243207278917738, test mean loss [0.00025771 0.00030362 0.00024279 0.00030885 0.00023191 0.00025606
 0.00026688]
Model epoch 120: train total loss -64.65009465493291, train mean loss 0.00020056249964462897, test mean loss [0.00025921 0.0003094  0.00024827 0.00030161 0.00023347 0.00024698
 0.00026608]
Model epoch 121: train total loss -64.48773528268178, train mean loss 0.00020805114413099317, test mean loss [0.00025841 0.00030011 0.00025485 0.00028575 0.00023249 0.00025444
 0.00026204]
Model epoch 122: train total loss -64.5488805548325, train mean loss 0.0002114793004258545, test mean loss [0.0002565  0.00029653 0.00024542 0.00031066 0.00022698 0.00025175
 0.00025598]
Model epoch 123: train total loss -64.64038866244118, train mean loss 0.00020639069401429052, test mean loss [0.00025409 0.0002992  0.00024236 0.0002919  0.00022368 0.00023765
 0.00026227]
Model epoch 124: train total loss -64.67984152433574, train mean loss 0.00019324425896560644, test mean loss [0.00025058 0.00028186 0.00024471 0.00027642 0.00022696 0.00023565
 0.00026399]
Model epoch 125: train total loss -64.71314910253382, train mean loss 0.0001821340116832188, test mean loss [0.00024945 0.00030272 0.0002431  0.00028763 0.0002191  0.00023422
 0.00026798]
Model epoch 126: train total loss -64.62876868279577, train mean loss 0.00019191598331573848, test mean loss [0.00025063 0.00029822 0.00023625 0.00027724 0.00022747 0.00023915
 0.00025367]
Model epoch 127: train total loss -64.70650756252506, train mean loss 0.00019096919665061531, test mean loss [0.00024509 0.00029793 0.00024086 0.00027657 0.0002179  0.00023742
 0.00026422]
Model epoch 128: train total loss -64.60646444939951, train mean loss 0.00023203064551321288, test mean loss [0.00024217 0.00028244 0.00023513 0.00028014 0.00021451 0.00023479
 0.00025223]
Model epoch 129: train total loss -64.59889904018098, train mean loss 0.0001758739426787414, test mean loss [0.00025487 0.00028806 0.00023738 0.0002699  0.00021199 0.00024324
 0.00024828]
Model epoch 130: train total loss -64.5578611924008, train mean loss 0.00017831261965110912, test mean loss [0.0002483  0.00029037 0.00026716 0.00028846 0.00021982 0.00023155
 0.00024653]
Model epoch 131: train total loss -64.77151619439832, train mean loss 0.00019859756195032938, test mean loss [0.00024941 0.00029207 0.00023673 0.00027394 0.00021337 0.00022852
 0.00024283]
Model epoch 132: train total loss -64.56480513638904, train mean loss 0.0001820247803176342, test mean loss [0.00024114 0.00028281 0.00023321 0.00027798 0.00021103 0.00023961
 0.00025426]
Model epoch 133: train total loss -64.78997114909417, train mean loss 0.00018243109906927708, test mean loss [0.00023985 0.00027706 0.00024328 0.00027017 0.00021369 0.00022751
 0.00024586]
Model epoch 134: train total loss -64.69638849023234, train mean loss 0.00018571177118519242, test mean loss [0.00024016 0.0002782  0.00022657 0.00026223 0.00020803 0.0002298
 0.0002457 ]
Model epoch 135: train total loss -64.71682067121465, train mean loss 0.0002175210056225514, test mean loss [0.00024201 0.00027943 0.00026082 0.00026619 0.00021542 0.00022707
 0.0002397 ]
Model epoch 136: train total loss -64.69424168672668, train mean loss 0.00019533176278272742, test mean loss [0.00023744 0.00027441 0.00023043 0.00026153 0.00020746 0.00025648
 0.00024757]
Model epoch 137: train total loss -64.82421387470475, train mean loss 0.00017449557896539585, test mean loss [0.0002347  0.00027564 0.00022255 0.00026633 0.00020765 0.00022312
 0.00024489]
Model epoch 138: train total loss -64.88157547981501, train mean loss 0.00018029332910089152, test mean loss [0.00023812 0.00026994 0.00022456 0.00026273 0.000212   0.00023006
 0.00023724]
Model epoch 139: train total loss -64.74060642713495, train mean loss 0.00018370591204798346, test mean loss [0.00024913 0.00027564 0.00022136 0.00025198 0.00020871 0.00022597
 0.00023137]
Model epoch 140: train total loss -64.68982791394102, train mean loss 0.0001899752258305871, test mean loss [0.0002315  0.00026808 0.00023438 0.00026346 0.00020686 0.00022181
 0.00023442]
Model epoch 141: train total loss -64.81755008263727, train mean loss 0.00016271115083272642, test mean loss [0.00023039 0.00027568 0.00022109 0.00026105 0.00020789 0.00021834
 0.00022832]
Model epoch 142: train total loss -64.70400719213004, train mean loss 0.0001794898505775995, test mean loss [0.00023447 0.00027159 0.0002238  0.00025394 0.0002048  0.00021374
 0.00022902]
Model epoch 143: train total loss -65.06951326849448, train mean loss 0.00020634250968800216, test mean loss [0.00023498 0.00027253 0.00021927 0.00024709 0.00020138 0.00021369
 0.00022762]
Model epoch 144: train total loss -64.92512501556565, train mean loss 0.0002059978455307223, test mean loss [0.00022568 0.00026723 0.00021803 0.0002478  0.0002095  0.00021958
 0.00024188]
Model epoch 145: train total loss -64.88811162124023, train mean loss 0.00016566408544835878, test mean loss [0.00023082 0.000265   0.00022087 0.0002491  0.00020198 0.0002136
 0.00023291]
Model epoch 146: train total loss -64.75960308985549, train mean loss 0.0001646217685872328, test mean loss [0.00023112 0.00026906 0.0002096  0.0002513  0.00019806 0.00022465
 0.00023133]
Model epoch 147: train total loss -64.87694314114077, train mean loss 0.00016285059124118386, test mean loss [0.00023254 0.00026841 0.00021301 0.00025013 0.00020817 0.0002081
 0.00023028]
Model epoch 148: train total loss -64.89343919187898, train mean loss 0.00018447460329769987, test mean loss [0.00023368 0.00027115 0.00020523 0.0002408  0.00019743 0.00020958
 0.00022601]
Model epoch 149: train total loss -64.94015688820245, train mean loss 0.00019454199280605718, test mean loss [0.00021836 0.0002664  0.00021905 0.00024265 0.00019864 0.00021606
 0.00022096]
Model epoch 150: train total loss -64.79097930047271, train mean loss 0.00015920285685435773, test mean loss [0.00021986 0.00026621 0.00021604 0.00024509 0.00020575 0.00020529
 0.00022606]
Model epoch 151: train total loss -64.87194334795011, train mean loss 0.00016919106398172358, test mean loss [0.00022942 0.00026373 0.00022659 0.00024647 0.00020262 0.00020811
 0.00021902]
Model epoch 152: train total loss -64.9457285357194, train mean loss 0.000182822987518135, test mean loss [0.00022784 0.00025753 0.00020886 0.00024308 0.00019508 0.00020718
 0.0002213 ]
Model epoch 153: train total loss -64.9289477646256, train mean loss 0.00015462500214161428, test mean loss [0.00022273 0.0002643  0.00020778 0.00023642 0.0001975  0.00021221
 0.00021293]
Model epoch 154: train total loss -64.95757922573195, train mean loss 0.0001565613927729234, test mean loss [0.00022397 0.00026303 0.0002091  0.00023913 0.0001965  0.00020369
 0.00021428]
Model epoch 155: train total loss -64.99752628186965, train mean loss 0.00015721118411417983, test mean loss [0.00022332 0.00025782 0.0002027  0.00023655 0.00019472 0.0002035
 0.0002193 ]
Model epoch 156: train total loss -64.71869077252045, train mean loss 0.00017829095171481568, test mean loss [0.00022449 0.00026497 0.00020994 0.00023109 0.00019644 0.00020356
 0.00022067]
Model epoch 157: train total loss -64.74501576195553, train mean loss 0.00018742451747540102, test mean loss [0.00022428 0.00026321 0.00020442 0.00023849 0.00018818 0.00020188
 0.00021629]
Model epoch 158: train total loss -64.81733256618266, train mean loss 0.00018740559535877698, test mean loss [0.00022574 0.00026217 0.00020028 0.00024223 0.00018739 0.00020545
 0.00020658]
Model epoch 159: train total loss -64.8645504028125, train mean loss 0.000159068172456807, test mean loss [0.00022581 0.00025657 0.00020769 0.00023819 0.000186   0.00020153
 0.00023299]
Model epoch 160: train total loss -65.02458414536602, train mean loss 0.00017664547907783091, test mean loss [0.00022113 0.00026297 0.0002024  0.0002347  0.00019228 0.00020081
 0.00020663]
Model epoch 161: train total loss -64.88704286830064, train mean loss 0.0001969999230079238, test mean loss [0.00021517 0.00024965 0.00020461 0.0002464  0.00018499 0.00020051
 0.00020994]
Model epoch 162: train total loss -64.9315896597475, train mean loss 0.00016625848094799223, test mean loss [0.00022188 0.00025246 0.00020461 0.00022947 0.0001788  0.00020117
 0.00020794]
Model epoch 163: train total loss -65.1994935283606, train mean loss 0.00018498009371938588, test mean loss [0.00021231 0.00024664 0.00019731 0.00022364 0.00018222 0.00019932
 0.00020423]
Model epoch 164: train total loss -65.06906424062392, train mean loss 0.0001764694546374339, test mean loss [0.0002106  0.00025057 0.00019342 0.00022956 0.00018049 0.00020449
 0.00021095]
Model epoch 165: train total loss -65.14431974880532, train mean loss 0.00017050873522641695, test mean loss [0.00021563 0.0002465  0.00019433 0.00022525 0.00018713 0.00019538
 0.00020703]
Model epoch 166: train total loss -65.02600860819422, train mean loss 0.00015069486246267944, test mean loss [0.00021014 0.0002527  0.00019616 0.00022501 0.00017911 0.00020077
 0.00020044]
Model epoch 167: train total loss -64.95794908309992, train mean loss 0.00014939344401669402, test mean loss [0.00021234 0.0002446  0.00019466 0.00022739 0.00018645 0.00021594
 0.00020558]
Model epoch 168: train total loss -65.01316041151313, train mean loss 0.00014771985911751187, test mean loss [0.00021057 0.00024288 0.00019472 0.00022161 0.00018012 0.0002094
 0.00019812]
Model epoch 169: train total loss -65.1563515203176, train mean loss 0.00018288793740995802, test mean loss [0.00020699 0.00024963 0.00018746 0.00023019 0.00017654 0.00019766
 0.0001993 ]
Model epoch 170: train total loss -65.15995319307535, train mean loss 0.00018193877697175395, test mean loss [0.00020815 0.00024397 0.00019199 0.00023137 0.0001803  0.00019275
 0.0001982 ]
Model epoch 171: train total loss -64.8861825887072, train mean loss 0.00020151816548981736, test mean loss [0.00020827 0.00025322 0.00020186 0.00021588 0.00017924 0.00019937
 0.00019244]
Model epoch 172: train total loss -65.08864194322925, train mean loss 0.00016455366537520885, test mean loss [0.00020509 0.00025285 0.00019195 0.00022067 0.00017847 0.00018919
 0.00019635]
Model epoch 173: train total loss -64.87525248588537, train mean loss 0.00019417786322050785, test mean loss [0.00020601 0.00024889 0.00018207 0.00021971 0.00017955 0.0001946
 0.00019789]
Model epoch 174: train total loss -65.11277837970428, train mean loss 0.00014373155046089702, test mean loss [0.00020319 0.00024329 0.0001948  0.0002163  0.00018741 0.00018697
 0.00020287]
Model epoch 175: train total loss -64.99791456640018, train mean loss 0.00016094141996120365, test mean loss [0.0002075  0.00023743 0.00018915 0.00021297 0.00017476 0.00019396
 0.00019468]
Model epoch 176: train total loss -65.15594142596265, train mean loss 0.00016750016890685902, test mean loss [0.00020823 0.00024671 0.00018575 0.00021992 0.00018065 0.00018668
 0.0001927 ]
Model epoch 177: train total loss -65.13251340273966, train mean loss 0.00014030031098122557, test mean loss [0.00020026 0.00023545 0.00018274 0.0002157  0.0001893  0.00018539
 0.00019313]
Model epoch 178: train total loss -65.28834371392085, train mean loss 0.00013737327464786772, test mean loss [0.00020808 0.00023645 0.00018507 0.00022727 0.00017334 0.00018913
 0.00018972]
Model epoch 179: train total loss -65.02223067856974, train mean loss 0.00014474420096050478, test mean loss [0.00020145 0.00024476 0.00020197 0.00021559 0.00017528 0.00019253
 0.00018858]
Model epoch 180: train total loss -64.98049827003891, train mean loss 0.0001791514756606909, test mean loss [0.00020903 0.00023681 0.0001897  0.00021395 0.0001835  0.00019125
 0.00021695]
Model epoch 181: train total loss -65.0189668055989, train mean loss 0.000179340611550402, test mean loss [0.00020298 0.00024103 0.00017903 0.00020939 0.00017206 0.00019116
 0.00019348]
Model epoch 182: train total loss -65.11901237378966, train mean loss 0.00013926730039699845, test mean loss [0.0002036  0.00023776 0.00019132 0.00020356 0.00017365 0.00018382
 0.00019275]
Model epoch 183: train total loss -65.36058084719315, train mean loss 0.00015367369429770256, test mean loss [0.00019271 0.00023788 0.00017481 0.00020847 0.00017251 0.00018847
 0.00018568]
Model epoch 184: train total loss -65.0617127885865, train mean loss 0.00016862317797465892, test mean loss [0.00020213 0.0002393  0.00018063 0.00021154 0.00017747 0.00018418
 0.00018927]
Model epoch 185: train total loss -65.20933703038233, train mean loss 0.00015989464041171717, test mean loss [0.0001978  0.00023053 0.00018587 0.00020971 0.0001802  0.00018307
 0.00018879]
Model epoch 186: train total loss -65.21947588219004, train mean loss 0.00015087761113338785, test mean loss [0.00019922 0.0002295  0.00018082 0.00020963 0.00016599 0.00018808
 0.00019308]
Model epoch 187: train total loss -65.25615708325037, train mean loss 0.00016282719737552732, test mean loss [0.00020859 0.00023501 0.00017639 0.00020671 0.00017309 0.00018562
 0.00018928]
Model epoch 188: train total loss -65.30267366967735, train mean loss 0.00013569000367828307, test mean loss [0.00019921 0.00023463 0.00017812 0.00020284 0.00018384 0.00018155
 0.00018388]
Model epoch 189: train total loss -65.1792420398549, train mean loss 0.0001562636453483669, test mean loss [0.00020345 0.00023154 0.00018367 0.00020956 0.00017669 0.00018634
 0.00018279]
Model epoch 190: train total loss -65.07313902386876, train mean loss 0.00015458808851694255, test mean loss [0.00019699 0.00022553 0.0001761  0.00020721 0.00017968 0.00017823
 0.00020797]
Model epoch 191: train total loss -65.25612779237348, train mean loss 0.00014424837876517488, test mean loss [0.0002052  0.00022965 0.00017892 0.00020111 0.00016869 0.00018294
 0.00018635]
Model epoch 192: train total loss -65.22606719101967, train mean loss 0.000139678731438092, test mean loss [0.00019599 0.00023456 0.00018597 0.00019371 0.00017392 0.00018037
 0.00018277]
Model epoch 193: train total loss -65.25314051905522, train mean loss 0.00015844590561392806, test mean loss [0.00019948 0.00022619 0.00017755 0.00019242 0.00018402 0.00018252
 0.00018098]
Model epoch 194: train total loss -65.30753525547833, train mean loss 0.0001446015085773457, test mean loss [0.00019267 0.00021957 0.00018396 0.0001989  0.00016413 0.00018631
 0.00017738]
Model epoch 195: train total loss -65.20510359901886, train mean loss 0.00015838963713655274, test mean loss [0.00019259 0.00022552 0.00017381 0.0002087  0.00016594 0.00017664
 0.00017253]
Model epoch 196: train total loss -65.12081897880843, train mean loss 0.00013877404486863876, test mean loss [0.00019803 0.00021919 0.00018744 0.00019761 0.0001597  0.00018512
 0.00017649]
Model epoch 197: train total loss -65.32322942009097, train mean loss 0.0001404899784112456, test mean loss [0.0001928  0.00023081 0.00018367 0.00019914 0.00016425 0.00018605
 0.0001723 ]
Model epoch 198: train total loss -65.37509006797521, train mean loss 0.00014358358323503551, test mean loss [0.00020127 0.00022242 0.00017326 0.00020481 0.00016153 0.00018145
 0.0001792 ]
Model epoch 199: train total loss -65.4688685084355, train mean loss 0.00013248096691015834, test mean loss [0.00018732 0.0002237  0.00017318 0.00019272 0.00016419 0.00017509
 0.00017903]
Model epoch 200: train total loss -65.26788511848959, train mean loss 0.0001419408212008298, test mean loss [0.00018869 0.00022318 0.00016859 0.00019849 0.00016773 0.00017327
 0.00017786]
Model epoch 201: train total loss -65.33227651642264, train mean loss 0.0001583787774845349, test mean loss [0.00018859 0.00022045 0.00017207 0.00020676 0.00016022 0.00017703
 0.00017919]
Model epoch 202: train total loss -65.3381531802728, train mean loss 0.0001319210825040612, test mean loss [0.00019107 0.00022158 0.00016591 0.00020089 0.00017113 0.0001665
 0.00017441]
Model epoch 203: train total loss -65.42280335123567, train mean loss 0.00013988928931227534, test mean loss [0.00018527 0.00021773 0.00017479 0.00019111 0.00016173 0.0001727
 0.0001879 ]
Model epoch 204: train total loss -65.12299537224546, train mean loss 0.000144845191962633, test mean loss [0.00018846 0.00022099 0.00016778 0.00019577 0.00019209 0.00019165
 0.00018208]
Model epoch 205: train total loss -65.42629618271033, train mean loss 0.00016300124356927396, test mean loss [0.00018819 0.00022194 0.00017051 0.00018838 0.00016624 0.00016925
 0.00017814]
Model epoch 206: train total loss -65.3586170871122, train mean loss 0.00017274563476176645, test mean loss [0.00018393 0.00021818 0.0001707  0.00019217 0.00016001 0.00017712
 0.00017818]
Model epoch 207: train total loss -65.36431392660896, train mean loss 0.00015476874946422894, test mean loss [0.00018879 0.00021865 0.00016239 0.00019599 0.00016223 0.00016648
 0.00017417]
Model epoch 208: train total loss -65.50368465628712, train mean loss 0.00015147163428179473, test mean loss [0.00019365 0.00021407 0.00016293 0.00018976 0.0001564  0.00016486
 0.00017492]
Model epoch 209: train total loss -65.55847517173804, train mean loss 0.00013824954489363928, test mean loss [0.00018608 0.00021764 0.00017204 0.0001881  0.0001593  0.00016459
 0.00018147]
Model epoch 210: train total loss -65.37524741505403, train mean loss 0.00016243158807314, test mean loss [0.00018616 0.00022028 0.00016155 0.00018973 0.00016093 0.00016989
 0.00016904]
Model epoch 211: train total loss -65.43384305216888, train mean loss 0.0001340440724512144, test mean loss [0.00019203 0.00021892 0.00016014 0.0001877  0.00015398 0.00016798
 0.00017991]
Model epoch 212: train total loss -65.39976090078493, train mean loss 0.00014718266434010776, test mean loss [0.0001805  0.0002088  0.00016327 0.00018891 0.00015667 0.00017027
 0.00017254]
Model epoch 213: train total loss -65.36438422169007, train mean loss 0.00014772173533949035, test mean loss [0.00019625 0.00021507 0.0001672  0.00019159 0.00015846 0.00017214
 0.00018699]
Model epoch 214: train total loss -65.42785631258359, train mean loss 0.0001319598966589326, test mean loss [0.00018676 0.0002091  0.00015823 0.00018758 0.00015514 0.00016973
 0.00016638]
Model epoch 215: train total loss -65.5223632067215, train mean loss 0.0001748743898455537, test mean loss [0.00018381 0.00020983 0.00016095 0.0002037  0.00016509 0.00016106
 0.00016381]
Model epoch 216: train total loss -65.3227342548275, train mean loss 0.00013757324580702067, test mean loss [0.00019165 0.00021632 0.00016068 0.00018691 0.00016564 0.00017337
 0.00017533]
Model epoch 217: train total loss -65.45754316653257, train mean loss 0.0001290746794610434, test mean loss [0.0001801  0.00021764 0.00016486 0.00018901 0.00016324 0.00016535
 0.00017697]
Model epoch 218: train total loss -65.32717884344599, train mean loss 0.00013357768915402897, test mean loss [0.00018407 0.00021107 0.00016482 0.00018203 0.00015918 0.00016641
 0.00019102]
Model epoch 219: train total loss -65.15177317673162, train mean loss 0.00014130990405667005, test mean loss [0.00018151 0.00020931 0.00016406 0.00017873 0.00017325 0.00016802
 0.00020299]
Model epoch 220: train total loss -65.27091006721179, train mean loss 0.00013679339581937363, test mean loss [0.00018067 0.00020887 0.00016462 0.00018411 0.00015884 0.0001677
 0.00017502]
Model epoch 221: train total loss -65.37539510439915, train mean loss 0.00013531005882681433, test mean loss [0.00018124 0.00020845 0.00016031 0.0001843  0.00015886 0.00016217
 0.00017593]
Model epoch 222: train total loss -65.52740033045478, train mean loss 0.0001323084915232448, test mean loss [0.0001807  0.00020485 0.00016089 0.00018262 0.00015285 0.00016688
 0.00018541]
Model epoch 223: train total loss -65.37795463282472, train mean loss 0.0001388422733325741, test mean loss [0.00018406 0.00020954 0.00017486 0.00018906 0.00016035 0.00016188
 0.00016437]
Model epoch 224: train total loss -65.4764714608396, train mean loss 0.00013970586851300065, test mean loss [0.00018155 0.00020862 0.00016709 0.0001826  0.00015342 0.00017615
 0.00017069]
Model epoch 225: train total loss -65.6151255845606, train mean loss 0.0001341434589734304, test mean loss [0.00018024 0.00019817 0.00016305 0.00019049 0.00015525 0.00016908
 0.0001593 ]
Model epoch 226: train total loss -65.3549582475319, train mean loss 0.0001240206675848972, test mean loss [0.00017854 0.00020698 0.00016899 0.00017786 0.00015487 0.00016862
 0.00016007]
Model epoch 227: train total loss -65.47948961966448, train mean loss 0.0001232113582958525, test mean loss [0.00017524 0.00020593 0.00015909 0.00017533 0.00015791 0.00016509
 0.00016852]
Model epoch 228: train total loss -65.59867450778134, train mean loss 0.00012372701002468856, test mean loss [0.000174   0.00020463 0.00015398 0.00018494 0.00015374 0.00016836
 0.00016169]
Model epoch 229: train total loss -65.2959962290839, train mean loss 0.0001285508712316511, test mean loss [0.00018246 0.00020407 0.00016735 0.00018376 0.00015439 0.00016624
 0.00016649]
Model epoch 230: train total loss -65.23453228968397, train mean loss 0.00012856630065562205, test mean loss [0.00019368 0.00020202 0.00015523 0.00018017 0.00015015 0.00015798
 0.00017185]
Model epoch 231: train total loss -65.58736266034785, train mean loss 0.00013796243392070773, test mean loss [0.00017366 0.00020516 0.00016066 0.00017894 0.00015024 0.00015459
 0.0001718 ]
Model epoch 232: train total loss -65.41397412103936, train mean loss 0.0001309057254199965, test mean loss [0.00017783 0.00020441 0.00016219 0.00017188 0.00015514 0.00017673
 0.00016407]
Model epoch 233: train total loss -65.56851838382225, train mean loss 0.00012893155135433796, test mean loss [0.00017427 0.00020563 0.00016849 0.00018153 0.00016302 0.00016756
 0.00016933]
Model epoch 234: train total loss -65.49958022912442, train mean loss 0.00012176188760298653, test mean loss [0.00017854 0.00021207 0.00015308 0.00018574 0.00016257 0.00015669
 0.00016232]
Model epoch 235: train total loss -65.5330721993675, train mean loss 0.00012010438991236451, test mean loss [0.00017827 0.00020326 0.00016071 0.00018453 0.00015233 0.00016364
 0.00015843]
Model epoch 236: train total loss -65.43433801936281, train mean loss 0.00012456293766451303, test mean loss [0.00018006 0.00019853 0.00015435 0.00017501 0.00015817 0.00015797
 0.00016236]
Model epoch 237: train total loss -65.66513315802887, train mean loss 0.0001325061429603193, test mean loss [0.000169   0.00019759 0.00015234 0.00017566 0.00015195 0.00015584
 0.00015484]
Model epoch 238: train total loss -65.54671504369563, train mean loss 0.00013775356140216443, test mean loss [0.00017581 0.00019742 0.00015626 0.0001813  0.00014689 0.00015878
 0.00015227]
Model epoch 239: train total loss -65.43799146772656, train mean loss 0.00012991335696220887, test mean loss [0.00017255 0.00019415 0.00016339 0.00017073 0.00014942 0.00015635
 0.00016359]
Model epoch 240: train total loss -65.47602613007263, train mean loss 0.00013211426087353736, test mean loss [0.00017172 0.00019728 0.00015397 0.00017558 0.00014951 0.00015595
 0.00017272]
Model epoch 241: train total loss -65.58757211557719, train mean loss 0.0001173263081502736, test mean loss [0.00017509 0.00019761 0.00015492 0.00017879 0.00014786 0.00015293
 0.00016399]
Model epoch 242: train total loss -65.61782616105062, train mean loss 0.00012523478400370186, test mean loss [0.00017365 0.00020729 0.00015008 0.00017473 0.00014708 0.00014842
 0.00016671]
Model epoch 243: train total loss -65.56820989782186, train mean loss 0.00012644491277321378, test mean loss [0.00017512 0.00019382 0.00014945 0.00016967 0.00015373 0.00015279
 0.0001637 ]
Model epoch 244: train total loss -65.56380441861015, train mean loss 0.00011991500462997214, test mean loss [0.00017541 0.0002011  0.00014306 0.00017339 0.00015167 0.00015486
 0.00015619]
Model epoch 245: train total loss -65.69891924172069, train mean loss 0.00012688730010705645, test mean loss [0.00017128 0.0001932  0.00015057 0.00017256 0.00014962 0.00015488
 0.00016525]
Model epoch 246: train total loss -65.53346216712832, train mean loss 0.00013916552479517987, test mean loss [0.00017803 0.00020251 0.00014745 0.00018503 0.00015303 0.00016083
 0.00015824]
Model epoch 247: train total loss -65.58123965692755, train mean loss 0.00012448287095846852, test mean loss [0.00016962 0.00019472 0.00015297 0.00017592 0.00015078 0.00015759
 0.00015458]
Model epoch 248: train total loss -65.38500542310862, train mean loss 0.00014963815253027916, test mean loss [0.00016892 0.00019172 0.000151   0.00017207 0.00015324 0.00015798
 0.00015832]
Model epoch 249: train total loss -65.63031058152232, train mean loss 0.0001378393307812189, test mean loss [0.00017287 0.00020147 0.00014918 0.00017263 0.00014973 0.00015986
 0.00015234]
Model epoch 250: train total loss -65.54875902968325, train mean loss 0.00012994305179563978, test mean loss [0.00016921 0.00019577 0.00015171 0.00017762 0.00014767 0.00015512
 0.00015531]
Model epoch 251: train total loss -65.76655748347345, train mean loss 0.00011967156183306615, test mean loss [0.0001692  0.00019791 0.00014687 0.00016725 0.00014477 0.00015754
 0.00015013]
Model epoch 252: train total loss -65.45617924498524, train mean loss 0.00013767628288135516, test mean loss [0.00016865 0.00019244 0.00014317 0.00017844 0.00014858 0.00015891
 0.00015471]
Model epoch 253: train total loss -65.60543130170366, train mean loss 0.00012050192236877316, test mean loss [0.00016534 0.00019686 0.00015337 0.00017317 0.00014665 0.0001655
 0.00015512]
Model epoch 254: train total loss -65.55369518436238, train mean loss 0.00012330639454754923, test mean loss [0.00017066 0.00019756 0.00014805 0.00017008 0.00014449 0.00015461
 0.00015535]
Model epoch 255: train total loss -65.5428371020817, train mean loss 0.00012238373576185582, test mean loss [0.0001673  0.00019863 0.00014845 0.00018782 0.00014651 0.00014939
 0.0001609 ]
Model epoch 256: train total loss -65.74072937174589, train mean loss 0.00012774270328786636, test mean loss [0.00016719 0.00020252 0.00014543 0.00016764 0.00014285 0.00015378
 0.00015355]
Model epoch 257: train total loss -65.73823689188076, train mean loss 0.00013837399771382677, test mean loss [0.00016706 0.00019398 0.00014696 0.00017899 0.00015088 0.00015002
 0.00015929]
Model epoch 258: train total loss -65.68200578112129, train mean loss 0.00014145053014157395, test mean loss [0.00016601 0.00019056 0.00014575 0.00018114 0.00015086 0.0001475
 0.00015383]
Model epoch 259: train total loss -65.66757362023851, train mean loss 0.00011765183213315627, test mean loss [0.00017135 0.00018739 0.00015092 0.00016956 0.00014594 0.00015501
 0.00015953]
Model epoch 260: train total loss -65.84237151248462, train mean loss 0.00012790385309574117, test mean loss [0.00016917 0.00019188 0.00015098 0.00015855 0.00014792 0.00014897
 0.00014939]
Model epoch 261: train total loss -65.78178803026454, train mean loss 0.00011956937350642282, test mean loss [0.00016741 0.00019258 0.00013873 0.0001739  0.00015192 0.00015075
 0.00015539]
Model epoch 262: train total loss -65.59319038230599, train mean loss 0.0001299642518529624, test mean loss [0.00017543 0.00018822 0.00016365 0.00016552 0.00014305 0.00014568
 0.00014913]
Model epoch 263: train total loss -65.60470580542608, train mean loss 0.0001380497690638211, test mean loss [0.00016571 0.00018216 0.00014839 0.00017855 0.00015563 0.00014765
 0.00015563]
Model epoch 264: train total loss -65.5212883939371, train mean loss 0.00012612816639739346, test mean loss [0.00016917 0.00019444 0.00014855 0.00016746 0.00014592 0.00015634
 0.00015388]
Model epoch 265: train total loss -65.45028061251473, train mean loss 0.00011583586902058929, test mean loss [0.00016863 0.00018439 0.00015339 0.00016825 0.00015037 0.00014298
 0.00015577]
Model epoch 266: train total loss -65.7894645962515, train mean loss 0.0001349023897000731, test mean loss [0.000164   0.00018618 0.00014457 0.00016804 0.00014654 0.00014439
 0.00015122]
Model epoch 267: train total loss -65.56084035527618, train mean loss 0.00014348044971429234, test mean loss [0.00017184 0.00018562 0.00014457 0.00017132 0.00014437 0.00015523
 0.00015083]
Model epoch 268: train total loss -65.56387603809706, train mean loss 0.00015433786580436987, test mean loss [0.0001683  0.00018971 0.00014171 0.00016886 0.00014642 0.0001482
 0.00014812]
Model epoch 269: train total loss -65.59624265485671, train mean loss 0.00013953057713557697, test mean loss [0.00016777 0.00018307 0.00014911 0.00017022 0.00014224 0.00014712
 0.00014516]
Model epoch 270: train total loss -65.76067734899803, train mean loss 0.00013114525905453243, test mean loss [0.00016597 0.00018334 0.00014316 0.00016233 0.00015087 0.00014809
 0.00014595]
Model epoch 271: train total loss -65.60446004137748, train mean loss 0.00013871544265627194, test mean loss [0.00016545 0.00018467 0.00014533 0.00016764 0.00014775 0.00015221
 0.00015315]
Model epoch 272: train total loss -65.73683320399864, train mean loss 0.00012407076627416765, test mean loss [0.00016111 0.00018527 0.0001426  0.00019216 0.00014591 0.00014807
 0.00015188]
Model epoch 273: train total loss -65.66056041506603, train mean loss 0.0001234241872967941, test mean loss [0.0001584  0.00019114 0.00014185 0.00016579 0.00014924 0.00014431
 0.00014531]
Model epoch 274: train total loss -65.9049314853351, train mean loss 0.0001176847232808663, test mean loss [0.00015951 0.00017927 0.00014026 0.00016199 0.00014093 0.00013923
 0.00015312]
Model epoch 275: train total loss -65.48593875487407, train mean loss 0.00012629736794322576, test mean loss [0.00016435 0.00019348 0.00015174 0.00016434 0.00014451 0.00016047
 0.00014793]
Model epoch 276: train total loss -65.6614561284273, train mean loss 0.00012405020780047887, test mean loss [0.00016223 0.00018777 0.00014308 0.0001622  0.00014282 0.00014702
 0.00014273]
Model epoch 277: train total loss -65.60400772325711, train mean loss 0.00012724678239173727, test mean loss [0.00015912 0.00018709 0.0001365  0.00016866 0.00014299 0.00015291
 0.00015449]
Model epoch 278: train total loss -65.79664072023665, train mean loss 0.00011143538655151331, test mean loss [0.00016663 0.0001837  0.00014355 0.00016516 0.00014526 0.00014084
 0.00014526]
Model epoch 279: train total loss -65.71055173793259, train mean loss 0.0001330530951218982, test mean loss [0.00016784 0.00018445 0.00014513 0.00016759 0.00013842 0.00014323
 0.00014792]
Model epoch 280: train total loss -65.70940675562457, train mean loss 0.00011193418980724595, test mean loss [0.00016083 0.00018624 0.00014166 0.00015591 0.00014341 0.00015325
 0.00014598]
Model epoch 281: train total loss -65.89673687490635, train mean loss 0.00012370180003980452, test mean loss [0.00016465 0.00018499 0.00013229 0.00016327 0.00014178 0.00014028
 0.00014802]
Model epoch 282: train total loss -65.79070368817379, train mean loss 0.00011990449184125063, test mean loss [0.00016689 0.00018019 0.00013871 0.00015858 0.0001364  0.00013912
 0.00014865]
Model epoch 283: train total loss -65.78052289645552, train mean loss 0.0001276101517532, test mean loss [0.00015743 0.00018426 0.00014275 0.0001653  0.00014386 0.00013812
 0.00014574]
Model epoch 284: train total loss -65.61901716385677, train mean loss 0.00014180877072201845, test mean loss [0.00015892 0.00018218 0.00014156 0.00017062 0.00014029 0.00014187
 0.00014815]
Model epoch 285: train total loss -65.7062813476111, train mean loss 0.00013880156126243697, test mean loss [0.00016439 0.00017689 0.00013532 0.00016161 0.0001453  0.0001447
 0.0001493 ]
Model epoch 286: train total loss -65.68563738646556, train mean loss 0.0001184585825255612, test mean loss [0.00015703 0.00017752 0.00013795 0.00016181 0.00013879 0.00013907
 0.00014854]
Model epoch 287: train total loss -65.81733633655278, train mean loss 0.00012876623907198345, test mean loss [0.00015665 0.00017632 0.00014377 0.00017223 0.00013802 0.00014258
 0.00015037]
Model epoch 288: train total loss -65.74168293967426, train mean loss 0.0001279313302208376, test mean loss [0.00016067 0.00017588 0.0001409  0.0001687  0.00014654 0.00013885
 0.00014181]
Model epoch 289: train total loss -65.54518396935354, train mean loss 0.00012305583236063984, test mean loss [0.00015993 0.00018644 0.00013507 0.00016025 0.00013803 0.00013854
 0.00015084]
Model epoch 290: train total loss -65.71825109074504, train mean loss 0.000118769135430011, test mean loss [0.00015907 0.00018722 0.00013718 0.00015966 0.00014313 0.00014133
 0.00014368]
Model epoch 291: train total loss -65.6674752208501, train mean loss 0.00013678506848947922, test mean loss [0.00016131 0.00017723 0.00014009 0.00015598 0.00014419 0.00014104
 0.00014724]
Model epoch 292: train total loss -65.80339729033246, train mean loss 0.00011747090453660283, test mean loss [0.00015826 0.00018416 0.0001331  0.00016777 0.00013577 0.0001407
 0.00014475]
Model epoch 293: train total loss -65.70083539311813, train mean loss 0.00011294696199109038, test mean loss [0.00015164 0.00018894 0.00013765 0.00016021 0.00014597 0.00014871
 0.00014103]
Model epoch 294: train total loss -65.62673507037586, train mean loss 0.0001154946128203291, test mean loss [0.00015414 0.00017518 0.00013478 0.00015928 0.0001383  0.00013666
 0.0001451 ]
Model epoch 295: train total loss -65.75817288192054, train mean loss 0.0001182922992297208, test mean loss [0.00015757 0.00017381 0.00013606 0.00015727 0.00013964 0.00014008
 0.00014478]
Model epoch 296: train total loss -65.79229056949745, train mean loss 0.0001398964338125855, test mean loss [0.00015759 0.00017585 0.00013773 0.00016817 0.00014082 0.00014672
 0.00013919]
Model epoch 297: train total loss -65.91938101681328, train mean loss 0.00011124157731902439, test mean loss [0.00015495 0.00017527 0.00013833 0.0001621  0.00013641 0.00014619
 0.00014725]
Model epoch 298: train total loss -65.88642529433072, train mean loss 0.0001071253854790239, test mean loss [0.000163   0.00018166 0.00013444 0.00015825 0.00013485 0.00013693
 0.00014112]
Model epoch 299: train total loss -65.75457711898255, train mean loss 0.00010873371600470384, test mean loss [0.00016101 0.00017374 0.00014239 0.00016037 0.00014235 0.00014847
 0.00014463]
Model epoch 300: train total loss -65.82856639644709, train mean loss 0.00011555826501554501, test mean loss [0.00015973 0.00017605 0.00013577 0.0001536  0.00014151 0.00013539
 0.00014822]
Model epoch 301: train total loss -65.9557130498544, train mean loss 0.0001226466177865015, test mean loss [0.0001545  0.00017327 0.00013065 0.00015627 0.00013751 0.00014113
 0.00014207]
Model epoch 302: train total loss -65.97526696184887, train mean loss 0.00011373014217961926, test mean loss [0.00015346 0.00017242 0.00013107 0.00016083 0.00013038 0.00013852
 0.00014859]
Model epoch 303: train total loss -66.06208430201507, train mean loss 0.00010517012313141584, test mean loss [0.00015104 0.00017259 0.00013661 0.0001502  0.00013178 0.0001365
 0.00014139]
Model epoch 304: train total loss -65.57608590099984, train mean loss 0.00013338460726646263, test mean loss [0.00015166 0.00017425 0.00013969 0.00017871 0.00013995 0.00014287
 0.00014059]
Model epoch 305: train total loss -65.84492247605496, train mean loss 0.00011313100619967718, test mean loss [0.00015482 0.00016839 0.00013201 0.00020114 0.00013095 0.00013676
 0.00013554]
Model epoch 306: train total loss -65.94259276085117, train mean loss 0.00012630175752988986, test mean loss [0.00015525 0.00016727 0.00013002 0.0001717  0.00013336 0.00013457
 0.00014202]
Model epoch 307: train total loss -65.84030696909856, train mean loss 0.00011790791340720483, test mean loss [0.00016289 0.00016862 0.00013291 0.00016806 0.0001368  0.00014182
 0.00013746]
Model epoch 308: train total loss -65.76791311351076, train mean loss 0.00011438017535723343, test mean loss [0.00016332 0.00017302 0.00014599 0.00015311 0.00013377 0.00014471
 0.00014115]
Model epoch 309: train total loss -65.8678945825223, train mean loss 0.00010997415278004866, test mean loss [0.00015748 0.00017655 0.00014224 0.00015041 0.00013156 0.00013347
 0.00013925]
Model epoch 310: train total loss -65.72748358044484, train mean loss 0.00013277531314465185, test mean loss [0.00016769 0.00017731 0.00013805 0.00016162 0.00013433 0.00014048
 0.00014391]
Model epoch 311: train total loss -65.7547940034912, train mean loss 0.00011632238305055604, test mean loss [0.0001593  0.00017187 0.00013745 0.00015683 0.00013583 0.00014155
 0.00013727]
Model epoch 312: train total loss -65.90717863842092, train mean loss 0.0001174087644701947, test mean loss [0.00014939 0.00016721 0.00013698 0.00015885 0.00013665 0.00014443
 0.00013856]
Model epoch 313: train total loss -65.79450092195711, train mean loss 0.00011380285836279876, test mean loss [0.00017019 0.00016875 0.00013528 0.00015625 0.00013847 0.00014011
 0.00014221]
Model epoch 314: train total loss -65.96592862514885, train mean loss 0.0001142691293415076, test mean loss [0.00015203 0.00016909 0.00013277 0.00016082 0.00013297 0.00013682
 0.00014525]
Model epoch 315: train total loss -65.91661171145329, train mean loss 0.0001074151906503394, test mean loss [0.0001532  0.00017606 0.00013644 0.00015144 0.00013683 0.00013413
 0.00013928]
Model epoch 316: train total loss -66.06597618727527, train mean loss 0.00010687154487373348, test mean loss [0.00015436 0.00017213 0.00013039 0.00015037 0.00013356 0.00014054
 0.00013592]
Model epoch 317: train total loss -65.83776011544853, train mean loss 0.00013513350566784016, test mean loss [0.00014902 0.00017835 0.00013276 0.00014759 0.00013791 0.00013346
 0.00013906]
Model epoch 318: train total loss -65.9972434234637, train mean loss 0.00011363404738755711, test mean loss [0.00015253 0.00018006 0.00013488 0.00015339 0.00013357 0.00013485
 0.00014016]
Model epoch 319: train total loss -65.86810530319201, train mean loss 0.00010991010664808555, test mean loss [0.00015498 0.00017971 0.00013679 0.00015032 0.00013323 0.00013541
 0.00013363]
Model epoch 320: train total loss -65.74147181615862, train mean loss 0.00011308649651306042, test mean loss [0.00015406 0.00017643 0.00013365 0.0001481  0.00013106 0.00013759
 0.00014364]
Model epoch 321: train total loss -65.89526261582338, train mean loss 0.00011267754227988023, test mean loss [0.00015395 0.00017243 0.00014052 0.00014861 0.00013328 0.00013499
 0.00013795]
Model epoch 322: train total loss -66.05065054430008, train mean loss 0.00012853384226495194, test mean loss [0.00015917 0.00018019 0.00013972 0.00015243 0.00013832 0.00013569
 0.00013816]
Model epoch 323: train total loss -66.0632925893915, train mean loss 0.00010939592794624016, test mean loss [0.00015462 0.00016576 0.00013749 0.00015468 0.00013487 0.00013461
 0.00014149]
Model epoch 324: train total loss -65.99737768261626, train mean loss 0.00012486757029474846, test mean loss [0.0001498  0.00016508 0.00013163 0.00017798 0.00012812 0.00013217
 0.00013775]
Model epoch 325: train total loss -65.96230913019788, train mean loss 0.00011551416550395386, test mean loss [0.00015604 0.00016585 0.00012935 0.00016038 0.00013544 0.00013052
 0.00014048]
Model epoch 326: train total loss -66.03616729506543, train mean loss 0.00011199849062182337, test mean loss [0.00015097 0.00016801 0.0001306  0.00015737 0.00013379 0.00013678
 0.00013638]
Model epoch 327: train total loss -65.86759593375513, train mean loss 0.00012695293660829008, test mean loss [0.00014903 0.00016913 0.00013779 0.0001535  0.00013339 0.00013646
 0.00013536]
Model epoch 328: train total loss -65.99207568100906, train mean loss 0.00010755187457485676, test mean loss [0.00014805 0.00016665 0.00012879 0.00015897 0.0001307  0.00013744
 0.00015821]
Model epoch 329: train total loss -66.12799360353773, train mean loss 0.00010134500564097248, test mean loss [0.00014453 0.0001689  0.00013132 0.00014973 0.00013719 0.0001339
 0.00013698]
Model epoch 330: train total loss -66.04635840290986, train mean loss 0.00010487661361907094, test mean loss [0.00014886 0.00017028 0.00013306 0.00014668 0.00013489 0.00013247
 0.00013383]
Model epoch 331: train total loss -66.04681366941972, train mean loss 0.00010700570167681266, test mean loss [0.00014841 0.00016747 0.00012991 0.00015299 0.00012521 0.00013123
 0.00014161]
Model epoch 332: train total loss -65.87268565746228, train mean loss 0.00012441002477833347, test mean loss [0.00014498 0.00016299 0.00013697 0.00015112 0.00013115 0.00013801
 0.00013835]
Model epoch 333: train total loss -65.88590751666031, train mean loss 0.00011838529728463857, test mean loss [0.00014546 0.00016511 0.0001325  0.00015282 0.00013575 0.00013596
 0.0001404 ]
Model epoch 334: train total loss -66.05730189984519, train mean loss 0.00010729316245014439, test mean loss [0.00015047 0.00016179 0.00013287 0.00014559 0.0001319  0.0001325
 0.0001325 ]
Model epoch 335: train total loss -65.8590308669416, train mean loss 0.00012762183332201696, test mean loss [0.00014905 0.00016695 0.0001298  0.00014871 0.0001275  0.00013667
 0.00012984]
Model epoch 336: train total loss -65.97913968963506, train mean loss 0.00011138535474779549, test mean loss [0.00014941 0.00016529 0.00013187 0.00014389 0.00012952 0.00013208
 0.00013865]
Model epoch 337: train total loss -65.91213114085893, train mean loss 0.00010690234184741678, test mean loss [0.00015531 0.00016603 0.00013728 0.00014712 0.00012977 0.0001396
 0.00014234]
Model epoch 338: train total loss -65.6513630344383, train mean loss 0.00011140331263019128, test mean loss [0.00016019 0.00016427 0.00013043 0.00015798 0.00013335 0.00013004
 0.00014178]
Model epoch 339: train total loss -65.90391663182888, train mean loss 0.00011157083555053043, test mean loss [0.00015053 0.00016483 0.00013893 0.00014715 0.00012736 0.0001482
 0.0001372 ]
Model epoch 340: train total loss -65.91169292066557, train mean loss 0.00011821367202644795, test mean loss [0.00014648 0.00015949 0.00013952 0.00014546 0.00013709 0.000145
 0.00013895]
Model epoch 341: train total loss -65.85938469471323, train mean loss 0.0001111816151298921, test mean loss [0.0001454  0.00017101 0.00013319 0.00014814 0.00012763 0.00013216
 0.00013337]
Model epoch 342: train total loss -65.81520622444445, train mean loss 0.00011661432110616692, test mean loss [0.00013951 0.00016635 0.00013514 0.00015504 0.00014121 0.00018004
 0.00013813]
Model epoch 343: train total loss -65.94742473457276, train mean loss 0.0001117203723997085, test mean loss [0.00013968 0.00015946 0.00013041 0.0001508  0.00013343 0.00014451
 0.00013408]
Model epoch 344: train total loss -66.08166112156827, train mean loss 0.00011178584642237662, test mean loss [0.00014437 0.00016582 0.00012602 0.00015104 0.00013269 0.00013796
 0.00013649]
Model epoch 345: train total loss -65.82341925549295, train mean loss 0.00011596556578462094, test mean loss [0.00014808 0.00016399 0.00012722 0.00014906 0.00012599 0.00016554
 0.00013214]
Model epoch 346: train total loss -65.83507581858127, train mean loss 0.0001110910031084499, test mean loss [0.00014814 0.00017356 0.00012401 0.00014423 0.00012987 0.00015223
 0.00013959]
Model epoch 347: train total loss -65.86029020906817, train mean loss 0.00011231736827902623, test mean loss [0.00014707 0.00016341 0.00013422 0.00015305 0.00012866 0.00013772
 0.00013688]
Model epoch 348: train total loss -66.0015079130793, train mean loss 0.00010478114004430334, test mean loss [0.00015355 0.00016791 0.00013318 0.00014535 0.00013983 0.00013588
 0.00013278]
Model epoch 349: train total loss -65.97292897530691, train mean loss 0.00010637973521782226, test mean loss [0.0001495  0.00016219 0.00012701 0.00014116 0.00013058 0.00013238
 0.0001366 ]
Model epoch 350: train total loss -66.0995381010038, train mean loss 0.00010660233659996293, test mean loss [0.00014108 0.00016828 0.00012988 0.00014259 0.00012848 0.0001348
 0.00014353]
Model epoch 351: train total loss -66.12572969489018, train mean loss 0.00010832626118183403, test mean loss [0.00015989 0.00015972 0.00012141 0.00014965 0.00013673 0.00013058
 0.00012818]
Model epoch 352: train total loss -65.98567220473427, train mean loss 0.00010439874157615575, test mean loss [0.00014175 0.0001663  0.00012793 0.00014599 0.00012775 0.00013103
 0.00013239]
Model epoch 353: train total loss -66.16173123950038, train mean loss 0.00010532020173143475, test mean loss [0.00013961 0.00016354 0.00011979 0.00015095 0.00012942 0.00012773
 0.00013083]
Model epoch 354: train total loss -66.15363248519873, train mean loss 0.00010083012646790103, test mean loss [0.000149   0.00016165 0.00013804 0.00014214 0.00012686 0.00012671
 0.00012768]
Model epoch 355: train total loss -66.14219026283838, train mean loss 0.00010757093901308853, test mean loss [0.00014403 0.00016546 0.00014001 0.00014437 0.00012747 0.00013647
 0.00013292]
Model epoch 356: train total loss -66.03521765035968, train mean loss 0.00010129218148945957, test mean loss [0.00014041 0.00016214 0.00012769 0.00015066 0.0001209  0.00013222
 0.00013056]
Model epoch 357: train total loss -65.95436163147727, train mean loss 0.00010867856290342643, test mean loss [0.000145   0.00016104 0.00012595 0.00014068 0.00012442 0.00012931
 0.00013764]
Model epoch 358: train total loss -65.95881594471365, train mean loss 0.0001046126481223898, test mean loss [0.00014115 0.00015842 0.00012884 0.00014641 0.00013335 0.00013279
 0.00012816]
Model epoch 359: train total loss -65.88272194465301, train mean loss 0.00010745498947956642, test mean loss [0.00014778 0.00016186 0.00013548 0.00015028 0.00013235 0.00012929
 0.00013144]
Model epoch 360: train total loss -66.1109324502314, train mean loss 0.00010395695850409863, test mean loss [0.00014792 0.00015897 0.00013037 0.00014566 0.00012866 0.00012987
 0.00013063]
Model epoch 361: train total loss -66.04560692116557, train mean loss 0.0001050008667961522, test mean loss [0.00014177 0.00016594 0.00012372 0.00014801 0.00012816 0.00012526
 0.00014039]
Model epoch 362: train total loss -65.9966592978284, train mean loss 0.00010686647310073493, test mean loss [0.00014287 0.00015433 0.00012679 0.00013819 0.00013192 0.00013341
 0.00013384]
Model epoch 363: train total loss -66.08468010557657, train mean loss 0.00010727720762548971, test mean loss [0.00014535 0.00015913 0.00013133 0.00014121 0.00012399 0.00012833
 0.00013195]
Model epoch 364: train total loss -66.09844650112, train mean loss 0.00010766118878222715, test mean loss [0.00014198 0.00017012 0.00012217 0.00013688 0.00013336 0.00013125
 0.00013077]
Model epoch 365: train total loss -65.99227551155512, train mean loss 0.00010534801208298172, test mean loss [0.00013668 0.00016228 0.00012801 0.0001468  0.00013328 0.00013571
 0.0001259 ]
Model epoch 366: train total loss -65.63791964878641, train mean loss 0.00011110504813487095, test mean loss [0.00015472 0.00016392 0.00012473 0.00014839 0.00012493 0.0001259
 0.00012354]
Model epoch 367: train total loss -66.02923647431248, train mean loss 0.00010643544217809857, test mean loss [0.00014772 0.00015218 0.00012732 0.00014037 0.00012627 0.00014094
 0.00012748]
Model epoch 368: train total loss -66.1484778291827, train mean loss 0.0001149059000506525, test mean loss [0.00014436 0.00015455 0.00012681 0.00014    0.00012629 0.00012834
 0.00012277]
Model epoch 369: train total loss -66.09917154766984, train mean loss 0.00010999763337392194, test mean loss [0.0001508  0.000155   0.00012715 0.00014866 0.00012417 0.00013147
 0.00012816]
Model epoch 370: train total loss -66.02746096870435, train mean loss 0.00010800757632979386, test mean loss [0.00014549 0.00016137 0.00012434 0.00014235 0.00012234 0.00012613
 0.0001375 ]
Model epoch 371: train total loss -66.15879145956802, train mean loss 0.00010313866054275506, test mean loss [0.00014286 0.00015958 0.0001323  0.00014527 0.00012323 0.00012786
 0.00013282]
Model epoch 372: train total loss -66.03361664657977, train mean loss 0.00011966641363011306, test mean loss [0.00014104 0.00015651 0.0001346  0.00015022 0.0001333  0.00012846
 0.00013528]
Model epoch 373: train total loss -66.0215733520039, train mean loss 0.00011647061544244913, test mean loss [0.0001422  0.00016104 0.00012937 0.00013898 0.00012729 0.00012536
 0.00013158]
Model trained in 374 epochs with 3000 transitions.
[2025-01-24 18:02:50,883][absl][INFO] - {'eval/walltime': 133.50568914413452, 'training/sps': 0.43398218679075035, 'training/walltime': 4037.3459446430206, 'training/model_train_time': 1591.3489592075348, 'training/other_time': 712.0627913475037, 'training/model_horizon': 4, 'training/hallucination_updates_per_training_step': 505, 'training/env_buffer_size': Array(4000, dtype=int32), 'model/train_total_loss': Array(-66.02157335, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00011647, dtype=float64), 'model/test_total_loss': Array(-65.47277429, dtype=float64), 'model/test_mean_loss': Array(0.00013655, dtype=float64), 'model/train_epochs': 374, 'model/sec_per_epoch': 4.249246716499329, 'sac/actor_loss': Array(-11.85219055, dtype=float64), 'sac/alpha': Array(0.0360124, dtype=float32), 'sac/alpha_loss': Array(0.0012611, dtype=float64), 'sac/buffer_current_size': Array(377045.56, dtype=float32), 'sac/critic_loss': Array(0.02857436, dtype=float64), 'eval/episode_forward_vel': Array(-18.25235526, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-18.80806652, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(9.43074649, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(2.43123563e-05, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-7.85047538, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(10.02283354, dtype=float64), 'eval/episode_rew_roll': Array(9.02537512, dtype=float64), 'eval/episode_rew_side_motion': Array(7.6303167, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(8.49459497, dtype=float64), 'eval/episode_rew_yaw': Array(5.93978851, dtype=float64), 'eval/episode_rew_z_vel_change': Array(3.6570919, dtype=float64), 'eval/episode_reward': Array(26.49097454, dtype=float64), 'eval/episode_step_count': Array(20503., dtype=float64), 'eval/avg_episode_length': Array(203., dtype=float64), 'eval/epoch_eval_time': 30.157485485076904, 'eval/sps': 33.15926324477015}
Steps / Eval:  4000.0
Reward is  26.49097453951561
Model horizon updated to 6.
Hallucination updates per training step updated to 752.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -29.641864705587864, train mean loss 0.04431405606125779, test mean loss [0.0429558  0.07143485 0.03900145 0.04214108 0.04090339 0.04294706
 0.03886905]
Model epoch 1: train total loss -35.99571244568145, train mean loss 0.03251352346787291, test mean loss [0.02976274 0.0377413  0.03316247 0.03528161 0.03133935 0.03088818
 0.02714252]
Model epoch 2: train total loss -40.83884405002553, train mean loss 0.02574002941884042, test mean loss [0.02219378 0.02130233 0.02861395 0.0319102  0.02803463 0.02411444
 0.02369788]
Model epoch 3: train total loss -44.56550653665604, train mean loss 0.022335374377175175, test mean loss [0.01954696 0.01990903 0.02431706 0.02772179 0.02315474 0.02125328
 0.02180096]
Model epoch 4: train total loss -47.683963588009405, train mean loss 0.019397394064572283, test mean loss [0.0166406  0.01792858 0.02165518 0.0246914  0.01929245 0.01754105
 0.01922112]
Model epoch 5: train total loss -49.873199627562634, train mean loss 0.01668805130895423, test mean loss [0.01427987 0.01635161 0.01874156 0.02175699 0.01672316 0.01528072
 0.01688665]
Model epoch 6: train total loss -51.75807607515956, train mean loss 0.016574472697095454, test mean loss [0.01319653 0.01463212 0.0167318  0.01998944 0.01398417 0.01331271
 0.01564088]
Model epoch 7: train total loss -53.276994340263826, train mean loss 0.014543323278002684, test mean loss [0.01226172 0.01327813 0.0150584  0.01786667 0.01157365 0.01086626
 0.01404637]
Model epoch 8: train total loss -54.30654344472119, train mean loss 0.011915574416715822, test mean loss [0.01040006 0.01207563 0.01328542 0.01596182 0.009517   0.00927161
 0.01350883]
Model epoch 9: train total loss -55.44194165321461, train mean loss 0.011133428661409027, test mean loss [0.00902907 0.00984999 0.01189702 0.01476918 0.0080877  0.00768521
 0.01214509]
Model epoch 10: train total loss -56.255256279596146, train mean loss 0.009055833106795698, test mean loss [0.00821949 0.00789854 0.01075735 0.01323487 0.00693818 0.00667257
 0.01090895]
Model epoch 11: train total loss -56.68962312199002, train mean loss 0.008504201267323111, test mean loss [0.00735402 0.00644034 0.00987613 0.01211217 0.00611242 0.00561809
 0.0102118 ]
Model epoch 12: train total loss -57.000029193364114, train mean loss 0.007726408000451325, test mean loss [0.00646745 0.00527925 0.00903423 0.01107469 0.0053401  0.00493139
 0.00920974]
Model epoch 13: train total loss -57.74743235622195, train mean loss 0.006237890876265473, test mean loss [0.00553168 0.004776   0.00798597 0.00986018 0.00489678 0.00423157
 0.00769844]
Model epoch 14: train total loss -58.19071602833629, train mean loss 0.005484260475374328, test mean loss [0.0050937  0.00428898 0.00731315 0.00897438 0.00434156 0.00377951
 0.00681892]
Model epoch 15: train total loss -58.60903317355915, train mean loss 0.004714754639912089, test mean loss [0.00422446 0.00407898 0.00638337 0.00798592 0.00375902 0.00336639
 0.00603798]
Model epoch 16: train total loss -58.797662821102996, train mean loss 0.004642052144280562, test mean loss [0.00357501 0.00354363 0.00543582 0.00730148 0.00332502 0.00315013
 0.0056234 ]
Model epoch 17: train total loss -59.113993009571864, train mean loss 0.00345502918822881, test mean loss [0.00319178 0.00330995 0.00512736 0.00651688 0.00270195 0.0029914
 0.00427945]
Model epoch 18: train total loss -59.22552630627053, train mean loss 0.003408525139020714, test mean loss [0.00287091 0.00304355 0.00444319 0.00577983 0.00244313 0.00260096
 0.0038042 ]
Model epoch 19: train total loss -60.08045490420338, train mean loss 0.0029100344776313222, test mean loss [0.00264559 0.00288401 0.00401113 0.0049919  0.0020274  0.00239289
 0.00326111]
Model epoch 20: train total loss -59.716688461478434, train mean loss 0.002869118125873795, test mean loss [0.00240216 0.00259588 0.00375287 0.00510608 0.00180097 0.00384826
 0.00307469]
Model epoch 21: train total loss -59.905064281600104, train mean loss 0.00222732638767072, test mean loss [0.00217209 0.00251903 0.00355283 0.00373059 0.00142395 0.00209061
 0.00253696]
Model epoch 22: train total loss -60.74488983054927, train mean loss 0.0020424837475552385, test mean loss [0.00206789 0.00223047 0.00323533 0.0033581  0.00150912 0.00187107
 0.00236912]
Model epoch 23: train total loss -60.678796610673565, train mean loss 0.0022252962250112404, test mean loss [0.00194913 0.00250746 0.00302459 0.00309657 0.00117951 0.00184635
 0.00229417]
Model epoch 24: train total loss -60.96427429199842, train mean loss 0.0019865461349519126, test mean loss [0.00184413 0.00209087 0.00289887 0.0030988  0.00106294 0.00165909
 0.00225526]
Model epoch 25: train total loss -61.005881919727656, train mean loss 0.0017725490796031015, test mean loss [0.00165371 0.00180335 0.00270092 0.00276414 0.00101236 0.00171499
 0.00214273]
Model epoch 26: train total loss -61.07653068781668, train mean loss 0.001773808492616544, test mean loss [0.0014938  0.00181951 0.0024696  0.00266414 0.00093193 0.00151677
 0.00205707]
Model epoch 27: train total loss -61.26015516868055, train mean loss 0.001334502800974693, test mean loss [0.00128883 0.00141472 0.00242177 0.00249624 0.00085457 0.00141458
 0.00181587]
Model epoch 28: train total loss -61.203865871206304, train mean loss 0.0016526043124674532, test mean loss [0.00123042 0.00137428 0.00219793 0.00258902 0.00085425 0.00135278
 0.0017138 ]
Model epoch 29: train total loss -61.49938442130845, train mean loss 0.0011272213601518574, test mean loss [0.0011694  0.00129113 0.00199711 0.00226828 0.00073447 0.00132169
 0.00172263]
Model epoch 30: train total loss -61.45891656498037, train mean loss 0.0013785194028212366, test mean loss [0.00113141 0.00123143 0.00190584 0.00227184 0.00067441 0.00133799
 0.00170882]
Model epoch 31: train total loss -61.81748695836669, train mean loss 0.0010541761555673405, test mean loss [0.00105224 0.00112454 0.00182405 0.00214396 0.00067981 0.00121082
 0.00153214]
Model epoch 32: train total loss -61.40922431855755, train mean loss 0.0012834121614861123, test mean loss [0.00097996 0.00105195 0.00169537 0.00204204 0.00061802 0.00113013
 0.00153567]
Model epoch 33: train total loss -61.97849087445111, train mean loss 0.0011306940161331161, test mean loss [0.00095969 0.00110123 0.00166553 0.0018991  0.0005724  0.00109255
 0.00134693]
Model epoch 34: train total loss -61.95970387727065, train mean loss 0.0010893188902443556, test mean loss [0.00139835 0.00099256 0.00151613 0.00193546 0.00056521 0.00102892
 0.00131331]
Model epoch 35: train total loss -61.886205778676185, train mean loss 0.0009093884681619005, test mean loss [0.00098126 0.00100253 0.00135646 0.00174734 0.00055091 0.0010025
 0.00130272]
Model epoch 36: train total loss -62.00232449987504, train mean loss 0.0009277396398897166, test mean loss [0.00089364 0.00083808 0.00138491 0.00175996 0.0005409  0.001004
 0.00129587]
Model epoch 37: train total loss -62.21803254496561, train mean loss 0.0008483746574965941, test mean loss [0.00076453 0.00093885 0.00142679 0.00155065 0.00059211 0.00089463
 0.00134791]
Model epoch 38: train total loss -62.16131699304457, train mean loss 0.0010064916942012767, test mean loss [0.00071513 0.00085792 0.00130753 0.00157682 0.00049244 0.00086818
 0.00125978]
Model epoch 39: train total loss -62.421182822828904, train mean loss 0.0007448101452529934, test mean loss [0.00068023 0.00081692 0.00116223 0.00149881 0.00045434 0.00083212
 0.00119787]
Model epoch 40: train total loss -62.6960049566847, train mean loss 0.0007284804182870096, test mean loss [0.00064904 0.00070216 0.00107258 0.00131664 0.0004413  0.00080664
 0.00105736]
Model epoch 41: train total loss -62.49640609360755, train mean loss 0.0006742841457779366, test mean loss [0.00063769 0.00071776 0.00109752 0.00127992 0.00042668 0.00075596
 0.00106964]
Model epoch 42: train total loss -62.34710936744308, train mean loss 0.0008905098298972834, test mean loss [0.00064412 0.00071134 0.00107194 0.00127967 0.0004041  0.00072672
 0.00100403]
Model epoch 43: train total loss -62.348495922678275, train mean loss 0.0007093626085437495, test mean loss [0.00059682 0.00075058 0.00105844 0.00115069 0.00044433 0.00069259
 0.00099873]
Model epoch 44: train total loss -63.09300743913676, train mean loss 0.0006397135514873256, test mean loss [0.00054961 0.00065736 0.00100069 0.00111812 0.00043887 0.00066422
 0.00092735]
Model epoch 45: train total loss -62.78434090771841, train mean loss 0.0006505441305175488, test mean loss [0.00052578 0.00060178 0.00093377 0.00101297 0.00037459 0.0006462
 0.00085148]
Model epoch 46: train total loss -62.73315691776801, train mean loss 0.0006072719896852455, test mean loss [0.00047977 0.00061062 0.00090323 0.0009715  0.00039375 0.00061942
 0.00085227]
Model epoch 47: train total loss -62.714346799526936, train mean loss 0.0006474770596304273, test mean loss [0.00050005 0.00062133 0.00084586 0.00096465 0.00050092 0.00062719
 0.00080735]
Model epoch 48: train total loss -63.0171726863286, train mean loss 0.0005897587111163965, test mean loss [0.00044004 0.00064366 0.00089961 0.00083694 0.00034448 0.00059454
 0.00086764]
Model epoch 49: train total loss -62.9777300827684, train mean loss 0.0004697867153277088, test mean loss [0.00053464 0.00056765 0.00088719 0.00080497 0.00033683 0.00057609
 0.0007632 ]
Model epoch 50: train total loss -62.979779077754564, train mean loss 0.000580872937070901, test mean loss [0.00042661 0.00055065 0.00079911 0.00080751 0.00034186 0.00054009
 0.00072048]
Model epoch 51: train total loss -62.602451148461675, train mean loss 0.00106265610521122, test mean loss [0.00392517 0.00054369 0.00083622 0.00075513 0.00039759 0.00052332
 0.00070109]
Model epoch 52: train total loss -62.692785330077434, train mean loss 0.0009070416311745925, test mean loss [0.00252804 0.00070276 0.00082922 0.00072654 0.00034996 0.0005293
 0.00076299]
Model epoch 53: train total loss -62.89858495810235, train mean loss 0.0006582538518806756, test mean loss [0.00145879 0.00052144 0.00072176 0.00068326 0.00032065 0.00050153
 0.00104896]
Model epoch 54: train total loss -62.89444245653899, train mean loss 0.0005552522516666671, test mean loss [0.00083391 0.00050522 0.00067928 0.00066517 0.00039586 0.00045978
 0.00072299]
Model epoch 55: train total loss -63.24396249553068, train mean loss 0.0005069959348193701, test mean loss [0.00077248 0.00049908 0.00066586 0.00061971 0.00031247 0.00045006
 0.00067161]
Model epoch 56: train total loss -63.00529352453295, train mean loss 0.00044127852768175476, test mean loss [0.00062805 0.00049317 0.00069255 0.00062975 0.00030217 0.00047396
 0.0006326 ]
Model epoch 57: train total loss -63.07833140155082, train mean loss 0.0004564938398470937, test mean loss [0.00053468 0.00048984 0.00065187 0.0005653  0.0003104  0.00044389
 0.00062265]
Model epoch 58: train total loss -63.24200407517607, train mean loss 0.0004407029537733203, test mean loss [0.00046776 0.00063082 0.00069801 0.00063138 0.0003084  0.00042281
 0.00059966]
Model epoch 59: train total loss -63.11064320390335, train mean loss 0.0005117584123952259, test mean loss [0.00041427 0.00050435 0.000629   0.0005672  0.00029451 0.00086006
 0.00052419]
Model epoch 60: train total loss -63.196770226737854, train mean loss 0.00046203968262796124, test mean loss [0.00040515 0.00043233 0.00059535 0.0005012  0.00028712 0.0006897
 0.00053914]
Model epoch 61: train total loss -63.313171687561315, train mean loss 0.0004067401497460161, test mean loss [0.00035497 0.00045713 0.00057278 0.00049481 0.00027769 0.00048753
 0.00051574]
Model epoch 62: train total loss -63.77370727689209, train mean loss 0.0004100137293991261, test mean loss [0.00034661 0.0003922  0.00058605 0.00045632 0.00062639 0.00050806
 0.00045706]
Model epoch 63: train total loss -63.29745115927717, train mean loss 0.0003810155177548717, test mean loss [0.00032853 0.00042891 0.00056555 0.00046481 0.00029542 0.00069254
 0.00046203]
Model epoch 64: train total loss -63.74851388071788, train mean loss 0.0003298663012134109, test mean loss [0.000313   0.00035503 0.0006024  0.0004386  0.0002715  0.00042075
 0.00044991]
Model epoch 65: train total loss -63.495851594507535, train mean loss 0.0003321764228112455, test mean loss [0.00029803 0.0003661  0.00050687 0.0004382  0.00027809 0.0003884
 0.00045782]
Model epoch 66: train total loss -63.64476359685872, train mean loss 0.0002993595943026743, test mean loss [0.00028552 0.00039759 0.00052135 0.00039835 0.00025405 0.00037121
 0.00042294]
Model epoch 67: train total loss -63.56392872195062, train mean loss 0.0003402942629643574, test mean loss [0.0003263  0.00033313 0.00046909 0.00040199 0.00029025 0.00035333
 0.00040258]
Model epoch 68: train total loss -63.83988239725874, train mean loss 0.00029312890077877186, test mean loss [0.00028161 0.00033036 0.00047755 0.00037536 0.0002654  0.00033677
 0.0003908 ]
Model epoch 69: train total loss -63.53594178387984, train mean loss 0.0002838918721645864, test mean loss [0.00027409 0.00037501 0.00046664 0.00041727 0.00025161 0.00032176
 0.00037762]
Model epoch 70: train total loss -63.564685324053244, train mean loss 0.0003213576270282846, test mean loss [0.0002535  0.00038203 0.00045569 0.00039246 0.00024774 0.0003123
 0.00039313]
Model epoch 71: train total loss -63.50878165245271, train mean loss 0.00030680256365115977, test mean loss [0.00031402 0.00029679 0.00046478 0.00036679 0.00024354 0.00030288
 0.00036031]
Model epoch 72: train total loss -63.87017474439958, train mean loss 0.00027626053328005067, test mean loss [0.00029929 0.00031652 0.00041296 0.00037185 0.00024639 0.0003007
 0.0003657 ]
Model epoch 73: train total loss -63.88975442538768, train mean loss 0.00027850777469806497, test mean loss [0.00026223 0.00028595 0.00050784 0.00034184 0.00023534 0.00029551
 0.00037263]
Model epoch 74: train total loss -63.74607719815715, train mean loss 0.0003020738218765, test mean loss [0.00024431 0.00026962 0.00053138 0.00034618 0.00027512 0.00028066
 0.0003509 ]
Model epoch 75: train total loss -63.64187580096875, train mean loss 0.00027968440621538385, test mean loss [0.00026455 0.00034685 0.0004525  0.00035238 0.00025665 0.00030603
 0.00037825]
Model epoch 76: train total loss -63.682167785440946, train mean loss 0.0003007933329146041, test mean loss [0.00025025 0.00028277 0.00042027 0.00033911 0.00023818 0.00026378
 0.00036171]
Model epoch 77: train total loss -64.14672113246417, train mean loss 0.00026835710417319117, test mean loss [0.00024293 0.00030325 0.00038708 0.00034227 0.0002401  0.00026598
 0.00033022]
Model epoch 78: train total loss -63.71790090980416, train mean loss 0.0002702725205595144, test mean loss [0.00024456 0.00024817 0.00038078 0.00033099 0.00022395 0.00025327
 0.00033552]
Model epoch 79: train total loss -64.03303153425193, train mean loss 0.00024023767717661908, test mean loss [0.00025612 0.00029013 0.00036488 0.00032176 0.0002258  0.00025349
 0.00032111]
Model epoch 80: train total loss -63.79722609858924, train mean loss 0.0002727276065381625, test mean loss [0.00024045 0.0002754  0.00042113 0.00035371 0.00022742 0.00023895
 0.00031858]
Model epoch 81: train total loss -64.27785084871992, train mean loss 0.00023333604552365717, test mean loss [0.0002575  0.0002777  0.00036457 0.00031379 0.00022579 0.00024573
 0.00031601]
Model epoch 82: train total loss -64.01541850208432, train mean loss 0.0002503974757134911, test mean loss [0.00024764 0.00024457 0.00037892 0.00032523 0.00022377 0.00025104
 0.00036736]
Model epoch 83: train total loss -63.94124597091872, train mean loss 0.00024377150865021103, test mean loss [0.00023604 0.00025761 0.00033187 0.00030613 0.0002346  0.00024181
 0.00031938]
Model epoch 84: train total loss -64.04547697202761, train mean loss 0.000230313215727327, test mean loss [0.00023024 0.00026867 0.0003468  0.00031196 0.00022627 0.00023765
 0.00029925]
Model epoch 85: train total loss -63.85102195738685, train mean loss 0.0002075104206797655, test mean loss [0.00025387 0.00025595 0.00032398 0.00032166 0.00021831 0.00024041
 0.00029508]
Model epoch 86: train total loss -64.22498487204416, train mean loss 0.0002152776323784713, test mean loss [0.00023658 0.00023924 0.00034893 0.00033278 0.00021944 0.00023784
 0.00028596]
Model epoch 87: train total loss -64.21508538340315, train mean loss 0.00024755122337284907, test mean loss [0.00022465 0.00025829 0.00032281 0.00030091 0.00020532 0.00022849
 0.00028918]
Model epoch 88: train total loss -64.23122605119384, train mean loss 0.00021717971310637545, test mean loss [0.00024335 0.00023702 0.00030305 0.00029516 0.0002164  0.00022061
 0.00027235]
Model epoch 89: train total loss -64.20203884756923, train mean loss 0.00021587583118428248, test mean loss [0.00022986 0.00023075 0.00030439 0.00029554 0.0002133  0.00023771
 0.00029474]
Model epoch 90: train total loss -64.16439674463771, train mean loss 0.0002169029823396306, test mean loss [0.00021859 0.0002337  0.00030614 0.0002755  0.00021211 0.00023284
 0.00028131]
Model epoch 91: train total loss -64.47667112562245, train mean loss 0.00022183444895704945, test mean loss [0.00020699 0.00022018 0.00029313 0.00030757 0.00024674 0.00022864
 0.00030486]
Model epoch 92: train total loss -64.23216799689864, train mean loss 0.00021774717331692658, test mean loss [0.00024849 0.00023703 0.00028005 0.00027813 0.00020647 0.00021899
 0.00027353]
Model epoch 93: train total loss -63.94877028078813, train mean loss 0.0002216739440383505, test mean loss [0.00022391 0.00024182 0.00029689 0.00028663 0.00022293 0.0002229
 0.00027564]
Model epoch 94: train total loss -64.40318588177077, train mean loss 0.00019382278976483034, test mean loss [0.00020504 0.00025455 0.00028267 0.000289   0.00020313 0.0002336
 0.00026164]
Model epoch 95: train total loss -64.33879869170178, train mean loss 0.00021506631195713545, test mean loss [0.00023737 0.00027953 0.00028416 0.00027045 0.00020593 0.00021579
 0.00027097]
Model epoch 96: train total loss -64.49323988744116, train mean loss 0.00021531885514718536, test mean loss [0.00021613 0.00022412 0.00028817 0.00027583 0.00020818 0.00025557
 0.00025122]
Model epoch 97: train total loss -64.06465914554117, train mean loss 0.00021291372489952193, test mean loss [0.000218   0.00021931 0.00028493 0.00026862 0.00020441 0.00021882
 0.00024058]
Model epoch 98: train total loss -64.09808633532487, train mean loss 0.0002013289634098509, test mean loss [0.00020967 0.00025453 0.00029229 0.00028363 0.00022091 0.00023235
 0.00024462]
Model epoch 99: train total loss -64.334850729822, train mean loss 0.0001818407147541665, test mean loss [0.00021085 0.00020607 0.0002666  0.00027467 0.00020174 0.00021106
 0.00025895]
Model epoch 100: train total loss -63.942144585876456, train mean loss 0.000271659461777262, test mean loss [0.00022242 0.00021102 0.0004175  0.0003335  0.00020769 0.00023881
 0.00025742]
Model epoch 101: train total loss -64.29855969149445, train mean loss 0.00020366888704068307, test mean loss [0.00021444 0.00020434 0.00031602 0.00029035 0.00020518 0.00022568
 0.00024445]
Model epoch 102: train total loss -64.1384195934445, train mean loss 0.000216373571126197, test mean loss [0.00022006 0.00022596 0.0003147  0.00027059 0.00021324 0.00022305
 0.00027466]
Model epoch 103: train total loss -64.36326547248473, train mean loss 0.00017472456675105311, test mean loss [0.00019896 0.00021854 0.000266   0.00025017 0.00021236 0.00020249
 0.00024741]
Model epoch 104: train total loss -64.23191917076002, train mean loss 0.00019852257143852394, test mean loss [0.00023331 0.00020282 0.00026219 0.00041933 0.0001916  0.00020918
 0.00023196]
Model epoch 105: train total loss -64.51115831122523, train mean loss 0.00019950239854749815, test mean loss [0.00019724 0.00019881 0.00024667 0.00026555 0.00020947 0.00020007
 0.00022654]
Model epoch 106: train total loss -64.67465361659725, train mean loss 0.0001924309071085513, test mean loss [0.00021978 0.00020091 0.00026507 0.00026358 0.00019798 0.00021398
 0.00021796]
Model epoch 107: train total loss -64.19852070017195, train mean loss 0.00020165502052879236, test mean loss [0.00020209 0.00021161 0.00026662 0.000248   0.00020166 0.00028955
 0.00023247]
Model epoch 108: train total loss -64.42178682232004, train mean loss 0.00020050731234431802, test mean loss [0.00019422 0.00021411 0.00024593 0.00024972 0.00019251 0.00022058
 0.0002229 ]
Model epoch 109: train total loss -64.54733716706717, train mean loss 0.00018383826976026157, test mean loss [0.00020354 0.00019432 0.00025258 0.00025199 0.0002082  0.00021919
 0.00023279]
Model epoch 110: train total loss -64.54269392601775, train mean loss 0.00018397728602499364, test mean loss [0.00019717 0.00019531 0.00027397 0.00024638 0.000189   0.00021544
 0.00022383]
Model epoch 111: train total loss -64.4411669968069, train mean loss 0.0001935772285727408, test mean loss [0.0001886  0.00018961 0.00023596 0.00038166 0.00019238 0.00019326
 0.00022382]
Model epoch 112: train total loss -64.4024982729504, train mean loss 0.00018102964088830106, test mean loss [0.00018874 0.00020615 0.00023297 0.00025958 0.00021167 0.00026479
 0.00023591]
Model epoch 113: train total loss -64.63242250267179, train mean loss 0.00016539155926151416, test mean loss [0.00019024 0.00019576 0.00024148 0.00024829 0.00018344 0.00020214
 0.00022079]
Model epoch 114: train total loss -64.5660364301956, train mean loss 0.00019469086944784303, test mean loss [0.00019034 0.00019795 0.00024403 0.00025145 0.00018825 0.00020384
 0.00022007]
Model epoch 115: train total loss -64.58705166990524, train mean loss 0.0001860089526940386, test mean loss [0.00021356 0.00018167 0.00027318 0.00024609 0.00018917 0.00022559
 0.00022626]
Model epoch 116: train total loss -64.7549349550074, train mean loss 0.0001809282406836572, test mean loss [0.00019083 0.00019246 0.00023112 0.00025268 0.00019506 0.00020507
 0.00021982]
Model epoch 117: train total loss -64.06113987535473, train mean loss 0.00023223648668415473, test mean loss [0.00034434 0.00018905 0.00026183 0.00023573 0.00022732 0.00023972
 0.0002416 ]
Model epoch 118: train total loss -64.54487963699955, train mean loss 0.00018230567415146386, test mean loss [0.00020321 0.00017887 0.00027082 0.0002462  0.00020711 0.0001882
 0.00020974]
Model epoch 119: train total loss -64.54492115766841, train mean loss 0.00018767584840925593, test mean loss [0.00019468 0.00019432 0.0002444  0.00023728 0.00018243 0.00020673
 0.00020951]
Model epoch 120: train total loss -64.21219477877328, train mean loss 0.000194929311620618, test mean loss [0.0001868  0.00019565 0.00023956 0.00023427 0.00020874 0.00019581
 0.00021315]
Model epoch 121: train total loss -64.46489423919607, train mean loss 0.00017505036106283382, test mean loss [0.00018379 0.0001824  0.0002279  0.00023999 0.00021389 0.00019637
 0.00021629]
Model epoch 122: train total loss -64.6409332352884, train mean loss 0.00016380969848672918, test mean loss [0.00019441 0.00020999 0.00022218 0.0002333  0.00019351 0.00021377
 0.00020103]
Model epoch 123: train total loss -64.67253766619639, train mean loss 0.00016540711321165734, test mean loss [0.00018556 0.00022028 0.00021319 0.00022851 0.00028824 0.00019371
 0.00020096]
Model epoch 124: train total loss -64.92157962125101, train mean loss 0.00015811415470218593, test mean loss [0.00018359 0.00019521 0.00021324 0.00024869 0.00018802 0.00017825
 0.00021236]
Model epoch 125: train total loss -64.75111767316055, train mean loss 0.00018260879760988096, test mean loss [0.00019615 0.00017586 0.00022549 0.00023119 0.00022153 0.0002127
 0.0002018 ]
Model epoch 126: train total loss -64.69119843426805, train mean loss 0.00018537118448259832, test mean loss [0.00018285 0.0001998  0.00022892 0.00023584 0.00018892 0.00019893
 0.0002289 ]
Model epoch 127: train total loss -64.32185214905029, train mean loss 0.00017200682584218621, test mean loss [0.00018766 0.00018156 0.00023703 0.00023401 0.00019813 0.00018347
 0.00025284]
Model epoch 128: train total loss -64.49696151055964, train mean loss 0.00016446971167661113, test mean loss [0.00018668 0.0001823  0.00020957 0.00026077 0.000212   0.00019336
 0.00022208]
Model epoch 129: train total loss -64.85373941007833, train mean loss 0.00016630400436319143, test mean loss [0.00017816 0.00017576 0.00022075 0.00022709 0.00017732 0.00019306
 0.00020623]
Model epoch 130: train total loss -64.86713900928049, train mean loss 0.00014501173660192866, test mean loss [0.00018177 0.00017063 0.00021343 0.00022594 0.00017818 0.00017822
 0.0001917 ]
Model epoch 131: train total loss -64.75124360735533, train mean loss 0.00015730438810470827, test mean loss [0.00018267 0.00019155 0.00020769 0.00023057 0.00019097 0.00018927
 0.00018865]
Model epoch 132: train total loss -64.9223297385514, train mean loss 0.0001490315224573938, test mean loss [0.00017879 0.00019066 0.00020262 0.00023201 0.0001746  0.0001762
 0.00019065]
Model epoch 133: train total loss -64.50160496097476, train mean loss 0.00016102698207348342, test mean loss [0.00018205 0.00017833 0.00019773 0.00023301 0.00021819 0.00019965
 0.00023522]
Model epoch 134: train total loss -64.85905676814984, train mean loss 0.00016187088796416186, test mean loss [0.00022776 0.00017007 0.0002239  0.00020998 0.00018634 0.00019713
 0.00018571]
Model epoch 135: train total loss -64.90883330860542, train mean loss 0.0001709392022897419, test mean loss [0.00018084 0.00019419 0.00026599 0.00021153 0.00018481 0.00018414
 0.00018439]
Model epoch 136: train total loss -64.82602242627831, train mean loss 0.00015920459625165165, test mean loss [0.00020671 0.00017125 0.00020358 0.00022309 0.00017394 0.00019768
 0.00019525]
Model epoch 137: train total loss -64.89138096353452, train mean loss 0.00015749040500902744, test mean loss [0.00017273 0.00019348 0.00021969 0.0002128  0.00017491 0.00018048
 0.00018653]
Model epoch 138: train total loss -64.96290313397763, train mean loss 0.00015921926735917188, test mean loss [0.00017787 0.00017301 0.00021703 0.00021146 0.00019426 0.00018511
 0.00021674]
Model epoch 139: train total loss -64.7164916837005, train mean loss 0.0001570287487119795, test mean loss [0.00017481 0.00016375 0.00020281 0.00020764 0.00017904 0.00019889
 0.00019098]
Model epoch 140: train total loss -64.94843211412068, train mean loss 0.00015768333527772053, test mean loss [0.0001792  0.00016725 0.00021633 0.000201   0.00017871 0.00019875
 0.00018762]
Model epoch 141: train total loss -64.99628073000895, train mean loss 0.0001557718913910618, test mean loss [0.0001679  0.00017631 0.00020333 0.00022556 0.00016962 0.00018206
 0.00020072]
Model epoch 142: train total loss -64.77581866008804, train mean loss 0.00015385449985549527, test mean loss [0.00018167 0.00017228 0.00025192 0.00022465 0.00023264 0.00018663
 0.00020268]
Model epoch 143: train total loss -64.80455907140944, train mean loss 0.00014314315160893608, test mean loss [0.00017189 0.00016963 0.00021309 0.00026129 0.00018491 0.00018769
 0.00018283]
Model epoch 144: train total loss -64.79579840374437, train mean loss 0.00015328635320969823, test mean loss [0.00018094 0.00017261 0.00019923 0.00020559 0.00017728 0.00017328
 0.00024222]
Model epoch 145: train total loss -64.96347955211962, train mean loss 0.00015905378105794226, test mean loss [0.00017403 0.00018688 0.00019272 0.00020044 0.00017155 0.00017763
 0.00020641]
Model epoch 146: train total loss -64.92316904096674, train mean loss 0.0001564870274642958, test mean loss [0.00017192 0.00016623 0.00019981 0.00021621 0.00016614 0.00017363
 0.00022895]
Model epoch 147: train total loss -64.77399171618383, train mean loss 0.0001584521324096981, test mean loss [0.0001716  0.00015981 0.0002569  0.00021609 0.00019416 0.00016142
 0.0002059 ]
Model epoch 148: train total loss -64.89109539439409, train mean loss 0.00015051326386454064, test mean loss [0.00017383 0.00016922 0.00018669 0.00022028 0.00017958 0.00017703
 0.00018748]
Model epoch 149: train total loss -64.95916706780794, train mean loss 0.0001613738663823492, test mean loss [0.00016458 0.00016517 0.00019869 0.00019744 0.00018788 0.000176
 0.00022177]
Model epoch 150: train total loss -64.77252070595787, train mean loss 0.00015788559065099342, test mean loss [0.00017702 0.00017445 0.00020946 0.0002007  0.00018064 0.00017254
 0.00018164]
Model epoch 151: train total loss -65.0577650253382, train mean loss 0.0001442179299124655, test mean loss [0.00018166 0.00017267 0.00021507 0.00018893 0.00019038 0.00017702
 0.00018997]
Model epoch 152: train total loss -64.71540356891846, train mean loss 0.0001593693131897383, test mean loss [0.00018585 0.00017372 0.00019099 0.00019625 0.00016757 0.00017534
 0.00018996]
Model epoch 153: train total loss -64.97613341402443, train mean loss 0.00015735902802344474, test mean loss [0.00018126 0.00016543 0.00022094 0.00024786 0.00016559 0.00017166
 0.00023517]
Model epoch 154: train total loss -64.86657572210439, train mean loss 0.00013673282202783667, test mean loss [0.00019401 0.00021056 0.00019214 0.00020238 0.00015898 0.00017403
 0.00020429]
Model epoch 155: train total loss -65.07230439177627, train mean loss 0.00013522535917975475, test mean loss [0.0001745  0.00017344 0.00019198 0.00019752 0.0001678  0.00017063
 0.00018519]
Model epoch 156: train total loss -65.12295014256047, train mean loss 0.00015312042066975803, test mean loss [0.00017771 0.00016159 0.00017863 0.00018798 0.00016889 0.00017239
 0.00018847]
Model epoch 157: train total loss -65.10258933484076, train mean loss 0.00014850160187317637, test mean loss [0.00018461 0.00015813 0.00020834 0.00019183 0.00017544 0.00016957
 0.00018556]
Model epoch 158: train total loss -64.79738025915728, train mean loss 0.00015144354476004008, test mean loss [0.00019172 0.00016695 0.00019337 0.00019385 0.00016966 0.00016714
 0.0002509 ]
Model epoch 159: train total loss -65.15480665035241, train mean loss 0.00014988104417089463, test mean loss [0.00018324 0.00016554 0.00019285 0.00018589 0.00016441 0.00018176
 0.00020346]
Model epoch 160: train total loss -65.09735077102387, train mean loss 0.00014426952918899377, test mean loss [0.00017893 0.0001563  0.00018486 0.00019567 0.00016253 0.00017986
 0.00019986]
Model epoch 161: train total loss -64.94000523187744, train mean loss 0.0001508513535050671, test mean loss [0.00017572 0.00016041 0.00018605 0.0001881  0.00016879 0.00017234
 0.00018116]
Model epoch 162: train total loss -65.08914224481535, train mean loss 0.00015048761538871908, test mean loss [0.00018254 0.00015916 0.00019303 0.00018454 0.00018303 0.00017602
 0.00018813]
Model epoch 163: train total loss -64.90295795054362, train mean loss 0.00014207418743360193, test mean loss [0.00016946 0.00016304 0.00020165 0.00017968 0.00015996 0.00017351
 0.00019172]
Model epoch 164: train total loss -64.95628831541204, train mean loss 0.00013392352830466137, test mean loss [0.00016269 0.0001669  0.00020005 0.0001882  0.0001659  0.0001719
 0.00017354]
Model epoch 165: train total loss -65.00375400270492, train mean loss 0.00014994364411180462, test mean loss [0.00016387 0.00015848 0.0002036  0.00018911 0.00016439 0.00016353
 0.00018889]
Model epoch 166: train total loss -64.95584667544237, train mean loss 0.00014632021384862237, test mean loss [0.00016759 0.00015815 0.00019141 0.00020048 0.00016876 0.00017779
 0.00018689]
Model epoch 167: train total loss -64.97731228061322, train mean loss 0.00014355894156795317, test mean loss [0.00016838 0.00014922 0.00019255 0.00020484 0.00016456 0.00017206
 0.00018124]
Model epoch 168: train total loss -65.13404993269454, train mean loss 0.00014995419441159752, test mean loss [0.00016069 0.0001521  0.00020367 0.00018882 0.00016779 0.00016559
 0.00017602]
Model epoch 169: train total loss -64.95630211801935, train mean loss 0.00015862079774990853, test mean loss [0.00016213 0.00018043 0.00018431 0.00019712 0.00016292 0.00016072
 0.00017853]
Model epoch 170: train total loss -64.96705118800767, train mean loss 0.00015993208567110357, test mean loss [0.0001687  0.0001604  0.00018936 0.00024055 0.00016391 0.00016965
 0.00022983]
Model epoch 171: train total loss -64.98511395746365, train mean loss 0.00012851056668478913, test mean loss [0.00017388 0.00015651 0.00018946 0.00018418 0.00016708 0.00016453
 0.00018365]
Model epoch 172: train total loss -65.2050674160082, train mean loss 0.0001501066053452416, test mean loss [0.00015591 0.00015832 0.00018642 0.00017719 0.00016175 0.00018257
 0.00017929]
Model epoch 173: train total loss -65.19036347306589, train mean loss 0.00015954013669416468, test mean loss [0.00017278 0.00019883 0.00017299 0.00017291 0.00016359 0.00017503
 0.00021718]
Model epoch 174: train total loss -65.05683898779358, train mean loss 0.00013636449234006893, test mean loss [0.00015582 0.00014773 0.00017676 0.00019194 0.00017206 0.00017066
 0.00018386]
Model epoch 175: train total loss -65.21765313217459, train mean loss 0.00013774075732686614, test mean loss [0.00016688 0.00015278 0.00017416 0.00017652 0.00016387 0.00016348
 0.00018187]
Model epoch 176: train total loss -65.06000650784918, train mean loss 0.00013513800605907566, test mean loss [0.00016271 0.00015279 0.00017902 0.00019094 0.00016913 0.00015841
 0.00017881]
Model epoch 177: train total loss -64.99599521482129, train mean loss 0.00013731503511886872, test mean loss [0.00015728 0.00017076 0.00025718 0.00018112 0.00015548 0.00015852
 0.00017329]
Model epoch 178: train total loss -64.93374892507453, train mean loss 0.00014799957224173393, test mean loss [0.00016421 0.00015242 0.00017941 0.00017573 0.00015432 0.0002023
 0.00016982]
Model epoch 179: train total loss -64.97924759347045, train mean loss 0.00014257788177069483, test mean loss [0.00016725 0.00015772 0.00018715 0.00017863 0.00016391 0.00016525
 0.00017769]
Model epoch 180: train total loss -65.07410131417572, train mean loss 0.00013756781289556524, test mean loss [0.00017494 0.00016476 0.00017992 0.0001774  0.0001728  0.00015673
 0.00016888]
Model epoch 181: train total loss -65.19962046623674, train mean loss 0.00015601108272765186, test mean loss [0.00017644 0.00015024 0.00020267 0.0001733  0.00015925 0.00017307
 0.00017454]
Model epoch 182: train total loss -64.99375468933867, train mean loss 0.000144973290638576, test mean loss [0.00015649 0.0001573  0.00017539 0.00016909 0.00016875 0.00016684
 0.00022157]
Model epoch 183: train total loss -65.08393906486585, train mean loss 0.00013232918787616624, test mean loss [0.00016176 0.00015331 0.00019187 0.00020829 0.00015987 0.00016023
 0.00017269]
Model epoch 184: train total loss -65.10263576201707, train mean loss 0.00015227738063438917, test mean loss [0.00017432 0.00019763 0.00018514 0.00017477 0.0001655  0.00017745
 0.00018615]
Model epoch 185: train total loss -65.12182618258264, train mean loss 0.00015495654351846633, test mean loss [0.00017241 0.00015832 0.00019159 0.00017994 0.00019531 0.00016057
 0.00020752]
Model epoch 186: train total loss -64.87530005487773, train mean loss 0.00014617876900093754, test mean loss [0.00015705 0.00014764 0.00017687 0.00017207 0.00017752 0.00016333
 0.00018082]
Model epoch 187: train total loss -65.0785774455951, train mean loss 0.0001495079066357022, test mean loss [0.00017715 0.00015078 0.00019359 0.00017714 0.00019728 0.00016518
 0.00017624]
Model epoch 188: train total loss -64.95459018959103, train mean loss 0.00013634039164666867, test mean loss [0.00015354 0.00016752 0.00018829 0.00020934 0.00015541 0.00015634
 0.00016946]
Model epoch 189: train total loss -65.3033412335224, train mean loss 0.00014099884839324005, test mean loss [0.00016532 0.00015502 0.00019769 0.00017982 0.00017837 0.00017256
 0.00017771]
Model epoch 190: train total loss -65.14951220614017, train mean loss 0.0001401425080879516, test mean loss [0.00015591 0.00016288 0.00018401 0.00018082 0.00017393 0.00015556
 0.00017192]
Model epoch 191: train total loss -65.08183671665243, train mean loss 0.00013679552856211941, test mean loss [0.0001538  0.000151   0.00019488 0.0001818  0.00015982 0.00017097
 0.00016915]
Model epoch 192: train total loss -64.71113180968172, train mean loss 0.00014602418097783281, test mean loss [0.00016434 0.00014469 0.00017323 0.000174   0.000185   0.00016868
 0.0001879 ]
Model epoch 193: train total loss -64.80996192982062, train mean loss 0.00012590993448181366, test mean loss [0.00015956 0.00014773 0.00018383 0.00018142 0.0001567  0.000165
 0.0001726 ]
Model epoch 194: train total loss -65.19152366824444, train mean loss 0.0001387328583814313, test mean loss [0.00015394 0.00015285 0.00017017 0.00017609 0.00019372 0.00016154
 0.00017788]
Model epoch 195: train total loss -65.12156160378791, train mean loss 0.00013594521193727814, test mean loss [0.00017306 0.00016405 0.00016923 0.0002044  0.0001567  0.00016028
 0.00016351]
Model epoch 196: train total loss -65.09363575901442, train mean loss 0.00013957490941697356, test mean loss [0.00017133 0.0001503  0.00018099 0.00016976 0.00015938 0.00017422
 0.00016418]
Model epoch 197: train total loss -65.39486619878251, train mean loss 0.00013987425798489276, test mean loss [0.00015933 0.00016056 0.00017895 0.00017196 0.00016825 0.00015469
 0.00016814]
Model epoch 198: train total loss -65.03655490032273, train mean loss 0.0001367158046547551, test mean loss [0.00020468 0.00015819 0.00018608 0.00017669 0.00017302 0.00015383
 0.00017531]
Model epoch 199: train total loss -65.19713065924498, train mean loss 0.00013752882521181602, test mean loss [0.00015204 0.00014358 0.0001775  0.00017688 0.00015075 0.00015582
 0.00017184]
Model epoch 200: train total loss -65.47404438909604, train mean loss 0.00012269395532692783, test mean loss [0.00016927 0.0001673  0.00016725 0.00016572 0.00015842 0.00016419
 0.00017327]
Model epoch 201: train total loss -65.35534215002022, train mean loss 0.0001422970509616762, test mean loss [0.00015765 0.00014694 0.0001972  0.00017451 0.00017838 0.00015918
 0.00017532]
Model epoch 202: train total loss -65.20246785569833, train mean loss 0.00014186062758238631, test mean loss [0.00018286 0.00015621 0.00017009 0.00016849 0.00016603 0.00016071
 0.00017523]
Model epoch 203: train total loss -65.18842584738162, train mean loss 0.00014453619652961136, test mean loss [0.00019348 0.0001631  0.00018178 0.00017943 0.00016269 0.00017031
 0.0001972 ]
Model epoch 204: train total loss -65.3875227266214, train mean loss 0.00012185581976417679, test mean loss [0.0001661  0.00015552 0.00017332 0.00016521 0.00015028 0.00015939
 0.00017214]
Model epoch 205: train total loss -65.18491583351995, train mean loss 0.00018687598651740163, test mean loss [0.00023782 0.00014284 0.00018508 0.00018709 0.00016981 0.00033214
 0.00016925]
Model epoch 206: train total loss -65.00146428735513, train mean loss 0.00016082619396358468, test mean loss [0.00018986 0.0001436  0.00016893 0.00016947 0.00015911 0.00029469
 0.00016557]
Model epoch 207: train total loss -64.91404826241332, train mean loss 0.0002968900325692994, test mean loss [0.00016569 0.00015625 0.00018258 0.0012667  0.00017158 0.00020998
 0.00015742]
Model epoch 208: train total loss -64.99102675655439, train mean loss 0.00015604195881181097, test mean loss [0.00019143 0.00014757 0.00016963 0.00022134 0.00015672 0.0001861
 0.00018171]
Model epoch 209: train total loss -65.05120405295986, train mean loss 0.00013805577511916608, test mean loss [0.00017115 0.00014447 0.00017668 0.0001976  0.00016233 0.00018074
 0.00017721]
Model epoch 210: train total loss -65.07963298200444, train mean loss 0.00014457430883433876, test mean loss [0.0001691  0.00015889 0.0001755  0.00016732 0.00015871 0.00018028
 0.000167  ]
Model epoch 211: train total loss -65.12244218256089, train mean loss 0.00013600573444189895, test mean loss [0.00017037 0.0001522  0.00016473 0.00016731 0.00015084 0.00016566
 0.00018677]
Model epoch 212: train total loss -65.32169906417066, train mean loss 0.00013568825526078608, test mean loss [0.00016196 0.00014497 0.0001762  0.00017332 0.00014695 0.00017102
 0.00017406]
Model epoch 213: train total loss -64.67138647483343, train mean loss 0.0002041560469609748, test mean loss [0.00020312 0.00014362 0.00076595 0.00016813 0.00015703 0.00025618
 0.00016544]
Model epoch 214: train total loss -65.08496571645033, train mean loss 0.00017255141136863234, test mean loss [0.00015483 0.0001612  0.00032    0.00016189 0.00015567 0.00035378
 0.00018716]
Model epoch 215: train total loss -64.96756337673513, train mean loss 0.00015455463776720496, test mean loss [0.00016632 0.00015065 0.00024408 0.00017869 0.00016481 0.00040584
 0.0001725 ]
Model epoch 216: train total loss -65.34451999019244, train mean loss 0.00014965891460312205, test mean loss [0.00016181 0.0001527  0.00020608 0.00016647 0.00016782 0.00023615
 0.00016017]
Model epoch 217: train total loss -65.3328807732337, train mean loss 0.00013672250478670848, test mean loss [0.00020262 0.00015069 0.00018107 0.00016172 0.00014964 0.00020396
 0.00016348]
Model epoch 218: train total loss -65.23488754010357, train mean loss 0.00013988864012185915, test mean loss [0.00016351 0.00017183 0.00019075 0.00017347 0.00016466 0.00018248
 0.00016743]
Model epoch 219: train total loss -65.20618153446594, train mean loss 0.00013622211985329935, test mean loss [0.00015985 0.00014262 0.00018299 0.00016841 0.00015362 0.00017386
 0.00016248]
Model epoch 220: train total loss -65.08201921754527, train mean loss 0.00014146603864809203, test mean loss [0.000155   0.00015716 0.00018293 0.00017367 0.00015365 0.0001651
 0.00016444]
Model trained in 221 epochs with 4000 transitions.
[2025-01-24 18:43:08,954][absl][INFO] - {'eval/walltime': 163.67018508911133, 'training/sps': 0.41878765325305534, 'training/walltime': 6425.190935373306, 'training/model_train_time': 1249.6517939567566, 'training/other_time': 1137.3630933761597, 'training/model_horizon': 6, 'training/hallucination_updates_per_training_step': 752, 'training/env_buffer_size': Array(5000, dtype=int32), 'model/train_total_loss': Array(-65.08201922, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00014147, dtype=float64), 'model/test_total_loss': Array(-65.03822678, dtype=float64), 'model/test_mean_loss': Array(0.00016456, dtype=float64), 'model/train_epochs': 221, 'model/sec_per_epoch': 5.644611771829528, 'sac/actor_loss': Array(-15.17931171, dtype=float64), 'sac/alpha': Array(0.03046523, dtype=float32), 'sac/alpha_loss': Array(-2.45041196e-05, dtype=float64), 'sac/buffer_current_size': Array(400000., dtype=float32), 'sac/critic_loss': Array(0.03266285, dtype=float64), 'eval/episode_forward_vel': Array(-269.00456064, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-0.31287225, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(47.84912965, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.24063553, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-115.7008863, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(52.70046924, dtype=float64), 'eval/episode_rew_roll': Array(50.13375652, dtype=float64), 'eval/episode_rew_side_motion': Array(37.12492988, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(61.18505256, dtype=float64), 'eval/episode_rew_yaw': Array(32.46277185, dtype=float64), 'eval/episode_rew_z_vel_change': Array(28.35757925, dtype=float64), 'eval/episode_reward': Array(194.17409289, dtype=float64), 'eval/episode_step_count': Array(499500., dtype=float64), 'eval/avg_episode_length': Array(1000., dtype=float64), 'eval/epoch_eval_time': 30.164495944976807, 'eval/sps': 33.151556778011624}
Steps / Eval:  5000.0
Reward is  194.17409289154213
Model horizon updated to 8.
Hallucination updates per training step updated to 1000.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -24.87060348728008, train mean loss 0.09155132955617908, test mean loss [0.09816977 0.04793953 0.06102525 0.08401483 0.09683678 0.1930388
 0.06128616]
Model epoch 1: train total loss -29.960140555592783, train mean loss 0.05897919910897323, test mean loss [0.06899112 0.04390015 0.05174995 0.05058427 0.06315402 0.07695932
 0.04728409]
Model epoch 2: train total loss -34.84927670511212, train mean loss 0.04568357920557606, test mean loss [0.06051426 0.03835491 0.04922405 0.04168173 0.05787192 0.05051402
 0.04485725]
Model epoch 3: train total loss -37.42874556791779, train mean loss 0.04401353778603236, test mean loss [0.05377334 0.03509627 0.04865762 0.04313248 0.05406847 0.04316718
 0.04269679]
Model epoch 4: train total loss -40.90653466901953, train mean loss 0.047940388352783504, test mean loss [0.05099009 0.03310158 0.04783745 0.04629195 0.05595308 0.04065313
 0.04304155]
Model epoch 5: train total loss -44.297760866278566, train mean loss 0.043504373415981394, test mean loss [0.04884348 0.03270617 0.04575353 0.04472668 0.05321557 0.0412139
 0.04650758]
Model epoch 6: train total loss -46.924769587640355, train mean loss 0.041205343002100055, test mean loss [0.04516216 0.03276689 0.04405816 0.04167475 0.04888087 0.03998475
 0.04383898]
Model epoch 7: train total loss -48.85720694873254, train mean loss 0.03692026018739284, test mean loss [0.04167245 0.03022143 0.04105899 0.03910119 0.04357157 0.03902893
 0.04060216]
Model epoch 8: train total loss -50.22679818530298, train mean loss 0.03179941503732377, test mean loss [0.03861941 0.02765144 0.0380437  0.03651131 0.03929504 0.03686346
 0.03552654]
Model epoch 9: train total loss -51.59722364130127, train mean loss 0.030641621775667864, test mean loss [0.03561524 0.02546897 0.03548691 0.03378008 0.036093   0.03633438
 0.0318766 ]
Model epoch 10: train total loss -52.61310800379893, train mean loss 0.028367743814325535, test mean loss [0.03323555 0.02355125 0.03316774 0.03158348 0.03420882 0.03337394
 0.02881515]
Model epoch 11: train total loss -53.0181326171684, train mean loss 0.026561059454609365, test mean loss [0.02994412 0.02203252 0.03096407 0.02957766 0.03256405 0.02934792
 0.02591195]
Model epoch 12: train total loss -53.486746942566334, train mean loss 0.027097710261854237, test mean loss [0.02742368 0.02046572 0.02896697 0.02828312 0.03117518 0.02631552
 0.02365823]
Model epoch 13: train total loss -54.77256908237971, train mean loss 0.02176557896748108, test mean loss [0.02508394 0.01919703 0.02680323 0.02691905 0.02969913 0.02399642
 0.02136118]
Model epoch 14: train total loss -54.7769530165344, train mean loss 0.023231789090380282, test mean loss [0.0232747  0.01788917 0.0250025  0.02538884 0.02800608 0.02241718
 0.01999492]
Model epoch 15: train total loss -55.39918993284012, train mean loss 0.02085369885364904, test mean loss [0.02163728 0.01683076 0.02333109 0.0239004  0.02699005 0.02102254
 0.01869394]
Model epoch 16: train total loss -55.791041905340286, train mean loss 0.020498115973638244, test mean loss [0.01989344 0.01596957 0.02180188 0.02297457 0.0256947  0.01960901
 0.01783366]
Model epoch 17: train total loss -56.064333291334435, train mean loss 0.01790278972041446, test mean loss [0.01857117 0.0154273  0.02047177 0.0216865  0.02454159 0.01884119
 0.01702611]
Model epoch 18: train total loss -56.85911479711621, train mean loss 0.015786600935927052, test mean loss [0.01733053 0.01465593 0.01945336 0.02058794 0.02392764 0.01786965
 0.01636059]
Model epoch 19: train total loss -57.09580536995887, train mean loss 0.015273853725738024, test mean loss [0.01652335 0.01406825 0.01855501 0.01966312 0.02312935 0.01691943
 0.01586026]
Model epoch 20: train total loss -57.07404850697699, train mean loss 0.01683630249240228, test mean loss [0.015749   0.01354896 0.0176269  0.01872958 0.02223594 0.01628065
 0.01527499]
Model epoch 21: train total loss -57.34124394872198, train mean loss 0.01761820120195307, test mean loss [0.01499796 0.01303566 0.01695873 0.01802176 0.02146789 0.01578381
 0.01501575]
Model epoch 22: train total loss -57.85517784307601, train mean loss 0.016149793475905786, test mean loss [0.01448993 0.01256394 0.01630404 0.01719246 0.02080478 0.01537841
 0.01463355]
Model epoch 23: train total loss -57.700631837894456, train mean loss 0.014240655905925966, test mean loss [0.01379647 0.0121251  0.01575986 0.01640583 0.0201551  0.01489676
 0.01426557]
Model epoch 24: train total loss -58.00120142670951, train mean loss 0.013086794979999681, test mean loss [0.01344129 0.01182589 0.01556004 0.01594319 0.01955951 0.01457399
 0.01391452]
Model epoch 25: train total loss -57.985196402713015, train mean loss 0.01418776586040752, test mean loss [0.01297367 0.01149469 0.01504809 0.01543639 0.01921588 0.01408296
 0.01365293]
Model epoch 26: train total loss -58.36141749119271, train mean loss 0.014256667700018774, test mean loss [0.01250522 0.01109923 0.01500243 0.01484056 0.01856047 0.01391389
 0.01333237]
Model epoch 27: train total loss -58.43487414267612, train mean loss 0.012796630088915384, test mean loss [0.01205296 0.01086611 0.01445826 0.01443805 0.01806418 0.01346169
 0.0131662 ]
Model epoch 28: train total loss -58.92727385464995, train mean loss 0.014596797981458248, test mean loss [0.01141407 0.01059932 0.01438911 0.01406774 0.01766733 0.01326506
 0.01294681]
Model epoch 29: train total loss -59.40542289214606, train mean loss 0.009815753357618409, test mean loss [0.0111509  0.010275   0.0140808  0.0134089  0.01697947 0.01292893
 0.01271112]
Model epoch 30: train total loss -59.434548892716634, train mean loss 0.011128785110294005, test mean loss [0.01068505 0.01006696 0.01395779 0.01324032 0.01655437 0.01261398
 0.01246251]
Model epoch 31: train total loss -59.28355512076266, train mean loss 0.012762561118183406, test mean loss [0.01041126 0.00981734 0.01370262 0.01293952 0.0161597  0.01238361
 0.01217768]
Model epoch 32: train total loss -59.31999792800451, train mean loss 0.010629464313982227, test mean loss [0.0102051  0.00953967 0.01339777 0.01263156 0.01557877 0.01230488
 0.01206617]
Model epoch 33: train total loss -59.50048024444736, train mean loss 0.01220755186646715, test mean loss [0.00997525 0.00940729 0.01326889 0.01232025 0.0151547  0.0119797
 0.01185873]
Model epoch 34: train total loss -59.74630684839822, train mean loss 0.010557382905095933, test mean loss [0.00970717 0.00909643 0.0131332  0.01181728 0.01477963 0.01188583
 0.01160953]
Model epoch 35: train total loss -59.63507587066339, train mean loss 0.012894118698193218, test mean loss [0.00954175 0.00890475 0.01287182 0.0116241  0.01454167 0.01179625
 0.01139032]
Model epoch 36: train total loss -59.770773952523164, train mean loss 0.010254707254036646, test mean loss [0.00941737 0.00883998 0.01283923 0.01138045 0.01424866 0.01152377
 0.01122268]
Model epoch 37: train total loss -59.99545678480575, train mean loss 0.012211511568710844, test mean loss [0.00921682 0.0085717  0.01264664 0.01097668 0.01407661 0.01133197
 0.01112763]
Model epoch 38: train total loss -60.20505868932061, train mean loss 0.008924701725173803, test mean loss [0.00899383 0.00842217 0.01245839 0.01085058 0.01393823 0.0111136
 0.01082515]
Model epoch 39: train total loss -59.86705200515409, train mean loss 0.00959286376104005, test mean loss [0.00886423 0.00825805 0.01238567 0.01072374 0.01373621 0.01106635
 0.01079062]
Model epoch 40: train total loss -59.79011691842341, train mean loss 0.011373947642557999, test mean loss [0.00878131 0.00809497 0.01207724 0.0105418  0.01346657 0.01085752
 0.01057496]
Model epoch 41: train total loss -60.27395169368932, train mean loss 0.010531908324745062, test mean loss [0.00858221 0.00802633 0.01208114 0.01020558 0.01316594 0.01074363
 0.01045847]
Model epoch 42: train total loss -60.31443896638725, train mean loss 0.01015214994577987, test mean loss [0.00840896 0.00782705 0.01184116 0.00993681 0.01302657 0.01071564
 0.01032494]
Model epoch 43: train total loss -60.39187959511388, train mean loss 0.010316459701536522, test mean loss [0.0083372  0.00769307 0.01180402 0.00990909 0.0128555  0.01044993
 0.01017686]
Model epoch 44: train total loss -60.46387536503525, train mean loss 0.010254854935784267, test mean loss [0.00826179 0.00756432 0.01159295 0.00977063 0.01265077 0.01033879
 0.00999624]
Model epoch 45: train total loss -60.5778703761322, train mean loss 0.00975179228441017, test mean loss [0.00808178 0.00748107 0.01138338 0.00955296 0.01249387 0.01028976
 0.00977962]
Model epoch 46: train total loss -60.521437039646656, train mean loss 0.009568634509414078, test mean loss [0.00811646 0.00743842 0.01131892 0.00944417 0.01226976 0.0101149
 0.0097628 ]
Model epoch 47: train total loss -60.87025036055208, train mean loss 0.00865695566109594, test mean loss [0.0078776  0.00730774 0.01108339 0.00940606 0.01197023 0.0098665
 0.00973564]
Model epoch 48: train total loss -60.60730058329596, train mean loss 0.008435792431464317, test mean loss [0.00782535 0.0073153  0.01103428 0.00914378 0.01184095 0.00972868
 0.0094911 ]
Model epoch 49: train total loss -60.9419852238779, train mean loss 0.00838574656649403, test mean loss [0.00778427 0.00713502 0.01092566 0.00894132 0.01162086 0.00967982
 0.00944771]
Model epoch 50: train total loss -60.99860818841173, train mean loss 0.008123147935977106, test mean loss [0.00766831 0.00699155 0.01075274 0.00877378 0.01156277 0.00961584
 0.00934161]
Model epoch 51: train total loss -60.94620466662021, train mean loss 0.007879018157261478, test mean loss [0.0075932  0.00690327 0.01066427 0.00870332 0.01139448 0.00960566
 0.00913894]
Model epoch 52: train total loss -61.14901804915516, train mean loss 0.00825365242783434, test mean loss [0.0074676  0.00675981 0.01066008 0.00854585 0.01126788 0.00938142
 0.00906219]
Model epoch 53: train total loss -60.7978802080501, train mean loss 0.007682832845452547, test mean loss [0.00733612 0.00676274 0.01052257 0.00843606 0.01102507 0.00925769
 0.0089352 ]
Model epoch 54: train total loss -61.344115996751796, train mean loss 0.008426108026213377, test mean loss [0.00724319 0.00663283 0.01039248 0.00830217 0.01097664 0.00916043
 0.00891477]
Model epoch 55: train total loss -61.13935775867115, train mean loss 0.008570465189446843, test mean loss [0.00723967 0.00643177 0.01034058 0.00809631 0.01085588 0.00910349
 0.0088353 ]
Model epoch 56: train total loss -61.08508544961807, train mean loss 0.006648285008155766, test mean loss [0.00714043 0.00636928 0.01016294 0.00798712 0.01062944 0.0088409
 0.00860722]
Model epoch 57: train total loss -61.37415201478721, train mean loss 0.008041669140710191, test mean loss [0.00700381 0.00631549 0.01011385 0.00795574 0.01058505 0.00888944
 0.00863927]
Model epoch 58: train total loss -61.38513820877053, train mean loss 0.007148389859228072, test mean loss [0.00697175 0.00621249 0.00993234 0.0077629  0.010519   0.00874379
 0.00851993]
Model epoch 59: train total loss -60.874286768403685, train mean loss 0.009071505856607404, test mean loss [0.006942   0.00618813 0.00995358 0.0077552  0.01037799 0.00862031
 0.0083146 ]
Model epoch 60: train total loss -61.66561486143619, train mean loss 0.006125496410269526, test mean loss [0.00684354 0.00606865 0.00987739 0.00755764 0.01029552 0.0085832
 0.00827792]
Model epoch 61: train total loss -61.37746870992969, train mean loss 0.00716667874020308, test mean loss [0.00680193 0.00603112 0.00962145 0.00745955 0.01021886 0.00849521
 0.00824053]
Model epoch 62: train total loss -61.3827376746923, train mean loss 0.007065352972338755, test mean loss [0.00670249 0.00584397 0.00959488 0.00742668 0.01010983 0.00833854
 0.00813222]
Model epoch 63: train total loss -61.407066684948056, train mean loss 0.006042533628472149, test mean loss [0.00658225 0.00588172 0.00950604 0.00733642 0.00998623 0.00834451
 0.00800792]
Model epoch 64: train total loss -61.372946737879424, train mean loss 0.006758833504078462, test mean loss [0.00660474 0.00585138 0.00943855 0.00724176 0.0099142  0.00828029
 0.00796924]
Model epoch 65: train total loss -61.83719119397464, train mean loss 0.006123987714802812, test mean loss [0.00644007 0.00569081 0.00932902 0.00717673 0.00980018 0.00806672
 0.00788063]
Model epoch 66: train total loss -61.31464312346314, train mean loss 0.007515404195954222, test mean loss [0.00639945 0.00568061 0.00931253 0.00702083 0.00978939 0.0080764
 0.00772297]
Model epoch 67: train total loss -61.62826202530385, train mean loss 0.006739452642323296, test mean loss [0.00626625 0.00575406 0.00915059 0.00694462 0.00968883 0.00803294
 0.00774565]
Model epoch 68: train total loss -61.5917376958786, train mean loss 0.007295235210050735, test mean loss [0.0062193  0.00552424 0.00910747 0.00686157 0.00959834 0.00786902
 0.00770593]
Model epoch 69: train total loss -61.40349915390507, train mean loss 0.006182057648864073, test mean loss [0.0062288  0.00555388 0.0089981  0.00681468 0.00958098 0.00780066
 0.00755343]
Model epoch 70: train total loss -61.53816320544895, train mean loss 0.005042543411631373, test mean loss [0.00616431 0.00542522 0.00922788 0.00675322 0.00940364 0.00766957
 0.00767669]
Model epoch 71: train total loss -62.0503147214696, train mean loss 0.0050110942430836095, test mean loss [0.00606026 0.00537783 0.0088762  0.00662745 0.00936673 0.00755494
 0.00744447]
Model epoch 72: train total loss -61.988480310700936, train mean loss 0.0065266101658087265, test mean loss [0.00604461 0.0052492  0.00876905 0.00662119 0.00927095 0.0075129
 0.00731548]
Model epoch 73: train total loss -62.097236206682794, train mean loss 0.004993201071826251, test mean loss [0.00600662 0.005214   0.00865925 0.00651231 0.00921324 0.00755181
 0.007259  ]
Model epoch 74: train total loss -62.13762956073094, train mean loss 0.004839968725902527, test mean loss [0.00594896 0.00522344 0.00861758 0.00645802 0.00913731 0.00743837
 0.00728567]
Model epoch 75: train total loss -61.81856414362594, train mean loss 0.00666707740511285, test mean loss [0.00584956 0.0050582  0.0085653  0.00641528 0.00915155 0.00729148
 0.0071277 ]
Model epoch 76: train total loss -61.77155245533204, train mean loss 0.006590096632363002, test mean loss [0.00580882 0.00510529 0.00847903 0.0062695  0.00907321 0.00736226
 0.00703375]
Model epoch 77: train total loss -62.13966696120175, train mean loss 0.006324995058437618, test mean loss [0.005803   0.00494375 0.00834197 0.00627536 0.00900854 0.00718643
 0.00697597]
Model epoch 78: train total loss -62.22061358141108, train mean loss 0.006922964089469249, test mean loss [0.00565597 0.00493805 0.00829119 0.00620233 0.00888168 0.00711547
 0.00698346]
Model epoch 79: train total loss -61.90521965429442, train mean loss 0.005593303168617708, test mean loss [0.00566219 0.00487976 0.00824631 0.00615192 0.00883578 0.00699753
 0.00696828]
Model epoch 80: train total loss -62.18196963009079, train mean loss 0.006840130469924058, test mean loss [0.00560021 0.0048869  0.00814769 0.00608783 0.00880424 0.00694568
 0.00680519]
Model epoch 81: train total loss -61.881392449283624, train mean loss 0.0057302467895403355, test mean loss [0.00558374 0.00490615 0.00816834 0.00609342 0.00878655 0.00689418
 0.00673626]
Model epoch 82: train total loss -62.12404360439603, train mean loss 0.006606938521316584, test mean loss [0.00556071 0.00477316 0.00806618 0.00602168 0.00871989 0.00688979
 0.00672271]
Model epoch 83: train total loss -62.362661928518605, train mean loss 0.005660352572423678, test mean loss [0.00545417 0.00472814 0.0079675  0.00592095 0.00858823 0.00679244
 0.00656418]
Model epoch 84: train total loss -62.53282105066175, train mean loss 0.005543634965706854, test mean loss [0.005423   0.00468238 0.00787719 0.00592532 0.00856436 0.00665263
 0.00649285]
Model epoch 85: train total loss -62.5001181342125, train mean loss 0.004382727930833303, test mean loss [0.00539387 0.00461871 0.00783539 0.00585832 0.00847452 0.00661913
 0.00655797]
Model epoch 86: train total loss -62.30375689332356, train mean loss 0.006613719001813117, test mean loss [0.00531833 0.00462995 0.00780184 0.00583733 0.00850395 0.00650064
 0.00640485]
Model epoch 87: train total loss -61.91176997089072, train mean loss 0.0069945631896488215, test mean loss [0.00528569 0.0045659  0.00770639 0.00574321 0.00837554 0.00656598
 0.00634304]
Model epoch 88: train total loss -62.35119486121656, train mean loss 0.005120476593456979, test mean loss [0.00530287 0.00447071 0.00767578 0.00577344 0.00827654 0.00641685
 0.0063658 ]
Model epoch 89: train total loss -62.76342532372163, train mean loss 0.00405291616859294, test mean loss [0.00525698 0.00442076 0.00757006 0.00578896 0.0082749  0.00642987
 0.006266  ]
Model epoch 90: train total loss -62.34591173782471, train mean loss 0.004076737066779634, test mean loss [0.00518829 0.00440079 0.00758241 0.00567334 0.00824727 0.00639407
 0.00613302]
Model epoch 91: train total loss -62.484921117970174, train mean loss 0.006167842653305344, test mean loss [0.00516653 0.00440205 0.00744545 0.00558996 0.00808494 0.00641009
 0.00608252]
Model epoch 92: train total loss -62.52765274853085, train mean loss 0.005648260413812001, test mean loss [0.00509475 0.00435085 0.00742473 0.00552456 0.00806994 0.0062211
 0.00605944]
Model epoch 93: train total loss -62.49690181121369, train mean loss 0.006272715197086369, test mean loss [0.0050528  0.00434198 0.00731154 0.005514   0.00799433 0.0061554
 0.0059981 ]
Model epoch 94: train total loss -62.12189671558506, train mean loss 0.0066453693154196565, test mean loss [0.00506494 0.00433088 0.0074052  0.00545957 0.00795779 0.00615289
 0.0059647 ]
Model epoch 95: train total loss -62.63693403872834, train mean loss 0.0052541699761787485, test mean loss [0.00496909 0.00421914 0.00730532 0.00539453 0.00792762 0.00612359
 0.00586356]
Model epoch 96: train total loss -62.924974601241836, train mean loss 0.004437335921346546, test mean loss [0.0049696  0.00414397 0.00726115 0.00545128 0.00787872 0.00602906
 0.0058209 ]
Model epoch 97: train total loss -62.77987953542193, train mean loss 0.0046522795049116885, test mean loss [0.00487042 0.0041184  0.00714152 0.00545592 0.00781752 0.00600158
 0.00576506]
Model epoch 98: train total loss -62.75952986221913, train mean loss 0.004286282510752239, test mean loss [0.0048411  0.00410309 0.00711998 0.00539173 0.00775733 0.00599335
 0.00572263]
Model epoch 99: train total loss -62.46766254661198, train mean loss 0.004769802539860148, test mean loss [0.00486996 0.00408393 0.0069897  0.00531715 0.0077116  0.00589804
 0.00568061]
Model epoch 100: train total loss -62.47477201149216, train mean loss 0.005338894052568599, test mean loss [0.00482067 0.00409066 0.00691197 0.00528905 0.00774578 0.00579163
 0.00553378]
Model epoch 101: train total loss -62.506539603988855, train mean loss 0.005037289765384998, test mean loss [0.00474239 0.00403608 0.00692552 0.00522956 0.00765185 0.00583074
 0.00555406]
Model epoch 102: train total loss -62.63558698213241, train mean loss 0.005335217994748131, test mean loss [0.00470209 0.0039162  0.00698265 0.00524198 0.00757919 0.00575556
 0.00543908]
Model epoch 103: train total loss -62.764623322240915, train mean loss 0.004621264003397549, test mean loss [0.00468312 0.00395399 0.00684758 0.00514357 0.007566   0.00576331
 0.00549515]
Model epoch 104: train total loss -62.22184116831458, train mean loss 0.005340924757564355, test mean loss [0.00463742 0.00392678 0.00677363 0.00504438 0.00750515 0.00565934
 0.00540531]
Model epoch 105: train total loss -62.74891794110176, train mean loss 0.005239201321862045, test mean loss [0.00459152 0.00387732 0.00677862 0.00510042 0.00746569 0.00562889
 0.00541333]
Model epoch 106: train total loss -62.74183877375855, train mean loss 0.005361074110659548, test mean loss [0.00454988 0.00385762 0.0066732  0.00506297 0.0074055  0.00559701
 0.00536245]
Model epoch 107: train total loss -62.80037400214353, train mean loss 0.005580589815210251, test mean loss [0.00453054 0.0038329  0.00660467 0.00499046 0.00748548 0.00555536
 0.00526331]
Model epoch 108: train total loss -62.58605768447745, train mean loss 0.0057307707577646545, test mean loss [0.00452782 0.00374873 0.00656135 0.00501197 0.0073698  0.00556567
 0.00531552]
Model epoch 109: train total loss -62.72336541624969, train mean loss 0.0048225850217946875, test mean loss [0.00449662 0.00372098 0.00658226 0.00495811 0.00732456 0.00550859
 0.00519001]
Model epoch 110: train total loss -62.58557082400078, train mean loss 0.003983736004144545, test mean loss [0.00442295 0.00369554 0.00646212 0.00497588 0.00722622 0.00546485
 0.0051272 ]
Model epoch 111: train total loss -62.69425556290463, train mean loss 0.005001985720158509, test mean loss [0.00442742 0.00368252 0.00646253 0.00488226 0.00714611 0.00536258
 0.00526706]
Model epoch 112: train total loss -63.04728366642199, train mean loss 0.0034131907429083112, test mean loss [0.00437348 0.00366955 0.006398   0.00489089 0.00719796 0.00536566
 0.0051285 ]
Model epoch 113: train total loss -63.27921712860221, train mean loss 0.0034014485980530676, test mean loss [0.00437888 0.00365094 0.00631612 0.00484837 0.00713977 0.00531682
 0.00503314]
Model epoch 114: train total loss -62.734366404004675, train mean loss 0.004367376251217638, test mean loss [0.00432075 0.00366577 0.00628919 0.00483329 0.00707424 0.00524485
 0.00500358]
Model epoch 115: train total loss -62.850104065647514, train mean loss 0.004890146300396055, test mean loss [0.00434395 0.00356775 0.00628655 0.00475651 0.00697666 0.00523097
 0.00500378]
Model epoch 116: train total loss -62.85906300375425, train mean loss 0.004621154277721576, test mean loss [0.00426186 0.00357228 0.00622049 0.0047552  0.00697235 0.00520386
 0.00498328]
Model epoch 117: train total loss -62.793269975735214, train mean loss 0.004830085962232102, test mean loss [0.00425561 0.00350772 0.0062111  0.00466122 0.00691661 0.00516033
 0.00487721]
Model epoch 118: train total loss -62.646951803111875, train mean loss 0.003938242820950122, test mean loss [0.00420947 0.00354789 0.00619218 0.00463066 0.00689427 0.00512873
 0.00485825]
Model epoch 119: train total loss -62.9974411172678, train mean loss 0.0038748351900941822, test mean loss [0.0041776  0.0034646  0.00613796 0.00464116 0.00686695 0.00506621
 0.00489729]
Model epoch 120: train total loss -62.75441054425663, train mean loss 0.0052889105671698735, test mean loss [0.00411039 0.00348723 0.00602372 0.00466587 0.00684058 0.00505802
 0.0048253 ]
Model epoch 121: train total loss -63.197340619886084, train mean loss 0.003601779482072122, test mean loss [0.00410396 0.00351656 0.00602476 0.00464667 0.00686153 0.00500461
 0.00476861]
Model epoch 122: train total loss -63.01689600942152, train mean loss 0.0033784207010252834, test mean loss [0.00409643 0.00345438 0.00595142 0.00451132 0.00674984 0.00503182
 0.00474659]
Model epoch 123: train total loss -63.297775554980284, train mean loss 0.003455008295510066, test mean loss [0.00410873 0.00339094 0.00588583 0.00456051 0.00677856 0.00499536
 0.00476615]
Model epoch 124: train total loss -63.16219947487157, train mean loss 0.003673816336083793, test mean loss [0.00406218 0.00338088 0.00586638 0.00452394 0.0067218  0.00491408
 0.00473007]
Model epoch 125: train total loss -62.986223731373364, train mean loss 0.003510059299262746, test mean loss [0.00407976 0.00335664 0.00582069 0.00447101 0.00668523 0.00489624
 0.00468268]
Model epoch 126: train total loss -63.17060849501275, train mean loss 0.003657687468490134, test mean loss [0.00404199 0.00333112 0.00575256 0.00448563 0.00658302 0.00481593
 0.00471439]
Model epoch 127: train total loss -62.9171112336361, train mean loss 0.004100908958973065, test mean loss [0.00395854 0.00330431 0.0056993  0.00454311 0.00659969 0.00480808
 0.00460811]
Model epoch 128: train total loss -63.1994515445727, train mean loss 0.004523751170870532, test mean loss [0.00398475 0.00330562 0.00566364 0.00442882 0.00653529 0.00477457
 0.00459967]
Model epoch 129: train total loss -63.267883643297736, train mean loss 0.0028861740772156332, test mean loss [0.00408405 0.00325426 0.00560272 0.00441733 0.0065577  0.00485053
 0.00457205]
Model epoch 130: train total loss -63.09891511950612, train mean loss 0.003123996176560624, test mean loss [0.00395991 0.00321834 0.00560773 0.00437459 0.00648268 0.0048989
 0.00456314]
Model epoch 131: train total loss -63.077250398666216, train mean loss 0.0033768074782580112, test mean loss [0.0039379  0.00385896 0.00554079 0.00434826 0.00650837 0.00478818
 0.00456579]
Model epoch 132: train total loss -62.97317575785737, train mean loss 0.005089864144808473, test mean loss [0.00389707 0.00355242 0.00545901 0.00430748 0.00641417 0.00471393
 0.00450796]
Model epoch 133: train total loss -63.189581285184396, train mean loss 0.004221900764386121, test mean loss [0.00386734 0.00340271 0.00545461 0.00427222 0.00644468 0.00470888
 0.00446585]
Model epoch 134: train total loss -63.42379736552327, train mean loss 0.0035342142751209307, test mean loss [0.00385697 0.00330858 0.00543238 0.00423311 0.00638976 0.0046421
 0.00447833]
Model epoch 135: train total loss -63.2636663582603, train mean loss 0.0037471723050938152, test mean loss [0.00385143 0.0032131  0.00535018 0.00425164 0.00637814 0.00463019
 0.00441875]
Model epoch 136: train total loss -63.40389983270214, train mean loss 0.00370279933952331, test mean loss [0.00379526 0.00319497 0.00531871 0.00420699 0.00642572 0.00457943
 0.0044234 ]
Model epoch 137: train total loss -62.92228899435216, train mean loss 0.003457824216596146, test mean loss [0.00378333 0.00316085 0.00535336 0.004199   0.00636968 0.00461336
 0.0043724 ]
Model epoch 138: train total loss -63.101512618679685, train mean loss 0.003758123205285833, test mean loss [0.00375732 0.00312971 0.00528107 0.00417638 0.00630984 0.00461094
 0.00437859]
Model epoch 139: train total loss -63.153243703175725, train mean loss 0.004144955446209675, test mean loss [0.0037522  0.00310307 0.00515045 0.00413956 0.00619586 0.00457579
 0.00433775]
Model epoch 140: train total loss -63.5805072856342, train mean loss 0.0037671187142510835, test mean loss [0.00373719 0.00303958 0.00522845 0.00421092 0.00617409 0.00453646
 0.00433196]
Model epoch 141: train total loss -63.49597906149567, train mean loss 0.0038628438831244637, test mean loss [0.00370996 0.00302498 0.00521898 0.00417385 0.00616269 0.00454447
 0.00425458]
Model epoch 142: train total loss -63.14785922175942, train mean loss 0.0033991611301786655, test mean loss [0.00367364 0.00296149 0.00509564 0.00466635 0.0061652  0.00452384
 0.00422756]
Model epoch 143: train total loss -63.28472442267709, train mean loss 0.0028002327542976666, test mean loss [0.00369987 0.00298307 0.00510013 0.00417284 0.00614481 0.00442426
 0.00423578]
Model epoch 144: train total loss -63.30836299288963, train mean loss 0.003206812505781788, test mean loss [0.00363357 0.00295618 0.00504328 0.0041239  0.00613776 0.00444888
 0.00423271]
Model epoch 145: train total loss -63.194622719395035, train mean loss 0.0034165258049014624, test mean loss [0.00358947 0.00290012 0.00499448 0.0040824  0.00608808 0.00446231
 0.00419604]
Model epoch 146: train total loss -63.66949954269922, train mean loss 0.002461053016839585, test mean loss [0.00362976 0.00293162 0.00499856 0.00401338 0.00607115 0.0044059
 0.00416435]
Model epoch 147: train total loss -63.3471548501117, train mean loss 0.003673518336383656, test mean loss [0.00363197 0.00286404 0.00493567 0.00403995 0.00605002 0.0044034
 0.0041758 ]
Model epoch 148: train total loss -63.56645543874137, train mean loss 0.0034204304191026483, test mean loss [0.00358458 0.00285789 0.00492348 0.00397658 0.00599884 0.00436523
 0.00416558]
Model epoch 149: train total loss -63.27697664363724, train mean loss 0.003066138047318191, test mean loss [0.00353652 0.0028171  0.00490792 0.00397626 0.00597136 0.0043752
 0.00416758]
Model epoch 150: train total loss -63.51930710704229, train mean loss 0.003556217313998361, test mean loss [0.00350651 0.00278424 0.00482903 0.00401205 0.00598232 0.00434402
 0.00412828]
Model epoch 151: train total loss -63.401150099494814, train mean loss 0.003620229222114616, test mean loss [0.00348701 0.00279626 0.00484785 0.00401947 0.00596101 0.0043096
 0.00412404]
Model epoch 152: train total loss -63.41163734399035, train mean loss 0.004136664940241358, test mean loss [0.00353043 0.00271821 0.00477264 0.00397164 0.00592372 0.0043121
 0.00408847]
Model epoch 153: train total loss -63.502759727780585, train mean loss 0.0031264871825611405, test mean loss [0.00344624 0.00275511 0.00475926 0.00388929 0.00589495 0.0042888
 0.00402703]
Model epoch 154: train total loss -63.6636321341406, train mean loss 0.002687644303720321, test mean loss [0.00351093 0.0027494  0.00474064 0.0039192  0.00588401 0.00431306
 0.00401881]
Model epoch 155: train total loss -63.59570387270474, train mean loss 0.0033298111504770794, test mean loss [0.00341632 0.00273849 0.00460742 0.00391496 0.00588026 0.00432534
 0.00400106]
Model epoch 156: train total loss -63.89557636402894, train mean loss 0.0023647944978232335, test mean loss [0.00340427 0.00271576 0.00468521 0.00388725 0.00584242 0.00425491
 0.0039918 ]
Model epoch 157: train total loss -63.14084427720155, train mean loss 0.004415135339361727, test mean loss [0.0033839  0.00269167 0.00456607 0.00387252 0.00589543 0.00422058
 0.00397754]
Model epoch 158: train total loss -63.30632462623483, train mean loss 0.003287136427824832, test mean loss [0.00336631 0.0026821  0.00457624 0.00383749 0.00582509 0.00418118
 0.00399602]
Model epoch 159: train total loss -63.466610380700914, train mean loss 0.0031738587249309676, test mean loss [0.00334567 0.00266323 0.00457538 0.00381996 0.00577789 0.00419567
 0.0039119 ]
Model epoch 160: train total loss -63.4832482793001, train mean loss 0.0028292170270850766, test mean loss [0.00334403 0.0026424  0.00453001 0.00385268 0.00575027 0.00414862
 0.0038913 ]
Model epoch 161: train total loss -63.47989160148405, train mean loss 0.0030801275025459846, test mean loss [0.00331932 0.00264906 0.00449673 0.00383522 0.00575094 0.00413498
 0.00394144]
Model epoch 162: train total loss -63.57036214909412, train mean loss 0.0028925031516941107, test mean loss [0.00333859 0.00262229 0.00445899 0.00383105 0.00569009 0.00413517
 0.00388731]
Model epoch 163: train total loss -63.6140264081711, train mean loss 0.003306178610557155, test mean loss [0.00328171 0.00255052 0.00444444 0.00380211 0.00568634 0.00416151
 0.0038981 ]
Model epoch 164: train total loss -63.63065004488008, train mean loss 0.003193568673709389, test mean loss [0.00327496 0.00257854 0.00436969 0.00380753 0.00566152 0.00409528
 0.00387187]
Model epoch 165: train total loss -63.73352002208148, train mean loss 0.002599896514717763, test mean loss [0.00327693 0.00253172 0.00436896 0.00378222 0.00565182 0.00408678
 0.00383988]
Model epoch 166: train total loss -63.557036399104724, train mean loss 0.0031957553489228075, test mean loss [0.00321612 0.00250638 0.00433688 0.00371613 0.00564482 0.00406465
 0.0038449 ]
Model epoch 167: train total loss -63.33161670967692, train mean loss 0.003479063875630868, test mean loss [0.00321376 0.00255769 0.00429142 0.0037464  0.0056098  0.0040419
 0.00380348]
Model epoch 168: train total loss -63.852928271010185, train mean loss 0.0034589753841797587, test mean loss [0.00322936 0.00249564 0.00428965 0.00372716 0.00557418 0.00405667
 0.00381597]
Model epoch 169: train total loss -63.35893364823152, train mean loss 0.0028853539444228743, test mean loss [0.0031924  0.00249048 0.00420358 0.00370199 0.00559198 0.00401384
 0.00375586]
Model epoch 170: train total loss -63.50114853184187, train mean loss 0.003410000065702619, test mean loss [0.00316062 0.00247782 0.00424434 0.00370062 0.00555362 0.00402931
 0.00374852]
Model epoch 171: train total loss -63.669714045589394, train mean loss 0.0026846674022768836, test mean loss [0.00317241 0.00245622 0.00420353 0.00368169 0.00553397 0.00400424
 0.00372798]
Model epoch 172: train total loss -63.61919769875646, train mean loss 0.0034824884054536014, test mean loss [0.00315549 0.00242577 0.0042376  0.00365824 0.00550223 0.00397058
 0.00372142]
Model epoch 173: train total loss -63.411618574645445, train mean loss 0.002835471542290078, test mean loss [0.00311355 0.00246224 0.0041871  0.00366636 0.00547226 0.00394488
 0.00375019]
Model epoch 174: train total loss -63.86367893779844, train mean loss 0.0018837066235919725, test mean loss [0.00312356 0.00239933 0.00414232 0.00366991 0.00550828 0.00395292
 0.00373857]
Model epoch 175: train total loss -63.6952998015131, train mean loss 0.0022037397892118566, test mean loss [0.00310878 0.00239543 0.00414327 0.00361636 0.00545944 0.00394037
 0.00368508]
Model epoch 176: train total loss -63.629071473767326, train mean loss 0.003668865540228684, test mean loss [0.00309596 0.00244639 0.00412424 0.00360452 0.00542951 0.00388798
 0.00368418]
Model epoch 177: train total loss -63.62180177023669, train mean loss 0.002468704775676098, test mean loss [0.00311246 0.00242085 0.00410656 0.00361823 0.00544943 0.00388124
 0.00383869]
Model epoch 178: train total loss -63.5335201502154, train mean loss 0.003869635393977884, test mean loss [0.00304592 0.00235771 0.00407105 0.00358266 0.00541486 0.00388184
 0.00373278]
Model epoch 179: train total loss -63.549422148432285, train mean loss 0.0027442576688789565, test mean loss [0.00304314 0.00237054 0.0040654  0.00360465 0.00537496 0.00389829
 0.00367895]
Model epoch 180: train total loss -63.631785374644956, train mean loss 0.0029868259323246977, test mean loss [0.00300583 0.00234773 0.00402786 0.00362533 0.00539767 0.00383211
 0.00363085]
Model epoch 181: train total loss -63.62384571176177, train mean loss 0.0029849108751489207, test mean loss [0.00300953 0.00238422 0.00404384 0.00358715 0.00537462 0.0038659
 0.0036359 ]
Model epoch 182: train total loss -63.59601867542033, train mean loss 0.0027717186137771054, test mean loss [0.00300183 0.00230591 0.00398579 0.00357154 0.00533724 0.00383524
 0.00358241]
Model epoch 183: train total loss -63.91545214364433, train mean loss 0.002840736070052622, test mean loss [0.00299032 0.00230464 0.00403787 0.00356611 0.00530625 0.0038051
 0.00359421]
Model epoch 184: train total loss -63.92344691308881, train mean loss 0.0021345901577031826, test mean loss [0.0029542  0.00231289 0.00397847 0.0035544  0.00528983 0.0038203
 0.00362565]
Model epoch 185: train total loss -64.03007454581136, train mean loss 0.002398661044797278, test mean loss [0.00293825 0.00229965 0.00395824 0.00353731 0.00531704 0.00378115
 0.00358656]
Model epoch 186: train total loss -63.8087482268333, train mean loss 0.0018162115945627119, test mean loss [0.00291741 0.00225004 0.0039419  0.00352233 0.00527375 0.00374361
 0.00358106]
Model epoch 187: train total loss -63.791942562599374, train mean loss 0.002586519577975757, test mean loss [0.00289615 0.00223921 0.00387733 0.00348664 0.00523829 0.00383689
 0.00358119]
Model epoch 188: train total loss -63.59165587465472, train mean loss 0.0028892795068043197, test mean loss [0.0028977  0.00220054 0.00389917 0.00348535 0.00529623 0.00374247
 0.00349295]
Model epoch 189: train total loss -63.69259686359821, train mean loss 0.0022728034392985926, test mean loss [0.00287371 0.00220693 0.003878   0.00347141 0.00534661 0.00370439
 0.00351529]
Model epoch 190: train total loss -63.821282570057335, train mean loss 0.0028800885550117673, test mean loss [0.00287467 0.0021931  0.00381426 0.00348894 0.00525478 0.00375541
 0.00347423]
Model epoch 191: train total loss -63.494971330639686, train mean loss 0.002308659769381534, test mean loss [0.00282541 0.00232387 0.0038389  0.00346217 0.00524395 0.00371212
 0.00348243]
Model epoch 192: train total loss -63.62227431192933, train mean loss 0.0032395562549213898, test mean loss [0.00282618 0.00292848 0.00377769 0.00344458 0.0052477  0.00367923
 0.00347296]
Model epoch 193: train total loss -63.82660294956568, train mean loss 0.0034349668398538278, test mean loss [0.00278047 0.00260758 0.00383096 0.0034087  0.00520787 0.00368385
 0.00347498]
Model epoch 194: train total loss -63.59489641169407, train mean loss 0.0027831608440608674, test mean loss [0.00280288 0.00240438 0.00376014 0.00346263 0.00517378 0.00367234
 0.00342377]
Model epoch 195: train total loss -63.472636656649065, train mean loss 0.002425057191454827, test mean loss [0.00280204 0.00232938 0.00378097 0.00343493 0.00515605 0.00365106
 0.00342782]
Model epoch 196: train total loss -63.82991202222717, train mean loss 0.0035089634644128505, test mean loss [0.0027488  0.00231068 0.00377011 0.0033908  0.00516089 0.00363826
 0.00344029]
Model epoch 197: train total loss -63.67588384757835, train mean loss 0.0026476193378124056, test mean loss [0.00275588 0.00227162 0.00374922 0.00337771 0.00517274 0.00363861
 0.00342583]
Model epoch 198: train total loss -63.94347334189668, train mean loss 0.002538163745879446, test mean loss [0.00275666 0.0022754  0.00368871 0.00339979 0.00509966 0.00362897
 0.00340598]
Model epoch 199: train total loss -63.60756095593726, train mean loss 0.0021146500321845975, test mean loss [0.00272894 0.00296297 0.00374242 0.00333649 0.00506984 0.00360395
 0.00340263]
Model epoch 200: train total loss -64.24299223867762, train mean loss 0.0021287962614904973, test mean loss [0.00271194 0.00234259 0.00362207 0.00334186 0.00501447 0.00359731
 0.0033734 ]
Model epoch 201: train total loss -63.81636607641534, train mean loss 0.002366751064865395, test mean loss [0.00269456 0.00217152 0.00364807 0.00338075 0.00505967 0.00357024
 0.0033649 ]
Model epoch 202: train total loss -63.609478867383906, train mean loss 0.002856341703739343, test mean loss [0.00268049 0.00216172 0.00370912 0.00330593 0.00507554 0.00360931
 0.00336761]
Model epoch 203: train total loss -63.951737530768725, train mean loss 0.002170568353762595, test mean loss [0.00265413 0.00211674 0.00362199 0.00329888 0.00502727 0.00359057
 0.0033781 ]
Model epoch 204: train total loss -63.799304956372445, train mean loss 0.002496443796660338, test mean loss [0.00265851 0.00210288 0.00358682 0.00326888 0.00500927 0.00355695
 0.00335989]
Model epoch 205: train total loss -63.88855954212922, train mean loss 0.0021554911670618655, test mean loss [0.00268787 0.00209921 0.00362695 0.0032476  0.00496947 0.00353733
 0.00333114]
Model epoch 206: train total loss -63.947573664316536, train mean loss 0.002977865659057108, test mean loss [0.0026425  0.00209501 0.0035723  0.00332934 0.00500466 0.00350248
 0.00330555]
Model epoch 207: train total loss -63.9608196553469, train mean loss 0.0024342674450005216, test mean loss [0.00265551 0.00206847 0.00357249 0.003262   0.00494287 0.00354146
 0.00326514]
Model epoch 208: train total loss -64.07709311816556, train mean loss 0.0023774461138080824, test mean loss [0.00262313 0.00202097 0.00356288 0.00322672 0.00493292 0.00351552
 0.00330264]
Model epoch 209: train total loss -63.863971771647286, train mean loss 0.002067305119041101, test mean loss [0.00263516 0.00204196 0.00352856 0.00328414 0.00494434 0.00351517
 0.00325315]
Model epoch 210: train total loss -63.797519426565486, train mean loss 0.0024377579674208522, test mean loss [0.0025955  0.00204715 0.00352441 0.00322804 0.00492205 0.00344677
 0.00324312]
Model epoch 211: train total loss -63.80266638405495, train mean loss 0.002938041052225491, test mean loss [0.00258218 0.00208012 0.00349779 0.00326883 0.00491405 0.00350243
 0.00326684]
Model epoch 212: train total loss -63.814349340907654, train mean loss 0.002080224585272672, test mean loss [0.00253609 0.0020218  0.0035058  0.00321558 0.00491409 0.00349197
 0.00324839]
Model epoch 213: train total loss -63.889221446876874, train mean loss 0.0016486737473307583, test mean loss [0.00255526 0.00199441 0.00346795 0.0032199  0.00489866 0.00346286
 0.00322838]
Model epoch 214: train total loss -64.10086530954527, train mean loss 0.0019514569292574586, test mean loss [0.00250309 0.00195624 0.00348719 0.00317957 0.00488124 0.00343878
 0.00324145]
Model epoch 215: train total loss -64.1362530173958, train mean loss 0.0023667334218865337, test mean loss [0.00252708 0.00197344 0.00346794 0.00314801 0.00486726 0.00339352
 0.00322049]
Model epoch 216: train total loss -63.90124993817231, train mean loss 0.0025671310843963396, test mean loss [0.00251892 0.00194611 0.00342133 0.00317007 0.00481567 0.00341242
 0.0032195 ]
Model epoch 217: train total loss -64.05028749667242, train mean loss 0.0026436067332312207, test mean loss [0.00251848 0.00191856 0.00343435 0.00314333 0.00480729 0.00344604
 0.00320707]
Model epoch 218: train total loss -63.845641697075294, train mean loss 0.0024486419830047506, test mean loss [0.00247535 0.00190631 0.0034462  0.00313841 0.00485587 0.00339156
 0.00321839]
Model epoch 219: train total loss -63.78646413857037, train mean loss 0.002880586078943515, test mean loss [0.00245349 0.00192992 0.00348022 0.00314355 0.00484959 0.00336148
 0.00322633]
Model epoch 220: train total loss -64.21536954867574, train mean loss 0.002576638147978567, test mean loss [0.00246471 0.00190262 0.00333883 0.00313405 0.0048051  0.00335071
 0.0032452 ]
Model epoch 221: train total loss -63.997501725303344, train mean loss 0.003157167398715304, test mean loss [0.00246445 0.00188036 0.00334398 0.00315774 0.00478305 0.0033383
 0.00319637]
Model epoch 222: train total loss -64.18151098885394, train mean loss 0.002711933094789201, test mean loss [0.00245459 0.00188517 0.00337043 0.00312856 0.00474871 0.00333804
 0.00318519]
Model epoch 223: train total loss -63.89641391574655, train mean loss 0.0019741541866833377, test mean loss [0.00240888 0.00186095 0.00331185 0.00310578 0.00474368 0.00333707
 0.00316285]
Model epoch 224: train total loss -63.90981620126055, train mean loss 0.001990556864852218, test mean loss [0.00239468 0.0018517  0.00330787 0.00311446 0.00473055 0.00331849
 0.00317102]
Model epoch 225: train total loss -64.06152052793107, train mean loss 0.0019896451091022346, test mean loss [0.00236962 0.00184736 0.00327274 0.00310812 0.00472774 0.00329216
 0.00318246]
Model epoch 226: train total loss -64.15746293004055, train mean loss 0.00201400721965361, test mean loss [0.00240313 0.00183849 0.00331357 0.00309997 0.00471885 0.00330728
 0.00309986]
Model epoch 227: train total loss -63.97570350267254, train mean loss 0.002015741480551922, test mean loss [0.00234512 0.00183748 0.00328042 0.00308092 0.0047007  0.00328042
 0.00314367]
Model epoch 228: train total loss -64.29893400405788, train mean loss 0.0019694228792767124, test mean loss [0.00234732 0.00181781 0.00328777 0.00304458 0.00464901 0.00331602
 0.00316787]
Model epoch 229: train total loss -64.09511864662828, train mean loss 0.002310614960599973, test mean loss [0.00231778 0.00179962 0.00322781 0.0030467  0.00462449 0.00329874
 0.00321055]
Model epoch 230: train total loss -64.1608227755658, train mean loss 0.0019829755304416542, test mean loss [0.00230107 0.00182245 0.00319252 0.00302904 0.00458536 0.0032571
 0.00310437]
Model epoch 231: train total loss -64.20688298205938, train mean loss 0.0021626378196510526, test mean loss [0.00230531 0.00182734 0.00323568 0.003016   0.00467716 0.0032751
 0.00312389]
Model epoch 232: train total loss -64.0130343328527, train mean loss 0.002027650935606567, test mean loss [0.00228396 0.00178554 0.00320012 0.00299267 0.00460032 0.00326463
 0.00308591]
Model epoch 233: train total loss -63.97396208792714, train mean loss 0.0015115608808203675, test mean loss [0.00225548 0.00178434 0.00321325 0.00301708 0.00469726 0.00323139
 0.00308919]
Model epoch 234: train total loss -63.97778638110359, train mean loss 0.0023408969398133455, test mean loss [0.00222487 0.00207006 0.00320893 0.00305068 0.00458044 0.00321219
 0.00306705]
Model epoch 235: train total loss -64.11670920165038, train mean loss 0.002480773480712104, test mean loss [0.00221726 0.00183442 0.00320934 0.00304473 0.00455566 0.00323365
 0.00307201]
Model epoch 236: train total loss -64.04641128532053, train mean loss 0.0018154356765221022, test mean loss [0.00222484 0.00183894 0.00313353 0.00302869 0.00457383 0.00324976
 0.00305347]
Model epoch 237: train total loss -64.23961934435685, train mean loss 0.0025745079597775085, test mean loss [0.00220929 0.00180337 0.00316999 0.00299915 0.00453686 0.00319557
 0.00301915]
Model epoch 238: train total loss -64.24038292624202, train mean loss 0.0024337647990198045, test mean loss [0.00218081 0.0017565  0.00314343 0.00296291 0.00448276 0.0032146
 0.00303467]
Model epoch 239: train total loss -63.82558419730859, train mean loss 0.0021797733591540063, test mean loss [0.00218715 0.00170255 0.00330045 0.00300776 0.00450236 0.00322825
 0.00302248]
Model epoch 240: train total loss -64.17980210894332, train mean loss 0.0020691591935204706, test mean loss [0.00223031 0.00175459 0.00314864 0.0029849  0.00446277 0.00321075
 0.00302598]
Model epoch 241: train total loss -64.11208976493472, train mean loss 0.0021684206459504202, test mean loss [0.00215102 0.00170834 0.00313845 0.00297249 0.00447052 0.00317475
 0.00301064]
Model epoch 242: train total loss -64.22207123548675, train mean loss 0.002629521984036931, test mean loss [0.00216216 0.00173691 0.00306956 0.00298218 0.00441253 0.00313432
 0.00297604]
Model epoch 243: train total loss -63.91065779355127, train mean loss 0.002741924121105735, test mean loss [0.00214367 0.0017511  0.00311781 0.00293174 0.00450572 0.00318083
 0.00300029]
Model epoch 244: train total loss -64.17954626029149, train mean loss 0.002500320290273237, test mean loss [0.00214119 0.00170382 0.00310019 0.00292564 0.00441931 0.00315574
 0.00301205]
Model epoch 245: train total loss -64.34933095802798, train mean loss 0.0013978235994030522, test mean loss [0.002114   0.00171395 0.00304251 0.00295988 0.00438543 0.00311694
 0.00300052]
Model epoch 246: train total loss -64.07062753836772, train mean loss 0.0016892044814806981, test mean loss [0.00210996 0.00169146 0.00305917 0.00293745 0.00436518 0.00314378
 0.00300966]
Model epoch 247: train total loss -64.17641344745905, train mean loss 0.003443155237996508, test mean loss [0.00211415 0.00173704 0.00307164 0.0029207  0.00435393 0.00312097
 0.00298839]
Model epoch 248: train total loss -64.46392345719994, train mean loss 0.001655451188431914, test mean loss [0.00207045 0.00170645 0.0030156  0.0028998  0.00432853 0.00306918
 0.00296202]
Model epoch 249: train total loss -64.12630824700253, train mean loss 0.0014838528764671444, test mean loss [0.00212732 0.00167889 0.00303338 0.00288309 0.00430402 0.00307894
 0.00295035]
Model epoch 250: train total loss -63.99127573436104, train mean loss 0.002121536731400773, test mean loss [0.00207783 0.00167144 0.0029971  0.00286447 0.00429519 0.0031169
 0.00294045]
Model epoch 251: train total loss -64.0953441133068, train mean loss 0.002317650264312494, test mean loss [0.00208096 0.00165282 0.00305535 0.00289024 0.0043423  0.00308432
 0.00293607]
Model epoch 252: train total loss -64.339413693741, train mean loss 0.002718674981863156, test mean loss [0.00207866 0.00164277 0.00302048 0.00291472 0.00426869 0.0030756
 0.0029352 ]
Model epoch 253: train total loss -64.39955511747037, train mean loss 0.002092081194355382, test mean loss [0.00203025 0.00167016 0.0029528  0.00286657 0.00424029 0.00308101
 0.00291517]
Model epoch 254: train total loss -64.17233170152437, train mean loss 0.0026159261437513352, test mean loss [0.00204081 0.00165033 0.00295547 0.00285993 0.00425243 0.00305917
 0.0028881 ]
Model epoch 255: train total loss -64.21060415460222, train mean loss 0.002396599447757979, test mean loss [0.00202421 0.00160687 0.00292969 0.00282006 0.00426756 0.0030443
 0.00291287]
Model epoch 256: train total loss -63.95227003438423, train mean loss 0.0027915757176250077, test mean loss [0.0020044  0.00162232 0.00292902 0.00285594 0.00425018 0.00304492
 0.00288287]
Model epoch 257: train total loss -64.57368324191347, train mean loss 0.0013725926757866104, test mean loss [0.001999   0.00161142 0.00292089 0.00286147 0.00423537 0.00305464
 0.00289274]
Model epoch 258: train total loss -64.30722694856092, train mean loss 0.0021805004020843954, test mean loss [0.0020061  0.00159484 0.00293544 0.00285902 0.00424442 0.00306394
 0.00289299]
Model epoch 259: train total loss -64.49020553085714, train mean loss 0.002160738721256194, test mean loss [0.00198803 0.00157394 0.00291434 0.00281006 0.00423484 0.00300175
 0.00287821]
Model epoch 260: train total loss -64.20711460321608, train mean loss 0.002176215122951739, test mean loss [0.0019451  0.00160867 0.00286155 0.00284    0.00417934 0.00302325
 0.00288129]
Model epoch 261: train total loss -64.07594049791753, train mean loss 0.0024829058412239144, test mean loss [0.00199404 0.00161576 0.00293331 0.00284279 0.00414272 0.00301489
 0.00286117]
Model epoch 262: train total loss -64.45587039346033, train mean loss 0.001568547218669954, test mean loss [0.00196288 0.00159489 0.00294595 0.00283296 0.00416745 0.00299759
 0.00288379]
Model epoch 263: train total loss -64.35750218401863, train mean loss 0.0018040031211380922, test mean loss [0.00194319 0.00157793 0.00285118 0.00279301 0.00415081 0.00295215
 0.00285638]
Model epoch 264: train total loss -64.24830798332435, train mean loss 0.002639580384544157, test mean loss [0.0019459  0.00156639 0.00286523 0.00282746 0.00413693 0.00297538
 0.00282381]
Model epoch 265: train total loss -64.42127156391668, train mean loss 0.0024885429863524366, test mean loss [0.00195273 0.00160448 0.00286325 0.00281706 0.00411691 0.0029479
 0.00286328]
Model epoch 266: train total loss -64.21787672713526, train mean loss 0.0024714690421505205, test mean loss [0.00193525 0.0016133  0.00283454 0.00277692 0.00415365 0.00294626
 0.0028259 ]
Model epoch 267: train total loss -64.23695728672045, train mean loss 0.001433751267218717, test mean loss [0.00191557 0.00158898 0.00286533 0.0027716  0.00407718 0.00295496
 0.00277906]
Model epoch 268: train total loss -64.14185788597342, train mean loss 0.0017122925991219899, test mean loss [0.00188438 0.00157614 0.00284904 0.00279786 0.00408251 0.00292398
 0.00280957]
Model epoch 269: train total loss -64.19063870101469, train mean loss 0.0021609340647060155, test mean loss [0.00187732 0.00158399 0.00279826 0.00274991 0.00405709 0.00292993
 0.002833  ]
Model epoch 270: train total loss -63.977010987260684, train mean loss 0.0025045696215192418, test mean loss [0.0018953  0.00156512 0.002806   0.00277908 0.00406143 0.00291642
 0.00279048]
Model epoch 271: train total loss -64.11779010795175, train mean loss 0.0015839541064581345, test mean loss [0.0018411  0.00154827 0.00279315 0.00275125 0.00405287 0.00291141
 0.00281598]
Model epoch 272: train total loss -64.47658166716278, train mean loss 0.0015323944578206562, test mean loss [0.00185266 0.00152591 0.00276773 0.0027882  0.00402687 0.00286842
 0.00279805]
Model epoch 273: train total loss -64.30967061159177, train mean loss 0.0020169895898328816, test mean loss [0.00184561 0.00153691 0.00277249 0.00275455 0.00398858 0.00290323
 0.00279912]
Model epoch 274: train total loss -64.53153069291957, train mean loss 0.0015286192828134174, test mean loss [0.00186421 0.00155417 0.00273592 0.0026937  0.00398162 0.00287294
 0.00277889]
Model epoch 275: train total loss -64.2208503417679, train mean loss 0.0021583437620040047, test mean loss [0.0018547  0.00154123 0.00273319 0.00272194 0.00401633 0.00287327
 0.00278728]
Model epoch 276: train total loss -64.25209834253411, train mean loss 0.0021838567692561137, test mean loss [0.00180916 0.00150147 0.00270798 0.00268916 0.00401053 0.00288283
 0.00281036]
Model epoch 277: train total loss -64.50350916513445, train mean loss 0.001642701181139032, test mean loss [0.00185991 0.00150527 0.00273269 0.00268508 0.00392364 0.00287325
 0.00276204]
Model epoch 278: train total loss -64.51157842962327, train mean loss 0.0017767972526992223, test mean loss [0.00179036 0.00152531 0.0027514  0.00271038 0.00396512 0.00284499
 0.00275921]
Model epoch 279: train total loss -64.45384417826736, train mean loss 0.0016101795142971413, test mean loss [0.00178598 0.00151886 0.00274273 0.00269971 0.00393799 0.00282129
 0.00274039]
Model epoch 280: train total loss -64.52931610676349, train mean loss 0.0017335612417754109, test mean loss [0.00179928 0.00149781 0.00270357 0.00269587 0.00388232 0.00282419
 0.00274165]
Model epoch 281: train total loss -64.2602747338155, train mean loss 0.0017184626174390361, test mean loss [0.00181462 0.00152712 0.00266299 0.00266917 0.00389085 0.00288954
 0.0027112 ]
Model epoch 282: train total loss -64.43131317293606, train mean loss 0.0016930120574502386, test mean loss [0.00177296 0.00148834 0.00266158 0.0026688  0.00392551 0.00282171
 0.00269403]
Model epoch 283: train total loss -64.35607132047228, train mean loss 0.0014138105668941026, test mean loss [0.00177077 0.00151522 0.00263365 0.00268213 0.00388686 0.00280043
 0.00272608]
Model epoch 284: train total loss -64.29368248257188, train mean loss 0.0021790660034007024, test mean loss [0.00173348 0.00151578 0.0026235  0.00265285 0.00388882 0.00281124
 0.00269582]
Model epoch 285: train total loss -64.2623616530604, train mean loss 0.0018339290820090547, test mean loss [0.00178902 0.00148104 0.00263896 0.00262435 0.00384906 0.00277902
 0.00270318]
Model epoch 286: train total loss -64.43583219565136, train mean loss 0.0016201484981132911, test mean loss [0.00173711 0.00145988 0.00262242 0.0026779  0.00387156 0.00276858
 0.00269295]
Model epoch 287: train total loss -64.3318424027328, train mean loss 0.001309437446571548, test mean loss [0.00175346 0.00145464 0.00262161 0.00264422 0.00381299 0.00276888
 0.00266914]
Model epoch 288: train total loss -64.43920211451544, train mean loss 0.0017342085352867274, test mean loss [0.00173354 0.00146076 0.00266664 0.00265709 0.0038241  0.0027989
 0.00268833]
Model epoch 289: train total loss -64.54560149787534, train mean loss 0.0017304763682904807, test mean loss [0.00171767 0.00146389 0.00261102 0.00260885 0.00378019 0.00276722
 0.00266223]
Model epoch 290: train total loss -64.43522288019084, train mean loss 0.0017899694003812975, test mean loss [0.00172916 0.00149921 0.00261815 0.0025858  0.00381573 0.00276345
 0.00265463]
Model epoch 291: train total loss -64.53973045445986, train mean loss 0.002335011025664448, test mean loss [0.00172511 0.00143543 0.00260227 0.0026241  0.00379633 0.00277353
 0.00265874]
Model epoch 292: train total loss -64.67817553055303, train mean loss 0.0010637239451356604, test mean loss [0.00170695 0.00145716 0.00258151 0.00261076 0.00378824 0.00277214
 0.00266215]
Model epoch 293: train total loss -64.22682971991878, train mean loss 0.0016318997138491309, test mean loss [0.00166683 0.00143554 0.00258421 0.002641   0.00374262 0.00275296
 0.00265589]
Model epoch 294: train total loss -64.72261479752706, train mean loss 0.0012260953850044198, test mean loss [0.00169552 0.00144047 0.00255945 0.00258293 0.00377455 0.00273587
 0.00264159]
Model epoch 295: train total loss -64.36274974273077, train mean loss 0.001683328539732494, test mean loss [0.00167109 0.00145808 0.00251446 0.00260977 0.00378672 0.00272856
 0.00261764]
Model epoch 296: train total loss -64.84466951905222, train mean loss 0.00112484697472797, test mean loss [0.00166832 0.00140739 0.00252134 0.00260244 0.0037034  0.00272055
 0.00261842]
Model epoch 297: train total loss -64.44715254491952, train mean loss 0.0015501530465413485, test mean loss [0.00167075 0.00140977 0.00257019 0.00262292 0.0037063  0.00274989
 0.00260663]
Model epoch 298: train total loss -64.53966705587361, train mean loss 0.0015990182962634623, test mean loss [0.0016724  0.0014372  0.00249848 0.00258185 0.0036867  0.00271282
 0.00258828]
Model epoch 299: train total loss -64.39260765502756, train mean loss 0.0015612979364027328, test mean loss [0.00166528 0.00142754 0.00250789 0.00257114 0.00367622 0.00270486
 0.00258046]
Model epoch 300: train total loss -64.73068354517171, train mean loss 0.0010547046157846655, test mean loss [0.00164411 0.00141784 0.00247218 0.00256231 0.00370346 0.00270961
 0.00258782]
Model epoch 301: train total loss -64.39126173266996, train mean loss 0.001187853085128451, test mean loss [0.0016464  0.00136196 0.00250073 0.00257823 0.00367554 0.0027059
 0.00259185]
Model epoch 302: train total loss -64.67257677389658, train mean loss 0.001265423182236309, test mean loss [0.00163088 0.00136693 0.00249406 0.00254341 0.00366599 0.00265764
 0.0025893 ]
Model epoch 303: train total loss -64.409944410935, train mean loss 0.0012588257429162301, test mean loss [0.00163389 0.00136115 0.00250073 0.00253125 0.00365806 0.00270182
 0.00258727]
Model epoch 304: train total loss -64.42693522293894, train mean loss 0.001779088591931658, test mean loss [0.00162198 0.0013633  0.00248499 0.00256157 0.00363255 0.00267536
 0.00258177]
Model epoch 305: train total loss -64.26155224218816, train mean loss 0.0014316379947825408, test mean loss [0.00163856 0.00137442 0.00247525 0.00252987 0.00366496 0.00268597
 0.00257384]
Model epoch 306: train total loss -64.4539502247743, train mean loss 0.0013155807779215607, test mean loss [0.00158832 0.00136354 0.00248245 0.00252714 0.00357515 0.00265375
 0.00256385]
Model epoch 307: train total loss -64.5450685933815, train mean loss 0.0015237458984235998, test mean loss [0.00159056 0.00136078 0.00245041 0.00251363 0.00363491 0.00264451
 0.00255344]
Model epoch 308: train total loss -64.27587499491206, train mean loss 0.0016396468577267098, test mean loss [0.0015866  0.00141862 0.00248295 0.00257011 0.0035809  0.00264095
 0.00254466]
Model epoch 309: train total loss -64.35046144105678, train mean loss 0.001686713568869542, test mean loss [0.00158105 0.0014354  0.00244189 0.00250685 0.00356881 0.00267729
 0.00254112]
Model epoch 310: train total loss -64.84960345142733, train mean loss 0.0011101737750684696, test mean loss [0.00156939 0.00150972 0.00241417 0.00251889 0.00352186 0.00262314
 0.00251808]
Model epoch 311: train total loss -64.37695861452943, train mean loss 0.0019856721368778606, test mean loss [0.00154639 0.00141736 0.00241223 0.00250508 0.00352853 0.00266933
 0.00253929]
Model epoch 312: train total loss -64.42243545208888, train mean loss 0.0014896752502818382, test mean loss [0.00156102 0.00141236 0.00240385 0.00254471 0.00352703 0.00263263
 0.00249751]
Model epoch 313: train total loss -64.58078672903144, train mean loss 0.0009937337701733605, test mean loss [0.00156373 0.00136966 0.00240372 0.00252477 0.00353649 0.00261182
 0.00251434]
Model epoch 314: train total loss -64.43170332162681, train mean loss 0.0014869760523544748, test mean loss [0.00156452 0.00138591 0.00238453 0.00251288 0.00352673 0.00257926
 0.00254848]
Model epoch 315: train total loss -64.51204683223717, train mean loss 0.0009266309238681587, test mean loss [0.00153845 0.00139526 0.0024147  0.00251413 0.00354252 0.00259079
 0.00254823]
Model epoch 316: train total loss -64.42834997186003, train mean loss 0.001677964698360857, test mean loss [0.00154188 0.00137036 0.00237238 0.00249164 0.00350075 0.00258536
 0.00250306]
Model epoch 317: train total loss -64.47339736379149, train mean loss 0.001492975131084711, test mean loss [0.0015164  0.00138007 0.00237115 0.00247308 0.00351477 0.00256409
 0.00247579]
Model epoch 318: train total loss -64.664419676775, train mean loss 0.0013692996549538807, test mean loss [0.00152219 0.00138645 0.00234149 0.0024691  0.00348006 0.00256681
 0.00248016]
Model epoch 319: train total loss -64.41681713771307, train mean loss 0.0016369502738720993, test mean loss [0.0015462  0.00133174 0.00235391 0.00249803 0.00347314 0.0025954
 0.00246638]
Model epoch 320: train total loss -64.42442930541856, train mean loss 0.002004608186048398, test mean loss [0.00152937 0.00132331 0.00235256 0.00246105 0.00347019 0.0025797
 0.00248596]
Model epoch 321: train total loss -64.91416299972224, train mean loss 0.0008616442592536455, test mean loss [0.00152621 0.00131352 0.00235124 0.00244437 0.00341735 0.00256305
 0.00245305]
Model epoch 322: train total loss -64.76330570537229, train mean loss 0.0011911710721281838, test mean loss [0.00149111 0.00131873 0.00235839 0.00244775 0.00339836 0.00257611
 0.00248851]
Model epoch 323: train total loss -64.47397669790274, train mean loss 0.002160109473056321, test mean loss [0.00147051 0.00129876 0.00234388 0.00242777 0.00349628 0.00252217
 0.00246503]
Model epoch 324: train total loss -64.64763431114362, train mean loss 0.0013064778884458877, test mean loss [0.00149233 0.00130446 0.00234139 0.00242609 0.00344298 0.00248834
 0.00247122]
Model epoch 325: train total loss -64.8330976737, train mean loss 0.0007676360276528416, test mean loss [0.0014941  0.0013192  0.00228914 0.00242041 0.0033825  0.00252119
 0.00241361]
Model epoch 326: train total loss -64.6822459327396, train mean loss 0.0013445749587148715, test mean loss [0.00147542 0.00128116 0.00232624 0.00243567 0.00338667 0.00249962
 0.0024453 ]
Model epoch 327: train total loss -64.79971411834316, train mean loss 0.0010651936263363748, test mean loss [0.00149954 0.00130515 0.00227785 0.0023772  0.00329377 0.00252483
 0.00246198]
Model epoch 328: train total loss -64.63880127192508, train mean loss 0.00115545800645404, test mean loss [0.00145326 0.00132418 0.0022982  0.00240149 0.00333905 0.00249598
 0.00245673]
Model epoch 329: train total loss -64.50889516227181, train mean loss 0.0014222624306622633, test mean loss [0.00143145 0.00128849 0.00230247 0.0024271  0.00338937 0.00249708
 0.00244865]
Model epoch 330: train total loss -64.45395731806789, train mean loss 0.0017290458332406364, test mean loss [0.00142356 0.00129645 0.00232768 0.00238636 0.00332834 0.00254068
 0.00240398]
Model epoch 331: train total loss -64.51695804396002, train mean loss 0.0012804581191973663, test mean loss [0.00144779 0.00129342 0.00228274 0.00236986 0.00330709 0.00248236
 0.00241281]
Model epoch 332: train total loss -64.53396619225516, train mean loss 0.0014312501274525026, test mean loss [0.00148482 0.00130423 0.00223954 0.00238393 0.00331877 0.00247186
 0.00253425]
Model epoch 333: train total loss -64.6535562349251, train mean loss 0.0008680198833080369, test mean loss [0.00144301 0.00124821 0.00221902 0.00239753 0.00332654 0.00245629
 0.00245549]
Model epoch 334: train total loss -64.36758684403885, train mean loss 0.0014253103984524992, test mean loss [0.00142163 0.00128878 0.00224193 0.0023933  0.00333486 0.00244277
 0.00240583]
Model epoch 335: train total loss -64.3146965525436, train mean loss 0.0012712652041912851, test mean loss [0.00142711 0.00125974 0.00223605 0.00238107 0.00325674 0.0024705
 0.00238085]
Model epoch 336: train total loss -64.73769496172773, train mean loss 0.0011164967116402533, test mean loss [0.00141475 0.00122749 0.00219904 0.00237688 0.00323708 0.00246072
 0.00238423]
Model epoch 337: train total loss -64.8327171994192, train mean loss 0.0011847060355384903, test mean loss [0.00138165 0.00124123 0.00222988 0.00234831 0.00319169 0.00242677
 0.00236294]
Model epoch 338: train total loss -64.64455175047964, train mean loss 0.001559868375256327, test mean loss [0.00148868 0.0012547  0.00220063 0.00232707 0.0032368  0.00244382
 0.00235478]
Model epoch 339: train total loss -64.74450085945105, train mean loss 0.0008223207351093279, test mean loss [0.0014073  0.00126215 0.00220924 0.00237013 0.00316397 0.00245499
 0.00234478]
Model epoch 340: train total loss -64.75071688675486, train mean loss 0.0011803151853000413, test mean loss [0.00140863 0.00124517 0.00222429 0.00232513 0.00319068 0.00244649
 0.00234171]
Model epoch 341: train total loss -64.65398152697065, train mean loss 0.0009930483646371849, test mean loss [0.00138699 0.00126223 0.00220494 0.00234432 0.00319549 0.00245688
 0.00237497]
Model epoch 342: train total loss -64.60912344268071, train mean loss 0.0013729805887635678, test mean loss [0.00140879 0.00124105 0.00222703 0.00234695 0.0031432  0.00243707
 0.0023319 ]
Model epoch 343: train total loss -64.41389807959902, train mean loss 0.0011674068200838443, test mean loss [0.00136505 0.00124216 0.00218539 0.00232962 0.00316093 0.00239282
 0.00234416]
Model epoch 344: train total loss -64.59057148785989, train mean loss 0.002168902021795879, test mean loss [0.00144129 0.00124251 0.00218086 0.00231174 0.00311795 0.00240555
 0.00234799]
Model epoch 345: train total loss -64.62711751612402, train mean loss 0.0014116349157876319, test mean loss [0.00134946 0.00121819 0.00216972 0.002319   0.00312024 0.00240766
 0.00231317]
Model epoch 346: train total loss -64.74610311010854, train mean loss 0.0011929600452222325, test mean loss [0.001377   0.00124742 0.00213961 0.00230505 0.0031006  0.00238659
 0.0023375 ]
Model epoch 347: train total loss -64.96151222441068, train mean loss 0.0007135571068698453, test mean loss [0.00135371 0.0011944  0.00215134 0.00232921 0.00312339 0.00237884
 0.00228915]
Model epoch 348: train total loss -64.45183342131452, train mean loss 0.0017365282844598584, test mean loss [0.00133555 0.00121338 0.00217159 0.00235832 0.00310718 0.00235231
 0.00231447]
Model epoch 349: train total loss -64.53331306991089, train mean loss 0.0014253170355868782, test mean loss [0.00135901 0.00120156 0.00220732 0.0023093  0.00310112 0.00238051
 0.00229182]
Model epoch 350: train total loss -64.57198894485542, train mean loss 0.001302861430891364, test mean loss [0.00134353 0.00121462 0.00214741 0.0023004  0.00309287 0.00234942
 0.00229745]
Model epoch 351: train total loss -64.59854598412015, train mean loss 0.0014343015059800107, test mean loss [0.00130534 0.00119315 0.00211856 0.00228177 0.00311237 0.00232965
 0.00232204]
Model epoch 352: train total loss -64.82245917912648, train mean loss 0.0012238948832827975, test mean loss [0.00132094 0.00119109 0.00213099 0.00228864 0.00302731 0.00235095
 0.00228125]
Model epoch 353: train total loss -64.69706349610517, train mean loss 0.0013950752657760396, test mean loss [0.00134869 0.00117903 0.00210578 0.00227453 0.00303893 0.00237249
 0.00227137]
Model epoch 354: train total loss -64.6012581667061, train mean loss 0.0015715872403464653, test mean loss [0.00132713 0.00118905 0.00213806 0.00227301 0.00302994 0.00236278
 0.0022787 ]
Model epoch 355: train total loss -64.59806751924839, train mean loss 0.0009336866099994888, test mean loss [0.00130816 0.00117044 0.00211455 0.00227191 0.00299577 0.0023207
 0.00228713]
Model epoch 356: train total loss -64.6980946856082, train mean loss 0.0012147434724851685, test mean loss [0.00131909 0.00119071 0.00211942 0.0022656  0.00299173 0.00231403
 0.00227618]
Model epoch 357: train total loss -64.96734439308834, train mean loss 0.0011480932674822896, test mean loss [0.0013081  0.00122149 0.00209502 0.00223655 0.00301081 0.00230862
 0.00226383]
Model epoch 358: train total loss -64.67165880139821, train mean loss 0.0012258329698928803, test mean loss [0.00130849 0.00115709 0.00205785 0.00231399 0.0029953  0.00230892
 0.00225373]
Model epoch 359: train total loss -64.50849827536312, train mean loss 0.0016361109934491544, test mean loss [0.00130285 0.001178   0.00205729 0.00223695 0.00302494 0.00227557
 0.00222063]
Model epoch 360: train total loss -64.35309559993253, train mean loss 0.0016910374539569144, test mean loss [0.00130263 0.00114748 0.00205527 0.00222777 0.00297473 0.00233731
 0.00221798]
Model epoch 361: train total loss -64.63376508837031, train mean loss 0.0013493818322478494, test mean loss [0.00130056 0.00116572 0.00205315 0.00222363 0.0029582  0.00234295
 0.00223237]
Model epoch 362: train total loss -64.53642804488315, train mean loss 0.0012775697405265172, test mean loss [0.00129222 0.0011797  0.00201669 0.00223054 0.00296642 0.00234764
 0.0022228 ]
Model epoch 363: train total loss -64.56278987814018, train mean loss 0.0010445762422191028, test mean loss [0.00127731 0.00115929 0.00204313 0.00219094 0.00297676 0.00229091
 0.00224436]
Model epoch 364: train total loss -64.99361352788887, train mean loss 0.0010501568838844092, test mean loss [0.00129684 0.00115413 0.00204702 0.00219603 0.00290994 0.00225814
 0.00222336]
Model epoch 365: train total loss -64.81746466080905, train mean loss 0.0011374402527345462, test mean loss [0.00129167 0.00123257 0.00204723 0.00222151 0.00295482 0.00229431
 0.00218798]
Model epoch 366: train total loss -64.73333632409928, train mean loss 0.0009922372482526665, test mean loss [0.00132628 0.00116604 0.00205033 0.00222297 0.00291119 0.00222901
 0.00217241]
Model epoch 367: train total loss -64.72465457431446, train mean loss 0.0010125249506623309, test mean loss [0.00128058 0.00116421 0.00203588 0.00221492 0.00291974 0.00223663
 0.00215061]
Model epoch 368: train total loss -64.73753735527151, train mean loss 0.0016823456456135865, test mean loss [0.00128422 0.00114005 0.00198171 0.00220109 0.00290008 0.00221166
 0.00218348]
Model epoch 369: train total loss -64.60572829189007, train mean loss 0.001027045276921292, test mean loss [0.00127665 0.00114062 0.00199584 0.00217015 0.00290425 0.00226004
 0.00219802]
Model epoch 370: train total loss -64.5956421168736, train mean loss 0.0015107059732615612, test mean loss [0.00122592 0.00114152 0.00202699 0.00216246 0.0028434  0.00226606
 0.00218498]
Model epoch 371: train total loss -64.84290140678281, train mean loss 0.0008583941076851666, test mean loss [0.00123934 0.001109   0.00197715 0.00216529 0.00283626 0.00224411
 0.00219651]
Model epoch 372: train total loss -64.85579027926306, train mean loss 0.0015088543964288754, test mean loss [0.00125559 0.00113161 0.00197738 0.00215631 0.00287567 0.00220169
 0.00214445]
Model epoch 373: train total loss -64.78694132288358, train mean loss 0.0012865155591022099, test mean loss [0.00123927 0.00113853 0.00201641 0.00212748 0.0028007  0.00216139
 0.00216337]
Model epoch 374: train total loss -64.764360062611, train mean loss 0.0011128076921946355, test mean loss [0.00121601 0.0011516  0.00197905 0.00214148 0.00283804 0.00220574
 0.00215955]
Model epoch 375: train total loss -64.69127503305849, train mean loss 0.0014615916342541218, test mean loss [0.00122328 0.0011878  0.0019524  0.00215035 0.00281183 0.00218435
 0.00217343]
Model epoch 376: train total loss -64.83014452452925, train mean loss 0.0010620809044798285, test mean loss [0.00119497 0.00115257 0.00195276 0.0021476  0.00280278 0.00214737
 0.00218241]
Model epoch 377: train total loss -64.88145244820666, train mean loss 0.0007040764409365721, test mean loss [0.00121735 0.00112446 0.00193836 0.00213281 0.00281759 0.0022101
 0.00212426]
Model epoch 378: train total loss -64.62775887018958, train mean loss 0.0009990025313047811, test mean loss [0.00122082 0.0011335  0.00191728 0.00210796 0.00276367 0.00218176
 0.00216122]
Model epoch 379: train total loss -64.90353711424142, train mean loss 0.0007591175632336025, test mean loss [0.00123878 0.00112277 0.00194382 0.00210626 0.00279254 0.0021534
 0.00217252]
Model epoch 380: train total loss -64.86718954637824, train mean loss 0.0012647053887383747, test mean loss [0.00123913 0.0011269  0.00191984 0.00209527 0.00277713 0.00218492
 0.00213157]
Model epoch 381: train total loss -64.65910169624121, train mean loss 0.0010166534820631762, test mean loss [0.00120382 0.0011317  0.00191419 0.00209324 0.00274365 0.00213154
 0.00212466]
Model epoch 382: train total loss -64.97623229225523, train mean loss 0.001182315867142467, test mean loss [0.00121253 0.00111979 0.00189202 0.00207035 0.00278494 0.00214004
 0.00209205]
Model epoch 383: train total loss -64.72181552173497, train mean loss 0.001275682885318109, test mean loss [0.00121786 0.00111154 0.00189675 0.00207615 0.00275564 0.00210287
 0.0020921 ]
Model epoch 384: train total loss -64.8332574997294, train mean loss 0.001209220594837345, test mean loss [0.00119574 0.00112189 0.00189264 0.00210058 0.0027245  0.00209991
 0.00212105]
Model epoch 385: train total loss -64.72912507610882, train mean loss 0.0015085819447602305, test mean loss [0.0011695  0.00109504 0.00191752 0.00206308 0.00271107 0.0021183
 0.00212088]
Model epoch 386: train total loss -64.9439309009865, train mean loss 0.0007096949785025026, test mean loss [0.00116939 0.00109142 0.00189808 0.00208985 0.00267892 0.0020921
 0.0021147 ]
Model epoch 387: train total loss -64.69718431385971, train mean loss 0.0009971161216959397, test mean loss [0.00117622 0.00110094 0.00188714 0.00208803 0.00270828 0.00208618
 0.00208462]
Model epoch 388: train total loss -64.75530193455722, train mean loss 0.0011293981299070682, test mean loss [0.00117408 0.00109331 0.00188471 0.00204096 0.00267991 0.0020791
 0.00212244]
Model epoch 389: train total loss -64.60096737717652, train mean loss 0.0011155278744472011, test mean loss [0.00116548 0.0010901  0.00187975 0.00206389 0.00269302 0.00208691
 0.00209147]
Model epoch 390: train total loss -64.73023063486404, train mean loss 0.0011222690228428495, test mean loss [0.00116417 0.00110724 0.00184812 0.00203592 0.00267986 0.00207044
 0.00205731]
Model epoch 391: train total loss -64.96913610736608, train mean loss 0.0007050631302490683, test mean loss [0.00116203 0.00108514 0.00186092 0.00208623 0.00268178 0.00204799
 0.00205172]
Model epoch 392: train total loss -65.03316570346763, train mean loss 0.0009540334031782634, test mean loss [0.001161   0.00107747 0.00184534 0.00206727 0.00262227 0.00208322
 0.00205382]
Model epoch 393: train total loss -64.9374517813263, train mean loss 0.0009621581957291821, test mean loss [0.00114055 0.00109378 0.00182082 0.00203577 0.00260358 0.00204035
 0.00205271]
Model epoch 394: train total loss -64.93677122926293, train mean loss 0.0013082179164406985, test mean loss [0.00113514 0.00106501 0.00183654 0.00204831 0.00261375 0.00204371
 0.00204133]
Model epoch 395: train total loss -64.83558232839287, train mean loss 0.0010998982558963256, test mean loss [0.00114862 0.00107805 0.00184577 0.00206518 0.0026113  0.00206342
 0.00206733]
Model epoch 396: train total loss -64.90318625147236, train mean loss 0.0009489157106183845, test mean loss [0.0011339  0.00106572 0.00183028 0.00202828 0.00260355 0.00203227
 0.00202879]
Model epoch 397: train total loss -64.90840987310592, train mean loss 0.001042727246309045, test mean loss [0.001147   0.00106495 0.00182396 0.00207324 0.00260537 0.00202355
 0.0020231 ]
Model epoch 398: train total loss -64.90520034848292, train mean loss 0.0011429570614459822, test mean loss [0.00115204 0.00105646 0.00182638 0.0020169  0.00260134 0.00200099
 0.00200941]
Model epoch 399: train total loss -64.85396631767662, train mean loss 0.0010793527726933167, test mean loss [0.00112189 0.00107625 0.00177982 0.00202189 0.00256106 0.00202439
 0.00203071]
Model epoch 400: train total loss -64.75240074345751, train mean loss 0.0008059841115375481, test mean loss [0.00111734 0.00105682 0.0018038  0.00203461 0.00257634 0.00202424
 0.00201592]
Model epoch 401: train total loss -64.83293821270155, train mean loss 0.001064334902154976, test mean loss [0.0010937  0.00103965 0.00181322 0.0019961  0.00255984 0.00202114
 0.00202857]
Model epoch 402: train total loss -64.82501056468818, train mean loss 0.0008943003432254566, test mean loss [0.0011005  0.001046   0.00179177 0.00201526 0.00255401 0.00199738
 0.00202752]
Model epoch 403: train total loss -64.79703790944295, train mean loss 0.0008117105038905894, test mean loss [0.00113097 0.00106412 0.00176253 0.00202458 0.00260778 0.00201331
 0.00199072]
Model epoch 404: train total loss -64.9941265398082, train mean loss 0.0009023629379212942, test mean loss [0.00107874 0.00107013 0.00174782 0.00200602 0.00256168 0.00199474
 0.00199252]
Model epoch 405: train total loss -64.90087662641551, train mean loss 0.0009684671470215792, test mean loss [0.00110074 0.00107158 0.00176544 0.00201136 0.00251275 0.00196994
 0.00199172]
Model epoch 406: train total loss -65.08445734920471, train mean loss 0.0008409527421163908, test mean loss [0.00109823 0.00103064 0.00179693 0.00194258 0.00253587 0.00195748
 0.00200251]
Model epoch 407: train total loss -64.9782341394169, train mean loss 0.0011599897228798768, test mean loss [0.00107584 0.00102714 0.00174012 0.00199047 0.00255461 0.0019691
 0.00198876]
Model epoch 408: train total loss -65.01896625548822, train mean loss 0.0007478936768271083, test mean loss [0.00106363 0.00103989 0.00174373 0.00195675 0.00251775 0.00198106
 0.00196249]
Model epoch 409: train total loss -64.60614475373285, train mean loss 0.0012238724537252195, test mean loss [0.00108667 0.00103045 0.00172726 0.00196097 0.00245111 0.00195039
 0.00197942]
Model epoch 410: train total loss -64.9341741614199, train mean loss 0.0007251455137136504, test mean loss [0.00104908 0.00102724 0.00171966 0.00194571 0.0024741  0.00193901
 0.00199561]
Model epoch 411: train total loss -64.99638888898201, train mean loss 0.0009943940793637994, test mean loss [0.00109747 0.00102189 0.00173544 0.00196491 0.00246519 0.00192245
 0.00196108]
Model epoch 412: train total loss -64.82961490128001, train mean loss 0.0019495873100640786, test mean loss [0.00105201 0.00100745 0.00173788 0.00197038 0.0024736  0.00189259
 0.00194612]
Model epoch 413: train total loss -64.89338121444952, train mean loss 0.0010322629012723963, test mean loss [0.00108438 0.00104596 0.00170036 0.00194513 0.00242926 0.0018986
 0.00196148]
Model epoch 414: train total loss -64.63134569530979, train mean loss 0.0009164705658830583, test mean loss [0.00109207 0.00100086 0.00172299 0.00200651 0.00243722 0.00190228
 0.0019851 ]
Model epoch 415: train total loss -64.7254299322314, train mean loss 0.0013686903732344823, test mean loss [0.00108019 0.0010204  0.00171597 0.00192158 0.00242247 0.00189518
 0.00194317]
Model epoch 416: train total loss -64.94558477782034, train mean loss 0.0010669076438594995, test mean loss [0.00108793 0.00102117 0.00177832 0.00195252 0.00241002 0.0019207
 0.0019597 ]
Model epoch 417: train total loss -64.83779287905153, train mean loss 0.0007538378415472792, test mean loss [0.00107502 0.0010051  0.00175458 0.00194198 0.00240191 0.0018936
 0.00195949]
Model epoch 418: train total loss -65.03736567562166, train mean loss 0.0012006427891303258, test mean loss [0.00107662 0.00101436 0.00173813 0.00191589 0.00237863 0.00187266
 0.00193037]
Model epoch 419: train total loss -64.6569044968484, train mean loss 0.0009758683342109176, test mean loss [0.0010607  0.00102496 0.00172414 0.0018993  0.00241224 0.00191162
 0.00193435]
Model epoch 420: train total loss -64.68230423291223, train mean loss 0.0010615871057387957, test mean loss [0.00105926 0.00098482 0.00170282 0.00188923 0.00238275 0.00189893
 0.00190877]
Model epoch 421: train total loss -64.93064120225796, train mean loss 0.0007756517290408179, test mean loss [0.00104138 0.00100178 0.00171482 0.00187535 0.00241816 0.0018633
 0.0019112 ]
Model epoch 422: train total loss -64.85059890573822, train mean loss 0.00098795869163868, test mean loss [0.00101645 0.00101238 0.00171866 0.00188344 0.00237052 0.00188081
 0.00190607]
Model epoch 423: train total loss -64.83565786792106, train mean loss 0.0005707352415566518, test mean loss [0.00101113 0.00104127 0.00168129 0.0019035  0.00234268 0.00187483
 0.00192295]
Model epoch 424: train total loss -64.72495958406981, train mean loss 0.0008464684209097221, test mean loss [0.0010069  0.00100231 0.00167017 0.00191441 0.00234559 0.00184742
 0.00189758]
Model epoch 425: train total loss -65.02536187552842, train mean loss 0.0009311179123662077, test mean loss [0.00102169 0.00103264 0.00166367 0.00186648 0.00236171 0.00186536
 0.00190674]
Model epoch 426: train total loss -64.88192010816843, train mean loss 0.0008613145795910945, test mean loss [0.00102839 0.00101117 0.00166877 0.00186956 0.00232259 0.00185382
 0.00193743]
Model epoch 427: train total loss -64.94553703539802, train mean loss 0.0006866711307832327, test mean loss [0.00105092 0.00099187 0.0016319  0.00184855 0.00240978 0.00185322
 0.00191007]
Model epoch 428: train total loss -64.90446747706619, train mean loss 0.0010919032222206314, test mean loss [0.00103123 0.00097711 0.00163121 0.00183431 0.00235111 0.00182515
 0.00188883]
Model epoch 429: train total loss -65.07321921232047, train mean loss 0.0008764550199019422, test mean loss [0.001017   0.00098868 0.00162141 0.00184106 0.00235313 0.00182342
 0.00190234]
Model epoch 430: train total loss -64.8395721619889, train mean loss 0.000991819817251819, test mean loss [0.00101987 0.00098758 0.00163523 0.00187254 0.00228536 0.00182773
 0.00189941]
Model epoch 431: train total loss -64.95236884750155, train mean loss 0.0011156275186214296, test mean loss [0.0009991  0.00099562 0.00163344 0.00183128 0.00233895 0.00179491
 0.00187998]
Model epoch 432: train total loss -64.90707975502394, train mean loss 0.0009665250966911471, test mean loss [0.0009864  0.00098696 0.00166505 0.00186626 0.0023051  0.00177896
 0.00187504]
Model epoch 433: train total loss -65.00975670954841, train mean loss 0.0010114016069916792, test mean loss [0.00099917 0.00097931 0.00159015 0.00180931 0.0022933  0.00178511
 0.00188242]
Model epoch 434: train total loss -64.971630750386, train mean loss 0.0006873143161414672, test mean loss [0.00099977 0.00099397 0.00163476 0.00184143 0.00224454 0.00181717
 0.00186165]
Model epoch 435: train total loss -64.90434082241406, train mean loss 0.0010440269390133386, test mean loss [0.00096867 0.00095357 0.00162705 0.0018519  0.00225553 0.00177269
 0.00193526]
Model epoch 436: train total loss -64.68037998215023, train mean loss 0.0009909478976697517, test mean loss [0.00097562 0.00094418 0.00163568 0.00183574 0.00228831 0.00177884
 0.00188816]
Model epoch 437: train total loss -64.45944075558893, train mean loss 0.0008494318104161958, test mean loss [0.00095898 0.0009907  0.00217701 0.00183373 0.00227202 0.00176533
 0.00188357]
Model epoch 438: train total loss -65.0833562112553, train mean loss 0.0009028610493101924, test mean loss [0.00098656 0.00095395 0.00170418 0.00180908 0.00221773 0.00173538
 0.00183414]
Model epoch 439: train total loss -65.0977309617686, train mean loss 0.0012320375294998778, test mean loss [0.00098417 0.00101627 0.00162978 0.00181461 0.00225039 0.00175134
 0.0018699 ]
Model epoch 440: train total loss -65.1196803008472, train mean loss 0.001199202292333045, test mean loss [0.00097138 0.00097231 0.00161271 0.00183698 0.00225223 0.00176338
 0.00186619]
Model epoch 441: train total loss -64.80009674214224, train mean loss 0.0011262456865576585, test mean loss [0.00095339 0.00096566 0.00160202 0.0018338  0.00222637 0.00174559
 0.001864  ]
Model epoch 442: train total loss -64.8441952841119, train mean loss 0.00041879791142706435, test mean loss [0.00097346 0.00096272 0.0015799  0.0018255  0.00219216 0.0017432
 0.00185453]
Model epoch 443: train total loss -64.70456383542715, train mean loss 0.0007578307929798189, test mean loss [0.00094391 0.00094668 0.00158367 0.00179819 0.00220192 0.00173411
 0.00184049]
Model epoch 444: train total loss -64.87425790890384, train mean loss 0.0012293238023766075, test mean loss [0.00097164 0.00095258 0.00157284 0.00180894 0.00217416 0.00172412
 0.00183237]
Model epoch 445: train total loss -64.96961964644336, train mean loss 0.0006641945352792226, test mean loss [0.00095987 0.00095222 0.00154604 0.00179711 0.00218928 0.00172787
 0.00183316]
Model epoch 446: train total loss -65.10838318349658, train mean loss 0.001143273903300578, test mean loss [0.00095154 0.00095537 0.00156346 0.0017789  0.00215487 0.00168379
 0.00181176]
Model epoch 447: train total loss -65.11592527908068, train mean loss 0.0009425215254502818, test mean loss [0.00095537 0.00095755 0.00155259 0.00180996 0.00221014 0.00174516
 0.00179385]
Model epoch 448: train total loss -64.65071429288875, train mean loss 0.001073162090683259, test mean loss [0.00092724 0.00093337 0.00153769 0.00180406 0.00218092 0.00169965
 0.00182531]
Model epoch 449: train total loss -64.90895869537881, train mean loss 0.0010487367816655888, test mean loss [0.00096945 0.00094867 0.00152622 0.00179916 0.00213632 0.00167938
 0.00182917]
Model epoch 450: train total loss -65.05622022675716, train mean loss 0.0009388505963462067, test mean loss [0.00095278 0.0009608  0.00155514 0.0017744  0.00211228 0.00171402
 0.00178757]
Model epoch 451: train total loss -64.93201841909402, train mean loss 0.0009207976109378196, test mean loss [0.0009363  0.00092654 0.00152163 0.00177588 0.00215027 0.00170046
 0.00180206]
Model epoch 452: train total loss -65.02251568735095, train mean loss 0.0007083662880410287, test mean loss [0.00092768 0.00097526 0.00151687 0.0018037  0.00214256 0.00166153
 0.00181429]
Model epoch 453: train total loss -64.89203778509585, train mean loss 0.001005252678322521, test mean loss [0.00093311 0.00095531 0.00149899 0.00177705 0.00210383 0.00166652
 0.00178687]
Model epoch 454: train total loss -65.0796042502796, train mean loss 0.0009638509164600296, test mean loss [0.00096369 0.00092437 0.00150158 0.00180225 0.00211521 0.00166754
 0.00181555]
Model epoch 455: train total loss -65.08462055624973, train mean loss 0.0007208280250459165, test mean loss [0.00093176 0.00093003 0.00150449 0.00175679 0.00209239 0.00168316
 0.00178141]
Model epoch 456: train total loss -65.2173991919299, train mean loss 0.0006629664253188461, test mean loss [0.00091752 0.00094739 0.00148626 0.00175103 0.00207708 0.00165451
 0.00178117]
Model epoch 457: train total loss -65.08518705942727, train mean loss 0.0007341003488899802, test mean loss [0.00090804 0.00092939 0.0014847  0.00174945 0.00208663 0.00168888
 0.00177642]
Model epoch 458: train total loss -65.25506421048632, train mean loss 0.0007597085947011155, test mean loss [0.00092627 0.00093559 0.00146473 0.00172151 0.00212156 0.00162315
 0.00176221]
Model epoch 459: train total loss -65.0381304220646, train mean loss 0.0006666241268678716, test mean loss [0.00092016 0.00091165 0.00146502 0.00172427 0.0020589  0.00172022
 0.00178366]
Model epoch 460: train total loss -65.03972666314968, train mean loss 0.0007257964536275021, test mean loss [0.0009312  0.00094075 0.00144629 0.00171886 0.00210287 0.00164072
 0.00175402]
Model epoch 461: train total loss -64.97522609993173, train mean loss 0.0007412336762242211, test mean loss [0.00088735 0.0009166  0.00145668 0.0017297  0.00205578 0.00165807
 0.00177909]
Model epoch 462: train total loss -64.9112635551048, train mean loss 0.0008166999648051849, test mean loss [0.00088883 0.00089367 0.00146036 0.00171987 0.00204509 0.00164456
 0.00172076]
Model epoch 463: train total loss -64.80356212567729, train mean loss 0.0010037326132744948, test mean loss [0.0009157  0.00090815 0.00145246 0.00172848 0.00202538 0.00164031
 0.00177411]
Model epoch 464: train total loss -64.98028187056904, train mean loss 0.0009593873431196855, test mean loss [0.00089338 0.00090819 0.00146618 0.0016943  0.00203983 0.00161281
 0.00175493]
Model epoch 465: train total loss -65.16292981835618, train mean loss 0.0005934298901958221, test mean loss [0.00086298 0.00089182 0.00144664 0.0017168  0.00203552 0.00162664
 0.00173973]
Model epoch 466: train total loss -65.24609784583893, train mean loss 0.0008883709781695365, test mean loss [0.00088098 0.00092089 0.0014473  0.00168635 0.00200552 0.00158793
 0.00173692]
Model epoch 467: train total loss -65.10845540049888, train mean loss 0.0007310619852142257, test mean loss [0.00091002 0.00097626 0.00144103 0.00169695 0.00204057 0.00162533
 0.00172322]
Model epoch 468: train total loss -64.89944095089852, train mean loss 0.0009771338022290313, test mean loss [0.00090288 0.00091669 0.00143713 0.00170523 0.00202418 0.00162736
 0.00173273]
Model epoch 469: train total loss -64.98405847640366, train mean loss 0.0010802084319542354, test mean loss [0.00089815 0.00091072 0.00141466 0.00170108 0.00199833 0.00160505
 0.00174228]
Model epoch 470: train total loss -65.22266516722036, train mean loss 0.0012171315146400552, test mean loss [0.0008872  0.00092701 0.0014027  0.00170101 0.00197773 0.0015886
 0.00167818]
Model epoch 471: train total loss -64.96159364895252, train mean loss 0.0007895570084924674, test mean loss [0.00086264 0.00091288 0.00140336 0.0016933  0.00196506 0.00159302
 0.00171271]
Model epoch 472: train total loss -64.83852345739783, train mean loss 0.0010691709833477345, test mean loss [0.00085314 0.00090224 0.00139099 0.00166792 0.00198609 0.00158305
 0.00171168]
Model epoch 473: train total loss -65.00033332094533, train mean loss 0.0007046289955817661, test mean loss [0.00087453 0.00089252 0.0014506  0.00165706 0.00205988 0.00158291
 0.00171721]
Model epoch 474: train total loss -65.07208385217744, train mean loss 0.0006668724010508264, test mean loss [0.00087249 0.00090686 0.00140784 0.00168719 0.00201151 0.00155465
 0.00171439]
Model epoch 475: train total loss -65.14442361638915, train mean loss 0.000992466952110641, test mean loss [0.00089073 0.00089881 0.00139271 0.00168745 0.00200453 0.00154505
 0.00167519]
Model epoch 476: train total loss -65.04452983904494, train mean loss 0.000909414840081234, test mean loss [0.00085898 0.00089876 0.0013896  0.00164967 0.00195635 0.0015437
 0.00169128]
Model epoch 477: train total loss -64.97955655264418, train mean loss 0.00120592509208867, test mean loss [0.0008788  0.00089943 0.00139876 0.00170818 0.00198474 0.00154939
 0.00170121]
Model epoch 478: train total loss -65.09960238910482, train mean loss 0.0008568083057228328, test mean loss [0.00088715 0.00089441 0.00140959 0.00167574 0.00194766 0.00152269
 0.00167895]
Model epoch 479: train total loss -64.85501453148937, train mean loss 0.0007904384742918812, test mean loss [0.00087454 0.00089015 0.00138511 0.00167406 0.00197205 0.00152331
 0.00171078]
Model epoch 480: train total loss -65.13519215757617, train mean loss 0.0008020360713697402, test mean loss [0.00087147 0.00087976 0.00139068 0.00165366 0.00192926 0.00154043
 0.00169075]
Model epoch 481: train total loss -64.75979636967207, train mean loss 0.0009033295614905788, test mean loss [0.00086117 0.00087427 0.00137529 0.00167769 0.00194583 0.0015273
 0.00166487]
Model epoch 482: train total loss -65.10947685679888, train mean loss 0.0005626720283081461, test mean loss [0.00084883 0.00089109 0.00139343 0.00165834 0.00193873 0.001493
 0.00168037]
Model epoch 483: train total loss -64.94944053904452, train mean loss 0.0008942960205854243, test mean loss [0.00082697 0.00087228 0.00137284 0.00165794 0.00195848 0.00153419
 0.00208219]
Model epoch 484: train total loss -65.22778884440297, train mean loss 0.0007265265100544991, test mean loss [0.00082748 0.00085808 0.00136651 0.0016278  0.00189874 0.00153901
 0.0024223 ]
Model epoch 485: train total loss -64.86229694524492, train mean loss 0.0008907249863027749, test mean loss [0.00085473 0.00085573 0.00135256 0.00164986 0.00196276 0.00152184
 0.00212747]
Model epoch 486: train total loss -64.9040833071156, train mean loss 0.0008151777997821002, test mean loss [0.00083447 0.00085291 0.00137239 0.00164805 0.00190738 0.00148931
 0.00199288]
Model epoch 487: train total loss -65.11800759902764, train mean loss 0.000848854876513917, test mean loss [0.00084083 0.0008657  0.00134944 0.00162672 0.00190333 0.00146095
 0.00185032]
Model epoch 488: train total loss -65.02271247087867, train mean loss 0.0005106631297962003, test mean loss [0.00085172 0.00088666 0.0013254  0.00167279 0.00189549 0.0015031
 0.00177194]
Model epoch 489: train total loss -64.75603893673131, train mean loss 0.0012460042874736744, test mean loss [0.00082102 0.00085714 0.0013643  0.00165081 0.00187294 0.00149495
 0.00170646]
Model epoch 490: train total loss -65.05650239672568, train mean loss 0.0008359389888145546, test mean loss [0.00083011 0.00085188 0.00133821 0.00160311 0.00188022 0.00148387
 0.00170367]
Model epoch 491: train total loss -65.04901293048502, train mean loss 0.0008100711908110523, test mean loss [0.00083351 0.00083599 0.00131816 0.00161203 0.00192428 0.00148294
 0.00171523]
Model epoch 492: train total loss -65.01130343634738, train mean loss 0.0010228493055388307, test mean loss [0.00084346 0.00086043 0.00132928 0.00162785 0.00188513 0.00150036
 0.00171019]
Model epoch 493: train total loss -65.09892988111258, train mean loss 0.0010008290492615338, test mean loss [0.00084296 0.00086523 0.00133233 0.00157531 0.00188784 0.00147194
 0.00168801]
Model epoch 494: train total loss -64.76471224031933, train mean loss 0.0009530990643763539, test mean loss [0.00083238 0.00087341 0.0013068  0.00159499 0.00186791 0.00148251
 0.00165884]
Model epoch 495: train total loss -64.8814094108306, train mean loss 0.0006887037705840634, test mean loss [0.00083258 0.00088969 0.00132613 0.00160438 0.00186506 0.00147288
 0.00166113]
Model epoch 496: train total loss -65.14868335059316, train mean loss 0.0007365335506258238, test mean loss [0.00083366 0.00084532 0.00129468 0.00159131 0.00185353 0.00144576
 0.00164717]
Model epoch 497: train total loss -65.05122231848979, train mean loss 0.0005579489454375198, test mean loss [0.0008227  0.00087205 0.00129564 0.00158843 0.00184407 0.00147625
 0.00165943]
Model epoch 498: train total loss -65.16615231630199, train mean loss 0.0008234378808309607, test mean loss [0.00082765 0.00084729 0.00127435 0.00157814 0.00182994 0.00143608
 0.00164701]
Model epoch 499: train total loss -64.95847045849571, train mean loss 0.0008211106340561934, test mean loss [0.00082363 0.00083626 0.00128678 0.00157679 0.00180925 0.00142085
 0.00163789]
Model epoch 500: train total loss -65.07884891589214, train mean loss 0.0009360043371489837, test mean loss [0.00083769 0.00085971 0.00130484 0.00158924 0.00181985 0.00143045
 0.00161695]
Model epoch 501: train total loss -65.14610908928195, train mean loss 0.0010541544428832829, test mean loss [0.00081869 0.00086982 0.00129344 0.00156774 0.00180789 0.00143619
 0.00164563]
Model epoch 502: train total loss -65.10939962139182, train mean loss 0.0008372484706284831, test mean loss [0.00083396 0.0008322  0.00125893 0.00156453 0.00185008 0.0014352
 0.0017611 ]
Model epoch 503: train total loss -65.1304478634746, train mean loss 0.0007156140893333734, test mean loss [0.0008212  0.00083985 0.00130681 0.00155372 0.00181062 0.00142064
 0.0016472 ]
Model epoch 504: train total loss -65.0956440042144, train mean loss 0.00051575331174326, test mean loss [0.00081529 0.00081939 0.00126598 0.0015512  0.00178277 0.00143175
 0.0016131 ]
Model epoch 505: train total loss -65.29752953482816, train mean loss 0.000686640924656731, test mean loss [0.00079888 0.00084783 0.00127207 0.00155201 0.00177828 0.00141612
 0.00160097]
Model epoch 506: train total loss -64.93764642573181, train mean loss 0.0006946289823107048, test mean loss [0.00081233 0.00095003 0.00129207 0.00156827 0.00178761 0.00141247
 0.00159863]
Model epoch 507: train total loss -64.92267080321905, train mean loss 0.000840671711179148, test mean loss [0.00083987 0.00109076 0.00126358 0.00154795 0.00178932 0.00140322
 0.00156943]
Model epoch 508: train total loss -65.09759654040884, train mean loss 0.0006238179235388821, test mean loss [0.00079301 0.00085415 0.00125529 0.0015353  0.00179014 0.00138882
 0.0015846 ]
Model epoch 509: train total loss -65.31186948567054, train mean loss 0.000817409227377644, test mean loss [0.00080212 0.00080074 0.00122989 0.00153637 0.00176831 0.00140117
 0.00157264]
Model epoch 510: train total loss -65.23426306521118, train mean loss 0.0007230723448131584, test mean loss [0.00080662 0.00083906 0.00122457 0.00152275 0.00176408 0.00139318
 0.00160086]
Model epoch 511: train total loss -64.96137273926698, train mean loss 0.0009500216415012867, test mean loss [0.00081678 0.00081347 0.00123574 0.00150981 0.00182569 0.00138905
 0.00157763]
Model epoch 512: train total loss -65.11906904509355, train mean loss 0.000493115623073663, test mean loss [0.00082954 0.00080541 0.00124055 0.00154696 0.00183556 0.00138955
 0.00156982]
Model epoch 513: train total loss -65.0428690124496, train mean loss 0.000647140359399155, test mean loss [0.00081523 0.00079306 0.00125427 0.00149727 0.00181674 0.00139516
 0.00159353]
Model epoch 514: train total loss -65.14108615067936, train mean loss 0.000591939022577868, test mean loss [0.00079901 0.00083491 0.00123075 0.00150286 0.00179664 0.0013793
 0.0016317 ]
Model epoch 515: train total loss -65.07325604512548, train mean loss 0.0009252044702709697, test mean loss [0.00079868 0.00082403 0.00122568 0.00148607 0.00179483 0.00138922
 0.00158082]
Model epoch 516: train total loss -65.22471468781067, train mean loss 0.0006997041541282195, test mean loss [0.00081178 0.00082447 0.00122378 0.00152429 0.00179976 0.00136061
 0.0015536 ]
Model epoch 517: train total loss -65.2489791259761, train mean loss 0.00072214124235461, test mean loss [0.0008161  0.00080957 0.00121094 0.00151118 0.001778   0.00134887
 0.00152644]
Model epoch 518: train total loss -64.76535355215229, train mean loss 0.0010174797549868484, test mean loss [0.00079718 0.00081399 0.0012523  0.00151971 0.0017685  0.00136161
 0.00153622]
Model epoch 519: train total loss -64.93727769549429, train mean loss 0.00039644078088206313, test mean loss [0.00076707 0.00080342 0.00121267 0.00146943 0.0017432  0.001353
 0.00159164]
Model epoch 520: train total loss -65.31020847176559, train mean loss 0.0009132734241172449, test mean loss [0.00078843 0.00080627 0.001195   0.00148955 0.00173602 0.00133977
 0.00154598]
Model epoch 521: train total loss -65.10850944798719, train mean loss 0.000658472801157726, test mean loss [0.0007667  0.00081267 0.00119693 0.00148045 0.00174165 0.00133807
 0.00151017]
Model epoch 522: train total loss -65.19558451227583, train mean loss 0.0006465495039201487, test mean loss [0.00091391 0.00081664 0.00118561 0.00152152 0.00171832 0.00135659
 0.00153635]
Model epoch 523: train total loss -65.23188507231592, train mean loss 0.0006362760115001001, test mean loss [0.0010015  0.00078772 0.00119486 0.00149768 0.00169004 0.00133509
 0.00154027]
Model epoch 524: train total loss -65.12228887140866, train mean loss 0.0009034371862495864, test mean loss [0.00087907 0.00078725 0.00120319 0.00148883 0.00170785 0.00134137
 0.00150765]
Model epoch 525: train total loss -64.99073931396707, train mean loss 0.0010118079625482375, test mean loss [0.00082912 0.00077744 0.00117399 0.00148706 0.00169453 0.00133638
 0.00149961]
Model epoch 526: train total loss -65.25393946544752, train mean loss 0.0006480352716963277, test mean loss [0.00081021 0.0007622  0.00117749 0.00146274 0.00168525 0.00133199
 0.00150593]
Model epoch 527: train total loss -65.03672337675621, train mean loss 0.0008362527475068963, test mean loss [0.00080576 0.00077394 0.00115369 0.00145052 0.00168997 0.0013339
 0.0014953 ]
Model epoch 528: train total loss -64.9875787576895, train mean loss 0.0006638187116286789, test mean loss [0.00078807 0.00084117 0.00115644 0.00147229 0.00169072 0.0013127
 0.0015001 ]
Model epoch 529: train total loss -65.0963679490445, train mean loss 0.0006265327801341365, test mean loss [0.00076828 0.00076674 0.00119558 0.00144099 0.0016774  0.00129607
 0.00146573]
Model epoch 530: train total loss -65.18651748528127, train mean loss 0.0009253177179271245, test mean loss [0.00076274 0.00078134 0.00119672 0.00144679 0.00165667 0.0013162
 0.00148397]
Model epoch 531: train total loss -65.191147737403, train mean loss 0.0006066042295073339, test mean loss [0.00075549 0.0007888  0.00114372 0.00144269 0.00166612 0.00132362
 0.0014678 ]
Model epoch 532: train total loss -65.2458937677368, train mean loss 0.0006432419665387577, test mean loss [0.00076513 0.00076734 0.00116488 0.00145424 0.00166765 0.00129142
 0.0015065 ]
Model epoch 533: train total loss -65.2851174197787, train mean loss 0.00044175196717169076, test mean loss [0.00075746 0.00076384 0.00114406 0.00146188 0.00166674 0.00130393
 0.00147362]
Model epoch 534: train total loss -65.30999258798148, train mean loss 0.0005224275139767506, test mean loss [0.00076674 0.00078292 0.00114975 0.0014252  0.00164633 0.00132835
 0.00146785]
Model epoch 535: train total loss -65.0864367706004, train mean loss 0.0005811510559195577, test mean loss [0.00095733 0.00078363 0.00113439 0.00144906 0.00164385 0.00131522
 0.00144824]
Model epoch 536: train total loss -64.98368798474, train mean loss 0.0010368961940174293, test mean loss [0.00079305 0.00077107 0.00111683 0.00144933 0.00165234 0.00129679
 0.00147589]
Model epoch 537: train total loss -65.1496858372466, train mean loss 0.0006245370021637727, test mean loss [0.00076764 0.00081772 0.0011296  0.00142134 0.0016431  0.00128613
 0.00144423]
Model epoch 538: train total loss -65.17566138861861, train mean loss 0.0006953477141915868, test mean loss [0.00077348 0.0007864  0.00113167 0.00142938 0.00166367 0.00129036
 0.00144415]
Model epoch 539: train total loss -65.32459339382879, train mean loss 0.0004950157075669072, test mean loss [0.00074989 0.00075809 0.00114822 0.00143624 0.00160255 0.00130561
 0.0014743 ]
Model epoch 540: train total loss -65.00077940038456, train mean loss 0.000666751005606782, test mean loss [0.00072728 0.00077611 0.00112319 0.0014059  0.00161337 0.00129176
 0.00143333]
Model epoch 541: train total loss -65.15487197115223, train mean loss 0.0007735540597440764, test mean loss [0.00075625 0.00077455 0.00111766 0.00140459 0.00161175 0.00127214
 0.00144   ]
Model epoch 542: train total loss -65.19769611246984, train mean loss 0.0005689754824146192, test mean loss [0.00073213 0.00076027 0.00111264 0.00140274 0.00158744 0.00126087
 0.00144581]
Model epoch 543: train total loss -65.30558697327723, train mean loss 0.0003927288700612647, test mean loss [0.00074195 0.0007368  0.00115631 0.00142182 0.00158246 0.00125221
 0.00143622]
Model epoch 544: train total loss -65.27165356456238, train mean loss 0.0008241069189509728, test mean loss [0.00072675 0.00075874 0.00112498 0.00139776 0.0016066  0.00124966
 0.00141767]
Model epoch 545: train total loss -65.4860489151271, train mean loss 0.0005893881153127351, test mean loss [0.00073664 0.0007512  0.00113142 0.00137894 0.00158971 0.00125087
 0.00141975]
Model epoch 546: train total loss -65.3062525459063, train mean loss 0.0006108056144075287, test mean loss [0.00070292 0.00075868 0.00109732 0.00140468 0.00157756 0.00126887
 0.001419  ]
Model epoch 547: train total loss -65.0852302273788, train mean loss 0.0005333125847058728, test mean loss [0.00076239 0.00076369 0.00111053 0.0013701  0.00157038 0.00124095
 0.00140256]
Model epoch 548: train total loss -65.0700064051958, train mean loss 0.0007164814888190935, test mean loss [0.00072031 0.00075779 0.00111836 0.00141222 0.00156025 0.00123703
 0.00142613]
Model epoch 549: train total loss -65.5440051933209, train mean loss 0.0005841036488496912, test mean loss [0.00071784 0.00079188 0.00109639 0.00139732 0.00153496 0.00127501
 0.00144329]
Model epoch 550: train total loss -65.16145963337367, train mean loss 0.0007597924572739243, test mean loss [0.00072346 0.00076955 0.00108304 0.00139934 0.00156563 0.00126606
 0.00140348]
Model epoch 551: train total loss -65.38918893890798, train mean loss 0.0005220940080458493, test mean loss [0.00072968 0.00072535 0.00111343 0.00138205 0.00155758 0.00122196
 0.00140634]
Model epoch 552: train total loss -65.08071687768268, train mean loss 0.0006461927197705981, test mean loss [0.00070456 0.00073745 0.00108163 0.00138988 0.00155783 0.00123014
 0.00142678]
Model epoch 553: train total loss -65.30123441576184, train mean loss 0.000958123520393706, test mean loss [0.00072161 0.00072656 0.00106903 0.0013472  0.00156004 0.00121252
 0.00139112]
Model epoch 554: train total loss -65.4389310904765, train mean loss 0.0007685407112061816, test mean loss [0.00073212 0.00071952 0.00109048 0.00138055 0.00152512 0.00126062
 0.00141189]
Model epoch 555: train total loss -65.50667517966099, train mean loss 0.00040956209320242183, test mean loss [0.00072418 0.00071148 0.00109732 0.00138977 0.00151569 0.00124543
 0.00142184]
Model epoch 556: train total loss -65.63343290310642, train mean loss 0.0004817816926551708, test mean loss [0.00069951 0.00071964 0.0011099  0.00135515 0.00154389 0.00125085
 0.00138834]
Model epoch 557: train total loss -65.52765944000019, train mean loss 0.0005399835037299062, test mean loss [0.00072696 0.00073103 0.00108822 0.0013643  0.00152841 0.00124213
 0.00138946]
Model epoch 558: train total loss -65.27531681521104, train mean loss 0.0007038745378379295, test mean loss [0.00072813 0.00073009 0.00105673 0.00145162 0.00152764 0.00123538
 0.00138415]
Model epoch 559: train total loss -65.36444375946222, train mean loss 0.0004922278934744847, test mean loss [0.00071262 0.00071425 0.00105837 0.00135027 0.00151568 0.0012058
 0.00139065]
Model epoch 560: train total loss -65.42660546296283, train mean loss 0.000512794107463879, test mean loss [0.00071747 0.00072215 0.00107244 0.00136844 0.00155916 0.00121477
 0.00139135]
Model epoch 561: train total loss -65.38266172454529, train mean loss 0.0006820351493900833, test mean loss [0.00068915 0.00073579 0.0010807  0.00134164 0.00152309 0.00121919
 0.00141741]
Model epoch 562: train total loss -65.39740538471516, train mean loss 0.0004826253974949948, test mean loss [0.00071168 0.000731   0.00104818 0.00136312 0.00149636 0.00124465
 0.00139293]
Model epoch 563: train total loss -65.1356462039896, train mean loss 0.0005452298550368007, test mean loss [0.00070228 0.00071308 0.00108531 0.00137272 0.00148678 0.0011868
 0.00138395]
Model epoch 564: train total loss -65.21251621120186, train mean loss 0.0007565117235003591, test mean loss [0.0006995  0.00071103 0.00107203 0.00137741 0.00150419 0.00118639
 0.00139452]
Model epoch 565: train total loss -65.2453172944005, train mean loss 0.0005823020547490879, test mean loss [0.00070155 0.00071147 0.00104841 0.00133472 0.00146425 0.0011912
 0.00136005]
Model epoch 566: train total loss -65.16875026948219, train mean loss 0.0008708655709040831, test mean loss [0.00069461 0.0007252  0.00104636 0.0013192  0.00149615 0.00119101
 0.00137727]
Model epoch 567: train total loss -65.15690793044696, train mean loss 0.0009028538679830874, test mean loss [0.00071418 0.00072436 0.00104126 0.00134634 0.00148895 0.00117919
 0.00136244]
Model epoch 568: train total loss -65.64874488906958, train mean loss 0.0004919261561156355, test mean loss [0.00072282 0.00072305 0.00103724 0.00133837 0.00148016 0.00118919
 0.00136497]
Model epoch 569: train total loss -65.24371330468227, train mean loss 0.0006318826537430241, test mean loss [0.00076446 0.00071667 0.00103763 0.00136443 0.00144029 0.00115849
 0.00136844]
Model epoch 570: train total loss -65.11121892967913, train mean loss 0.0007199554201303888, test mean loss [0.00071601 0.00070556 0.00103738 0.00135192 0.00143829 0.00117567
 0.00132298]
Model epoch 571: train total loss -64.93355883796906, train mean loss 0.0006602304337058022, test mean loss [0.00068921 0.00073868 0.00102683 0.00136824 0.00143733 0.0011608
 0.00135816]
Model epoch 572: train total loss -65.32546921764151, train mean loss 0.0007340926578332079, test mean loss [0.00069715 0.0007308  0.00101416 0.00134426 0.00145477 0.0011616
 0.0013523 ]
Model epoch 573: train total loss -65.24515819578944, train mean loss 0.00045291006229043334, test mean loss [0.00069781 0.0007359  0.00104076 0.00130843 0.0014504  0.00115628
 0.00134829]
Model epoch 574: train total loss -65.38120749143866, train mean loss 0.0003615014607116362, test mean loss [0.0006834  0.00070302 0.00103923 0.00132477 0.00145466 0.00116321
 0.00133471]
Model epoch 575: train total loss -65.16160040036989, train mean loss 0.0012017781762417043, test mean loss [0.00069277 0.0007056  0.0010144  0.00131137 0.00142061 0.00114368
 0.00133121]
Model epoch 576: train total loss -65.26319418942676, train mean loss 0.0008128174322635662, test mean loss [0.00069736 0.00074165 0.001048   0.00132967 0.00142489 0.00113333
 0.00131612]
Model epoch 577: train total loss -65.16547508523924, train mean loss 0.0004743071941222329, test mean loss [0.00068415 0.00071262 0.00102464 0.00132226 0.00142879 0.00113265
 0.00129347]
Model epoch 578: train total loss -65.42977440307372, train mean loss 0.0006920127649530995, test mean loss [0.00069249 0.00070505 0.00100979 0.00129816 0.00142304 0.00114165
 0.00132345]
Model epoch 579: train total loss -65.35895925326165, train mean loss 0.000509644035866927, test mean loss [0.00068591 0.00069749 0.00101084 0.00127802 0.00140402 0.00113531
 0.00133226]
Model epoch 580: train total loss -65.58140180848451, train mean loss 0.0009356392270327844, test mean loss [0.00068655 0.00071512 0.00101805 0.00129199 0.00139805 0.00112668
 0.00131544]
Model epoch 581: train total loss -65.42841368193284, train mean loss 0.0004729395586143754, test mean loss [0.00067898 0.00073664 0.00102225 0.00130041 0.00143557 0.0011281
 0.00130762]
Model epoch 582: train total loss -65.2328345990986, train mean loss 0.0003884823602485837, test mean loss [0.0007019  0.0006973  0.00100304 0.00126522 0.00140739 0.00114093
 0.00130362]
Model epoch 583: train total loss -65.37213900831219, train mean loss 0.0007531169474029287, test mean loss [0.00068794 0.0007009  0.00102171 0.00127545 0.00138943 0.00113669
 0.00132688]
Model epoch 584: train total loss -65.38327171132534, train mean loss 0.0006292446691007838, test mean loss [0.00068999 0.00069128 0.0010059  0.0012528  0.0013928  0.00115295
 0.00132111]
Model epoch 585: train total loss -65.35083233035859, train mean loss 0.0007171328849884481, test mean loss [0.00067691 0.00067108 0.00101038 0.00127976 0.00139876 0.00111142
 0.00127699]
Model epoch 586: train total loss -65.41511995901982, train mean loss 0.000617539443663669, test mean loss [0.00068582 0.0006693  0.00101994 0.00126453 0.00139745 0.00112448
 0.00128588]
Model epoch 587: train total loss -65.2719299521295, train mean loss 0.0007422297569136271, test mean loss [0.00067071 0.00070263 0.00100882 0.00125185 0.00140324 0.00114953
 0.00129985]
Model epoch 588: train total loss -65.53450514392192, train mean loss 0.000689090164215917, test mean loss [0.00066645 0.00066372 0.00098242 0.0012323  0.00137492 0.00110173
 0.00132921]
Model epoch 589: train total loss -65.27958077139087, train mean loss 0.0005896249624531397, test mean loss [0.00066558 0.00069394 0.00100533 0.00124357 0.00135274 0.00111655
 0.00132269]
Model epoch 590: train total loss -65.27701636418703, train mean loss 0.000519447730236454, test mean loss [0.00071129 0.00066062 0.00097518 0.00126035 0.00137644 0.0011108
 0.00127789]
Model epoch 591: train total loss -65.32559972028723, train mean loss 0.0005258186678735758, test mean loss [0.00066816 0.00068465 0.00100288 0.00125039 0.00143162 0.00108126
 0.00125814]
Model epoch 592: train total loss -65.51195577522594, train mean loss 0.0005680301284666123, test mean loss [0.0006644  0.00071343 0.00098031 0.00123861 0.00138121 0.00111157
 0.00127153]
Model epoch 593: train total loss -65.55800877870165, train mean loss 0.0005838459120362421, test mean loss [0.0006824  0.00068871 0.00097748 0.0012558  0.00140031 0.0010765
 0.00124885]
Model epoch 594: train total loss -65.43938888246014, train mean loss 0.00045323846473423093, test mean loss [0.00066651 0.00066254 0.00098584 0.0012344  0.00138567 0.00106193
 0.00124339]
Model epoch 595: train total loss -65.37321851404775, train mean loss 0.0005055174604326201, test mean loss [0.0006787  0.000674   0.00096517 0.00124272 0.00134656 0.00109955
 0.00126009]
Model epoch 596: train total loss -65.42318003508402, train mean loss 0.0006423231164085513, test mean loss [0.00064434 0.00067173 0.00096622 0.00125163 0.00137758 0.00109773
 0.00126273]
Model epoch 597: train total loss -65.34648577510228, train mean loss 0.0003336214529230772, test mean loss [0.00066781 0.00066864 0.00097171 0.00123212 0.00134451 0.00109301
 0.00125737]
Model epoch 598: train total loss -65.53926367895215, train mean loss 0.0006127463267974073, test mean loss [0.00066952 0.00067409 0.00095154 0.00121659 0.00132574 0.00104567
 0.00126122]
Model epoch 599: train total loss -65.64879853996982, train mean loss 0.0004961654559262301, test mean loss [0.00065776 0.00065252 0.00094921 0.00122194 0.00134877 0.001071
 0.00125894]
Model epoch 600: train total loss -65.4329198276282, train mean loss 0.000641653565335815, test mean loss [0.00066128 0.00067236 0.00094419 0.00123339 0.00131907 0.00105369
 0.00123313]
Model epoch 601: train total loss -65.29785152971235, train mean loss 0.0005638577634774441, test mean loss [0.00065871 0.00069213 0.00097095 0.00122293 0.00132052 0.00107511
 0.00124458]
Model epoch 602: train total loss -65.32860638898921, train mean loss 0.0005552062244465319, test mean loss [0.00064647 0.00064518 0.0009528  0.00120021 0.00132533 0.00104739
 0.00124723]
Model epoch 603: train total loss -65.35212703456291, train mean loss 0.0007337151840217484, test mean loss [0.00064622 0.00067233 0.00093991 0.00120903 0.00133424 0.0010733
 0.00125142]
Model epoch 604: train total loss -65.36259759998805, train mean loss 0.0007810246914512464, test mean loss [0.00064682 0.00068376 0.0009418  0.00123251 0.00133625 0.00107363
 0.00127575]
Model epoch 605: train total loss -65.3142692051308, train mean loss 0.0005362053173042175, test mean loss [0.00064686 0.00066071 0.00097253 0.00118808 0.00131056 0.0010597
 0.00125644]
Model epoch 606: train total loss -65.31571437796555, train mean loss 0.0003738887454336712, test mean loss [0.00065282 0.00065664 0.00092877 0.00120586 0.0013546  0.00106043
 0.00122047]
Model epoch 607: train total loss -65.38525661976271, train mean loss 0.0005519545375801151, test mean loss [0.00065177 0.00063088 0.0009202  0.00121561 0.00132833 0.00105546
 0.00121893]
Model epoch 608: train total loss -65.54969295051028, train mean loss 0.0003575455653742199, test mean loss [0.00064576 0.00069368 0.0009442  0.00118208 0.00133728 0.00104317
 0.00122263]
Model epoch 609: train total loss -65.45858481264183, train mean loss 0.0005341233256749829, test mean loss [0.00065238 0.00065926 0.00096287 0.00121016 0.00131811 0.00103689
 0.00121599]
Model epoch 610: train total loss -65.36524828027126, train mean loss 0.0006364126456832778, test mean loss [0.00064206 0.00067785 0.0009736  0.00116515 0.00134693 0.00104432
 0.0012368 ]
Model epoch 611: train total loss -65.11390957833699, train mean loss 0.00041610466223942236, test mean loss [0.00063362 0.00064532 0.00096232 0.00117489 0.00132224 0.00103404
 0.00122573]
Model epoch 612: train total loss -65.54172603327585, train mean loss 0.0005293778667834814, test mean loss [0.0006313  0.00066034 0.00093342 0.00116572 0.00130716 0.00105483
 0.00119686]
Model epoch 613: train total loss -65.39130473883411, train mean loss 0.0006193186240626565, test mean loss [0.00063403 0.00067309 0.00093536 0.00117083 0.00128804 0.00101799
 0.0012268 ]
Model epoch 614: train total loss -65.1997919937206, train mean loss 0.0005439532694749996, test mean loss [0.00067838 0.00065479 0.00093642 0.00117415 0.00132183 0.00105186
 0.0011785 ]
Model epoch 615: train total loss -65.30625370105932, train mean loss 0.000512081399101355, test mean loss [0.00070127 0.00065565 0.00089299 0.00117411 0.00131923 0.00103173
 0.00121375]
Model epoch 616: train total loss -65.27754090289265, train mean loss 0.0005611988933499279, test mean loss [0.00065447 0.00064504 0.00091786 0.0011553  0.00127716 0.00105678
 0.00117603]
Model epoch 617: train total loss -65.32245268037647, train mean loss 0.0004011441980257935, test mean loss [0.00065042 0.00065106 0.0009325  0.00115905 0.00130401 0.00104479
 0.00119338]
Model epoch 618: train total loss -65.32652430616591, train mean loss 0.0006350725965420794, test mean loss [0.0006301  0.00065361 0.00093754 0.00114006 0.00129959 0.00103457
 0.00118218]
Model epoch 619: train total loss -65.27055619207194, train mean loss 0.00039409791079895534, test mean loss [0.00063404 0.00069306 0.00091704 0.00118    0.00128024 0.00102317
 0.00121607]
Model epoch 620: train total loss -65.05709372065232, train mean loss 0.0004162094347193833, test mean loss [0.00067483 0.00066317 0.00091651 0.0011911  0.00132059 0.00101282
 0.0011876 ]
Model epoch 621: train total loss -65.04659711521083, train mean loss 0.000596730679353374, test mean loss [0.00063298 0.00064142 0.00092229 0.00115715 0.00127673 0.00102286
 0.00117633]
Model epoch 622: train total loss -65.23114463468815, train mean loss 0.0006470885301134277, test mean loss [0.00065536 0.00069194 0.00092392 0.0011716  0.00123539 0.00101437
 0.00117066]
Model epoch 623: train total loss -65.22376148403447, train mean loss 0.0006368907393240641, test mean loss [0.00062726 0.00065009 0.00090254 0.00117289 0.00124859 0.00104879
 0.00116096]
Model epoch 624: train total loss -65.40668681783694, train mean loss 0.0005328420003498463, test mean loss [0.00062198 0.0006393  0.00088711 0.0011324  0.00122987 0.00106038
 0.00116046]
Model epoch 625: train total loss -65.69417397188406, train mean loss 0.00043227541918798806, test mean loss [0.0006265  0.00062139 0.00091284 0.00111986 0.00126871 0.00104645
 0.00117077]
Model epoch 626: train total loss -65.42402630842213, train mean loss 0.0005592851553403636, test mean loss [0.00063451 0.00064408 0.00089722 0.00115798 0.00122955 0.00102079
 0.00114967]
Model epoch 627: train total loss -65.63831465414738, train mean loss 0.0005533718739161508, test mean loss [0.00062591 0.00065258 0.00089017 0.00111729 0.00126416 0.0010116
 0.00119047]
Model epoch 628: train total loss -65.40964476235234, train mean loss 0.000575952705415664, test mean loss [0.00061762 0.00063687 0.00090305 0.00112689 0.00124089 0.00101107
 0.00120861]
Model epoch 629: train total loss -65.39113485737963, train mean loss 0.0005998538490556135, test mean loss [0.00062586 0.00066287 0.00090064 0.00120736 0.00123478 0.00100304
 0.00120698]
Model epoch 630: train total loss -65.31255399625421, train mean loss 0.0005033924714597112, test mean loss [0.00062617 0.00062723 0.00088816 0.00115689 0.0012294  0.00099389
 0.00116665]
Model epoch 631: train total loss -65.3636428362958, train mean loss 0.0005875476621655739, test mean loss [0.00062806 0.00064495 0.00090561 0.00110421 0.00123535 0.00099923
 0.00116864]
Model epoch 632: train total loss -65.24134094340926, train mean loss 0.0006201083597638262, test mean loss [0.0006222  0.00064691 0.00092929 0.00111678 0.00122005 0.00109336
 0.00116965]
Model epoch 633: train total loss -65.33008851045348, train mean loss 0.00045735689581162824, test mean loss [0.00062421 0.00062257 0.00090372 0.00113921 0.00123711 0.0009799
 0.00114845]
Model epoch 634: train total loss -65.44599788131252, train mean loss 0.0005515970120877245, test mean loss [0.0006215  0.00062454 0.00091948 0.00109983 0.00122176 0.00098257
 0.00115123]
Model epoch 635: train total loss -65.26080265174836, train mean loss 0.0006566926925182117, test mean loss [0.00060907 0.00062301 0.00090461 0.00109101 0.00122461 0.00097272
 0.001171  ]
Model epoch 636: train total loss -65.69364423387776, train mean loss 0.0008170611264590354, test mean loss [0.00062415 0.00062901 0.00087111 0.00109618 0.00122296 0.00097455
 0.00116726]
Model epoch 637: train total loss -65.51618435070095, train mean loss 0.0006144538182149408, test mean loss [0.00060103 0.00063103 0.00088632 0.00111978 0.00122338 0.0009796
 0.00114532]
Model epoch 638: train total loss -65.53730801631656, train mean loss 0.0005051833856875962, test mean loss [0.00061264 0.00062617 0.00088838 0.00112845 0.00122001 0.00095995
 0.00113802]
Model epoch 639: train total loss -65.37115962742833, train mean loss 0.0005439000999442595, test mean loss [0.00060723 0.00061937 0.00089372 0.00110963 0.0012016  0.00095643
 0.00114248]
Model epoch 640: train total loss -65.04394725106602, train mean loss 0.00037098467932410574, test mean loss [0.00061416 0.00061207 0.00089691 0.00111261 0.00117674 0.00120689
 0.0011239 ]
Model epoch 641: train total loss -65.27924712685345, train mean loss 0.0005453959299068001, test mean loss [0.00065344 0.00062623 0.00089639 0.00108362 0.00119173 0.00106078
 0.00111122]
Model epoch 642: train total loss -65.09984501878228, train mean loss 0.0004677882274398869, test mean loss [0.00063481 0.00062013 0.00087189 0.00111074 0.00118064 0.00103026
 0.00110827]
Model epoch 643: train total loss -65.06348749781797, train mean loss 0.0006258051484297091, test mean loss [0.00063188 0.0006505  0.00086623 0.00107916 0.00117947 0.00098902
 0.00112895]
Model epoch 644: train total loss -65.490540231495, train mean loss 0.0006765407386988056, test mean loss [0.0006234  0.00062727 0.00087854 0.00112425 0.00118661 0.00097239
 0.00110245]
Model epoch 645: train total loss -65.10537128419841, train mean loss 0.0006456938632047474, test mean loss [0.00061949 0.00062807 0.00085364 0.00110432 0.00119501 0.00096146
 0.00112173]
Model epoch 646: train total loss -65.26234107564892, train mean loss 0.0004195780751341995, test mean loss [0.00062244 0.00063146 0.00088701 0.00109365 0.00118003 0.00093477
 0.00114252]
Model epoch 647: train total loss -65.65743624350763, train mean loss 0.0004881234679259433, test mean loss [0.00060136 0.00062245 0.00085867 0.00110605 0.00119    0.00095844
 0.00109798]
Model epoch 648: train total loss -65.45875582242925, train mean loss 0.0005669503956329667, test mean loss [0.00064361 0.00059893 0.00086529 0.00108642 0.00116011 0.00097208
 0.00110191]
Model epoch 649: train total loss -65.37475909744012, train mean loss 0.0007738593679601086, test mean loss [0.00064239 0.0006028  0.00086495 0.00107238 0.00117069 0.00096333
 0.00109963]
Model epoch 650: train total loss -65.30030611322722, train mean loss 0.0007693364474101091, test mean loss [0.00063019 0.00061648 0.00084571 0.00105799 0.00115879 0.00094886
 0.00108623]
Model epoch 651: train total loss -65.24471394110762, train mean loss 0.00041090615208026375, test mean loss [0.00059819 0.00060076 0.00089675 0.00109677 0.0011527  0.00098349
 0.00111813]
Model epoch 652: train total loss -65.42047831271138, train mean loss 0.0005582621509661816, test mean loss [0.00061747 0.00063782 0.00085496 0.00104805 0.00115556 0.00094133
 0.00109436]
Model epoch 653: train total loss -65.35622939358096, train mean loss 0.000681961285854114, test mean loss [0.00061895 0.00061287 0.00086613 0.00107435 0.00116528 0.00089953
 0.00114283]
Model epoch 654: train total loss -65.34111670352767, train mean loss 0.0004773999455010309, test mean loss [0.00061104 0.00060787 0.00085104 0.00107792 0.00113999 0.00093098
 0.00111051]
Model epoch 655: train total loss -65.28074349485621, train mean loss 0.0005062259534900987, test mean loss [0.00060195 0.00061776 0.00085401 0.00103799 0.00113552 0.00091849
 0.0011032 ]
Model epoch 656: train total loss -65.46114749617897, train mean loss 0.0003468106258552807, test mean loss [0.00058754 0.00061572 0.00086921 0.00105203 0.00115511 0.00094755
 0.00109638]
Model epoch 657: train total loss -65.24624369177201, train mean loss 0.0005470210402790935, test mean loss [0.00062002 0.0006107  0.00083928 0.00107433 0.00113145 0.00095325
 0.00107221]
Model epoch 658: train total loss -65.35152546515978, train mean loss 0.00039325790484794526, test mean loss [0.00060251 0.00063511 0.00084184 0.00106379 0.00112399 0.00094284
 0.00106753]
Model epoch 659: train total loss -65.49184190840539, train mean loss 0.00043577061867235, test mean loss [0.00062485 0.0006288  0.00082784 0.00106172 0.00112353 0.00094773
 0.00104725]
Model epoch 660: train total loss -65.57373878725609, train mean loss 0.00044714593019347225, test mean loss [0.00063182 0.00059999 0.00082866 0.00104238 0.00112712 0.00093729
 0.00108163]
Model epoch 661: train total loss -65.50906963483983, train mean loss 0.0004481548110251107, test mean loss [0.00062611 0.00060957 0.00081746 0.00104346 0.00111638 0.00093666
 0.00105716]
Model epoch 662: train total loss -65.47065697755166, train mean loss 0.00039970748896844913, test mean loss [0.00061492 0.00058617 0.00082974 0.00103769 0.001121   0.00094213
 0.00106084]
Model epoch 663: train total loss -65.51399980212517, train mean loss 0.00033470689907319305, test mean loss [0.00060462 0.00060264 0.00084675 0.00106423 0.00108762 0.00093972
 0.00107387]
Model epoch 664: train total loss -65.4859745522505, train mean loss 0.00036036384505824223, test mean loss [0.00061386 0.00060536 0.0008246  0.00100841 0.00111649 0.00093698
 0.00105683]
Model epoch 665: train total loss -65.46207387188313, train mean loss 0.000481368159476769, test mean loss [0.00061109 0.00059045 0.0008213  0.00106459 0.00111563 0.00094075
 0.00107732]
Model epoch 666: train total loss -65.53246866666561, train mean loss 0.00043866790969263714, test mean loss [0.0005919  0.00059416 0.00081994 0.0010543  0.00109508 0.00091487
 0.00107001]
Model epoch 667: train total loss -65.4133643748839, train mean loss 0.00046797942774608745, test mean loss [0.00059628 0.00059397 0.00082208 0.00104563 0.00108157 0.00090907
 0.00106242]
Model epoch 668: train total loss -65.27748284432411, train mean loss 0.000646111018574893, test mean loss [0.00060032 0.0006019  0.00081806 0.00103345 0.00108205 0.0008991
 0.00106157]
Model epoch 669: train total loss -65.36706639703888, train mean loss 0.00044593197663119936, test mean loss [0.00059902 0.00057422 0.00085773 0.0010325  0.00108498 0.00090705
 0.00104831]
Model epoch 670: train total loss -65.31403480821584, train mean loss 0.0004706854759318313, test mean loss [0.0005942  0.00061884 0.00081732 0.00100678 0.00108304 0.00094469
 0.0010563 ]
Model epoch 671: train total loss -65.29482425475571, train mean loss 0.0005304771874560023, test mean loss [0.00060379 0.00060208 0.00080752 0.00103816 0.00108372 0.00093175
 0.00102716]
Model epoch 672: train total loss -65.3775071280736, train mean loss 0.0003658009678358704, test mean loss [0.0006226  0.00059127 0.0008207  0.00101629 0.00108308 0.0009224
 0.00106238]
Model epoch 673: train total loss -65.58041548981492, train mean loss 0.0005011092392840692, test mean loss [0.00061591 0.00060349 0.00080399 0.00102802 0.00106056 0.00092377
 0.0010729 ]
Model epoch 674: train total loss -65.43570571951642, train mean loss 0.00034448548961488174, test mean loss [0.00060808 0.00058409 0.00080826 0.00100383 0.00107833 0.00087155
 0.00103913]
Model epoch 675: train total loss -65.35419855509845, train mean loss 0.0006276476009128668, test mean loss [0.00059977 0.00060279 0.00081958 0.00100791 0.00106195 0.00089497
 0.00102026]
Model epoch 676: train total loss -65.46253075806291, train mean loss 0.00043074920891951045, test mean loss [0.00059996 0.00057587 0.00081029 0.00101817 0.00109644 0.00089266
 0.00104006]
Model epoch 677: train total loss -65.6385271374219, train mean loss 0.00035261941977571254, test mean loss [0.00061571 0.00061133 0.00080639 0.00102424 0.0010638  0.0008707
 0.00102021]
Model epoch 678: train total loss -65.41594793301752, train mean loss 0.00041832892358150016, test mean loss [0.00060005 0.00059493 0.00080086 0.00100846 0.00105769 0.00087556
 0.001041  ]
Model epoch 679: train total loss -65.56141379889183, train mean loss 0.0004392582473602245, test mean loss [0.00055829 0.00059911 0.00079798 0.0010233  0.00106687 0.00086083
 0.0010387 ]
Model epoch 680: train total loss -65.37141904489711, train mean loss 0.0005361251409986269, test mean loss [0.00058398 0.00061686 0.00080346 0.00101066 0.00104624 0.00088262
 0.00102199]
Model epoch 681: train total loss -65.3675704002259, train mean loss 0.0004636721798944722, test mean loss [0.00058108 0.00058261 0.00078339 0.00100622 0.00108097 0.00089463
 0.00101463]
Model epoch 682: train total loss -65.32680651771646, train mean loss 0.00028315459417697393, test mean loss [0.00059057 0.00061003 0.00079757 0.00097049 0.00105587 0.00090267
 0.00101651]
Model epoch 683: train total loss -65.19714495079728, train mean loss 0.00048332199567264306, test mean loss [0.00058662 0.00058524 0.00077372 0.00103906 0.00102187 0.00088921
 0.00100868]
Model epoch 684: train total loss -65.33433611664533, train mean loss 0.0005970014761841618, test mean loss [0.00060169 0.00057601 0.00079429 0.0010069  0.00101942 0.0009039
 0.00104158]
Model epoch 685: train total loss -65.4215328146465, train mean loss 0.0004969420275152656, test mean loss [0.00058798 0.00059875 0.00076802 0.00101599 0.00103585 0.00090366
 0.00104648]
Model epoch 686: train total loss -65.40226820823341, train mean loss 0.0005045539626836464, test mean loss [0.00058188 0.00058337 0.00077543 0.00098877 0.00104241 0.00088606
 0.00104458]
Model epoch 687: train total loss -65.76758826415097, train mean loss 0.00039165803875420354, test mean loss [0.00061776 0.00060266 0.00077111 0.00098596 0.00104559 0.00087477
 0.00102037]
Model epoch 688: train total loss -65.60132476976551, train mean loss 0.00041078322526982283, test mean loss [0.00058987 0.00060362 0.00078356 0.00097625 0.00101634 0.00087884
 0.0010298 ]
Model epoch 689: train total loss -65.57844005090469, train mean loss 0.00040775657110508646, test mean loss [0.00058513 0.00057573 0.00078969 0.00096827 0.00101966 0.00087679
 0.0009942 ]
Model epoch 690: train total loss -65.47864532432065, train mean loss 0.00045377335602445046, test mean loss [0.00060496 0.00061967 0.00077465 0.00097634 0.00102891 0.0008587
 0.00101364]
Model epoch 691: train total loss -65.55226541524466, train mean loss 0.00041993035984047735, test mean loss [0.00057353 0.00058754 0.00076674 0.00097384 0.00099123 0.00088203
 0.00103158]
Model epoch 692: train total loss -65.5215129513062, train mean loss 0.0005007992107318627, test mean loss [0.0005985  0.00057412 0.00076691 0.00097724 0.00102455 0.00085135
 0.00099716]
Model epoch 693: train total loss -65.33628851971737, train mean loss 0.0005525364859329502, test mean loss [0.00059076 0.00058025 0.00075997 0.00098261 0.00102314 0.00085245
 0.0010106 ]
Model epoch 694: train total loss -65.31184685393758, train mean loss 0.00047699163970385636, test mean loss [0.00058782 0.00056273 0.00077187 0.00095062 0.00101242 0.000886
 0.00113897]
Model epoch 695: train total loss -65.58826680784894, train mean loss 0.0005167790668317928, test mean loss [0.00059376 0.00056701 0.00076797 0.00096299 0.00101005 0.00086108
 0.00107426]
Model epoch 696: train total loss -65.71782990647681, train mean loss 0.0004792526114046626, test mean loss [0.00057407 0.00058427 0.00075905 0.00095197 0.00100086 0.00086847
 0.0010324 ]
Model epoch 697: train total loss -65.47077423763584, train mean loss 0.00035641001134681095, test mean loss [0.00057437 0.00060362 0.00074235 0.00094587 0.00101811 0.00088428
 0.00100784]
Model epoch 698: train total loss -65.61966787549173, train mean loss 0.00048092267314133537, test mean loss [0.00058075 0.00056527 0.00075573 0.00092433 0.0010068  0.00086036
 0.00101064]
Model epoch 699: train total loss -65.54136066457785, train mean loss 0.0005858228862912068, test mean loss [0.00058128 0.00056703 0.00073882 0.00097511 0.00097579 0.00086947
 0.00103172]
Model epoch 700: train total loss -65.57925322230896, train mean loss 0.0003749880584875289, test mean loss [0.00060505 0.00058542 0.00075734 0.0009295  0.00098388 0.00084029
 0.00100024]
Model epoch 701: train total loss -65.28751828407756, train mean loss 0.0005654541082452023, test mean loss [0.00057519 0.00056806 0.00076136 0.00093165 0.00099965 0.00083945
 0.00100065]
Model epoch 702: train total loss -65.58628391516085, train mean loss 0.00039833789027479916, test mean loss [0.00056976 0.00056411 0.00077172 0.00092345 0.00096575 0.0008187
 0.00098799]
Model epoch 703: train total loss -65.69229150334088, train mean loss 0.000462842595014025, test mean loss [0.00058889 0.00055069 0.00075142 0.00095936 0.00097242 0.0008327
 0.0009804 ]
Model epoch 704: train total loss -65.44678429333881, train mean loss 0.0003919527846878719, test mean loss [0.00058245 0.00055585 0.00074156 0.00096078 0.00095307 0.00083057
 0.0009861 ]
Model epoch 705: train total loss -65.42255594806801, train mean loss 0.0006738123267308874, test mean loss [0.0005727  0.00055765 0.00073596 0.00093839 0.00095688 0.00085368
 0.00097566]
Model epoch 706: train total loss -65.3026452542151, train mean loss 0.0005604130566322272, test mean loss [0.00057646 0.00055636 0.0007397  0.00093182 0.00095514 0.00083923
 0.00096822]
Model epoch 707: train total loss -65.44131210901743, train mean loss 0.0004805741291850969, test mean loss [0.00057259 0.00057297 0.00075405 0.00094687 0.00096369 0.00081967
 0.00104328]
Model epoch 708: train total loss -65.40658170849902, train mean loss 0.0003886720942610199, test mean loss [0.00058177 0.00054356 0.00072441 0.00093575 0.00094694 0.00085153
 0.00100519]
Model epoch 709: train total loss -65.90103174006369, train mean loss 0.00034923301763251286, test mean loss [0.00057453 0.00053941 0.00072718 0.0009108  0.00095191 0.00084392
 0.00101416]
Model epoch 710: train total loss -65.75394100539786, train mean loss 0.0003474022841394059, test mean loss [0.00058014 0.00052395 0.00074259 0.0009307  0.0009424  0.00084815
 0.00098923]
Model epoch 711: train total loss -65.32044866366692, train mean loss 0.0006551174099842, test mean loss [0.00059053 0.00055833 0.00075492 0.00092539 0.00094036 0.00081433
 0.00099902]
Model epoch 712: train total loss -65.45656881016805, train mean loss 0.0004168899546991838, test mean loss [0.000593   0.00054612 0.000729   0.0009199  0.00091783 0.00083058
 0.00099022]
Model epoch 713: train total loss -65.74540638388552, train mean loss 0.00034332658469286555, test mean loss [0.00056842 0.00055099 0.00071618 0.00094266 0.00094563 0.00085344
 0.0009922 ]
Model epoch 714: train total loss -65.67849906633815, train mean loss 0.0003462992761265159, test mean loss [0.0005845  0.00056199 0.00072572 0.00093261 0.00091855 0.0008178
 0.00096196]
Model epoch 715: train total loss -65.59871812063103, train mean loss 0.00036569737134936034, test mean loss [0.0005626  0.00055293 0.00072103 0.00091006 0.00094442 0.00085944
 0.00097364]
Model epoch 716: train total loss -65.72056745594611, train mean loss 0.0004655700022180989, test mean loss [0.00056491 0.0005536  0.00071545 0.0009059  0.00092792 0.00082766
 0.00099185]
Model epoch 717: train total loss -65.49861374192726, train mean loss 0.0004121463687510524, test mean loss [0.00061031 0.00054691 0.00071896 0.00092108 0.00091709 0.00082395
 0.00095622]
Model epoch 718: train total loss -65.41128477885749, train mean loss 0.00042794006042843247, test mean loss [0.0005793  0.0005352  0.00071102 0.00092198 0.00091637 0.00081646
 0.00097633]
Model epoch 719: train total loss -65.68908408665109, train mean loss 0.0004861553115501875, test mean loss [0.0005712  0.00055323 0.00069452 0.00090243 0.00092327 0.00081613
 0.00096614]
Model epoch 720: train total loss -65.56335358517931, train mean loss 0.0005116482054758584, test mean loss [0.00058548 0.00053868 0.00069664 0.00087181 0.000924   0.00082542
 0.00093441]
Model epoch 721: train total loss -65.34629076178217, train mean loss 0.00030628423337845343, test mean loss [0.0005767  0.00054676 0.00071534 0.00088765 0.00092331 0.00081992
 0.0009436 ]
Model epoch 722: train total loss -65.62165962278972, train mean loss 0.0003858100875429752, test mean loss [0.00058479 0.00053886 0.00070765 0.00090883 0.00091001 0.00084833
 0.0009423 ]
Model epoch 723: train total loss -65.65626220647741, train mean loss 0.00037467027291149024, test mean loss [0.00061641 0.00054344 0.0006912  0.00087254 0.00091512 0.00084273
 0.00093774]
Model epoch 724: train total loss -65.66367897133128, train mean loss 0.0004175875078589454, test mean loss [0.0006309  0.00053535 0.00070511 0.00087075 0.00092267 0.0008105
 0.00095798]
Model epoch 725: train total loss -65.6536353633784, train mean loss 0.00037657649689640135, test mean loss [0.00063441 0.00053826 0.00068889 0.00086632 0.00089029 0.00080483
 0.00093611]
Model epoch 726: train total loss -65.35506399792948, train mean loss 0.0004677327787988481, test mean loss [0.00061931 0.00054421 0.00072845 0.00087115 0.00091083 0.00079263
 0.0009317 ]
Model epoch 727: train total loss -65.67936475557656, train mean loss 0.0003022711068921399, test mean loss [0.0005975  0.00052609 0.00070722 0.00087782 0.00088548 0.00077979
 0.00095911]
Model epoch 728: train total loss -65.412352681205, train mean loss 0.0005941471744241597, test mean loss [0.00060116 0.00055141 0.00071004 0.00086436 0.0009107  0.00080367
 0.00092462]
Model epoch 729: train total loss -65.64479655862976, train mean loss 0.00044325342205555333, test mean loss [0.0006014  0.00053165 0.00073218 0.00086125 0.00086946 0.00082716
 0.00093938]
Model epoch 730: train total loss -65.75330133924605, train mean loss 0.0005454548009508564, test mean loss [0.00060254 0.00053774 0.00072505 0.00086058 0.00090992 0.00080617
 0.00090368]
Model epoch 731: train total loss -65.55811764707465, train mean loss 0.0003891549789299854, test mean loss [0.00058534 0.0005308  0.00069703 0.00085197 0.00087379 0.00081722
 0.00092279]
Model epoch 732: train total loss -65.46028707225145, train mean loss 0.0004616877079055375, test mean loss [0.0005849  0.00055567 0.00072136 0.00086693 0.00089074 0.00080349
 0.00101379]
Model epoch 733: train total loss -65.70583268557552, train mean loss 0.0004944345093757231, test mean loss [0.00059749 0.00056742 0.00071369 0.00084017 0.00087571 0.00079128
 0.00099848]
Model epoch 734: train total loss -65.49314809932993, train mean loss 0.0006661793148007206, test mean loss [0.000628   0.00053509 0.000732   0.00087235 0.00089236 0.00079015
 0.00095394]
Model epoch 735: train total loss -65.2726281848336, train mean loss 0.0003327609795799749, test mean loss [0.00058843 0.00053168 0.00070322 0.0008427  0.00089374 0.00078838
 0.00095351]
Model epoch 736: train total loss -65.4792113441368, train mean loss 0.0004649967787008435, test mean loss [0.00061664 0.00052301 0.00071658 0.00083567 0.00089791 0.00083367
 0.00092961]
Model epoch 737: train total loss -65.57448928938096, train mean loss 0.0005255914759434017, test mean loss [0.00056306 0.0005519  0.00068773 0.00082537 0.00085974 0.0007872
 0.000947  ]
Model epoch 738: train total loss -65.46287414595437, train mean loss 0.0004437582265197574, test mean loss [0.00056696 0.00052792 0.00070196 0.00081728 0.00087697 0.00077085
 0.00092973]
Model epoch 739: train total loss -65.65137637873018, train mean loss 0.00038666687672640195, test mean loss [0.00059746 0.00052369 0.00071834 0.00084566 0.00085561 0.00079646
 0.00092674]
Model epoch 740: train total loss -65.61226067553318, train mean loss 0.0005807413485376863, test mean loss [0.00056618 0.00054993 0.00070024 0.00081648 0.00085883 0.00078182
 0.00091821]
Model epoch 741: train total loss -65.71915035418922, train mean loss 0.0004489622076897568, test mean loss [0.00056874 0.00053755 0.00070197 0.00084944 0.00086721 0.00082198
 0.00092055]
Model epoch 742: train total loss -65.58686604170747, train mean loss 0.0004123678046583111, test mean loss [0.00057009 0.00054163 0.00069408 0.00085003 0.0008679  0.0007937
 0.00091923]
Model epoch 743: train total loss -65.5796851676648, train mean loss 0.0004723759748425348, test mean loss [0.00057034 0.00053822 0.00072348 0.00083693 0.00087502 0.00080886
 0.0009063 ]
Model epoch 744: train total loss -65.86679725442188, train mean loss 0.0003526965087256406, test mean loss [0.00055526 0.00052767 0.00069089 0.00080441 0.00085833 0.00078981
 0.00092513]
Model epoch 745: train total loss -65.62653866544004, train mean loss 0.0004112483087504388, test mean loss [0.0005637  0.00053838 0.00069454 0.00083303 0.00088412 0.00078476
 0.00092411]
Model epoch 746: train total loss -65.61775476497071, train mean loss 0.0004235091813397865, test mean loss [0.00054943 0.00054336 0.00069375 0.00084415 0.00086725 0.00078856
 0.00094322]
Model epoch 747: train total loss -65.5680385380489, train mean loss 0.0006387822052690999, test mean loss [0.00054694 0.00050392 0.00068909 0.00082997 0.00082146 0.00077122
 0.00092432]
Model epoch 748: train total loss -65.74030752614553, train mean loss 0.0003665742703594409, test mean loss [0.00055944 0.00054143 0.00067797 0.00080734 0.00086993 0.00079617
 0.00093223]
Model epoch 749: train total loss -65.46588714210917, train mean loss 0.0004155232952102226, test mean loss [0.00055452 0.00051133 0.00066625 0.00081921 0.00087504 0.00078935
 0.00093875]
Model epoch 750: train total loss -65.51765755968515, train mean loss 0.00030069275473766595, test mean loss [0.00054789 0.00051092 0.00068046 0.00079885 0.00084793 0.00078669
 0.00093922]
Model epoch 751: train total loss -65.41611738252207, train mean loss 0.00037591013326898284, test mean loss [0.00054322 0.0005119  0.00066644 0.00081682 0.00084773 0.00077693
 0.00090532]
Model epoch 752: train total loss -65.4104560690078, train mean loss 0.0003059020147046062, test mean loss [0.00056358 0.00052319 0.00067826 0.00081681 0.0008352  0.00077341
 0.00094415]
Model epoch 753: train total loss -65.74666025788609, train mean loss 0.000406043388345808, test mean loss [0.00055437 0.00050661 0.00067684 0.00081704 0.00085979 0.00076394
 0.00093443]
Model epoch 754: train total loss -65.61184496854254, train mean loss 0.0004548911008734359, test mean loss [0.00055045 0.00053098 0.00068563 0.00081809 0.0008422  0.00077079
 0.00091031]
Model epoch 755: train total loss -65.70555691518298, train mean loss 0.0003665595400798564, test mean loss [0.00055414 0.00053148 0.00067664 0.00082441 0.00082829 0.00076984
 0.00089386]
Model epoch 756: train total loss -65.35870682117216, train mean loss 0.0004897234327925936, test mean loss [0.00055469 0.00050644 0.0006654  0.00081661 0.00083026 0.00079626
 0.00090795]
Model epoch 757: train total loss -65.50673172198402, train mean loss 0.0004300734342475948, test mean loss [0.00055906 0.0004931  0.00066073 0.00082026 0.0008378  0.00077892
 0.00089469]
Model epoch 758: train total loss -65.67598199914048, train mean loss 0.0003324707914771375, test mean loss [0.00054402 0.00050365 0.00066571 0.00080017 0.00080941 0.00077605
 0.00088328]
Model epoch 759: train total loss -65.80526248474771, train mean loss 0.0004069040148999804, test mean loss [0.00055204 0.00049728 0.00065137 0.00079168 0.00080061 0.00077493
 0.0008964 ]
Model epoch 760: train total loss -65.68830409062697, train mean loss 0.00040209098487305585, test mean loss [0.00053667 0.00050679 0.00066211 0.00080157 0.00080713 0.00077193
 0.00088937]
Model epoch 761: train total loss -65.70413333439672, train mean loss 0.00047819201605919185, test mean loss [0.00053726 0.00048261 0.0006535  0.00082054 0.00082094 0.00076278
 0.00090615]
Model epoch 762: train total loss -65.29151530322726, train mean loss 0.0005535149290653244, test mean loss [0.00055045 0.00053626 0.00068037 0.00080993 0.0008184  0.00074382
 0.00088998]
Model epoch 763: train total loss -65.46892417463798, train mean loss 0.0004923990080762724, test mean loss [0.00055851 0.0005052  0.00065807 0.00077406 0.00080022 0.0007813
 0.00089833]
Model epoch 764: train total loss -65.69431346534813, train mean loss 0.0003400978767196797, test mean loss [0.00053417 0.00052276 0.00064126 0.00076979 0.00080174 0.00075962
 0.00088759]
Model epoch 765: train total loss -65.5058378741922, train mean loss 0.00028896257304350726, test mean loss [0.00053968 0.00054209 0.00065316 0.00076424 0.00083258 0.00076693
 0.00087331]
Model epoch 766: train total loss -65.66710114855886, train mean loss 0.0003954740949128694, test mean loss [0.00051824 0.00053697 0.00065306 0.00078366 0.00081943 0.00078709
 0.00086599]
Model epoch 767: train total loss -65.76886872977015, train mean loss 0.00045609040309566604, test mean loss [0.00054556 0.00051364 0.00065394 0.00078889 0.00079308 0.00075997
 0.00089381]
Model epoch 768: train total loss -65.65561582557471, train mean loss 0.00039377564996626556, test mean loss [0.00052903 0.00049446 0.00064412 0.00077122 0.00082099 0.00073533
 0.00089711]
Model epoch 769: train total loss -65.5924045152826, train mean loss 0.00038168699369467966, test mean loss [0.00054954 0.00049968 0.00064537 0.00077497 0.00079517 0.00076561
 0.00089924]
Model epoch 770: train total loss -65.37015720929277, train mean loss 0.00047707838628719453, test mean loss [0.00053493 0.00048771 0.00063619 0.00077818 0.0008022  0.00078517
 0.00090653]
Model epoch 771: train total loss -65.4469646873667, train mean loss 0.0004117568880038887, test mean loss [0.00052063 0.00049568 0.00065971 0.00078558 0.00076797 0.00075689
 0.00092605]
Model epoch 772: train total loss -65.63572991370238, train mean loss 0.0005444847622587469, test mean loss [0.00052672 0.00050298 0.00064284 0.0007594  0.00077784 0.0007619
 0.00089476]
Model epoch 773: train total loss -65.58909103527782, train mean loss 0.0003794242545762559, test mean loss [0.00052653 0.00048879 0.00063723 0.00081153 0.00079313 0.00077777
 0.00089333]
Model epoch 774: train total loss -65.52184432090047, train mean loss 0.00041216306165089967, test mean loss [0.00052298 0.00049867 0.00064295 0.0008032  0.00078873 0.00080934
 0.00086855]
Model epoch 775: train total loss -65.37375578452334, train mean loss 0.000363069298437797, test mean loss [0.00052555 0.00050417 0.0006667  0.00077669 0.00080839 0.00077645
 0.00088519]
Model epoch 776: train total loss -65.37049292371954, train mean loss 0.0003821439709964212, test mean loss [0.0005215  0.00050033 0.0006406  0.00074576 0.00081579 0.00077101
 0.0008845 ]
Model epoch 777: train total loss -65.57024068153395, train mean loss 0.00043835536463491165, test mean loss [0.00053279 0.0005043  0.0006472  0.00077093 0.00078905 0.00076601
 0.00086479]
Model epoch 778: train total loss -65.74405034322275, train mean loss 0.0004008061807459939, test mean loss [0.00054103 0.00049549 0.00061781 0.0007714  0.00077847 0.00074377
 0.0008882 ]
Model epoch 779: train total loss -65.3220275867484, train mean loss 0.000402721021669698, test mean loss [0.00053425 0.00052113 0.00063515 0.00075405 0.00081856 0.00077321
 0.00086605]
Model epoch 780: train total loss -65.9057385343375, train mean loss 0.0005459633034760322, test mean loss [0.0005281  0.00049974 0.00064474 0.00076136 0.00078758 0.00076372
 0.00086977]
Model epoch 781: train total loss -65.76345839570483, train mean loss 0.0006261803323863577, test mean loss [0.00051156 0.00050452 0.00065672 0.00074305 0.00078206 0.000736
 0.00088847]
Model epoch 782: train total loss -65.71528642583093, train mean loss 0.00037987698553716703, test mean loss [0.00052176 0.0005179  0.0006475  0.00076025 0.0007846  0.00074615
 0.00086712]
Model epoch 783: train total loss -65.36575904938017, train mean loss 0.0002780231720729172, test mean loss [0.00053154 0.00050145 0.00064671 0.00075823 0.00077095 0.00072417
 0.00089645]
Model epoch 784: train total loss -65.3126671560721, train mean loss 0.0004552048529045382, test mean loss [0.00053011 0.00049315 0.00063325 0.00072834 0.00078455 0.00075012
 0.00089637]
Model epoch 785: train total loss -65.61678120959344, train mean loss 0.0005003393252067038, test mean loss [0.00052925 0.00048631 0.0006411  0.00072899 0.00075422 0.00079275
 0.00085551]
Model epoch 786: train total loss -65.85124608843161, train mean loss 0.00031579556053269107, test mean loss [0.00051782 0.00049657 0.00063259 0.00076183 0.00075272 0.00072136
 0.0008843 ]
Model epoch 787: train total loss -65.48880160560877, train mean loss 0.0004829010306938239, test mean loss [0.00051152 0.00049192 0.00061569 0.00074191 0.00075776 0.00072738
 0.00086249]
Model epoch 788: train total loss -65.66578904441697, train mean loss 0.0003944056916228868, test mean loss [0.00052106 0.00048879 0.0006136  0.00072812 0.00074219 0.00073426
 0.00088025]
Model epoch 789: train total loss -65.39563837796878, train mean loss 0.00038633173625691813, test mean loss [0.00052124 0.0004709  0.00062958 0.00074142 0.00076587 0.00072297
 0.00085347]
Model epoch 790: train total loss -65.59247229296624, train mean loss 0.00032179517056270696, test mean loss [0.00053244 0.00047349 0.00062631 0.00073155 0.00073589 0.00073405
 0.00085288]
Model epoch 791: train total loss -65.65358653080554, train mean loss 0.0002660096166055394, test mean loss [0.00054753 0.00051052 0.00060125 0.00074154 0.00077314 0.00072282
 0.00085856]
Model epoch 792: train total loss -65.63066776963467, train mean loss 0.0005689757360578421, test mean loss [0.00054132 0.00048304 0.00065851 0.00074648 0.00076227 0.00070539
 0.00085138]
Model epoch 793: train total loss -65.61970476660368, train mean loss 0.00036627567866148064, test mean loss [0.00054258 0.00047984 0.00062924 0.00076308 0.00074887 0.00070705
 0.00085484]
Model epoch 794: train total loss -65.56180149357702, train mean loss 0.0003160021850846548, test mean loss [0.00054502 0.00049638 0.00062097 0.00072836 0.00075899 0.00072582
 0.00084479]
Model epoch 795: train total loss -65.722415398994, train mean loss 0.0003770686253590718, test mean loss [0.00054514 0.00049617 0.00061066 0.00073778 0.00073555 0.00082844
 0.00083383]
Model epoch 796: train total loss -65.58419316632668, train mean loss 0.0005647899988090677, test mean loss [0.00053604 0.00048708 0.00061068 0.00073761 0.00074024 0.00084016
 0.00083824]
Model epoch 797: train total loss -65.60277309882, train mean loss 0.00028418770730597863, test mean loss [0.0005358  0.00049227 0.00061338 0.00072262 0.00077122 0.00081897
 0.00084891]
Model epoch 798: train total loss -65.49737206641849, train mean loss 0.000444873786420839, test mean loss [0.00052673 0.00048335 0.0006043  0.00073445 0.00074765 0.00081275
 0.00083933]
Model epoch 799: train total loss -65.68411406371004, train mean loss 0.0002761613559687998, test mean loss [0.0005216  0.00047966 0.00061465 0.00071397 0.0007314  0.00084554
 0.00084561]
Model epoch 800: train total loss -65.84256633361971, train mean loss 0.0005122283797306532, test mean loss [0.00052583 0.00047038 0.00060241 0.00072712 0.00075913 0.00075549
 0.0008198 ]
Model epoch 801: train total loss -65.7189644962443, train mean loss 0.00030684970298554856, test mean loss [0.00051463 0.00048977 0.0006242  0.00072389 0.00078159 0.0007604
 0.00082957]
Model epoch 802: train total loss -65.54663177895007, train mean loss 0.0003634816213906273, test mean loss [0.0005261  0.00048534 0.00061613 0.00070599 0.0007721  0.000757
 0.00080034]
Model epoch 803: train total loss -65.74740854403662, train mean loss 0.0003159567771747782, test mean loss [0.0005231  0.0004923  0.00060371 0.00071918 0.00073053 0.00073153
 0.00080997]
Model epoch 804: train total loss -65.51016981891465, train mean loss 0.00042764100170279603, test mean loss [0.00053024 0.00047083 0.00061275 0.00074151 0.00072805 0.0007425
 0.00081526]
Model epoch 805: train total loss -65.6805354502697, train mean loss 0.00034794610120927503, test mean loss [0.00052152 0.00046029 0.00061201 0.00070963 0.00073061 0.0007225
 0.00083082]
Model epoch 806: train total loss -65.48642779972607, train mean loss 0.0003456756377087663, test mean loss [0.00052494 0.00047742 0.00060312 0.00069718 0.00072379 0.00070926
 0.00084014]
Model epoch 807: train total loss -65.58097111035741, train mean loss 0.00035612672488067253, test mean loss [0.00054436 0.00048428 0.00061238 0.00070584 0.00071711 0.00070943
 0.00081439]
Model epoch 808: train total loss -65.87152861100788, train mean loss 0.00038671079396333216, test mean loss [0.0005671  0.00047731 0.00059396 0.00070586 0.00072113 0.00072881
 0.00080677]
Model epoch 809: train total loss -65.73957389912634, train mean loss 0.0003021868982699914, test mean loss [0.00051905 0.00046181 0.00058279 0.00070172 0.00072781 0.00070413
 0.00082416]
Model epoch 810: train total loss -65.68508655698166, train mean loss 0.00034010392803732214, test mean loss [0.00051791 0.0004677  0.00059682 0.00071277 0.00072556 0.00071639
 0.00081887]
Model epoch 811: train total loss -65.4740033866947, train mean loss 0.0003744271037047729, test mean loss [0.00054579 0.00047186 0.0005978  0.00069286 0.00071111 0.00071913
 0.00080994]
Model epoch 812: train total loss -65.60525582304382, train mean loss 0.0002989804637322368, test mean loss [0.00053113 0.00045645 0.00057839 0.00070648 0.00071544 0.00071317
 0.00083548]
Model epoch 813: train total loss -65.57180172973972, train mean loss 0.00037291572430888026, test mean loss [0.00053222 0.00045359 0.00057499 0.00067891 0.00071782 0.00068773
 0.00084567]
Model epoch 814: train total loss -65.55161370724767, train mean loss 0.00026454812476738124, test mean loss [0.00052002 0.00045232 0.00058779 0.00068238 0.0006974  0.0007318
 0.00081217]
Model epoch 815: train total loss -65.82134425184846, train mean loss 0.00044930791701717804, test mean loss [0.0005289  0.00045606 0.00057977 0.00069953 0.00072296 0.0007129
 0.0008012 ]
Model epoch 816: train total loss -65.77489524428248, train mean loss 0.0004348932310378091, test mean loss [0.00052907 0.0004679  0.00058683 0.00068473 0.00072803 0.00072252
 0.00079847]
Model epoch 817: train total loss -65.75469640433462, train mean loss 0.0002960212349015707, test mean loss [0.00052467 0.00044758 0.00064908 0.00069522 0.00072009 0.00071732
 0.00080635]
Model epoch 818: train total loss -65.85394231255421, train mean loss 0.0002867599238388052, test mean loss [0.00052023 0.00048507 0.00058924 0.00068566 0.00068908 0.00074368
 0.00079973]
Model epoch 819: train total loss -65.56942874382474, train mean loss 0.0004078858607944902, test mean loss [0.00050352 0.00045428 0.00056932 0.00070128 0.00070975 0.00071535
 0.00080401]
Model epoch 820: train total loss -65.7488479145996, train mean loss 0.00034943299863777273, test mean loss [0.00052104 0.00045072 0.0005711  0.00069166 0.00071677 0.00069382
 0.0008054 ]
Model epoch 821: train total loss -65.60566272946043, train mean loss 0.0003402402442679445, test mean loss [0.00056126 0.0004616  0.00058291 0.00069456 0.00072064 0.00068095
 0.00080248]
Model epoch 822: train total loss -65.60748434140356, train mean loss 0.00045870613150874863, test mean loss [0.00053713 0.00048342 0.0005859  0.00068846 0.00071152 0.00071984
 0.00079707]
Model epoch 823: train total loss -65.66547034095171, train mean loss 0.00034380559015183515, test mean loss [0.00051578 0.00046781 0.00056541 0.00066404 0.0007116  0.00070024
 0.00080526]
Model epoch 824: train total loss -65.79171953559698, train mean loss 0.0003880346443629922, test mean loss [0.00052436 0.00046847 0.00057564 0.00065731 0.00072802 0.00069078
 0.00079607]
Model epoch 825: train total loss -65.79549353564018, train mean loss 0.00027730415750464775, test mean loss [0.00052833 0.00051242 0.00057159 0.00066463 0.00070541 0.00067977
 0.00080599]
Model epoch 826: train total loss -65.55977843119231, train mean loss 0.00027946439680899576, test mean loss [0.00050784 0.00045847 0.00056928 0.00066935 0.0007244  0.00069426
 0.00080099]
Model epoch 827: train total loss -65.29833863445334, train mean loss 0.00038808862298253234, test mean loss [0.00049512 0.00045993 0.00058702 0.00074629 0.00071552 0.00069419
 0.00081576]
Model epoch 828: train total loss -65.61824205364698, train mean loss 0.0003493106180850514, test mean loss [0.00051901 0.00045504 0.00055565 0.00069463 0.00070855 0.00070093
 0.00080926]
Model epoch 829: train total loss -65.65782050871998, train mean loss 0.00028315104548284437, test mean loss [0.00051433 0.00045065 0.0005687  0.00067495 0.00068476 0.00068593
 0.00077771]
Model epoch 830: train total loss -65.54143990212415, train mean loss 0.0002785772098305236, test mean loss [0.00051155 0.00044796 0.00055421 0.00066646 0.00069815 0.00067379
 0.00078418]
Model epoch 831: train total loss -65.75581774748056, train mean loss 0.00048358125596723365, test mean loss [0.0004998  0.00046846 0.00056646 0.00067636 0.00069444 0.00069165
 0.00079247]
Model epoch 832: train total loss -65.42846009493577, train mean loss 0.000345969151022816, test mean loss [0.00050356 0.00046989 0.00056182 0.00067793 0.0007004  0.00068063
 0.00079182]
Model epoch 833: train total loss -65.46145915613732, train mean loss 0.00037208364930275056, test mean loss [0.00051567 0.00045364 0.00056397 0.00067904 0.00068636 0.00068515
 0.00078919]
Model epoch 834: train total loss -65.91320911885458, train mean loss 0.00023819929999837732, test mean loss [0.0004996  0.00048226 0.00055681 0.00066435 0.00069999 0.00069001
 0.00079212]
Model epoch 835: train total loss -65.71150877085667, train mean loss 0.00036841270138839537, test mean loss [0.00049846 0.00044069 0.00055584 0.00064118 0.00070122 0.00065957
 0.00079938]
Model epoch 836: train total loss -65.77778883639775, train mean loss 0.00040683772925652513, test mean loss [0.00051176 0.00045091 0.00057797 0.00065519 0.0006869  0.00064123
 0.0007875 ]
Model epoch 837: train total loss -65.92107187915141, train mean loss 0.0003267365652102312, test mean loss [0.00051084 0.00043791 0.00056413 0.000674   0.00066731 0.00068543
 0.0007848 ]
Model epoch 838: train total loss -65.52296949985995, train mean loss 0.00035413781847347793, test mean loss [0.00050934 0.00044823 0.00055221 0.00065527 0.0006897  0.00066934
 0.00077631]
Model epoch 839: train total loss -65.49680051332338, train mean loss 0.00044191765027715054, test mean loss [0.00050357 0.00043714 0.00055657 0.00065454 0.00066808 0.00066073
 0.0007631 ]
Model epoch 840: train total loss -65.27232654827284, train mean loss 0.0003377476620039605, test mean loss [0.00050394 0.0004501  0.0005587  0.00068255 0.00068659 0.00067614
 0.00077792]
Model epoch 841: train total loss -65.60209862824762, train mean loss 0.0005446854474047722, test mean loss [0.00050584 0.00045234 0.00058805 0.00066305 0.00068182 0.0006766
 0.00076229]
Model epoch 842: train total loss -65.673657854254, train mean loss 0.00032084890462940203, test mean loss [0.00050591 0.00044555 0.00055231 0.00065742 0.00066006 0.00066473
 0.00076036]
Model epoch 843: train total loss -65.4680178026827, train mean loss 0.0003374989461882808, test mean loss [0.00050864 0.00045804 0.00056173 0.00067851 0.00065576 0.00066101
 0.00075247]
Model epoch 844: train total loss -65.65519877037511, train mean loss 0.0003319980884919527, test mean loss [0.00053148 0.00044492 0.00054767 0.00068364 0.00064786 0.00068358
 0.00078855]
Model epoch 845: train total loss -65.85126435073991, train mean loss 0.0003979000038811306, test mean loss [0.00051578 0.00043275 0.00056211 0.00065766 0.00067914 0.0006704
 0.00076439]
Model epoch 846: train total loss -65.87708382040398, train mean loss 0.0003071230934632398, test mean loss [0.00050502 0.00045726 0.000543   0.00067695 0.00067945 0.00067189
 0.00077404]
Model epoch 847: train total loss -65.8391917263524, train mean loss 0.0004910751072501542, test mean loss [0.00048096 0.00044537 0.00053282 0.00066694 0.00066956 0.0006621
 0.00075688]
Model epoch 848: train total loss -65.69677369719824, train mean loss 0.00035165162702532443, test mean loss [0.00049355 0.00043877 0.00053525 0.00064227 0.00065327 0.0006627
 0.00074093]
Model epoch 849: train total loss -65.75778538168215, train mean loss 0.0003218584105866624, test mean loss [0.00049372 0.00044558 0.00055421 0.0006327  0.00065953 0.00064018
 0.00077484]
Model epoch 850: train total loss -65.72392484208912, train mean loss 0.00040059167849732625, test mean loss [0.00049217 0.0004328  0.00055372 0.00064873 0.00065333 0.00064688
 0.00072836]
Model epoch 851: train total loss -65.93994483343758, train mean loss 0.00025790923376000063, test mean loss [0.00050916 0.00045381 0.00055471 0.00065436 0.00067079 0.00065554
 0.00074591]
Model epoch 852: train total loss -65.68227785096362, train mean loss 0.0003810387904046549, test mean loss [0.00050673 0.00046797 0.00055176 0.0006323  0.00063345 0.00065373
 0.00074686]
Model epoch 853: train total loss -66.00708045434008, train mean loss 0.00028058323610571716, test mean loss [0.00052818 0.00043848 0.00053571 0.00064834 0.00066905 0.00065446
 0.00075079]
Model epoch 854: train total loss -65.53502110452159, train mean loss 0.0002936199975195845, test mean loss [0.00051552 0.00044339 0.00055625 0.00064994 0.00065601 0.00065792
 0.00076769]
Model epoch 855: train total loss -65.62446261188362, train mean loss 0.00026336297280848655, test mean loss [0.0005043  0.00043396 0.00054888 0.0006608  0.0006516  0.00064505
 0.00076573]
Model epoch 856: train total loss -65.66280280551044, train mean loss 0.00035876537135996035, test mean loss [0.00049674 0.00041791 0.00054058 0.000648   0.00064566 0.0006473
 0.00073873]
Model epoch 857: train total loss -65.4248643489814, train mean loss 0.00040630602478125663, test mean loss [0.00049998 0.00041344 0.00056373 0.00062964 0.00065272 0.0006465
 0.0007397 ]
Model epoch 858: train total loss -65.6835607160429, train mean loss 0.0004026544392536885, test mean loss [0.00050435 0.0004451  0.00055087 0.00067054 0.00064201 0.0006401
 0.00073642]
Model epoch 859: train total loss -65.59555532095797, train mean loss 0.00034525971530832683, test mean loss [0.0004882  0.00042645 0.00055769 0.00065145 0.00064678 0.00069448
 0.00074081]
Model epoch 860: train total loss -65.70834208570565, train mean loss 0.0003290634441692509, test mean loss [0.000503   0.00041591 0.00053511 0.00064392 0.00064319 0.0006514
 0.00073115]
Model epoch 861: train total loss -65.59436540014786, train mean loss 0.00030355640765359856, test mean loss [0.00052598 0.00043921 0.0005556  0.00064656 0.00064764 0.00065656
 0.00073648]
Model epoch 862: train total loss -65.35053492272468, train mean loss 0.000341877428015366, test mean loss [0.00053373 0.00044907 0.00058503 0.00062464 0.00065141 0.00064002
 0.00074623]
Model epoch 863: train total loss -65.57198927779015, train mean loss 0.00037016070043935595, test mean loss [0.00051045 0.0004233  0.00054104 0.00065931 0.00067163 0.00064638
 0.00075207]
Model epoch 864: train total loss -65.55140175533047, train mean loss 0.00037229181940871576, test mean loss [0.00049954 0.0004394  0.00056388 0.00062791 0.00066059 0.0006495
 0.00073875]
Model epoch 865: train total loss -65.29070336646686, train mean loss 0.0005182904791656333, test mean loss [0.00049396 0.00044934 0.00055049 0.00065856 0.0006589  0.00067503
 0.00073326]
Model epoch 866: train total loss -65.85291048227019, train mean loss 0.00028269540420913607, test mean loss [0.00050619 0.00042647 0.00056978 0.00064611 0.00064342 0.00062889
 0.00072819]
Model epoch 867: train total loss -66.1118237796905, train mean loss 0.0002500082576241292, test mean loss [0.00049781 0.000444   0.00054501 0.00062792 0.00063815 0.00064197
 0.00074352]
Model epoch 868: train total loss -65.60754905234477, train mean loss 0.00040718041544059457, test mean loss [0.00048383 0.00044016 0.00052786 0.00063725 0.00069181 0.00064932
 0.00072872]
Model epoch 869: train total loss -65.7303508684307, train mean loss 0.0002340014673119499, test mean loss [0.00047894 0.00044154 0.00053263 0.00066204 0.00067155 0.00059095
 0.00074126]
Model epoch 870: train total loss -65.66212077733998, train mean loss 0.00024291712378430154, test mean loss [0.00050104 0.00042465 0.00052707 0.00062088 0.00064919 0.00063624
 0.00073086]
Model epoch 871: train total loss -65.70642068763817, train mean loss 0.0004342106902319716, test mean loss [0.00049466 0.00041558 0.00052962 0.00063029 0.00066088 0.0006184
 0.00074915]
Model epoch 872: train total loss -65.67932616595192, train mean loss 0.00026368375905080763, test mean loss [0.00049265 0.0004142  0.00052277 0.00061481 0.00067544 0.00065434
 0.00074176]
Model epoch 873: train total loss -65.55638060926418, train mean loss 0.00035371383603049176, test mean loss [0.00049553 0.0004264  0.0005442  0.00063869 0.00064675 0.00066808
 0.00073448]
Model epoch 874: train total loss -65.62333116586505, train mean loss 0.00035768887654870514, test mean loss [0.00048982 0.00040565 0.0005241  0.00062151 0.0006416  0.00064136
 0.00072135]
Model epoch 875: train total loss -65.50794422491127, train mean loss 0.0003787007392961071, test mean loss [0.00049821 0.00042472 0.00053013 0.0006207  0.00065119 0.00062737
 0.00072061]
Model epoch 876: train total loss -65.89428063479383, train mean loss 0.0002703171774696978, test mean loss [0.00049614 0.00041335 0.00051521 0.0006345  0.00061787 0.00063952
 0.00074116]
Model epoch 877: train total loss -65.76905499762394, train mean loss 0.0003364685346984651, test mean loss [0.0004935  0.00041274 0.00050535 0.00063193 0.00063544 0.0006136
 0.00072074]
Model epoch 878: train total loss -65.63624056814363, train mean loss 0.0003980516627323721, test mean loss [0.00048549 0.00042471 0.00052519 0.00060538 0.00064121 0.00062166
 0.00073707]
Model epoch 879: train total loss -65.59854537672528, train mean loss 0.000536708510227342, test mean loss [0.00048179 0.00041958 0.00052551 0.00059869 0.00064018 0.0006323
 0.00072439]
Model epoch 880: train total loss -65.61704756188277, train mean loss 0.0003406626843282274, test mean loss [0.00049561 0.00041388 0.00053908 0.00065475 0.00062311 0.00065211
 0.0007554 ]
Model epoch 881: train total loss -65.73327734391442, train mean loss 0.00039420998965441204, test mean loss [0.00048792 0.00040891 0.00052371 0.0006255  0.00063544 0.00062963
 0.00071186]
Model epoch 882: train total loss -65.96391263851154, train mean loss 0.00027987215866487206, test mean loss [0.00049693 0.00042292 0.00053181 0.00059661 0.00064515 0.00061266
 0.00072462]
Model epoch 883: train total loss -65.54086757756387, train mean loss 0.0003324762984282334, test mean loss [0.00048563 0.00040693 0.00052818 0.00059458 0.00062513 0.00061095
 0.00071148]
Model epoch 884: train total loss -65.86269144249381, train mean loss 0.0002742492988020116, test mean loss [0.00048542 0.00041328 0.0005274  0.00062062 0.00063238 0.00061991
 0.00069523]
Model epoch 885: train total loss -65.78134358638587, train mean loss 0.00030749393655502976, test mean loss [0.00048781 0.0004004  0.00050604 0.00061703 0.00061326 0.00060495
 0.00070464]
Model epoch 886: train total loss -65.68496364192444, train mean loss 0.0003139688679460319, test mean loss [0.00049862 0.00041058 0.00051846 0.00061459 0.00062758 0.00060999
 0.00072136]
Model epoch 887: train total loss -65.4553477602694, train mean loss 0.00031513708361410186, test mean loss [0.00049222 0.0004182  0.0005201  0.00061056 0.00063886 0.00059432
 0.00073397]
Model epoch 888: train total loss -65.49732082914399, train mean loss 0.000272102834646836, test mean loss [0.00049051 0.00042974 0.00053039 0.00062716 0.00063879 0.00062956
 0.00070592]
Model epoch 889: train total loss -65.96354920924274, train mean loss 0.0002150098520692937, test mean loss [0.00048849 0.00043899 0.0005288  0.00061428 0.00062564 0.00062779
 0.00070344]
Model epoch 890: train total loss -65.58916552304467, train mean loss 0.0002846010908184043, test mean loss [0.00047674 0.00040966 0.00053161 0.00061969 0.00061139 0.00061601
 0.00071693]
Model epoch 891: train total loss -65.68821848809954, train mean loss 0.0003880942125893086, test mean loss [0.00049717 0.00041716 0.0005351  0.00061339 0.00061806 0.00060534
 0.00069011]
Model epoch 892: train total loss -65.83163442902827, train mean loss 0.000314536065013317, test mean loss [0.00048862 0.00041684 0.00052711 0.00060644 0.00062315 0.00059497
 0.00069879]
Model epoch 893: train total loss -65.83602388826569, train mean loss 0.00028876208960441435, test mean loss [0.00047601 0.00038749 0.00051852 0.00059566 0.00061717 0.00058869
 0.00071504]
Model epoch 894: train total loss -65.88371668854363, train mean loss 0.0004895117976019093, test mean loss [0.00046506 0.00038922 0.00052596 0.00059111 0.00061064 0.00059395
 0.00069139]
Model epoch 895: train total loss -65.42568324758336, train mean loss 0.00031095196996723225, test mean loss [0.00047777 0.0004024  0.00051329 0.00060682 0.00062128 0.00061949
 0.00069221]
Model epoch 896: train total loss -65.73845576750982, train mean loss 0.00026452040754676833, test mean loss [0.00048085 0.00043153 0.00049345 0.00059459 0.00060744 0.00059617
 0.0006934 ]
Model epoch 897: train total loss -65.85473494586411, train mean loss 0.00035964441012427737, test mean loss [0.00048867 0.0004251  0.00051148 0.0005867  0.0006066  0.0006146
 0.0006935 ]
Model epoch 898: train total loss -65.79038394048176, train mean loss 0.00030109089607722436, test mean loss [0.00048534 0.00043138 0.00050424 0.00059576 0.00061469 0.000618
 0.00067001]
Model epoch 899: train total loss -65.66401554850563, train mean loss 0.000342407432927989, test mean loss [0.0005046  0.00043341 0.00050509 0.00060093 0.0006     0.00060316
 0.00068667]
Model epoch 900: train total loss -65.63624782055544, train mean loss 0.00037948632287437573, test mean loss [0.00048058 0.00042835 0.00050835 0.00060118 0.0006091  0.00061949
 0.00066594]
Model epoch 901: train total loss -65.41179494832173, train mean loss 0.0003359589594193534, test mean loss [0.00047572 0.00042059 0.0005094  0.00061865 0.00058676 0.00057911
 0.0007358 ]
Model epoch 902: train total loss -65.83470442328277, train mean loss 0.0002904346328971986, test mean loss [0.00047286 0.00041494 0.00051167 0.00060877 0.00062109 0.00058573
 0.00071208]
Model epoch 903: train total loss -65.7218000463996, train mean loss 0.000306158546330043, test mean loss [0.00047082 0.00039609 0.00049981 0.00060081 0.00062044 0.00059972
 0.00069145]
Model epoch 904: train total loss -65.9030926117488, train mean loss 0.0003911397251455473, test mean loss [0.00048242 0.00040154 0.0005024  0.00060477 0.00058682 0.00062926
 0.00067158]
Model epoch 905: train total loss -65.56496717634573, train mean loss 0.0002786449801566782, test mean loss [0.00048957 0.00037357 0.00049951 0.00058994 0.00059043 0.00062588
 0.00069234]
Model epoch 906: train total loss -65.79592024591645, train mean loss 0.0003534560380281938, test mean loss [0.00048427 0.00038479 0.00051197 0.00059607 0.00060316 0.00059934
 0.0006828 ]
Model epoch 907: train total loss -65.62605376236166, train mean loss 0.00028218813119002353, test mean loss [0.000464   0.00038579 0.00049806 0.00059008 0.00060985 0.00058749
 0.00067189]
Model epoch 908: train total loss -65.79683022717526, train mean loss 0.0003226156311460881, test mean loss [0.0004791  0.00040691 0.00049972 0.00057355 0.00058567 0.00059563
 0.00067479]
Model epoch 909: train total loss -65.68611364064357, train mean loss 0.0004947223341221799, test mean loss [0.00046733 0.00039749 0.00051317 0.00059418 0.00060976 0.00058308
 0.00067883]
Model epoch 910: train total loss -65.98217983123918, train mean loss 0.0003179583087476418, test mean loss [0.00047147 0.00040936 0.00051909 0.00057065 0.00059303 0.00057711
 0.00068202]
Model epoch 911: train total loss -65.7855380549258, train mean loss 0.00022756974203696936, test mean loss [0.00046795 0.00041265 0.00052418 0.00060167 0.00058329 0.00060544
 0.00067371]
Model epoch 912: train total loss -65.62667499614766, train mean loss 0.0002841716874191494, test mean loss [0.00047494 0.00039573 0.00051453 0.00060837 0.00059032 0.00063495
 0.00078721]
Model epoch 913: train total loss -65.79274763029089, train mean loss 0.0003432480232591022, test mean loss [0.00047044 0.00039572 0.00050286 0.00058833 0.00060248 0.00062845
 0.00070866]
Model epoch 914: train total loss -65.75499942992829, train mean loss 0.00037972936971347856, test mean loss [0.00047176 0.00042328 0.00049665 0.00061135 0.00061522 0.00059355
 0.00068359]
Model trained in 915 epochs with 5000 transitions.
[2025-01-24 20:57:23,979][absl][INFO] - {'eval/walltime': 193.72699642181396, 'training/sps': 0.12461148810757486, 'training/walltime': 14450.133219480515, 'training/model_train_time': 6436.945133924484, 'training/other_time': 1587.1601567268372, 'training/model_horizon': 8, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(6000, dtype=int32), 'model/train_total_loss': Array(-65.75499943, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00037973, dtype=float64), 'model/test_total_loss': Array(-64.63296793, dtype=float64), 'model/test_mean_loss': Array(0.00055649, dtype=float64), 'model/train_epochs': 915, 'model/sec_per_epoch': 7.032465290892971, 'sac/actor_loss': Array(-22.94787702, dtype=float64), 'sac/alpha': Array(0.02677977, dtype=float32), 'sac/alpha_loss': Array(3.82023522e-05, dtype=float64), 'sac/buffer_current_size': Array(400000.03, dtype=float32), 'sac/critic_loss': Array(0.06685993, dtype=float64), 'eval/episode_forward_vel': Array(-154.0306099, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-4.74735008, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(23.18349447, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.23438975, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-66.24972469, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(24.92919334, dtype=float64), 'eval/episode_rew_roll': Array(24.12541698, dtype=float64), 'eval/episode_rew_side_motion': Array(19.68232759, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(17.28401682, dtype=float64), 'eval/episode_rew_yaw': Array(7.61539473, dtype=float64), 'eval/episode_rew_z_vel_change': Array(12.18565716, dtype=float64), 'eval/episode_reward': Array(56.67861439, dtype=float64), 'eval/episode_step_count': Array(117855., dtype=float64), 'eval/avg_episode_length': Array(486., dtype=float64), 'eval/epoch_eval_time': 30.056811332702637, 'eval/sps': 33.27032894244415}
Steps / Eval:  6000.0
Reward is  56.678614394346745
Model horizon updated to 10.
Hallucination updates per training step updated to 1000.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -36.946955681328426, train mean loss 0.03001193336065919, test mean loss [0.02849017 0.02445707 0.02125797 0.02414078 0.03357916 0.03817525
 0.02551002]
Model epoch 1: train total loss -44.55919051206596, train mean loss 0.0198445505775111, test mean loss [0.02255631 0.01838179 0.015041   0.01540829 0.01875146 0.01785335
 0.0183846 ]
Model epoch 2: train total loss -49.84279343286466, train mean loss 0.015270520938097443, test mean loss [0.0180452  0.01307461 0.01069015 0.01127629 0.01455795 0.01392616
 0.01417151]
Model epoch 3: train total loss -53.19995193362782, train mean loss 0.011563209919212229, test mean loss [0.01445712 0.00931549 0.0082129  0.00872359 0.01144371 0.01071649
 0.0115495 ]
Model epoch 4: train total loss -55.41045808565238, train mean loss 0.008424447483552366, test mean loss [0.01161832 0.00718474 0.00658972 0.0067873  0.00872511 0.00903753
 0.0093575 ]
Model epoch 5: train total loss -56.826059200317836, train mean loss 0.0069698555020943674, test mean loss [0.0092287  0.00568799 0.0053485  0.00558856 0.00678649 0.0073407
 0.00744418]
Model epoch 6: train total loss -57.70863418258962, train mean loss 0.006462675457059873, test mean loss [0.00729422 0.00489535 0.0045777  0.00471281 0.00554553 0.00615232
 0.00632007]
Model epoch 7: train total loss -59.03388019820716, train mean loss 0.004858990376800244, test mean loss [0.00586552 0.00434938 0.00407786 0.00414803 0.00468747 0.00534085
 0.00560787]
Model epoch 8: train total loss -59.57597728626871, train mean loss 0.004592153870684064, test mean loss [0.00483152 0.00391361 0.00369661 0.00373598 0.00407009 0.00458345
 0.00507852]
Model epoch 9: train total loss -59.51438140817232, train mean loss 0.004486196985725078, test mean loss [0.00408049 0.00363974 0.0034401  0.00336207 0.00364432 0.00410147
 0.00451137]
Model epoch 10: train total loss -60.534099374067594, train mean loss 0.003090868719251962, test mean loss [0.00356892 0.00334377 0.00322201 0.0031545  0.00325889 0.00377508
 0.00425848]
Model epoch 11: train total loss -60.48532857417135, train mean loss 0.0037631795055017192, test mean loss [0.00317593 0.00311377 0.00303037 0.0029436  0.00303562 0.00347988
 0.00387565]
Model epoch 12: train total loss -60.99868357986455, train mean loss 0.002906772252840554, test mean loss [0.00285126 0.00293996 0.00283962 0.00273789 0.00286145 0.00323885
 0.00360864]
Model epoch 13: train total loss -61.43373653461977, train mean loss 0.0025856090613547073, test mean loss [0.00264123 0.00277088 0.00272943 0.00260745 0.00267585 0.00306612
 0.00337715]
Model epoch 14: train total loss -61.45728167861527, train mean loss 0.0026157598925686957, test mean loss [0.00241437 0.00259504 0.00260624 0.0025217  0.00252286 0.00287409
 0.00333639]
Model epoch 15: train total loss -61.6192206250639, train mean loss 0.0029010551126189728, test mean loss [0.00229233 0.00244128 0.00246323 0.00237206 0.00239257 0.00267777
 0.00314684]
Model epoch 16: train total loss -61.95891827738178, train mean loss 0.0025284375862133905, test mean loss [0.00217602 0.00233934 0.00235769 0.00228723 0.00229771 0.00255508
 0.0030242 ]
Model epoch 17: train total loss -62.41129216348185, train mean loss 0.0019403624844014367, test mean loss [0.00206078 0.00222821 0.00224973 0.00217445 0.00221342 0.00243368
 0.00288449]
Model epoch 18: train total loss -62.06288696515739, train mean loss 0.0018093865562001893, test mean loss [0.00194305 0.00210099 0.00216327 0.00206391 0.00211922 0.00232307
 0.00277764]
Model epoch 19: train total loss -62.07418351235337, train mean loss 0.0016715205310873578, test mean loss [0.00190217 0.00207276 0.00208572 0.00199625 0.00205787 0.00221314
 0.00269317]
Model epoch 20: train total loss -62.35689249486452, train mean loss 0.002195834513296318, test mean loss [0.00176206 0.00199054 0.00202712 0.00189352 0.00196404 0.00214502
 0.00258837]
Model epoch 21: train total loss -62.46099112195509, train mean loss 0.0015794922935107897, test mean loss [0.0017475  0.00187831 0.00198694 0.00185015 0.00188906 0.00207171
 0.00252493]
Model epoch 22: train total loss -62.11650715983149, train mean loss 0.0017030055190505392, test mean loss [0.00166195 0.00181193 0.00190551 0.0017781  0.00181369 0.00200019
 0.00249439]
Model epoch 23: train total loss -62.07028498527635, train mean loss 0.002459099480221898, test mean loss [0.00160529 0.00173437 0.00185827 0.0017071  0.00177388 0.00192439
 0.002368  ]
Model epoch 24: train total loss -62.22054457710984, train mean loss 0.0020010293636675953, test mean loss [0.00155179 0.00175867 0.00182954 0.00166059 0.00171028 0.00187068
 0.0023592 ]
Model epoch 25: train total loss -62.716025216414586, train mean loss 0.0016012852881266105, test mean loss [0.00150785 0.00164444 0.00174185 0.00160289 0.00174318 0.00182096
 0.00227792]
Model epoch 26: train total loss -62.65268116013248, train mean loss 0.0016231517127548538, test mean loss [0.00145801 0.00160078 0.00171108 0.0015549  0.00163276 0.00177009
 0.00218659]
Model epoch 27: train total loss -62.401438958396994, train mean loss 0.0015478155590121425, test mean loss [0.00140086 0.00154209 0.0016392  0.00150031 0.00156615 0.00174307
 0.0021365 ]
Model epoch 28: train total loss -62.68864328090056, train mean loss 0.001326544272429462, test mean loss [0.00134259 0.00147565 0.0015867  0.00148421 0.00152818 0.00167745
 0.00214869]
Model epoch 29: train total loss -62.95909945221489, train mean loss 0.0011687794893047337, test mean loss [0.00129469 0.00145926 0.00155627 0.00145569 0.0015221  0.00164325
 0.00206627]
Model epoch 30: train total loss -62.509831405889756, train mean loss 0.0015356867148628196, test mean loss [0.00123776 0.0014     0.00153036 0.00142647 0.00147375 0.00162551
 0.00202533]
Model epoch 31: train total loss -63.20920602917781, train mean loss 0.0013762999716913167, test mean loss [0.00120328 0.00137978 0.00148663 0.0013781  0.00144358 0.00156123
 0.001995  ]
Model epoch 32: train total loss -62.815810403000604, train mean loss 0.0013412986272896622, test mean loss [0.00119062 0.00135112 0.00146973 0.00134072 0.00139943 0.00152783
 0.0019337 ]
Model epoch 33: train total loss -62.95984749039684, train mean loss 0.001284500377506044, test mean loss [0.00115759 0.00131163 0.00140636 0.00131294 0.00141154 0.00148403
 0.00191605]
Model epoch 34: train total loss -63.100068642376996, train mean loss 0.0014399217164062707, test mean loss [0.00113729 0.00128908 0.00139121 0.00129185 0.0013607  0.00147083
 0.00189919]
Model epoch 35: train total loss -63.37872626193203, train mean loss 0.001268554833946457, test mean loss [0.00109825 0.00126381 0.00133765 0.00126009 0.00135022 0.00143649
 0.00183314]
Model epoch 36: train total loss -63.00771465720691, train mean loss 0.0012917275550986347, test mean loss [0.0010566  0.00123322 0.00131857 0.00121156 0.00130016 0.00143037
 0.00179275]
Model epoch 37: train total loss -63.44314470688371, train mean loss 0.0010178246209629775, test mean loss [0.00104205 0.00121676 0.00131237 0.00119377 0.00127262 0.00138874
 0.00174195]
Model epoch 38: train total loss -63.33270011919413, train mean loss 0.0010276499481794302, test mean loss [0.00103211 0.00120569 0.00124936 0.00116165 0.00124584 0.00135576
 0.00172246]
Model epoch 39: train total loss -63.32568114847931, train mean loss 0.0010749961096033483, test mean loss [0.00099785 0.00116746 0.00124576 0.00113283 0.00123973 0.00131179
 0.00165934]
Model epoch 40: train total loss -63.1678168799401, train mean loss 0.001226203200894735, test mean loss [0.00099116 0.00115431 0.00120644 0.00112482 0.00121596 0.00127979
 0.00166699]
Model epoch 41: train total loss -63.534415229640274, train mean loss 0.0009363631451297896, test mean loss [0.00095205 0.00114003 0.00118638 0.00111463 0.00119092 0.00127439
 0.0016394 ]
Model epoch 42: train total loss -63.42985613045133, train mean loss 0.0009169743542706245, test mean loss [0.00096209 0.00110641 0.00116664 0.00107322 0.00114041 0.00124044
 0.00161705]
Model epoch 43: train total loss -63.411706718814315, train mean loss 0.0009986498607349893, test mean loss [0.00092649 0.00109957 0.00114161 0.00108007 0.00113565 0.00122457
 0.00160059]
Model epoch 44: train total loss -63.417578285646314, train mean loss 0.0008584258315979849, test mean loss [0.00090557 0.00107245 0.00114193 0.00104039 0.00111136 0.00120596
 0.0015938 ]
Model epoch 45: train total loss -63.64280941959923, train mean loss 0.0010029218285736957, test mean loss [0.00089418 0.0010492  0.00110207 0.00103966 0.00109927 0.00117118
 0.00155025]
Model epoch 46: train total loss -63.49893525390894, train mean loss 0.0013830240282030508, test mean loss [0.00087785 0.0010421  0.00110162 0.00103261 0.00107745 0.00115099
 0.00153884]
Model epoch 47: train total loss -63.45323869333505, train mean loss 0.0009232391938447118, test mean loss [0.00087336 0.00103107 0.00108691 0.00100182 0.00104901 0.00110961
 0.00150186]
Model epoch 48: train total loss -63.59241068452565, train mean loss 0.0011189465891821204, test mean loss [0.00084735 0.00100363 0.0010473  0.0009822  0.0010544  0.00109757
 0.00150882]
Model epoch 49: train total loss -63.466800074484645, train mean loss 0.0011197772858291702, test mean loss [0.00086317 0.000985   0.0010418  0.00099872 0.00104942 0.00109041
 0.00145075]
Model epoch 50: train total loss -63.86842654328167, train mean loss 0.0011321969047007503, test mean loss [0.0008262  0.00096415 0.00103347 0.0009535  0.00101043 0.00106022
 0.00142933]
Model epoch 51: train total loss -63.6532137376132, train mean loss 0.0009622396963539964, test mean loss [0.00082421 0.00095129 0.00101385 0.00094043 0.00102781 0.00104036
 0.00140889]
Model epoch 52: train total loss -63.59467054739277, train mean loss 0.0007959102478104906, test mean loss [0.00082405 0.00094599 0.00101678 0.00092276 0.00101661 0.00102887
 0.00136049]
Model epoch 53: train total loss -63.811336119029875, train mean loss 0.001008167907610269, test mean loss [0.00080688 0.00092246 0.00098283 0.00090517 0.00097757 0.00101565
 0.0013573 ]
Model epoch 54: train total loss -63.64037236481081, train mean loss 0.0010425155560104947, test mean loss [0.00081561 0.00092084 0.00097858 0.00089672 0.00098914 0.00098194
 0.00134198]
Model epoch 55: train total loss -63.58753568173355, train mean loss 0.0008712472837346172, test mean loss [0.00077157 0.00091051 0.00094931 0.00090134 0.00095298 0.00097376
 0.00134973]
Model epoch 56: train total loss -63.71032561814817, train mean loss 0.000848633552375109, test mean loss [0.00077112 0.00088443 0.00093195 0.00086768 0.0009651  0.00095939
 0.00132191]
Model epoch 57: train total loss -63.84886253559327, train mean loss 0.0007517180733070942, test mean loss [0.00076309 0.00086964 0.00090638 0.00085629 0.00094946 0.00093573
 0.00129471]
Model epoch 58: train total loss -63.48425300678834, train mean loss 0.0008034710606835561, test mean loss [0.00076407 0.0008682  0.00091465 0.00084702 0.00093688 0.00093259
 0.00126739]
Model epoch 59: train total loss -63.9650438135953, train mean loss 0.0008175485531478562, test mean loss [0.00073496 0.00083906 0.00092511 0.0008377  0.00093318 0.00093099
 0.0012661 ]
Model epoch 60: train total loss -63.9702509756003, train mean loss 0.0008318972333450831, test mean loss [0.00072831 0.00084335 0.0008757  0.00083171 0.00089955 0.00089097
 0.00123708]
Model epoch 61: train total loss -63.495036689259486, train mean loss 0.0008456562488765654, test mean loss [0.00072151 0.00084492 0.00086472 0.00082353 0.00092145 0.00086875
 0.00123118]
Model epoch 62: train total loss -63.94554451931758, train mean loss 0.0007580424845249167, test mean loss [0.00068755 0.0008122  0.00085548 0.0008014  0.00089164 0.00090555
 0.00120621]
Model epoch 63: train total loss -63.88780328339069, train mean loss 0.0008434415406585181, test mean loss [0.00068452 0.00082386 0.00084383 0.00079686 0.00089032 0.00086141
 0.00123158]
Model epoch 64: train total loss -63.895413167360175, train mean loss 0.0007564521331635372, test mean loss [0.00069417 0.00081844 0.00082947 0.0007812  0.00086108 0.00085661
 0.00118465]
Model epoch 65: train total loss -63.57682540803551, train mean loss 0.0009505666911662802, test mean loss [0.00066334 0.00079215 0.00083812 0.00077488 0.00086775 0.00083959
 0.00116461]
Model epoch 66: train total loss -63.78929090093753, train mean loss 0.0007119512202404534, test mean loss [0.00065622 0.00079785 0.00082069 0.00077649 0.00083753 0.00081792
 0.00116191]
Model epoch 67: train total loss -63.74152118268745, train mean loss 0.0007366024906383241, test mean loss [0.00066748 0.00076392 0.00081492 0.0007803  0.00084805 0.00080524
 0.0011351 ]
Model epoch 68: train total loss -63.83884379903401, train mean loss 0.000799759281820952, test mean loss [0.00065822 0.00078023 0.0008008  0.0007468  0.00085539 0.00080166
 0.00113938]
Model epoch 69: train total loss -64.31535363244399, train mean loss 0.0008255406227828802, test mean loss [0.00063313 0.00076037 0.00079556 0.00073904 0.00081865 0.0007833
 0.0011194 ]
Model epoch 70: train total loss -64.00003995194194, train mean loss 0.000590279142092052, test mean loss [0.00065418 0.00074112 0.00079433 0.00073181 0.00080444 0.00077395
 0.00110398]
Model epoch 71: train total loss -64.01137979709476, train mean loss 0.0007020351877364906, test mean loss [0.0006262  0.00074145 0.00077495 0.00072671 0.00079894 0.0007769
 0.00108855]
Model epoch 72: train total loss -63.96327180770403, train mean loss 0.000708398363404593, test mean loss [0.00062901 0.00073205 0.00075702 0.00069811 0.00080748 0.00074742
 0.00109355]
Model epoch 73: train total loss -64.03370150428681, train mean loss 0.0006976688648934901, test mean loss [0.00061182 0.00071888 0.00077867 0.00070954 0.00078337 0.00076283
 0.00108504]
Model epoch 74: train total loss -63.97900261282319, train mean loss 0.0007777173143600225, test mean loss [0.00060598 0.00073876 0.00073952 0.00070599 0.00078105 0.00073354
 0.00107061]
Model epoch 75: train total loss -63.88805279528403, train mean loss 0.0006625861008305174, test mean loss [0.00058936 0.00071488 0.00073037 0.00069013 0.00076906 0.00072975
 0.00104976]
Model epoch 76: train total loss -64.09974142162102, train mean loss 0.0007188050268646254, test mean loss [0.00060255 0.0007092  0.00073749 0.00067622 0.00078433 0.0007287
 0.00106836]
Model epoch 77: train total loss -64.00616449185868, train mean loss 0.0006013671742173093, test mean loss [0.00057443 0.00068629 0.00070955 0.00066592 0.00075479 0.00072347
 0.00106756]
Model epoch 78: train total loss -64.09557893008291, train mean loss 0.0005793375633242571, test mean loss [0.00057572 0.00070414 0.00071544 0.00066445 0.00072408 0.00071371
 0.00104262]
Model epoch 79: train total loss -64.13833737056126, train mean loss 0.0007298448173685029, test mean loss [0.00057599 0.0006934  0.00069686 0.00065587 0.00072957 0.00070249
 0.00102683]
Model epoch 80: train total loss -64.05801346379256, train mean loss 0.0006741288863272339, test mean loss [0.000558   0.00067571 0.00068354 0.00065288 0.00074592 0.00068994
 0.00100119]
Model epoch 81: train total loss -64.13463468089036, train mean loss 0.0007108390398464371, test mean loss [0.00057133 0.00066717 0.00066696 0.00069094 0.0007316  0.00070464
 0.00100683]
Model epoch 82: train total loss -64.06964947752455, train mean loss 0.0005727538570156201, test mean loss [0.00055629 0.00066253 0.00068024 0.00066088 0.00071571 0.00071575
 0.00097928]
Model epoch 83: train total loss -63.95253268844615, train mean loss 0.0006328864493364893, test mean loss [0.00055905 0.00066037 0.00067755 0.00063299 0.00069375 0.00066929
 0.00098256]
Model epoch 84: train total loss -63.91393981817565, train mean loss 0.0005516919918915341, test mean loss [0.00054947 0.00064236 0.00067826 0.00064793 0.00068491 0.00067674
 0.000975  ]
Model epoch 85: train total loss -64.0485278450534, train mean loss 0.0008318822735088134, test mean loss [0.0005527  0.00062969 0.00065956 0.00064371 0.00067873 0.00066267
 0.00095575]
Model epoch 86: train total loss -64.1465360751195, train mean loss 0.0006226371661900662, test mean loss [0.00054078 0.00063197 0.0006601  0.00061578 0.000722   0.00065444
 0.00096819]
Model epoch 87: train total loss -64.2240375315403, train mean loss 0.0007675764544067874, test mean loss [0.00055471 0.00062909 0.00065473 0.00060454 0.00069786 0.00064278
 0.00095861]
Model epoch 88: train total loss -64.20826601927804, train mean loss 0.0006387107658603188, test mean loss [0.00053355 0.00062545 0.00063204 0.00062017 0.00067296 0.00065634
 0.00095266]
Model epoch 89: train total loss -64.00113851572031, train mean loss 0.0005515062087203082, test mean loss [0.00055211 0.00062351 0.00063427 0.00061327 0.00065539 0.00063685
 0.00093136]
Model epoch 90: train total loss -64.01586811462833, train mean loss 0.0006580358233460055, test mean loss [0.00052524 0.00060826 0.00060972 0.00060321 0.0006639  0.00063205
 0.00093195]
Model epoch 91: train total loss -64.43034739308027, train mean loss 0.0005956679907823284, test mean loss [0.0005371  0.00060519 0.00060192 0.00061772 0.00066292 0.00064086
 0.00092439]
Model epoch 92: train total loss -64.40048528522749, train mean loss 0.0006173809574775373, test mean loss [0.00051869 0.00061857 0.00060951 0.0005981  0.00064635 0.0006161
 0.00091822]
Model epoch 93: train total loss -64.1613739635171, train mean loss 0.0006256712324019487, test mean loss [0.00051433 0.00061999 0.00058561 0.00057889 0.00062848 0.00062074
 0.00090474]
Model epoch 94: train total loss -64.4446357788764, train mean loss 0.0007413508649751172, test mean loss [0.00050654 0.00057574 0.00059972 0.00058912 0.00064348 0.00061667
 0.00092081]
Model epoch 95: train total loss -64.23540692419603, train mean loss 0.00046733951960978813, test mean loss [0.00050742 0.00057916 0.00057867 0.00056108 0.00062467 0.0006224
 0.00089367]
Model epoch 96: train total loss -63.94455335042738, train mean loss 0.0007117107791748827, test mean loss [0.00050297 0.0005827  0.00058726 0.00056988 0.00064457 0.00060072
 0.00087921]
Model epoch 97: train total loss -64.44049017226475, train mean loss 0.00047564816469172083, test mean loss [0.00050043 0.00057246 0.00057237 0.00058615 0.00065065 0.00058908
 0.00085686]
Model epoch 98: train total loss -64.26908790505331, train mean loss 0.00042867708696059403, test mean loss [0.00051758 0.0005686  0.00059544 0.0005647  0.00060458 0.00058453
 0.00089213]
Model epoch 99: train total loss -64.30454461627232, train mean loss 0.0005972483913445135, test mean loss [0.00049478 0.00057037 0.0005748  0.00055651 0.00061941 0.00058298
 0.00087378]
Model epoch 100: train total loss -64.22006094119013, train mean loss 0.0006693790798035509, test mean loss [0.00050074 0.00056603 0.00056693 0.00055104 0.00060773 0.00057898
 0.00085174]
Model epoch 101: train total loss -64.21155251942683, train mean loss 0.000536731953324007, test mean loss [0.00049161 0.00056053 0.00056162 0.00053524 0.00060168 0.00058048
 0.00085791]
Model epoch 102: train total loss -64.07313113255802, train mean loss 0.000500428195228853, test mean loss [0.00047304 0.00053926 0.00055164 0.00054626 0.00059497 0.00058236
 0.00084563]
Model epoch 103: train total loss -64.1517013727674, train mean loss 0.0006677028306044856, test mean loss [0.00048482 0.00054361 0.00054486 0.00053125 0.00060691 0.00057615
 0.00084974]
Model epoch 104: train total loss -64.34036265428139, train mean loss 0.00047829823561274285, test mean loss [0.00049515 0.00054293 0.00055594 0.00053292 0.00058256 0.0005779
 0.00084695]
Model epoch 105: train total loss -64.14245377058134, train mean loss 0.0005059679132056943, test mean loss [0.00047631 0.00052158 0.00053571 0.00051565 0.00058205 0.00055494
 0.00081485]
Model epoch 106: train total loss -64.52766871134, train mean loss 0.0005274385738743911, test mean loss [0.00047204 0.00053962 0.00053389 0.00054091 0.00057773 0.00056195
 0.00081471]
Model epoch 107: train total loss -64.43132590049558, train mean loss 0.0004629681651513528, test mean loss [0.00046325 0.00053122 0.00053181 0.00052315 0.00057912 0.000543
 0.00082318]
Model epoch 108: train total loss -64.58986660626395, train mean loss 0.0004246029653153694, test mean loss [0.00046654 0.00052662 0.0005171  0.0005282  0.00057525 0.00054278
 0.0008259 ]
Model epoch 109: train total loss -64.33742805617103, train mean loss 0.00047966063166970105, test mean loss [0.00047605 0.00052973 0.00052996 0.00050987 0.00058028 0.00052912
 0.00079137]
Model epoch 110: train total loss -64.31275170215503, train mean loss 0.0005798943554601961, test mean loss [0.00045968 0.0005163  0.00052529 0.00051297 0.00057439 0.0005379
 0.00079753]
Model epoch 111: train total loss -64.24344209100165, train mean loss 0.0005134293726780022, test mean loss [0.00045843 0.00050995 0.00051006 0.00049561 0.00055283 0.00054182
 0.00079113]
Model epoch 112: train total loss -64.57783893384584, train mean loss 0.00046034581357182365, test mean loss [0.00044926 0.00050392 0.00051489 0.00050063 0.00054973 0.00053093
 0.00079045]
Model epoch 113: train total loss -64.62588287409169, train mean loss 0.0003747291984738439, test mean loss [0.00043643 0.00050489 0.00051428 0.00049261 0.00054338 0.00052773
 0.00079878]
Model epoch 114: train total loss -64.37728584471301, train mean loss 0.0005608253329869697, test mean loss [0.00044014 0.00049991 0.00050767 0.00049905 0.00054604 0.0005081
 0.00078689]
Model epoch 115: train total loss -64.31186393175598, train mean loss 0.0005635398840548013, test mean loss [0.00043048 0.00048746 0.00050084 0.0004949  0.00054245 0.00051517
 0.00080502]
Model epoch 116: train total loss -64.29628088964074, train mean loss 0.0004341945626614092, test mean loss [0.00045971 0.00047879 0.00049583 0.00047101 0.00056017 0.00051547
 0.00078201]
Model epoch 117: train total loss -64.2668029697605, train mean loss 0.0004228547332097116, test mean loss [0.0004436  0.00047629 0.00050476 0.00049275 0.00053909 0.00050242
 0.00075385]
Model epoch 118: train total loss -64.37166384163568, train mean loss 0.0004530316473838873, test mean loss [0.00042996 0.00047609 0.00048179 0.00048167 0.00054081 0.00050202
 0.0007564 ]
Model epoch 119: train total loss -64.32149274591569, train mean loss 0.0004493299225862505, test mean loss [0.00043677 0.00047997 0.00048551 0.00048344 0.00056868 0.00049809
 0.00074739]
Model epoch 120: train total loss -64.41119500589947, train mean loss 0.0004614512458853834, test mean loss [0.00041267 0.00047651 0.00048749 0.00048121 0.00052452 0.00049267
 0.00074931]
Model epoch 121: train total loss -64.28945745196448, train mean loss 0.0004725780136101825, test mean loss [0.00041697 0.00046493 0.00045905 0.00048243 0.00054661 0.0004962
 0.0007612 ]
Model epoch 122: train total loss -64.52113530533819, train mean loss 0.0005452493109133216, test mean loss [0.00041939 0.00046676 0.00047457 0.00047152 0.0005101  0.00049951
 0.00074104]
Model epoch 123: train total loss -64.49840436376054, train mean loss 0.00044419956516904356, test mean loss [0.00041968 0.00048809 0.00046852 0.00045882 0.00051383 0.00050361
 0.00074198]
Model epoch 124: train total loss -64.26750080036211, train mean loss 0.0004447266359449141, test mean loss [0.00041295 0.00046461 0.00045692 0.00046031 0.00051317 0.00049339
 0.00072559]
Model epoch 125: train total loss -64.72582366017588, train mean loss 0.0005161185642288636, test mean loss [0.00041411 0.00045902 0.00044941 0.00046213 0.00051237 0.00049289
 0.00075262]
Model epoch 126: train total loss -64.55886294835722, train mean loss 0.00033867993185937156, test mean loss [0.00040586 0.0004504  0.00046079 0.00045556 0.00052826 0.00047496
 0.00071989]
Model epoch 127: train total loss -64.64190318319321, train mean loss 0.0004068920689835329, test mean loss [0.0004199  0.00045328 0.00045596 0.00046421 0.00050681 0.00047332
 0.00071864]
Model epoch 128: train total loss -64.34882193448803, train mean loss 0.00044986503484040316, test mean loss [0.00043134 0.00044104 0.00046083 0.0004591  0.00048639 0.00047001
 0.0007082 ]
Model epoch 129: train total loss -64.55072433841005, train mean loss 0.0004210201319614774, test mean loss [0.00041159 0.00044091 0.00044951 0.00045477 0.00049508 0.00047458
 0.00070307]
Model epoch 130: train total loss -64.52055855385615, train mean loss 0.0004305574853818322, test mean loss [0.0004004  0.00044111 0.00047705 0.00043451 0.0005039  0.00046586
 0.00070353]
Model epoch 131: train total loss -64.45212914229704, train mean loss 0.00045910181239960506, test mean loss [0.00038808 0.00044081 0.00046209 0.00042928 0.00048474 0.00047227
 0.00068728]
Model epoch 132: train total loss -64.35151009394941, train mean loss 0.00047646784316099296, test mean loss [0.00039891 0.0004448  0.00046859 0.00042699 0.00048528 0.00044481
 0.00070207]
Model epoch 133: train total loss -64.5993580418505, train mean loss 0.0004605313278001307, test mean loss [0.00040085 0.00044158 0.00044835 0.00044299 0.00049392 0.00045266
 0.00068982]
Model epoch 134: train total loss -64.55921540187384, train mean loss 0.00044380547071776535, test mean loss [0.00041495 0.0004362  0.00043157 0.00043412 0.00047747 0.00045568
 0.00069345]
Model epoch 135: train total loss -64.81126129578776, train mean loss 0.0003571823687103979, test mean loss [0.00039959 0.00042821 0.00044571 0.00042236 0.00048697 0.00044471
 0.00069896]
Model epoch 136: train total loss -64.52212320351914, train mean loss 0.0004112817545127146, test mean loss [0.00038749 0.00045571 0.00044402 0.00043069 0.00049478 0.00043746
 0.00068408]
Model epoch 137: train total loss -64.78467788594203, train mean loss 0.00037406174107920237, test mean loss [0.00039342 0.00042144 0.00044018 0.00041604 0.00048493 0.00043668
 0.00068009]
Model epoch 138: train total loss -64.51453671440112, train mean loss 0.00041101878481378094, test mean loss [0.00039297 0.0004282  0.00042315 0.00042027 0.00047075 0.00043191
 0.00066839]
Model epoch 139: train total loss -64.5637403445447, train mean loss 0.0005094885307002152, test mean loss [0.00040062 0.00042365 0.00043751 0.00040793 0.00046896 0.00045651
 0.00066801]
Model epoch 140: train total loss -64.75212103535499, train mean loss 0.0004957536789929356, test mean loss [0.00039791 0.00041003 0.00042168 0.00041438 0.00046731 0.0004332
 0.0006808 ]
Model epoch 141: train total loss -64.52921321018208, train mean loss 0.00035499188061815395, test mean loss [0.00038588 0.00040281 0.00043054 0.00047145 0.00047303 0.00042876
 0.00068321]
Model epoch 142: train total loss -64.59575047345139, train mean loss 0.00046192841641396143, test mean loss [0.00037953 0.00041516 0.00041448 0.00044471 0.0004752  0.00042724
 0.00065515]
Model epoch 143: train total loss -64.55818224146348, train mean loss 0.00047586083133521425, test mean loss [0.00038365 0.00041051 0.00042447 0.00042906 0.00045719 0.00042541
 0.00065385]
Model epoch 144: train total loss -64.42314833655362, train mean loss 0.00031965399217593476, test mean loss [0.00038199 0.00040062 0.00041173 0.00040476 0.00047751 0.00044412
 0.00066826]
Model epoch 145: train total loss -64.57811480339205, train mean loss 0.00035475406488866094, test mean loss [0.00037774 0.00041479 0.0004305  0.00041339 0.00046397 0.00041553
 0.00063876]
Model epoch 146: train total loss -64.54371246433764, train mean loss 0.0004034916479155684, test mean loss [0.00036862 0.00040016 0.00040169 0.00039944 0.00045918 0.00042801
 0.00065132]
Model epoch 147: train total loss -64.57561448804142, train mean loss 0.00043621812715776174, test mean loss [0.00038322 0.00039413 0.00040627 0.00038937 0.00044927 0.00042538
 0.00063692]
Model epoch 148: train total loss -64.67586929367151, train mean loss 0.00040606465306808267, test mean loss [0.00036419 0.00039887 0.00039737 0.00041046 0.0004427  0.00042855
 0.00064496]
Model epoch 149: train total loss -64.59930749412533, train mean loss 0.00039541205413785326, test mean loss [0.00037251 0.00040683 0.00039815 0.00039664 0.00044817 0.0004125
 0.00064364]
Model epoch 150: train total loss -64.61173073016036, train mean loss 0.0003216762238046597, test mean loss [0.00036735 0.00040454 0.00041309 0.00040315 0.00044285 0.00041033
 0.00064406]
Model epoch 151: train total loss -64.69269779594735, train mean loss 0.0004140909022625064, test mean loss [0.0003983  0.00039372 0.00038654 0.00038409 0.00044274 0.00040409
 0.00062406]
Model epoch 152: train total loss -64.57148634301547, train mean loss 0.00041063812173194913, test mean loss [0.00038858 0.00041993 0.00038668 0.00038262 0.00044866 0.00041109
 0.00062987]
Model epoch 153: train total loss -64.5463857877229, train mean loss 0.000342695756931819, test mean loss [0.00037289 0.00040557 0.00038346 0.00038373 0.00042736 0.00041738
 0.00061564]
Model epoch 154: train total loss -64.6756051390477, train mean loss 0.0003325242625375395, test mean loss [0.00036499 0.00038885 0.00038255 0.00040319 0.00043354 0.00042424
 0.00062446]
Model epoch 155: train total loss -65.06185092807013, train mean loss 0.00034999947288267354, test mean loss [0.00039371 0.0003754  0.00040103 0.00037293 0.00043544 0.00040558
 0.0006197 ]
Model epoch 156: train total loss -64.60008772532514, train mean loss 0.00039694870176533263, test mean loss [0.00037288 0.00038765 0.00038603 0.00037899 0.00042716 0.0003994
 0.000605  ]
Model epoch 157: train total loss -64.81085887895298, train mean loss 0.0005186511514448282, test mean loss [0.00036858 0.0004027  0.00037149 0.00038839 0.00042967 0.00039761
 0.0006085 ]
Model epoch 158: train total loss -64.67949926319716, train mean loss 0.00042868597090064454, test mean loss [0.00035654 0.0003879  0.00037951 0.00036952 0.00042231 0.00038103
 0.00061748]
Model epoch 159: train total loss -64.62685157191339, train mean loss 0.000413487924523613, test mean loss [0.00034685 0.00037549 0.0003838  0.00037738 0.00043629 0.00038193
 0.00059714]
Model epoch 160: train total loss -64.5688914836385, train mean loss 0.00033708049412385074, test mean loss [0.00035375 0.00037667 0.00037952 0.00039318 0.00043529 0.00039736
 0.00059828]
Model epoch 161: train total loss -64.77620507702568, train mean loss 0.0003101565704880812, test mean loss [0.00034626 0.00038134 0.00038308 0.00036836 0.00041403 0.00039496
 0.00059138]
Model epoch 162: train total loss -64.51879091730957, train mean loss 0.0003581657013008496, test mean loss [0.00035085 0.00038189 0.00037168 0.00036228 0.00042209 0.00039465
 0.00058592]
Model epoch 163: train total loss -64.54430049248457, train mean loss 0.00030805428448894053, test mean loss [0.00034957 0.00039485 0.00038222 0.00037021 0.00041951 0.00038383
 0.00058738]
Model epoch 164: train total loss -64.67553807173587, train mean loss 0.0003754520074452067, test mean loss [0.00034099 0.00039475 0.00037987 0.0003849  0.00041088 0.00037739
 0.00059021]
Model epoch 165: train total loss -64.73633261270012, train mean loss 0.000394846922412077, test mean loss [0.00036227 0.00037693 0.00036701 0.00036776 0.00042004 0.00037469
 0.00060032]
Model epoch 166: train total loss -64.71830719182552, train mean loss 0.00043387605574772754, test mean loss [0.0003532  0.00038834 0.00037112 0.00036434 0.00040143 0.00037936
 0.00057759]
Model epoch 167: train total loss -64.59116346541596, train mean loss 0.0003382861848729562, test mean loss [0.00034702 0.00037419 0.00036568 0.00036799 0.00040994 0.00037931
 0.00056917]
Model epoch 168: train total loss -64.85639277499502, train mean loss 0.00034760037651515, test mean loss [0.00035088 0.00036016 0.00036803 0.00036486 0.00040237 0.00038215
 0.00058614]
Model epoch 169: train total loss -64.68393575302301, train mean loss 0.00043854620793058453, test mean loss [0.00034324 0.00036851 0.0003685  0.00035346 0.00041035 0.00038808
 0.0005702 ]
Model epoch 170: train total loss -64.3497859369821, train mean loss 0.00035206838467861094, test mean loss [0.00034668 0.00036779 0.00036542 0.00036195 0.00042025 0.00038147
 0.00057782]
Model epoch 171: train total loss -64.47699910229454, train mean loss 0.00035694083819541567, test mean loss [0.00036444 0.00039656 0.00036218 0.00036142 0.00040223 0.00037252
 0.00056646]
Model epoch 172: train total loss -64.9023702968092, train mean loss 0.0003412539479853278, test mean loss [0.00034258 0.00038084 0.00035089 0.00035945 0.00040152 0.00036811
 0.00057749]
Model epoch 173: train total loss -64.72541247839386, train mean loss 0.00036289377535541007, test mean loss [0.00034415 0.00035957 0.00036068 0.00035557 0.00041416 0.00038604
 0.00057559]
Model epoch 174: train total loss -64.48141792932084, train mean loss 0.0003970002773248613, test mean loss [0.00035143 0.00036563 0.00037618 0.00034762 0.00040566 0.00037322
 0.0005468 ]
Model epoch 175: train total loss -64.64955388091923, train mean loss 0.00035326595546831505, test mean loss [0.00034427 0.00036588 0.00036216 0.00035451 0.00040079 0.00035952
 0.00055563]
Model epoch 176: train total loss -64.42695413565498, train mean loss 0.00037506096232396154, test mean loss [0.00033495 0.00037723 0.00036773 0.00037729 0.00040189 0.00037224
 0.0005482 ]
Model epoch 177: train total loss -64.7167766394418, train mean loss 0.00033163873250562954, test mean loss [0.00033714 0.00037619 0.0003657  0.00034766 0.00038833 0.00036295
 0.00054225]
Model epoch 178: train total loss -64.71252627637597, train mean loss 0.00035470158799344323, test mean loss [0.00033107 0.00035375 0.0003606  0.00035554 0.00038847 0.0003802
 0.00055631]
Model epoch 179: train total loss -64.56962600797578, train mean loss 0.0003964308185229372, test mean loss [0.00032418 0.00035872 0.00036057 0.00035117 0.0004125  0.00036914
 0.00055142]
Model epoch 180: train total loss -64.60772488977891, train mean loss 0.0003080719323036644, test mean loss [0.0003571  0.00037348 0.00035694 0.00035109 0.00039406 0.00036945
 0.0005333 ]
Model epoch 181: train total loss -64.61820217921371, train mean loss 0.00035751278071303615, test mean loss [0.00035245 0.00036224 0.00034966 0.00034758 0.00039099 0.00037376
 0.00054731]
Model epoch 182: train total loss -64.58565217457246, train mean loss 0.00039401053949300965, test mean loss [0.00033387 0.00036526 0.00036336 0.00035961 0.00039045 0.00036532
 0.00052434]
Model epoch 183: train total loss -64.69387309401559, train mean loss 0.0004090436423288643, test mean loss [0.00033401 0.00034782 0.00035188 0.00034388 0.00038444 0.00036231
 0.00052594]
Model epoch 184: train total loss -64.73125598192912, train mean loss 0.00032132087814308206, test mean loss [0.00032266 0.00035766 0.00036534 0.00035229 0.00039735 0.00034569
 0.00053119]
Model epoch 185: train total loss -64.89405013656388, train mean loss 0.0003398283617037542, test mean loss [0.00034129 0.00035473 0.00035999 0.0003399  0.0003861  0.00034952
 0.00052574]
Model epoch 186: train total loss -64.74509718136572, train mean loss 0.0003449743429038288, test mean loss [0.00033007 0.00034372 0.00036299 0.00034154 0.00037425 0.00035715
 0.00051867]
Model epoch 187: train total loss -64.824949913339, train mean loss 0.0002978628628978045, test mean loss [0.00033185 0.00036084 0.0003502  0.00033531 0.00037014 0.00036217
 0.00052144]
Model epoch 188: train total loss -64.96945813325775, train mean loss 0.0003486666252288311, test mean loss [0.00032821 0.00034243 0.00035022 0.00033468 0.00038006 0.00034731
 0.00052687]
Model epoch 189: train total loss -64.7899438886935, train mean loss 0.00042701920938086133, test mean loss [0.00033108 0.00034077 0.00034267 0.00033751 0.00039517 0.00035002
 0.0005269 ]
Model epoch 190: train total loss -64.56150393413769, train mean loss 0.00042528293616566753, test mean loss [0.00032308 0.00035285 0.0003547  0.00033446 0.00040194 0.00034159
 0.00051358]
Model epoch 191: train total loss -64.47189860404254, train mean loss 0.0003888522468418644, test mean loss [0.00031929 0.00034727 0.00033888 0.00034995 0.00036997 0.00033913
 0.00051657]
Model epoch 192: train total loss -64.57422395693997, train mean loss 0.0003199252015456014, test mean loss [0.0003259  0.00035129 0.0003447  0.0003408  0.00037633 0.00034399
 0.00052273]
Model epoch 193: train total loss -64.77591140953562, train mean loss 0.0003315274676343588, test mean loss [0.00031259 0.00034031 0.00033716 0.00032741 0.00037894 0.00033548
 0.00051015]
Model epoch 194: train total loss -64.7144173453867, train mean loss 0.0003761845136521213, test mean loss [0.00032181 0.00033938 0.00034737 0.00032854 0.00038149 0.0003428
 0.00050476]
Model epoch 195: train total loss -64.71666309811197, train mean loss 0.0003867031857721659, test mean loss [0.0003199  0.0003409  0.00032872 0.00033396 0.00036956 0.00032377
 0.00050556]
Model epoch 196: train total loss -64.91102113254742, train mean loss 0.00031455880302648916, test mean loss [0.00031773 0.00032075 0.0003348  0.00035649 0.00038241 0.00034527
 0.00050824]
Model epoch 197: train total loss -64.49541119803034, train mean loss 0.00032062426751754657, test mean loss [0.00032439 0.00033237 0.00034057 0.00035134 0.0003654  0.00033313
 0.00050152]
Model epoch 198: train total loss -64.77907073973721, train mean loss 0.00036408220314935145, test mean loss [0.00033252 0.00032897 0.00033559 0.00034383 0.00036012 0.00035595
 0.00047746]
Model epoch 199: train total loss -64.6811770770296, train mean loss 0.00030424225562172987, test mean loss [0.00032158 0.00032239 0.00033284 0.00032935 0.00036436 0.00034051
 0.00049978]
Model epoch 200: train total loss -64.54971496563171, train mean loss 0.00034360893773929514, test mean loss [0.00032095 0.00033573 0.00033538 0.00031807 0.00036615 0.00033791
 0.00049669]
Model epoch 201: train total loss -65.08580656086251, train mean loss 0.00033258038856711806, test mean loss [0.00032021 0.00032927 0.00032588 0.00032929 0.00037142 0.00032761
 0.00048321]
Model epoch 202: train total loss -64.84349263023529, train mean loss 0.00034343670675336316, test mean loss [0.0004028  0.0003323  0.00034164 0.00032814 0.00036693 0.00032599
 0.00049661]
Model epoch 203: train total loss -64.8080713035668, train mean loss 0.00030040206132510956, test mean loss [0.00033252 0.00033449 0.00033034 0.00031101 0.00035532 0.00033491
 0.00047856]
Model epoch 204: train total loss -64.70742714817706, train mean loss 0.00029250202119032867, test mean loss [0.0003113  0.00033578 0.00033553 0.00033501 0.00037841 0.00033813
 0.00047644]
Model epoch 205: train total loss -64.57860726698365, train mean loss 0.0002681342737573049, test mean loss [0.00032099 0.00033447 0.00034134 0.00035786 0.00035023 0.00033672
 0.00049031]
Model epoch 206: train total loss -64.96258939903947, train mean loss 0.0002978347740354913, test mean loss [0.00031514 0.00032402 0.00033005 0.00033321 0.0003611  0.0003363
 0.00049049]
Model epoch 207: train total loss -64.7601474399342, train mean loss 0.00032588592884246094, test mean loss [0.00030536 0.00032584 0.00032437 0.00034152 0.00035684 0.00032679
 0.00050196]
Model epoch 208: train total loss -64.85656786710568, train mean loss 0.0003328594841322406, test mean loss [0.00030566 0.0003316  0.0003302  0.00031685 0.00035731 0.00032884
 0.00047666]
Model epoch 209: train total loss -64.76050402150454, train mean loss 0.00033063781248383824, test mean loss [0.00032043 0.00032033 0.00033506 0.00031305 0.00036027 0.00031951
 0.00047625]
Model epoch 210: train total loss -64.90290709754075, train mean loss 0.0003180785115722376, test mean loss [0.00032374 0.00032967 0.0003327  0.00032892 0.00035547 0.00031959
 0.00049179]
Model epoch 211: train total loss -64.85741470256961, train mean loss 0.00036466415354145207, test mean loss [0.00032184 0.00032462 0.00032932 0.00032453 0.0003495  0.0003156
 0.00049923]
Model epoch 212: train total loss -64.7542721290053, train mean loss 0.0003601529738980799, test mean loss [0.00031334 0.00031709 0.00032498 0.00032991 0.0003513  0.00031562
 0.00046459]
Model epoch 213: train total loss -64.81250413093068, train mean loss 0.0002797261762746236, test mean loss [0.00030645 0.00032247 0.00032374 0.00031156 0.00034568 0.00033037
 0.00045825]
Model epoch 214: train total loss -64.80486813231977, train mean loss 0.0003122778958110095, test mean loss [0.00031215 0.00031536 0.00032318 0.00031188 0.00034726 0.00034544
 0.00046976]
Model epoch 215: train total loss -64.83182115372857, train mean loss 0.00034012544258925484, test mean loss [0.00030862 0.00032945 0.00033524 0.00031365 0.00035215 0.00032799
 0.00045841]
Model epoch 216: train total loss -64.51675039787864, train mean loss 0.00035832768763269094, test mean loss [0.00030804 0.00031265 0.00032648 0.00032132 0.00035113 0.00033396
 0.00046879]
Model epoch 217: train total loss -64.91105987500838, train mean loss 0.00028778704748551727, test mean loss [0.00030221 0.00031446 0.00031758 0.00030697 0.00034786 0.00032023
 0.00046917]
Model epoch 218: train total loss -64.86306108091708, train mean loss 0.00030994828603914294, test mean loss [0.00031145 0.00032153 0.00033739 0.00030478 0.00034991 0.00031305
 0.00046778]
Model epoch 219: train total loss -64.77522951437267, train mean loss 0.00028128490911821205, test mean loss [0.00030529 0.0003217  0.00032763 0.00031245 0.00033391 0.00031326
 0.0004586 ]
Model epoch 220: train total loss -65.07906873950398, train mean loss 0.0003200462975235686, test mean loss [0.00030002 0.00031312 0.00031522 0.00033065 0.00033978 0.00031191
 0.00045688]
Model epoch 221: train total loss -65.0861742995185, train mean loss 0.00031785469604020237, test mean loss [0.00030745 0.00031996 0.00031356 0.00031566 0.00034778 0.00031048
 0.00045256]
Model epoch 222: train total loss -64.35412383195316, train mean loss 0.0002882358976023387, test mean loss [0.00029827 0.00031442 0.0003078  0.00031017 0.00034694 0.00031366
 0.00045595]
Model epoch 223: train total loss -64.78362167193123, train mean loss 0.0003484088853865009, test mean loss [0.00031034 0.00032082 0.00031897 0.00030883 0.00034036 0.00032347
 0.00044785]
Model epoch 224: train total loss -64.69711040643794, train mean loss 0.0003012727094366459, test mean loss [0.00030681 0.0003066  0.00031882 0.00030169 0.00033528 0.00030914
 0.00046747]
Model epoch 225: train total loss -64.77147041337928, train mean loss 0.0003246851917742901, test mean loss [0.00030116 0.000325   0.00033028 0.00030803 0.00034054 0.00031198
 0.00044755]
Model epoch 226: train total loss -64.76986712352108, train mean loss 0.0003979791974747873, test mean loss [0.00032102 0.00031755 0.00031806 0.00030752 0.00033919 0.00030739
 0.00046798]
Model epoch 227: train total loss -64.84391740971293, train mean loss 0.00030897565556995955, test mean loss [0.00031379 0.00033929 0.00031107 0.00030098 0.0003313  0.0003036
 0.00046704]
Model epoch 228: train total loss -64.91220402967886, train mean loss 0.0003272599516430936, test mean loss [0.00030682 0.00032248 0.00033641 0.00029693 0.00034081 0.00029853
 0.00044403]
Model epoch 229: train total loss -64.71157223859623, train mean loss 0.0003092223786358111, test mean loss [0.00029239 0.00032555 0.00034553 0.00030842 0.00033731 0.00030154
 0.00046022]
Model epoch 230: train total loss -65.12371210572027, train mean loss 0.00028008543431306843, test mean loss [0.00029872 0.00031371 0.00032911 0.00029139 0.00035795 0.0003156
 0.00045453]
Model epoch 231: train total loss -64.9344571200093, train mean loss 0.0003995506436354501, test mean loss [0.00030005 0.00031288 0.0003331  0.00030588 0.00037682 0.00029598
 0.00043636]
Model epoch 232: train total loss -64.6440209127158, train mean loss 0.00027330236299141357, test mean loss [0.00028741 0.00031624 0.00031503 0.00030144 0.00033319 0.00030352
 0.00044133]
Model epoch 233: train total loss -65.00191743883143, train mean loss 0.0002911131536429548, test mean loss [0.00029794 0.00031082 0.00031444 0.00030328 0.00033834 0.00030193
 0.00044354]
Model epoch 234: train total loss -65.04087495983937, train mean loss 0.00029439614558097186, test mean loss [0.00030985 0.00029979 0.00031317 0.00029339 0.00034091 0.00031388
 0.00044866]
Model epoch 235: train total loss -64.69331444783586, train mean loss 0.0003594115799655075, test mean loss [0.00030602 0.00031752 0.00031209 0.00029959 0.00034774 0.00030289
 0.00043617]
Model epoch 236: train total loss -65.21306114610726, train mean loss 0.0003085688644471845, test mean loss [0.00029865 0.00030255 0.00031461 0.0002999  0.00032987 0.00032556
 0.00042363]
Model epoch 237: train total loss -64.64892244532294, train mean loss 0.0003386762371225154, test mean loss [0.00029525 0.00030785 0.00031291 0.00029774 0.00032617 0.00029842
 0.00042536]
Model epoch 238: train total loss -64.92112598357046, train mean loss 0.0002489069594416363, test mean loss [0.00029769 0.00031335 0.00031186 0.0003046  0.0003158  0.00029604
 0.00042554]
Model epoch 239: train total loss -64.89344124623628, train mean loss 0.000294210909821337, test mean loss [0.00030122 0.000304   0.00030656 0.00029416 0.000331   0.00030164
 0.0004188 ]
Model epoch 240: train total loss -65.05372551661372, train mean loss 0.0002942321772020908, test mean loss [0.00029439 0.00030231 0.00031003 0.0002964  0.00031681 0.00031189
 0.00056614]
Model epoch 241: train total loss -64.92628483546501, train mean loss 0.0002979512269284704, test mean loss [0.000311   0.00030322 0.00031602 0.00029344 0.00032656 0.00031835
 0.00054809]
Model epoch 242: train total loss -64.95349113062962, train mean loss 0.0003103831647493501, test mean loss [0.00029656 0.00030239 0.00030814 0.00028223 0.00032368 0.00030029
 0.00054625]
Model epoch 243: train total loss -64.9013262178446, train mean loss 0.00027833489489072937, test mean loss [0.00028685 0.00030257 0.0003081  0.00028852 0.00033037 0.00030154
 0.00052708]
Model epoch 244: train total loss -64.92342143467806, train mean loss 0.0003332111443240451, test mean loss [0.00029176 0.00030095 0.00030609 0.00028415 0.00032585 0.00030658
 0.00052597]
Model epoch 245: train total loss -64.90622097574999, train mean loss 0.000271913988891769, test mean loss [0.00029304 0.00030262 0.00030498 0.00028801 0.00032227 0.00028203
 0.00050562]
Model epoch 246: train total loss -65.25762077992634, train mean loss 0.00030035771380141875, test mean loss [0.00029816 0.00030111 0.00030209 0.0002939  0.00033039 0.00028431
 0.00050651]
Model epoch 247: train total loss -64.89827639043064, train mean loss 0.000263089200658765, test mean loss [0.00029902 0.00028962 0.00031378 0.00028838 0.00033333 0.00029342
 0.00050025]
Model epoch 248: train total loss -64.88716312072889, train mean loss 0.00030156428524547095, test mean loss [0.00028842 0.00030368 0.00030946 0.0002796  0.00035159 0.0002905
 0.0004817 ]
Model epoch 249: train total loss -64.92100040046516, train mean loss 0.00029661896280630805, test mean loss [0.00028685 0.00029784 0.00030232 0.00028711 0.00032323 0.0003074
 0.00048966]
Model epoch 250: train total loss -65.17404535539, train mean loss 0.0003486489195654253, test mean loss [0.00029827 0.00029706 0.00030536 0.00028835 0.00031657 0.00029096
 0.000482  ]
Model epoch 251: train total loss -64.87526784638072, train mean loss 0.0003421979918918029, test mean loss [0.0002896  0.00028933 0.00031273 0.00030166 0.00031609 0.00031795
 0.00047669]
Model epoch 252: train total loss -64.93642236230856, train mean loss 0.0003082148632941352, test mean loss [0.00029518 0.00028906 0.00030315 0.00027577 0.00031506 0.00030886
 0.00047617]
Model epoch 253: train total loss -65.12060767584921, train mean loss 0.0002778352895741848, test mean loss [0.00028876 0.00028713 0.00030133 0.00028292 0.00033735 0.00029173
 0.00047017]
Model epoch 254: train total loss -64.7850004140271, train mean loss 0.00032063512311330703, test mean loss [0.00029714 0.0002901  0.00029851 0.00027161 0.00032542 0.00028254
 0.00047379]
Model epoch 255: train total loss -64.8957232653702, train mean loss 0.0003160192192291845, test mean loss [0.00030797 0.00029389 0.0002981  0.00029567 0.0003192  0.00029509
 0.0004553 ]
Model epoch 256: train total loss -64.95117571542704, train mean loss 0.00031924535051606546, test mean loss [0.00029389 0.00029997 0.0002967  0.00031518 0.00032505 0.00028443
 0.00044819]
Model epoch 257: train total loss -64.95903103916505, train mean loss 0.0003146156886130547, test mean loss [0.00028389 0.00030273 0.00030587 0.00030147 0.00031606 0.00028813
 0.00050131]
Model epoch 258: train total loss -65.15518632355126, train mean loss 0.0002568505507933613, test mean loss [0.00028392 0.00031062 0.0002966  0.00027616 0.00032011 0.00028392
 0.0004631 ]
Model epoch 259: train total loss -65.20428436344099, train mean loss 0.0002449477094663018, test mean loss [0.00028658 0.00029546 0.00029983 0.00028107 0.00031596 0.00028098
 0.00046333]
Model epoch 260: train total loss -64.94800250557239, train mean loss 0.0003002519784965312, test mean loss [0.00029225 0.0002906  0.00029516 0.00027832 0.000312   0.00029083
 0.00044484]
Model epoch 261: train total loss -65.01224550661411, train mean loss 0.00026024151096804064, test mean loss [0.00028679 0.00028895 0.00029274 0.00028631 0.00030689 0.00028874
 0.00043506]
Model epoch 262: train total loss -64.99274385821606, train mean loss 0.0002810140556370735, test mean loss [0.00028914 0.0002909  0.00029854 0.00029829 0.00033204 0.00030841
 0.00043069]
Model epoch 263: train total loss -65.08507714128827, train mean loss 0.0003761397943725491, test mean loss [0.00028289 0.00028101 0.0002951  0.00028872 0.00031161 0.00026863
 0.00044527]
Model epoch 264: train total loss -64.85600505012096, train mean loss 0.0003103992001160485, test mean loss [0.00028576 0.00028225 0.00029356 0.00028572 0.00033813 0.00030606
 0.00043617]
Model epoch 265: train total loss -64.68365008615122, train mean loss 0.0003406480172603532, test mean loss [0.00028776 0.00029525 0.00030637 0.00027674 0.00033057 0.00027468
 0.00042019]
Model epoch 266: train total loss -64.91115541375986, train mean loss 0.00027307467624327003, test mean loss [0.00029065 0.00028471 0.00029569 0.00027328 0.00031369 0.00027825
 0.00042666]
Model epoch 267: train total loss -65.14156906367141, train mean loss 0.0002534289808628494, test mean loss [0.00029088 0.00027454 0.00031194 0.00028759 0.00034743 0.00028147
 0.00042829]
Model epoch 268: train total loss -64.76115133678466, train mean loss 0.0003536844361249718, test mean loss [0.00029291 0.00028088 0.00029771 0.00028508 0.00033589 0.00029564
 0.00041631]
Model epoch 269: train total loss -65.04909694468243, train mean loss 0.00027942049853050996, test mean loss [0.00028175 0.00027532 0.00029806 0.0002786  0.0003245  0.00031503
 0.0004252 ]
Model epoch 270: train total loss -64.90462776275608, train mean loss 0.00027952784086770187, test mean loss [0.00028177 0.00027763 0.00029428 0.00027496 0.00031165 0.00029443
 0.00040076]
Model epoch 271: train total loss -65.1359941557146, train mean loss 0.00027938971845149063, test mean loss [0.00027365 0.00028782 0.00029479 0.00028552 0.00031669 0.00027886
 0.0004261 ]
Model epoch 272: train total loss -65.04000216178056, train mean loss 0.000290891534438127, test mean loss [0.00029602 0.00027972 0.00029077 0.00027634 0.00030266 0.00029825
 0.00042204]
Model epoch 273: train total loss -65.11231766271459, train mean loss 0.00024947125868693583, test mean loss [0.00027344 0.0002879  0.00028803 0.00026948 0.00031049 0.00027139
 0.00041773]
Model epoch 274: train total loss -65.03545268711021, train mean loss 0.0002492386827379057, test mean loss [0.00027591 0.00028063 0.00028971 0.00026649 0.00031406 0.00027337
 0.00041053]
Model epoch 275: train total loss -65.11934990220219, train mean loss 0.0002690242832299725, test mean loss [0.00029105 0.00028189 0.00029871 0.00027226 0.00030297 0.00027415
 0.00040168]
Model epoch 276: train total loss -65.13178496212343, train mean loss 0.00031188021469145765, test mean loss [0.00027464 0.00026543 0.00029565 0.00028844 0.00030934 0.0002869
 0.00040568]
Model epoch 277: train total loss -64.69506265422534, train mean loss 0.0003077177123620621, test mean loss [0.00028061 0.00027623 0.00028065 0.00028076 0.00032441 0.00029567
 0.00040245]
Model epoch 278: train total loss -65.13392138936483, train mean loss 0.0002476212139102513, test mean loss [0.00027993 0.0003051  0.0002948  0.00026975 0.00030822 0.00027187
 0.00041248]
Model epoch 279: train total loss -64.74439094547756, train mean loss 0.0003025908909696307, test mean loss [0.0002767  0.00027351 0.00028188 0.00028165 0.00031173 0.00028311
 0.00039711]
Model epoch 280: train total loss -65.01342320725499, train mean loss 0.0002709896504337241, test mean loss [0.00027475 0.00028301 0.00028847 0.00027832 0.00030773 0.00027478
 0.00040546]
Model epoch 281: train total loss -64.85965420035023, train mean loss 0.00027232153808034255, test mean loss [0.00027883 0.00038109 0.00028814 0.00028186 0.00029863 0.00027718
 0.00040058]
Model epoch 282: train total loss -64.91803809159984, train mean loss 0.0002704412535041957, test mean loss [0.00028504 0.00040008 0.00029344 0.00027315 0.00029703 0.00028564
 0.00039277]
Model epoch 283: train total loss -64.94616684945346, train mean loss 0.00030975846589610667, test mean loss [0.00027995 0.00033429 0.00028858 0.00027515 0.00030289 0.00027492
 0.00038444]
Model epoch 284: train total loss -64.94996265101653, train mean loss 0.0003851480882672732, test mean loss [0.00027009 0.000304   0.00029232 0.00027979 0.00031688 0.00027921
 0.00038325]
Model epoch 285: train total loss -65.06376694368919, train mean loss 0.00027547895842682223, test mean loss [0.00027533 0.00030216 0.00027728 0.00028455 0.00029887 0.00027073
 0.00038893]
Model epoch 286: train total loss -64.98016006005247, train mean loss 0.00028402812403558836, test mean loss [0.0002872  0.00029147 0.0003054  0.00027901 0.00030841 0.00029148
 0.00038514]
Model epoch 287: train total loss -65.16655021861031, train mean loss 0.000301683300753139, test mean loss [0.00027156 0.00029021 0.00029634 0.00027866 0.00030209 0.00028289
 0.00039901]
Model epoch 288: train total loss -65.1300255641231, train mean loss 0.00025811530951306004, test mean loss [0.00027671 0.00028111 0.00028259 0.00026256 0.00031144 0.00027416
 0.00040463]
Model epoch 289: train total loss -65.08445329191916, train mean loss 0.0003028768211706336, test mean loss [0.00027657 0.00027616 0.00028912 0.00027917 0.00030428 0.00027726
 0.00037508]
Model epoch 290: train total loss -64.91958363628343, train mean loss 0.00028765697377407565, test mean loss [0.00028445 0.0002721  0.00028898 0.00027347 0.00031588 0.00026863
 0.00038546]
Model epoch 291: train total loss -64.88118966528793, train mean loss 0.00029093631715635814, test mean loss [0.00027708 0.00027818 0.00029846 0.00026394 0.00035626 0.00027291
 0.00038046]
Model epoch 292: train total loss -64.99439098754645, train mean loss 0.0002759255209042539, test mean loss [0.0002717  0.00026913 0.00029691 0.00028998 0.00033467 0.0002666
 0.00037701]
Model epoch 293: train total loss -64.99891241951852, train mean loss 0.0002581224520919645, test mean loss [0.00028248 0.00027588 0.00028069 0.00027092 0.00030925 0.00027588
 0.00036469]
Model epoch 294: train total loss -64.962093458875, train mean loss 0.00028387683908845347, test mean loss [0.00028306 0.00027046 0.00027824 0.00027992 0.00031382 0.00028025
 0.00036513]
Model epoch 295: train total loss -65.13176123338408, train mean loss 0.0002847366214956652, test mean loss [0.00027499 0.00027399 0.00028291 0.00027561 0.00031721 0.0002707
 0.00036245]
Model epoch 296: train total loss -64.89387049334077, train mean loss 0.0003046539272007645, test mean loss [0.00027276 0.00030348 0.00028953 0.00026875 0.00031124 0.00026378
 0.00035438]
Model epoch 297: train total loss -64.82747776004001, train mean loss 0.00027884634762402697, test mean loss [0.0002689  0.00027194 0.00028054 0.00026429 0.00031692 0.00026882
 0.00036265]
Model epoch 298: train total loss -65.00546558775534, train mean loss 0.0002746634289695746, test mean loss [0.00026692 0.00027837 0.00027774 0.0002843  0.00030179 0.00027547
 0.00037726]
Model epoch 299: train total loss -65.10898916187892, train mean loss 0.00026557997521990976, test mean loss [0.00028657 0.00027741 0.00027657 0.00027631 0.00029966 0.00026589
 0.00036889]
Model epoch 300: train total loss -64.97714509055976, train mean loss 0.00027789440380717595, test mean loss [0.00028261 0.0002794  0.00028373 0.00026777 0.00028606 0.00026367
 0.00037118]
Model epoch 301: train total loss -65.0701785809394, train mean loss 0.00026223039550988386, test mean loss [0.00028277 0.0002683  0.00027772 0.0002653  0.00031077 0.00027724
 0.00034954]
Model epoch 302: train total loss -64.93333761406278, train mean loss 0.00027705557768332637, test mean loss [0.00027597 0.00026377 0.000286   0.0002693  0.00029827 0.00027217
 0.00035113]
Model epoch 303: train total loss -64.90172714784534, train mean loss 0.00028515483339616737, test mean loss [0.00027729 0.0002785  0.00028275 0.00029621 0.00029697 0.00026612
 0.00035719]
Model epoch 304: train total loss -65.04765725408019, train mean loss 0.00027059974285243685, test mean loss [0.00027536 0.00026352 0.00027732 0.00027623 0.00029412 0.00025874
 0.0003507 ]
Model epoch 305: train total loss -65.20602451940998, train mean loss 0.0002863456444088227, test mean loss [0.00027867 0.00026597 0.00027203 0.00027919 0.00030546 0.00026551
 0.00034228]
Model epoch 306: train total loss -64.94375322219129, train mean loss 0.00028606545372798, test mean loss [0.00028528 0.00028076 0.00027397 0.0002735  0.00030474 0.00027107
 0.00034311]
Model epoch 307: train total loss -64.89894280064908, train mean loss 0.00028777465551653317, test mean loss [0.00027587 0.00026525 0.00028566 0.00026113 0.00030658 0.00026409
 0.00036147]
Model epoch 308: train total loss -65.03687617587333, train mean loss 0.0002973030499167765, test mean loss [0.0002811  0.00026427 0.00028006 0.00026319 0.00029579 0.00026852
 0.00034612]
Model epoch 309: train total loss -65.10128064094586, train mean loss 0.00029290769686391284, test mean loss [0.00028853 0.00027637 0.00027683 0.00025586 0.0002946  0.0002627
 0.00034293]
Model epoch 310: train total loss -65.07019344660719, train mean loss 0.000273089605264371, test mean loss [0.00026724 0.00026822 0.00027031 0.00025564 0.00029706 0.00027001
 0.00035958]
Model epoch 311: train total loss -65.06588135689199, train mean loss 0.00029438280632289115, test mean loss [0.00027482 0.00026595 0.00027669 0.0002679  0.00029485 0.00026658
 0.00034409]
Model epoch 312: train total loss -65.12765588879087, train mean loss 0.00026335499016021975, test mean loss [0.0002623  0.0002781  0.00027654 0.00025925 0.00032014 0.00025723
 0.00033903]
Model epoch 313: train total loss -64.68315138585534, train mean loss 0.0002759981407156194, test mean loss [0.00027597 0.00025965 0.00027951 0.00027468 0.00033457 0.00028173
 0.0003376 ]
Model epoch 314: train total loss -65.1762424468834, train mean loss 0.0002610085596529678, test mean loss [0.00027208 0.00026632 0.00027101 0.00027337 0.00030174 0.00027034
 0.0003282 ]
Model epoch 315: train total loss -65.12434186236065, train mean loss 0.0002301875394937494, test mean loss [0.00028226 0.00026958 0.00027535 0.0002737  0.00028983 0.00025907
 0.00033364]
Model epoch 316: train total loss -65.05629635425309, train mean loss 0.0002497242165507039, test mean loss [0.00027092 0.00027026 0.00027213 0.00025955 0.00029301 0.00026598
 0.00033908]
Model epoch 317: train total loss -65.42909795171333, train mean loss 0.00023170783752829357, test mean loss [0.00026625 0.00027689 0.00028776 0.0002603  0.00030882 0.00024774
 0.00033945]
Model epoch 318: train total loss -64.781684765016, train mean loss 0.0002898176616043939, test mean loss [0.00028229 0.0002637  0.00028491 0.00026035 0.00029025 0.00025937
 0.00034047]
Model epoch 319: train total loss -65.29785539794577, train mean loss 0.00021705365810950053, test mean loss [0.00026727 0.00025942 0.00027552 0.00026619 0.000291   0.00025667
 0.00033395]
Model epoch 320: train total loss -65.01397745138841, train mean loss 0.00029328105398405627, test mean loss [0.0002638  0.00026783 0.00028373 0.00024908 0.00028465 0.0002656
 0.00032684]
Model epoch 321: train total loss -65.24455942486573, train mean loss 0.00030702217681462365, test mean loss [0.00026135 0.00026882 0.00026493 0.00025544 0.0002997  0.00027312
 0.00034499]
Model epoch 322: train total loss -65.08650600063106, train mean loss 0.0003071405078216464, test mean loss [0.00026953 0.00026047 0.00027881 0.00026252 0.00028934 0.00026956
 0.00033756]
Model epoch 323: train total loss -65.04722397608609, train mean loss 0.0003137515574941955, test mean loss [0.00027422 0.00026444 0.00027372 0.0002596  0.00028531 0.00025818
 0.00033552]
Model epoch 324: train total loss -65.03530184833053, train mean loss 0.00031387835580859333, test mean loss [0.0002732  0.00027686 0.00028043 0.00025621 0.00030765 0.0002522
 0.00033409]
Model epoch 325: train total loss -65.10517740527537, train mean loss 0.0002814127566243704, test mean loss [0.00027208 0.00027704 0.00026637 0.00027829 0.00029078 0.00026303
 0.00033   ]
Model epoch 326: train total loss -65.20134887120759, train mean loss 0.00023527654808500474, test mean loss [0.00026579 0.00026513 0.00027253 0.00027073 0.00029465 0.00025559
 0.00033897]
Model epoch 327: train total loss -65.20857668361025, train mean loss 0.00031756897187764136, test mean loss [0.00026326 0.00026878 0.00027156 0.00025269 0.00028395 0.00026471
 0.00032264]
Model epoch 328: train total loss -64.9264359295817, train mean loss 0.00022161766898917828, test mean loss [0.00026132 0.00025918 0.00027492 0.00025379 0.00029765 0.00025081
 0.00033486]
Model epoch 329: train total loss -65.12394188621606, train mean loss 0.00021303014339680757, test mean loss [0.00027448 0.00025756 0.00027833 0.00025516 0.00028668 0.00025482
 0.00034038]
Model epoch 330: train total loss -65.20236223128019, train mean loss 0.00022814298953454423, test mean loss [0.00026212 0.00026821 0.00026841 0.00025808 0.00027943 0.00025975
 0.00032911]
Model epoch 331: train total loss -65.19038552919382, train mean loss 0.0002703003659747165, test mean loss [0.00026938 0.00026064 0.00026564 0.00024877 0.00028658 0.00026861
 0.00035559]
Model epoch 332: train total loss -65.13896355482505, train mean loss 0.00022348693542117038, test mean loss [0.00027137 0.00025664 0.00026086 0.00027114 0.00028765 0.00025323
 0.00033719]
Model epoch 333: train total loss -65.01936629874878, train mean loss 0.0003150065473514956, test mean loss [0.00027246 0.00027426 0.00028726 0.00028588 0.00028323 0.00025935
 0.00032867]
Model epoch 334: train total loss -65.1829902410999, train mean loss 0.0002775554555612084, test mean loss [0.00027485 0.0002767  0.00027538 0.00028231 0.0002824  0.00026128
 0.00031748]
Model epoch 335: train total loss -65.18831836113702, train mean loss 0.0002736148921633225, test mean loss [0.0002652  0.00027014 0.0002702  0.00025311 0.00027546 0.00025892
 0.00032274]
Model epoch 336: train total loss -65.334430433897, train mean loss 0.00024047366910425684, test mean loss [0.00026751 0.0002607  0.00027179 0.00026226 0.00027845 0.00025076
 0.00032421]
Model epoch 337: train total loss -65.05142934168866, train mean loss 0.00023945109571569438, test mean loss [0.00026831 0.0002699  0.00026906 0.00025629 0.00026944 0.00026401
 0.0003273 ]
Model epoch 338: train total loss -65.2799616211477, train mean loss 0.0002478261943186665, test mean loss [0.00027062 0.00025194 0.00027135 0.00025439 0.00030282 0.00025027
 0.00031947]
Model epoch 339: train total loss -64.72078030328532, train mean loss 0.00027619616885742043, test mean loss [0.00026694 0.00025819 0.00027627 0.00025623 0.00027576 0.00025608
 0.00031796]
Model epoch 340: train total loss -65.3677126470971, train mean loss 0.000248129663760821, test mean loss [0.00026694 0.00026441 0.00027975 0.0002585  0.00027848 0.00026141
 0.00032952]
Model epoch 341: train total loss -64.97818124886427, train mean loss 0.0002522913712841158, test mean loss [0.0002611  0.00026651 0.00027127 0.00025182 0.00029926 0.00025463
 0.00031683]
Model epoch 342: train total loss -65.17316695891705, train mean loss 0.00026878859343618203, test mean loss [0.00026187 0.00025859 0.00026926 0.00026167 0.00028406 0.00025819
 0.00031371]
Model epoch 343: train total loss -65.1042586303697, train mean loss 0.00031415251477082573, test mean loss [0.00027126 0.00025928 0.00027192 0.00027768 0.00029114 0.0002538
 0.00031627]
Model epoch 344: train total loss -65.12850556253241, train mean loss 0.0003144928699563212, test mean loss [0.000287   0.00025509 0.0002643  0.00027316 0.00028478 0.0002946
 0.00031023]
Model epoch 345: train total loss -64.9153746003342, train mean loss 0.0003074152376004072, test mean loss [0.00027002 0.00026452 0.00026883 0.00030533 0.0002806  0.00029614
 0.00030823]
Model epoch 346: train total loss -65.14614824945743, train mean loss 0.0002759019846845618, test mean loss [0.00026274 0.00026205 0.00027223 0.00028757 0.00029492 0.00027241
 0.00032574]
Model epoch 347: train total loss -65.02806934587474, train mean loss 0.0002754569837070294, test mean loss [0.00027137 0.00025055 0.00026205 0.00025977 0.00028781 0.00025297
 0.00030776]
Model epoch 348: train total loss -65.12916824165193, train mean loss 0.00026920649335434964, test mean loss [0.00027814 0.00025967 0.00026367 0.00025659 0.00028647 0.00025933
 0.00032225]
Model epoch 349: train total loss -65.15075445690071, train mean loss 0.0002839513124509651, test mean loss [0.00026115 0.00025936 0.00026242 0.00025699 0.00027638 0.00025837
 0.00030991]
Model epoch 350: train total loss -65.40074159058, train mean loss 0.00024513990050358523, test mean loss [0.00025811 0.00025817 0.00026223 0.00025526 0.00028053 0.00025885
 0.00031288]
Model epoch 351: train total loss -65.15175380995406, train mean loss 0.0002696111478190056, test mean loss [0.00025891 0.00026094 0.00026932 0.00024619 0.00028159 0.00025026
 0.00032053]
Model epoch 352: train total loss -65.3882443812026, train mean loss 0.0002404236310340479, test mean loss [0.00026866 0.00026655 0.00027631 0.00024355 0.00028188 0.0002553
 0.00031819]
Model epoch 353: train total loss -65.1045650394041, train mean loss 0.00026464786250667374, test mean loss [0.00026274 0.00025666 0.0002769  0.00025434 0.00028522 0.00024941
 0.00031538]
Model epoch 354: train total loss -64.99857210834998, train mean loss 0.00024114811378731418, test mean loss [0.00026951 0.00025654 0.00027588 0.0002513  0.00029066 0.00025228
 0.00031041]
Model epoch 355: train total loss -65.08840302111315, train mean loss 0.00027977293266744785, test mean loss [0.00026932 0.00026548 0.00027274 0.00027156 0.00028146 0.00024799
 0.00030159]
Model epoch 356: train total loss -65.21213260824653, train mean loss 0.0002609054125119847, test mean loss [0.00025733 0.00025039 0.00027298 0.00027569 0.00027982 0.00025409
 0.00031035]
Model epoch 357: train total loss -65.21426308515701, train mean loss 0.00023565653367077862, test mean loss [0.00025994 0.00025808 0.00026983 0.00025899 0.00026923 0.00025356
 0.00029948]
Model epoch 358: train total loss -65.1858939221776, train mean loss 0.00024787553683870364, test mean loss [0.00025801 0.00024598 0.00026053 0.0002569  0.00029239 0.00024732
 0.00030903]
Model epoch 359: train total loss -65.22322792044557, train mean loss 0.0002622044774677474, test mean loss [0.00025914 0.00026167 0.0002571  0.00025093 0.00029403 0.00023281
 0.00029944]
Model epoch 360: train total loss -65.28860795463005, train mean loss 0.00023706533077452155, test mean loss [0.00029335 0.00026109 0.00027419 0.00024206 0.00027835 0.00024706
 0.00031003]
Model epoch 361: train total loss -65.44715187206282, train mean loss 0.0002336356509899681, test mean loss [0.00027525 0.00026857 0.00026884 0.00023943 0.00029013 0.00024873
 0.00030842]
Model epoch 362: train total loss -65.47100238958416, train mean loss 0.000236173551907683, test mean loss [0.00025808 0.00025054 0.00026152 0.00024849 0.00029122 0.00024276
 0.00029689]
Model epoch 363: train total loss -64.94991953447276, train mean loss 0.0002886906053477141, test mean loss [0.00025065 0.00024804 0.00026451 0.00024209 0.00028711 0.00024075
 0.00030238]
Model epoch 364: train total loss -65.28570210055447, train mean loss 0.0002539698492183256, test mean loss [0.00025817 0.00024806 0.0002653  0.00026068 0.00029043 0.00024743
 0.00029478]
Model epoch 365: train total loss -65.28637979188073, train mean loss 0.00023447865600597655, test mean loss [0.00025582 0.00024619 0.0002499  0.00025763 0.00028322 0.00025857
 0.00029272]
Model epoch 366: train total loss -65.17755337685627, train mean loss 0.0002736284861292186, test mean loss [0.00026128 0.00025904 0.00025699 0.00025501 0.00029517 0.00025148
 0.00031516]
Model epoch 367: train total loss -65.10654298754274, train mean loss 0.0002632952762482229, test mean loss [0.00025889 0.00025737 0.00025826 0.00024422 0.00027769 0.00025375
 0.00029381]
Model epoch 368: train total loss -65.02238338281234, train mean loss 0.0002744818762057174, test mean loss [0.00026244 0.0002626  0.00025997 0.00024773 0.00028294 0.00023831
 0.0003021 ]
Model epoch 369: train total loss -65.44433643432023, train mean loss 0.00021921745328530698, test mean loss [0.00025536 0.00026133 0.00026455 0.00024247 0.00027438 0.00024938
 0.0002973 ]
Model epoch 370: train total loss -65.24368850865203, train mean loss 0.00032105029031628964, test mean loss [0.0002594  0.00025176 0.00026445 0.00024941 0.00027567 0.00024881
 0.0003069 ]
Model epoch 371: train total loss -64.9871899659313, train mean loss 0.0002461426032300803, test mean loss [0.00026164 0.00024522 0.00025705 0.00024865 0.00026964 0.00025296
 0.00030704]
Model trained in 372 epochs with 6000 transitions.
[2025-01-24 22:18:00,297][absl][INFO] - {'eval/walltime': 223.8260498046875, 'training/sps': 0.20806483497223408, 'training/walltime': 19256.327404737473, 'training/model_train_time': 3136.485887527466, 'training/other_time': 1668.877807378769, 'training/model_horizon': 10, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(7000, dtype=int32), 'model/train_total_loss': Array(-64.98718997, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00024614, dtype=float64), 'model/test_total_loss': Array(-64.44503537, dtype=float64), 'model/test_mean_loss': Array(0.00026317, dtype=float64), 'model/train_epochs': 372, 'model/sec_per_epoch': 8.425681844193448, 'sac/actor_loss': Array(-25.43202823, dtype=float64), 'sac/alpha': Array(0.02551216, dtype=float32), 'sac/alpha_loss': Array(8.56982895e-06, dtype=float64), 'sac/buffer_current_size': Array(400000.03, dtype=float32), 'sac/critic_loss': Array(0.10573988, dtype=float64), 'eval/episode_forward_vel': Array(-43.65125879, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-1.72598727, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(8.71787258, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.01127357, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-18.77473496, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(8.27237742, dtype=float64), 'eval/episode_rew_roll': Array(8.51278366, dtype=float64), 'eval/episode_rew_side_motion': Array(9.69268169, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(6.75583333, dtype=float64), 'eval/episode_rew_yaw': Array(7.58607413, dtype=float64), 'eval/episode_rew_z_vel_change': Array(4.86835978, dtype=float64), 'eval/episode_reward': Array(32.63600653, dtype=float64), 'eval/episode_step_count': Array(16653., dtype=float64), 'eval/avg_episode_length': Array(183., dtype=float64), 'eval/epoch_eval_time': 30.099053382873535, 'eval/sps': 33.22363621471908}
Steps / Eval:  7000.0
Reward is  32.636006534408125
Model horizon updated to 12.
Hallucination updates per training step updated to 1000.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -40.59720612744367, train mean loss 0.019983365390808028, test mean loss [0.02609312 0.0211656  0.01547724 0.01920167 0.02802734 0.01430498
 0.02030721]
Model epoch 1: train total loss -48.19739503695037, train mean loss 0.016366405333199444, test mean loss [0.01759975 0.01772983 0.01337486 0.01799197 0.0258715  0.0110171
 0.01931009]
Model epoch 2: train total loss -52.41918252017913, train mean loss 0.015765492994113797, test mean loss [0.01494135 0.01402292 0.01088128 0.01527046 0.02223292 0.00892452
 0.01632188]
Model epoch 3: train total loss -54.95601834895977, train mean loss 0.012421281301830797, test mean loss [0.01238762 0.01129894 0.00835023 0.01253353 0.01934236 0.00776292
 0.01407998]
Model epoch 4: train total loss -56.48575362227969, train mean loss 0.011211496521758098, test mean loss [0.01043157 0.0092529  0.00702464 0.01043989 0.01684234 0.00719422
 0.01247467]
Model epoch 5: train total loss -57.55601199101137, train mean loss 0.009495715977804853, test mean loss [0.00914363 0.00787907 0.00607586 0.00902709 0.01489919 0.00650832
 0.01124849]
Model epoch 6: train total loss -58.188838320363224, train mean loss 0.009018109144872574, test mean loss [0.0082947  0.00657524 0.00542266 0.00771615 0.013512   0.00599524
 0.0103959 ]
Model epoch 7: train total loss -58.96745166735918, train mean loss 0.008407606906897937, test mean loss [0.00776228 0.00575835 0.00487334 0.00718412 0.01224513 0.00553756
 0.00944564]
Model epoch 8: train total loss -59.20161449382649, train mean loss 0.007455505749721571, test mean loss [0.00734788 0.00511123 0.00441294 0.00649568 0.0110423  0.00522563
 0.00865509]
Model epoch 9: train total loss -59.43640889900451, train mean loss 0.006089702164301684, test mean loss [0.00685491 0.00462209 0.0040489  0.00595207 0.01008657 0.0048354
 0.00775908]
Model epoch 10: train total loss -60.00567200792981, train mean loss 0.0055597591448693084, test mean loss [0.00656899 0.00418807 0.00382363 0.00559512 0.00899701 0.00455872
 0.00715579]
Model epoch 11: train total loss -60.5494852393596, train mean loss 0.004975764397018949, test mean loss [0.00624656 0.00380437 0.00349968 0.00525401 0.00801462 0.00428116
 0.00663751]
Model epoch 12: train total loss -60.84060170498959, train mean loss 0.004068590255471124, test mean loss [0.00581274 0.00355003 0.0032852  0.00487613 0.00718456 0.00411424
 0.00623802]
Model epoch 13: train total loss -60.64225165334394, train mean loss 0.004446122767662515, test mean loss [0.00562151 0.00334988 0.0030783  0.00456392 0.00634274 0.00388217
 0.00585683]
Model epoch 14: train total loss -61.196785073971405, train mean loss 0.00393471169776852, test mean loss [0.0055034  0.00290579 0.00294127 0.00425129 0.00562618 0.00368986
 0.00540487]
Model epoch 15: train total loss -61.20530094986231, train mean loss 0.0032806435179953087, test mean loss [0.00513965 0.00274271 0.00269136 0.00415358 0.00507431 0.00354629
 0.00516441]
Model epoch 16: train total loss -61.422404366920645, train mean loss 0.003290995196783791, test mean loss [0.00496342 0.00254698 0.00260251 0.0039191  0.0045924  0.00343645
 0.00490425]
Model epoch 17: train total loss -61.65034021983291, train mean loss 0.0031112234600154374, test mean loss [0.00478253 0.00244921 0.00252323 0.00378986 0.00424375 0.00322734
 0.00452877]
Model epoch 18: train total loss -61.48834921811547, train mean loss 0.0034027911894617584, test mean loss [0.00467735 0.00231021 0.00236683 0.00363641 0.00403554 0.00306316
 0.00422676]
Model epoch 19: train total loss -61.882216922496376, train mean loss 0.002668331704891052, test mean loss [0.00442473 0.00214516 0.00228441 0.00338821 0.00360447 0.00299661
 0.00416352]
Model epoch 20: train total loss -62.1283494695063, train mean loss 0.0030817769063149637, test mean loss [0.00421096 0.00205483 0.00224809 0.00337421 0.00354852 0.00286404
 0.00383112]
Model epoch 21: train total loss -61.98570968281164, train mean loss 0.003064831297504878, test mean loss [0.00415355 0.00192102 0.00215078 0.00334289 0.00315245 0.0027628
 0.00363567]
Model epoch 22: train total loss -62.10899312395407, train mean loss 0.0025681717253382974, test mean loss [0.00406064 0.00180586 0.00202224 0.00309697 0.00325524 0.00268153
 0.00348324]
Model epoch 23: train total loss -62.16375453356585, train mean loss 0.0026729919677776423, test mean loss [0.0039444  0.00173379 0.00191565 0.00314336 0.00293491 0.00252444
 0.003294  ]
Model epoch 24: train total loss -62.012415858002626, train mean loss 0.0024626673101160734, test mean loss [0.00376458 0.0016109  0.00191299 0.00294264 0.00259173 0.00237544
 0.00304731]
Model epoch 25: train total loss -62.33096640732101, train mean loss 0.00195485302258685, test mean loss [0.00370536 0.00155559 0.00183865 0.00281453 0.00254843 0.00236487
 0.00291781]
Model epoch 26: train total loss -62.61594565608231, train mean loss 0.0022091588776657744, test mean loss [0.00358264 0.00157064 0.0018035  0.00285114 0.00256248 0.00230014
 0.00292288]
Model epoch 27: train total loss -62.41299340498899, train mean loss 0.00196628141598767, test mean loss [0.00359389 0.00145014 0.00177331 0.00264088 0.00242498 0.00220359
 0.00260692]
Model epoch 28: train total loss -62.553558346184786, train mean loss 0.001992941524890086, test mean loss [0.00351759 0.00147719 0.00170842 0.00253026 0.0022168  0.00218598
 0.00256391]
Model epoch 29: train total loss -62.39001314611585, train mean loss 0.0019933635299245983, test mean loss [0.00345305 0.00137826 0.0016151  0.0026145  0.00216677 0.00218389
 0.00246704]
Model epoch 30: train total loss -62.792656786790296, train mean loss 0.0018306278379065617, test mean loss [0.00338951 0.00128115 0.00158521 0.00254538 0.00208033 0.0020842
 0.00242393]
Model epoch 31: train total loss -63.02499400495053, train mean loss 0.0017219378665024013, test mean loss [0.00322782 0.00119874 0.00157743 0.00247452 0.00198157 0.00202186
 0.00225859]
Model epoch 32: train total loss -62.6370752640605, train mean loss 0.0021637068045197464, test mean loss [0.00320377 0.00119739 0.00155018 0.00241032 0.00187855 0.00207418
 0.00220398]
Model epoch 33: train total loss -63.112299042941444, train mean loss 0.0015485014908555577, test mean loss [0.0030847  0.00111476 0.00148542 0.00231355 0.00188915 0.00197475
 0.00209195]
Model epoch 34: train total loss -62.54074331826625, train mean loss 0.001494145990043982, test mean loss [0.00307137 0.00108734 0.00143664 0.00223255 0.00172987 0.00197166
 0.00209929]
Model epoch 35: train total loss -63.275006238224144, train mean loss 0.001188961002072597, test mean loss [0.00297712 0.00104838 0.00141716 0.00223093 0.00177363 0.00195057
 0.0019594 ]
Model epoch 36: train total loss -62.98109500314723, train mean loss 0.0014470853872400602, test mean loss [0.00289733 0.00102866 0.00134488 0.00209245 0.00161693 0.0018119
 0.00190322]
Model epoch 37: train total loss -63.05215083368717, train mean loss 0.0015611014610424792, test mean loss [0.00285045 0.00100659 0.0013373  0.00196864 0.00163492 0.00176756
 0.00175201]
Model epoch 38: train total loss -63.160428115318894, train mean loss 0.0017390158205683065, test mean loss [0.00281993 0.00099544 0.00127663 0.00200647 0.00156755 0.00174869
 0.00172694]
Model epoch 39: train total loss -63.15128448654151, train mean loss 0.0015784488241479392, test mean loss [0.00270707 0.00094193 0.00127258 0.00190132 0.00155241 0.00174522
 0.00169832]
Model epoch 40: train total loss -63.46044874527783, train mean loss 0.0013703078917312965, test mean loss [0.00264053 0.00092922 0.00124277 0.00186743 0.0015008  0.00172841
 0.00165898]
Model epoch 41: train total loss -63.144025517599104, train mean loss 0.0017282670509934067, test mean loss [0.00266167 0.00088788 0.00123259 0.00182455 0.0013896  0.00172479
 0.0016338 ]
Model epoch 42: train total loss -63.19873741403366, train mean loss 0.001170682410843421, test mean loss [0.0026197  0.00091182 0.0012247  0.00179565 0.00141574 0.00171129
 0.00155087]
Model epoch 43: train total loss -63.4722415576753, train mean loss 0.0013643959429900214, test mean loss [0.00256448 0.00084834 0.00118459 0.00171714 0.00135045 0.00164243
 0.00150229]
Model epoch 44: train total loss -63.186332005726236, train mean loss 0.0013234576873982914, test mean loss [0.00254361 0.00083571 0.00116831 0.00162058 0.00132706 0.00158974
 0.00139503]
Model epoch 45: train total loss -63.21841510593166, train mean loss 0.0014171387312752026, test mean loss [0.00242637 0.00084567 0.00114921 0.00160133 0.00129217 0.00165317
 0.00136436]
Model epoch 46: train total loss -63.487180304374256, train mean loss 0.000921333360606785, test mean loss [0.00235647 0.0008512  0.00116247 0.00154409 0.00128759 0.00163931
 0.0013483 ]
Model epoch 47: train total loss -63.32898168152852, train mean loss 0.0011500362663672084, test mean loss [0.00235561 0.00077571 0.00113873 0.00149525 0.00121638 0.00161398
 0.00130813]
Model epoch 48: train total loss -63.23670147064478, train mean loss 0.0011745434433862746, test mean loss [0.00245471 0.00075352 0.00106714 0.00151736 0.00121151 0.00146302
 0.00129216]
Model epoch 49: train total loss -63.2804496896834, train mean loss 0.001377325045540576, test mean loss [0.0022924  0.00076357 0.00106277 0.00149297 0.0011708  0.00151179
 0.00128203]
Model epoch 50: train total loss -63.49060730895281, train mean loss 0.0010432363546025753, test mean loss [0.00236166 0.00078448 0.00105868 0.00140919 0.00120712 0.00144603
 0.00120412]
Model epoch 51: train total loss -63.513240987800295, train mean loss 0.001171393703881925, test mean loss [0.00240873 0.00076704 0.00102312 0.00139846 0.00119851 0.00150243
 0.00123808]
Model epoch 52: train total loss -63.28347615470239, train mean loss 0.0010582596694396979, test mean loss [0.00230851 0.00074411 0.00099364 0.00133256 0.00111334 0.00143559
 0.00110946]
Model epoch 53: train total loss -63.36277357433555, train mean loss 0.0011884756911151753, test mean loss [0.00225179 0.00078438 0.00098941 0.00128057 0.00109233 0.00141902
 0.00112393]
Model epoch 54: train total loss -63.377234594079695, train mean loss 0.0010028153765454378, test mean loss [0.00223975 0.00073604 0.00097891 0.00125557 0.00113956 0.00141289
 0.00111077]
Model epoch 55: train total loss -63.54974835217536, train mean loss 0.000988604419626686, test mean loss [0.00221963 0.00074597 0.00097221 0.00116289 0.0011286  0.00149133
 0.0010594 ]
Model epoch 56: train total loss -63.750422940048615, train mean loss 0.0009192906091668661, test mean loss [0.00225077 0.0007771  0.00097853 0.00124606 0.00104809 0.00137767
 0.0010371 ]
Model epoch 57: train total loss -63.53282513219303, train mean loss 0.001110191749212339, test mean loss [0.00212875 0.00079458 0.00094465 0.00117979 0.00102864 0.00137975
 0.0010188 ]
Model epoch 58: train total loss -63.42059712712743, train mean loss 0.0008881343679658742, test mean loss [0.00208394 0.00072583 0.00093441 0.00116975 0.00108185 0.001378
 0.00098511]
Model epoch 59: train total loss -63.45689201211304, train mean loss 0.0008329005332239519, test mean loss [0.00210947 0.00072602 0.00094504 0.00112148 0.0011453  0.00129854
 0.00093697]
Model epoch 60: train total loss -63.524251091376605, train mean loss 0.0007735713234307981, test mean loss [0.00205459 0.00071086 0.00093921 0.00112006 0.00103833 0.0012717
 0.00095395]
Model epoch 61: train total loss -63.79143613016082, train mean loss 0.0007772683090813976, test mean loss [0.00213157 0.00069481 0.00088981 0.0010803  0.00101263 0.00133208
 0.00093525]
Model epoch 62: train total loss -63.51770132906664, train mean loss 0.0009611896683964928, test mean loss [0.00211313 0.00069428 0.00088431 0.00106699 0.00099087 0.00132057
 0.00085018]
Model epoch 63: train total loss -63.61350679809912, train mean loss 0.0009144004016934859, test mean loss [0.00198256 0.00071703 0.00087297 0.00102953 0.00101095 0.00126821
 0.00090667]
Model epoch 64: train total loss -63.63117190542819, train mean loss 0.0007824164449448854, test mean loss [0.00198286 0.00068852 0.00085288 0.00106965 0.00096087 0.00127904
 0.00089726]
Model epoch 65: train total loss -63.707044360534134, train mean loss 0.0008758732301701172, test mean loss [0.00203115 0.00074142 0.00083709 0.00102506 0.00092965 0.00123563
 0.00084705]
Model epoch 66: train total loss -63.82419042715682, train mean loss 0.0007754129845487197, test mean loss [0.00191188 0.00068316 0.00084346 0.00096024 0.00094296 0.00119724
 0.00086024]
Model epoch 67: train total loss -63.75928284120657, train mean loss 0.0005503825305202974, test mean loss [0.00195124 0.00073302 0.00088296 0.00098764 0.00095489 0.00120068
 0.00083857]
Model epoch 68: train total loss -64.01282823516107, train mean loss 0.0008125377857307122, test mean loss [0.00193436 0.00068714 0.00079107 0.000946   0.0009207  0.00118796
 0.00076701]
Model epoch 69: train total loss -63.67675597198494, train mean loss 0.0009559820355187985, test mean loss [0.0018867  0.00072217 0.00080259 0.00094446 0.00093323 0.0011718
 0.00096353]
Model epoch 70: train total loss -63.85541067538499, train mean loss 0.0007211868640696367, test mean loss [0.00187157 0.00069267 0.00080166 0.00095622 0.00085083 0.00108976
 0.00091361]
Model epoch 71: train total loss -63.87031425403049, train mean loss 0.0007716509933219729, test mean loss [0.00194333 0.0006759  0.00078263 0.00091882 0.00088194 0.00115146
 0.00082217]
Model epoch 72: train total loss -63.82542755695888, train mean loss 0.000726498318176139, test mean loss [0.00189006 0.00064898 0.00080839 0.00088304 0.00091666 0.00111872
 0.00074362]
Model epoch 73: train total loss -63.55339509120445, train mean loss 0.0008579864418337055, test mean loss [0.00180925 0.00064836 0.00077769 0.00089097 0.0008196  0.00107459
 0.00071447]
Model epoch 74: train total loss -63.778408609198394, train mean loss 0.00083374613912853, test mean loss [0.00189955 0.00065444 0.00075898 0.00079176 0.00089512 0.00114347
 0.00073508]
Model epoch 75: train total loss -64.06211407817865, train mean loss 0.0007182008025961309, test mean loss [0.00194392 0.00066985 0.00074453 0.0007961  0.00082155 0.00106371
 0.00072934]
Model epoch 76: train total loss -63.938592175201286, train mean loss 0.000849987377390367, test mean loss [0.00173289 0.00065209 0.00073853 0.00085121 0.00083651 0.00110051
 0.00072415]
Model epoch 77: train total loss -64.0796355983749, train mean loss 0.0008246203909860904, test mean loss [0.00172207 0.00068093 0.00071239 0.00080805 0.00076858 0.00101241
 0.00068066]
Model epoch 78: train total loss -63.76246498270017, train mean loss 0.0007725953642402601, test mean loss [0.00170102 0.00064949 0.00073215 0.00080418 0.00082729 0.00106134
 0.00068443]
Model epoch 79: train total loss -63.99719531114991, train mean loss 0.00065979411983804, test mean loss [0.00172951 0.00063936 0.00069925 0.00078069 0.00080424 0.00100325
 0.00065572]
Model epoch 80: train total loss -64.1294630146704, train mean loss 0.000605022560329405, test mean loss [0.00168469 0.00066879 0.00070612 0.00079614 0.00069943 0.0009803
 0.00065086]
Model epoch 81: train total loss -64.27133141415756, train mean loss 0.0005374806593442434, test mean loss [0.00168541 0.00065473 0.00069363 0.00072764 0.00073717 0.00095324
 0.00060946]
Model epoch 82: train total loss -64.05172991834941, train mean loss 0.0007003284392238054, test mean loss [0.00175111 0.00067666 0.00065031 0.00071677 0.00075902 0.00094729
 0.00062484]
Model epoch 83: train total loss -64.15440967109005, train mean loss 0.0006672833221601657, test mean loss [0.00164574 0.00064537 0.00068466 0.000741   0.000731   0.00100123
 0.00065937]
Model epoch 84: train total loss -64.07353964190567, train mean loss 0.0008219462560260694, test mean loss [0.00168706 0.0006266  0.00066712 0.00071584 0.00070503 0.00100427
 0.00057759]
Model epoch 85: train total loss -63.94687935370097, train mean loss 0.000484662943679836, test mean loss [0.00167711 0.00064608 0.00064744 0.00071344 0.00072389 0.00097125
 0.00061658]
Model epoch 86: train total loss -64.06210991982694, train mean loss 0.0007299356393608945, test mean loss [0.00161141 0.00068067 0.0006356  0.00068578 0.00066147 0.0008928
 0.00060966]
Model epoch 87: train total loss -64.06832235512549, train mean loss 0.0007444879042595657, test mean loss [0.00164059 0.00070303 0.00061883 0.00066711 0.00071811 0.00090862
 0.00056852]
Model epoch 88: train total loss -64.03657568653497, train mean loss 0.0006740606129397277, test mean loss [0.00162224 0.00067255 0.00062171 0.00067414 0.00072014 0.00087553
 0.00057334]
Model epoch 89: train total loss -64.04116858439357, train mean loss 0.0006077275916733025, test mean loss [0.00157263 0.00065111 0.0006102  0.00063467 0.00072839 0.00092959
 0.0005424 ]
Model epoch 90: train total loss -64.33142510808449, train mean loss 0.0006134600846475655, test mean loss [0.00148372 0.00059632 0.00063353 0.0006294  0.00067901 0.00096027
 0.00050536]
Model epoch 91: train total loss -64.0403171457281, train mean loss 0.0008486103312753746, test mean loss [0.00156968 0.00064655 0.0005851  0.00065026 0.0007111  0.00086022
 0.00051013]
Model epoch 92: train total loss -64.3656595760722, train mean loss 0.0004842755547550713, test mean loss [0.00158829 0.00062541 0.00070885 0.00061387 0.00067353 0.00088422
 0.00053094]
Model epoch 93: train total loss -63.87223002867932, train mean loss 0.0006531276743049243, test mean loss [0.00157749 0.00062106 0.00059742 0.00063338 0.00068532 0.00084297
 0.00054539]
Model epoch 94: train total loss -64.03304093758284, train mean loss 0.0008661257118278119, test mean loss [0.0015357  0.00063121 0.00058518 0.00059596 0.00065728 0.00088465
 0.00049703]
Model epoch 95: train total loss -63.98741728662936, train mean loss 0.0005261866681743404, test mean loss [0.00155048 0.00061639 0.00055781 0.00059201 0.00062915 0.00084012
 0.00050666]
Model epoch 96: train total loss -64.07415973462693, train mean loss 0.0005800448511797464, test mean loss [0.00150646 0.00063699 0.00059755 0.00056431 0.00068959 0.00088904
 0.00050369]
Model epoch 97: train total loss -64.0395116275873, train mean loss 0.0004632929148562974, test mean loss [0.00150472 0.00058565 0.00053944 0.00062026 0.00061065 0.00085241
 0.00050754]
Model epoch 98: train total loss -64.32372646931181, train mean loss 0.0005105162479681424, test mean loss [0.00149704 0.00066755 0.00053111 0.00059481 0.00058852 0.0008096
 0.00051564]
Model epoch 99: train total loss -64.48095091148434, train mean loss 0.000508395955798873, test mean loss [0.00146066 0.00061997 0.00054117 0.00062293 0.00060174 0.00079692
 0.00048633]
Model epoch 100: train total loss -63.96772135487909, train mean loss 0.0007032272990043604, test mean loss [0.00143311 0.0006085  0.00053421 0.00059495 0.00065641 0.00076701
 0.00049451]
Model epoch 101: train total loss -64.2885816382562, train mean loss 0.0005891846971210576, test mean loss [0.00139905 0.00058831 0.00052623 0.00057605 0.00057463 0.00079893
 0.00049426]
Model epoch 102: train total loss -63.92741552867472, train mean loss 0.0006127135582081319, test mean loss [0.00144956 0.00059037 0.0005281  0.00053638 0.00062098 0.00075631
 0.00046173]
Model epoch 103: train total loss -64.2109641538528, train mean loss 0.0006278607333610266, test mean loss [0.00138272 0.00056662 0.00053422 0.00053095 0.00060302 0.00076573
 0.00046574]
Model epoch 104: train total loss -64.22567518138533, train mean loss 0.0005136177239246425, test mean loss [0.00141646 0.00057812 0.00052711 0.00053843 0.00058561 0.00076527
 0.00045041]
Model epoch 105: train total loss -64.44780138546598, train mean loss 0.0004487721538653449, test mean loss [0.00141623 0.00059876 0.00049637 0.00050402 0.00056879 0.00076228
 0.00046213]
Model epoch 106: train total loss -64.29146362557789, train mean loss 0.0005565776268738552, test mean loss [0.00134256 0.00055923 0.00050034 0.00051268 0.00060973 0.00074057
 0.00045226]
Model epoch 107: train total loss -63.96594112623263, train mean loss 0.0005307342104575838, test mean loss [0.00135813 0.00057218 0.00050885 0.00050102 0.00056184 0.00073455
 0.00045242]
Model epoch 108: train total loss -64.37126772095858, train mean loss 0.0006221304560324446, test mean loss [0.00141559 0.00057242 0.00049744 0.00050646 0.00055915 0.00072765
 0.0004462 ]
Model epoch 109: train total loss -64.12705473215098, train mean loss 0.0005131109921321993, test mean loss [0.00137323 0.00058967 0.00049889 0.00049002 0.00054923 0.00075571
 0.00045496]
Model epoch 110: train total loss -64.1113128574044, train mean loss 0.000430976980482366, test mean loss [0.00138606 0.0005658  0.00047357 0.00050015 0.00055218 0.00073094
 0.000444  ]
Model epoch 111: train total loss -64.42046358315609, train mean loss 0.00048705911728397894, test mean loss [0.00137606 0.00061697 0.00047836 0.00048525 0.00055085 0.00073864
 0.00042092]
Model epoch 112: train total loss -64.21488489734766, train mean loss 0.0004727341010081687, test mean loss [0.00131862 0.00055602 0.00055769 0.00048163 0.00058587 0.00074117
 0.00042447]
Model epoch 113: train total loss -64.41903959861433, train mean loss 0.0004307532904060045, test mean loss [0.00129181 0.00055007 0.00084823 0.00047225 0.00054639 0.00069112
 0.00042877]
Model epoch 114: train total loss -64.2648329446437, train mean loss 0.0004831430919008016, test mean loss [0.0013653  0.00054906 0.00056312 0.00049818 0.00054378 0.0006884
 0.00042432]
Model epoch 115: train total loss -64.5100978419057, train mean loss 0.0003740236941480154, test mean loss [0.00125948 0.00055198 0.00054772 0.0004727  0.00056158 0.00070113
 0.00041515]
Model epoch 116: train total loss -64.16970941797734, train mean loss 0.00042550063408195593, test mean loss [0.00127312 0.00056491 0.00050684 0.00045535 0.00052223 0.00069436
 0.00041768]
Model epoch 117: train total loss -64.41694299972036, train mean loss 0.00045078062998660603, test mean loss [0.00129172 0.00058234 0.00046606 0.00046771 0.00051867 0.00065578
 0.00040959]
Model epoch 118: train total loss -64.15020049913979, train mean loss 0.0006289986724637284, test mean loss [0.00133823 0.00054219 0.00047993 0.00044264 0.0005461  0.00065983
 0.00040699]
Model epoch 119: train total loss -64.16035615522144, train mean loss 0.0004197283000264968, test mean loss [0.0013238  0.00059267 0.00044673 0.00044694 0.0005328  0.000654
 0.00039429]
Model epoch 120: train total loss -64.52278015363107, train mean loss 0.0004418385706982693, test mean loss [0.00131841 0.00053528 0.00044068 0.00046658 0.00052475 0.00065712
 0.00044694]
Model epoch 121: train total loss -63.99457150426872, train mean loss 0.0005801566689081127, test mean loss [0.0013252  0.00052895 0.00042832 0.00041969 0.00056419 0.00063667
 0.00040227]
Model epoch 122: train total loss -64.20697118742763, train mean loss 0.0003657806952467351, test mean loss [0.0012466  0.0005603  0.00041098 0.00044402 0.0005017  0.00060435
 0.00039967]
Model epoch 123: train total loss -64.1600819008306, train mean loss 0.000491823458336524, test mean loss [0.00123215 0.00056645 0.00041146 0.00042347 0.00050964 0.00056553
 0.0004086 ]
Model epoch 124: train total loss -64.60129870959877, train mean loss 0.0005380934622596102, test mean loss [0.00125048 0.00055826 0.00042209 0.00042169 0.0004869  0.00059861
 0.00041802]
Model epoch 125: train total loss -63.94660824009283, train mean loss 0.0004717702592835138, test mean loss [0.00126416 0.0005777  0.0004077  0.00043738 0.00051208 0.00058886
 0.00038748]
Model epoch 126: train total loss -64.31015420899149, train mean loss 0.000356549524273883, test mean loss [0.00124582 0.00053124 0.00043785 0.0004534  0.00049681 0.00061231
 0.00038383]
Model epoch 127: train total loss -64.61116477498886, train mean loss 0.00032213242246946163, test mean loss [0.00121371 0.00056806 0.00041547 0.00044496 0.00049567 0.00061081
 0.00036859]
Model epoch 128: train total loss -64.26943692574115, train mean loss 0.000430597571407228, test mean loss [0.00133238 0.00066338 0.00042146 0.00043142 0.00051124 0.00062531
 0.00037204]
Model epoch 129: train total loss -64.29275912597086, train mean loss 0.0005382839050457502, test mean loss [0.00126188 0.00053891 0.00037894 0.00036616 0.00045838 0.00056023
 0.00039517]
Model epoch 130: train total loss -64.37579326976234, train mean loss 0.00042230465957975624, test mean loss [0.00120303 0.00055018 0.00039718 0.00040001 0.00048197 0.00058781
 0.00041276]
Model epoch 131: train total loss -64.37573216816112, train mean loss 0.0004278159764320834, test mean loss [0.00131804 0.0005514  0.0003823  0.00038511 0.00049531 0.00059354
 0.00036989]
Model epoch 132: train total loss -64.2146361030878, train mean loss 0.0005287869549684786, test mean loss [0.00115247 0.00051826 0.00038894 0.00038721 0.0004573  0.00058751
 0.00038268]
Model epoch 133: train total loss -64.03694253876773, train mean loss 0.00041416527234517633, test mean loss [0.00115635 0.00051973 0.00040232 0.00040002 0.00047444 0.00057406
 0.00039016]
Model epoch 134: train total loss -64.39039202062231, train mean loss 0.00037400807674910284, test mean loss [0.00127199 0.00053413 0.00038494 0.00038912 0.00067687 0.000547
 0.00038671]
Model epoch 135: train total loss -64.41015515315407, train mean loss 0.0005515639537041695, test mean loss [0.00120835 0.00055177 0.00038865 0.00037012 0.00061463 0.00053331
 0.00039662]
Model epoch 136: train total loss -64.46334910293493, train mean loss 0.00037860728398533074, test mean loss [0.00110595 0.00050078 0.00037953 0.00037539 0.00056163 0.00050617
 0.0003588 ]
Model epoch 137: train total loss -64.34046932321004, train mean loss 0.00046706991025422754, test mean loss [0.0011306  0.00052275 0.00035105 0.00038142 0.00055278 0.00055274
 0.00037564]
Model epoch 138: train total loss -64.40571148680199, train mean loss 0.0004294183992564431, test mean loss [0.0011625  0.00056702 0.00035404 0.00037806 0.00049963 0.00051703
 0.00036441]
Model epoch 139: train total loss -64.34835698106862, train mean loss 0.000388338914703422, test mean loss [0.00112636 0.00053422 0.00035616 0.0003485  0.00053833 0.0005006
 0.00035056]
Model epoch 140: train total loss -64.29932394797198, train mean loss 0.0005195441381004065, test mean loss [0.00112069 0.00052556 0.00033676 0.00036423 0.00047563 0.00053136
 0.00036423]
Model epoch 141: train total loss -64.50598259857816, train mean loss 0.00041165791234160456, test mean loss [0.00123829 0.00052559 0.00034579 0.00034856 0.00053227 0.00051465
 0.00035135]
Model epoch 142: train total loss -64.0948194127268, train mean loss 0.0004609515312472858, test mean loss [0.00116343 0.00053102 0.00035636 0.00037123 0.0005416  0.00050518
 0.0003557 ]
Model epoch 143: train total loss -64.51290564882744, train mean loss 0.0004405208236006407, test mean loss [0.00117054 0.00049836 0.00033849 0.00034305 0.00045414 0.00048699
 0.00035714]
Model epoch 144: train total loss -64.44270494580067, train mean loss 0.0003879306651107537, test mean loss [0.00107401 0.00052007 0.00034859 0.00038    0.00044065 0.00051608
 0.00035928]
Model epoch 145: train total loss -64.4131143698857, train mean loss 0.0004624951472672587, test mean loss [0.00115262 0.00069289 0.00032955 0.00032465 0.00043531 0.00049582
 0.00035153]
Model epoch 146: train total loss -64.47597207352356, train mean loss 0.0003772591339797941, test mean loss [0.00119056 0.00062134 0.00034589 0.00032846 0.00045189 0.00047543
 0.00033872]
Model epoch 147: train total loss -64.32285729391941, train mean loss 0.0004467607175136399, test mean loss [0.00113441 0.00063113 0.00033329 0.00035339 0.00043839 0.00049221
 0.00044809]
Model epoch 148: train total loss -64.4760864854029, train mean loss 0.00037364372592748875, test mean loss [0.00110887 0.00054712 0.0003439  0.00034921 0.00044999 0.00047929
 0.00040781]
Model epoch 149: train total loss -64.39259843639661, train mean loss 0.00034685388463649697, test mean loss [0.00113291 0.00051432 0.00033998 0.00032058 0.00042948 0.00048415
 0.00043803]
Model epoch 150: train total loss -64.39610003017101, train mean loss 0.0005734880375266153, test mean loss [0.0010971  0.00049462 0.00034658 0.00032751 0.00048285 0.00049778
 0.00038984]
Model epoch 151: train total loss -64.22530180890558, train mean loss 0.0003426519855208783, test mean loss [0.00108075 0.00051354 0.00033255 0.00030353 0.00044564 0.00049084
 0.00038882]
Model epoch 152: train total loss -64.4887686298806, train mean loss 0.00045198273900942535, test mean loss [0.00102453 0.00049339 0.0003163  0.00033323 0.00043472 0.0004518
 0.00035427]
Model epoch 153: train total loss -64.70921861529192, train mean loss 0.0003681844884206526, test mean loss [0.0010564  0.00056169 0.00034213 0.00032748 0.00040386 0.00044516
 0.00035146]
Model epoch 154: train total loss -64.49787369406963, train mean loss 0.0003690850575145592, test mean loss [0.00115861 0.00052094 0.00031168 0.00033696 0.00041764 0.00046764
 0.00034564]
Model epoch 155: train total loss -64.34086747892209, train mean loss 0.0003668507186162392, test mean loss [0.00113558 0.00055526 0.00032378 0.0003269  0.00048081 0.0004827
 0.00033593]
Model epoch 156: train total loss -64.43443334791995, train mean loss 0.0003407463133402991, test mean loss [0.00109542 0.00056677 0.00031704 0.00031916 0.00046014 0.00043841
 0.00038006]
Model epoch 157: train total loss -64.3061211357975, train mean loss 0.0004394803223878467, test mean loss [0.00108554 0.00052439 0.00029673 0.00036297 0.00042171 0.00043382
 0.00036011]
Model epoch 158: train total loss -64.58414642559153, train mean loss 0.0003442055169836223, test mean loss [0.00104388 0.00050852 0.00030906 0.00033096 0.00041164 0.00047397
 0.00032497]
Model epoch 159: train total loss -64.87183417930153, train mean loss 0.00037070464053055993, test mean loss [0.00106461 0.00057322 0.00031508 0.00031988 0.00041662 0.00045627
 0.00034399]
Model epoch 160: train total loss -64.5743298642638, train mean loss 0.0003869234669987133, test mean loss [0.00102492 0.00049289 0.00030075 0.00033381 0.0004483  0.00044078
 0.00032882]
Model epoch 161: train total loss -64.44873057350148, train mean loss 0.0005506079875879991, test mean loss [0.00108536 0.00049649 0.00030302 0.00031053 0.00043113 0.00043322
 0.00032113]
Model epoch 162: train total loss -64.45048305361954, train mean loss 0.00033673210502419416, test mean loss [0.00113799 0.00053895 0.00034163 0.00036005 0.00042771 0.00041753
 0.00030828]
Model epoch 163: train total loss -64.61024154963512, train mean loss 0.00034791962978029836, test mean loss [0.00100811 0.00054517 0.00031106 0.00029029 0.00040541 0.00041325
 0.00031341]
Model epoch 164: train total loss -64.51138846315125, train mean loss 0.0003335457867829005, test mean loss [0.00099845 0.00054097 0.00029786 0.00031    0.00042689 0.00043491
 0.00032811]
Model epoch 165: train total loss -64.27498528169431, train mean loss 0.0004330006489200581, test mean loss [0.00097266 0.00048959 0.0002934  0.00033796 0.00043151 0.00043229
 0.00031287]
Model epoch 166: train total loss -64.3048568305801, train mean loss 0.0004118120692216524, test mean loss [0.00094281 0.00051485 0.00031707 0.00030191 0.00042088 0.00041689
 0.00036501]
Model epoch 167: train total loss -64.40874142991416, train mean loss 0.00033892756599585125, test mean loss [0.00094917 0.00052272 0.00030361 0.00029754 0.00042465 0.00038662
 0.00035863]
Model epoch 168: train total loss -64.37571590341375, train mean loss 0.0003974880716444312, test mean loss [0.00095014 0.0005135  0.00029806 0.00029915 0.00041321 0.0004301
 0.00035241]
Model epoch 169: train total loss -64.66472569412183, train mean loss 0.0003611603693230805, test mean loss [0.00094637 0.00048942 0.0002935  0.00027742 0.0003854  0.00038116
 0.0003726 ]
Model epoch 170: train total loss -64.60043633857904, train mean loss 0.00035485058439349516, test mean loss [0.00095591 0.00048284 0.00032067 0.00029886 0.00039401 0.00040882
 0.0003444 ]
Model epoch 171: train total loss -64.5396583195694, train mean loss 0.00029252022309144397, test mean loss [0.00097806 0.00049263 0.00030481 0.00028002 0.00037654 0.00039741
 0.00031121]
Model epoch 172: train total loss -64.47760361347828, train mean loss 0.000375773939233365, test mean loss [0.0009408  0.00052871 0.00031111 0.00028898 0.00042421 0.00039464
 0.00031842]
Model epoch 173: train total loss -64.61247013036773, train mean loss 0.00036033660910363987, test mean loss [0.00094072 0.00047932 0.00030662 0.00027959 0.00039791 0.00039764
 0.00031429]
Model epoch 174: train total loss -64.33364369714002, train mean loss 0.00033086529031897476, test mean loss [0.00096526 0.00048621 0.00028214 0.00026966 0.00039054 0.00040278
 0.00032555]
Model epoch 175: train total loss -64.78867182184027, train mean loss 0.0003810669766004767, test mean loss [0.00090095 0.00048146 0.00029652 0.00027856 0.00041288 0.00042017
 0.00032883]
Model epoch 176: train total loss -64.50356595311133, train mean loss 0.00030075891057084196, test mean loss [0.0010533  0.00048648 0.00030462 0.00026609 0.00040444 0.00043508
 0.00032539]
Model epoch 177: train total loss -64.87167961454404, train mean loss 0.0003585418789708747, test mean loss [0.00101641 0.00052752 0.00030462 0.00030084 0.00038986 0.00040361
 0.00030712]
Model epoch 178: train total loss -64.76807426404793, train mean loss 0.00037716133430191817, test mean loss [0.00103126 0.00049612 0.00030485 0.00027865 0.00039424 0.00039051
 0.00030378]
Model epoch 179: train total loss -64.56278436750978, train mean loss 0.0003723417081535569, test mean loss [0.00101574 0.00052614 0.00029365 0.0002837  0.00037037 0.00038242
 0.00030663]
Model epoch 180: train total loss -64.75597164902186, train mean loss 0.0002898606839117003, test mean loss [0.00093629 0.00053711 0.00028374 0.00029517 0.00039406 0.00036431
 0.00030396]
Model epoch 181: train total loss -64.43880311139095, train mean loss 0.0003164366649735544, test mean loss [0.00095701 0.00047615 0.00029572 0.00026804 0.00038657 0.0003518
 0.00031269]
Model epoch 182: train total loss -64.65927511815424, train mean loss 0.0003168182988998135, test mean loss [0.0009534  0.00048344 0.00028871 0.00027038 0.00040786 0.00037085
 0.00029658]
Model epoch 183: train total loss -64.65570673614472, train mean loss 0.0005111125314292208, test mean loss [0.00093374 0.00053861 0.00028268 0.00024968 0.00042281 0.00035487
 0.00031388]
Model epoch 184: train total loss -64.75771982277227, train mean loss 0.00035628387377351295, test mean loss [0.00100809 0.00046696 0.00029182 0.00027727 0.00037861 0.0003524
 0.00034381]
Model epoch 185: train total loss -64.56886784594664, train mean loss 0.00045065457746371155, test mean loss [0.00095636 0.00050665 0.00032526 0.00025664 0.00039299 0.00039467
 0.00030429]
Model epoch 186: train total loss -64.65760594039166, train mean loss 0.0003837731093630132, test mean loss [0.00091987 0.00049639 0.00029571 0.00024258 0.00041469 0.00035569
 0.00029275]
Model epoch 187: train total loss -64.8977370625093, train mean loss 0.00028055905136911143, test mean loss [0.00090497 0.00049031 0.00028451 0.00025322 0.00040542 0.00034359
 0.00029996]
Model epoch 188: train total loss -64.68356790358807, train mean loss 0.0004061618736548654, test mean loss [0.00092278 0.000495   0.00030235 0.00025892 0.00039926 0.00035587
 0.00030206]
Model epoch 189: train total loss -64.73069905537248, train mean loss 0.0003679605902770241, test mean loss [0.00091287 0.00049467 0.00029989 0.00026227 0.00040926 0.00036473
 0.00029676]
Model epoch 190: train total loss -64.86700161864908, train mean loss 0.0003366929771399373, test mean loss [0.00092919 0.00055244 0.00033653 0.00026145 0.00037928 0.00033483
 0.00028724]
Model epoch 191: train total loss -64.72180532747467, train mean loss 0.00035826947326070773, test mean loss [0.00084385 0.00048431 0.00031709 0.00024116 0.00036675 0.0003438
 0.00033808]
Model epoch 192: train total loss -64.12881459451596, train mean loss 0.0004261645852628896, test mean loss [0.00092923 0.00049529 0.00031287 0.00025325 0.00035858 0.00033
 0.00032329]
Model epoch 193: train total loss -64.64439637254993, train mean loss 0.00030016000107932267, test mean loss [0.0009205  0.00055325 0.00029406 0.00031766 0.00042817 0.0003336
 0.00029605]
Model epoch 194: train total loss -64.65210027119254, train mean loss 0.0003849838170311857, test mean loss [0.00094773 0.00047243 0.00028665 0.00028389 0.00040234 0.00032725
 0.00030087]
Model epoch 195: train total loss -64.53248974339037, train mean loss 0.0003053184765150443, test mean loss [0.00095159 0.00047383 0.00028698 0.00028621 0.00038265 0.00032567
 0.00031017]
Model epoch 196: train total loss -64.71690015609023, train mean loss 0.00031289779047219624, test mean loss [0.00089406 0.00047927 0.00028086 0.00027556 0.00036587 0.00032227
 0.00028247]
Model epoch 197: train total loss -64.54439132567614, train mean loss 0.00031730320976249335, test mean loss [0.00090347 0.0004476  0.00045901 0.00025389 0.00036496 0.00031017
 0.00030909]
Model epoch 198: train total loss -64.82280051956057, train mean loss 0.00034772561660127683, test mean loss [0.00089237 0.00045537 0.00049195 0.000245   0.00036657 0.00033703
 0.00028286]
Model epoch 199: train total loss -64.50922277108305, train mean loss 0.00037469195254137566, test mean loss [0.00085532 0.00054701 0.00035908 0.0002366  0.00035245 0.00031564
 0.00030508]
Model epoch 200: train total loss -64.74546867572192, train mean loss 0.00028642759672270354, test mean loss [0.00083625 0.00055195 0.00035536 0.00022188 0.00036569 0.00034372
 0.00030109]
Model epoch 201: train total loss -64.70628039889074, train mean loss 0.0003612292474909478, test mean loss [0.00087028 0.00052684 0.00028878 0.00023536 0.00037313 0.00032652
 0.0003117 ]
Model epoch 202: train total loss -64.71487729217807, train mean loss 0.00029672381722912144, test mean loss [0.00083845 0.00048606 0.00028025 0.00025409 0.00035559 0.00031861
 0.00027668]
Model epoch 203: train total loss -64.77125107081854, train mean loss 0.0003108411680995656, test mean loss [0.00090259 0.00047698 0.00028309 0.00024779 0.00037134 0.00033319
 0.00027123]
Model epoch 204: train total loss -64.60180339580742, train mean loss 0.00028256593690509667, test mean loss [0.00084122 0.00046921 0.00027216 0.00023131 0.00036735 0.00030231
 0.00025959]
Model epoch 205: train total loss -64.65386167338923, train mean loss 0.00028978379689050633, test mean loss [0.00085613 0.00049571 0.0002883  0.00026027 0.00036912 0.00030266
 0.00027386]
Model epoch 206: train total loss -65.04739716774284, train mean loss 0.00036857301693735714, test mean loss [0.00089645 0.000479   0.0002688  0.00021079 0.00035131 0.00029571
 0.00028369]
Model epoch 207: train total loss -64.67213181619758, train mean loss 0.00033611230292701253, test mean loss [0.00082556 0.00046222 0.00029674 0.00021658 0.00034071 0.00029081
 0.00027929]
Model epoch 208: train total loss -64.81194309571656, train mean loss 0.0003485944764425797, test mean loss [0.00097081 0.00050997 0.00028122 0.00022576 0.00035745 0.00029357
 0.00027964]
Model epoch 209: train total loss -64.59252094986648, train mean loss 0.0003145420364574608, test mean loss [0.00082035 0.0004963  0.00027845 0.00025195 0.00035382 0.00031863
 0.00028615]
Model epoch 210: train total loss -64.65208734653793, train mean loss 0.00030771491010944625, test mean loss [0.00089532 0.00042996 0.00028534 0.00023994 0.00036371 0.0002863
 0.00028303]
Model epoch 211: train total loss -64.64801233622086, train mean loss 0.0002953930733661547, test mean loss [0.00087066 0.0004341  0.00026467 0.00022413 0.00034244 0.00031448
 0.00027185]
Model epoch 212: train total loss -64.53092008842243, train mean loss 0.0003146694382464688, test mean loss [0.00079602 0.00044334 0.00026879 0.00022204 0.00075551 0.0002966
 0.00025773]
Model epoch 213: train total loss -65.05574534889155, train mean loss 0.00031786359409748127, test mean loss [0.00083417 0.00048162 0.00027763 0.00023061 0.00061003 0.00029172
 0.00027442]
Model epoch 214: train total loss -64.79466154046617, train mean loss 0.00029516856847690417, test mean loss [0.00085616 0.00049456 0.00028858 0.00021669 0.00040491 0.00031665
 0.00025329]
Model epoch 215: train total loss -64.92399076714486, train mean loss 0.0002515294191853224, test mean loss [0.0008846  0.00045303 0.00028112 0.00021833 0.00035859 0.00032527
 0.0002627 ]
Model epoch 216: train total loss -64.6322961810139, train mean loss 0.000304892349781945, test mean loss [0.00090799 0.0004832  0.00028915 0.0002191  0.00035067 0.00027939
 0.00025783]
Model epoch 217: train total loss -64.66311101652323, train mean loss 0.0003602926826332812, test mean loss [0.0009223  0.00048223 0.00027669 0.00023179 0.00035863 0.00028526
 0.0002841 ]
Model epoch 218: train total loss -64.70265599521123, train mean loss 0.0002839843447645426, test mean loss [0.00093414 0.00057192 0.0002872  0.0002187  0.00032284 0.00028775
 0.00028407]
Model epoch 219: train total loss -64.48666478829807, train mean loss 0.0002669873790418112, test mean loss [0.00089732 0.00046075 0.00027852 0.00023769 0.0004159  0.00026654
 0.0002689 ]
Model epoch 220: train total loss -64.87571210404036, train mean loss 0.000316970496722381, test mean loss [0.00085046 0.00043744 0.00028899 0.0002114  0.00034999 0.00027777
 0.00027152]
Model epoch 221: train total loss -64.8806801636683, train mean loss 0.0003760192023480505, test mean loss [0.00086108 0.00049951 0.00031793 0.00022904 0.00031315 0.00029865
 0.00026012]
Model epoch 222: train total loss -64.90084449080997, train mean loss 0.0002568086405751803, test mean loss [0.00081953 0.00048525 0.00027556 0.0002129  0.00035533 0.00027771
 0.00026521]
Model epoch 223: train total loss -64.714564486707, train mean loss 0.0003089120536120186, test mean loss [0.00087654 0.0004619  0.00027852 0.00021871 0.00035809 0.00028865
 0.00026538]
Model epoch 224: train total loss -64.48458758755605, train mean loss 0.0003465269701592002, test mean loss [0.00081611 0.00044349 0.00027814 0.00020024 0.00037484 0.00028663
 0.00026421]
Model epoch 225: train total loss -64.67004907210588, train mean loss 0.000305534598110917, test mean loss [0.00086944 0.00044613 0.00029148 0.00022817 0.00036038 0.00029416
 0.00025619]
Model epoch 226: train total loss -64.60047248581662, train mean loss 0.000270136044029135, test mean loss [0.00081474 0.00044736 0.00026881 0.00022162 0.00037341 0.00027369
 0.0002602 ]
Model epoch 227: train total loss -64.7164838486293, train mean loss 0.00033103518290971166, test mean loss [0.00082504 0.00047552 0.00027699 0.00019482 0.00034859 0.00026849
 0.00026383]
Model epoch 228: train total loss -64.83520206064685, train mean loss 0.00028376242655430936, test mean loss [0.00083006 0.00045623 0.00027992 0.00018771 0.00032563 0.00028015
 0.00028017]
Model epoch 229: train total loss -64.7517740104907, train mean loss 0.00032995040119326494, test mean loss [0.00083391 0.0004561  0.00028186 0.00021002 0.00032331 0.00027203
 0.00025758]
Model epoch 230: train total loss -64.76860500144808, train mean loss 0.00031021438285400464, test mean loss [0.00084312 0.00044036 0.00027059 0.00020163 0.00033881 0.00026785
 0.00025068]
Model epoch 231: train total loss -64.87301845229362, train mean loss 0.0003629846247502063, test mean loss [0.00085069 0.00045447 0.00026706 0.00022566 0.00035905 0.00028857
 0.00026673]
Model epoch 232: train total loss -64.4637892991889, train mean loss 0.0002974603244128911, test mean loss [0.00083597 0.00044203 0.00028773 0.00021196 0.00033597 0.00028615
 0.00026642]
Model epoch 233: train total loss -64.78309070676094, train mean loss 0.0002507261105254769, test mean loss [0.00079632 0.00045701 0.00029509 0.00019291 0.00032241 0.0002824
 0.00029198]
Model epoch 234: train total loss -64.71182924976408, train mean loss 0.00029684207767174264, test mean loss [0.00081541 0.00062251 0.00030435 0.00019685 0.00034082 0.00031957
 0.00026038]
Model epoch 235: train total loss -64.8015597682893, train mean loss 0.00028083166415909685, test mean loss [0.00083215 0.00052209 0.00026986 0.00020819 0.00032224 0.00028305
 0.00025713]
Model epoch 236: train total loss -64.63798608705471, train mean loss 0.0003070413330874821, test mean loss [0.00082548 0.00052065 0.00026056 0.00018792 0.00033593 0.00025875
 0.00026473]
Model epoch 237: train total loss -64.69396447416028, train mean loss 0.0002819868886274264, test mean loss [0.00082324 0.00053474 0.0002571  0.00020277 0.00031689 0.00026752
 0.00026501]
Model epoch 238: train total loss -64.84895136492678, train mean loss 0.0003226680540740885, test mean loss [0.00080477 0.00051591 0.00027804 0.00020777 0.00032135 0.00026327
 0.00025324]
Model epoch 239: train total loss -64.68627041170083, train mean loss 0.0003129308099428709, test mean loss [0.00089131 0.00047145 0.00027746 0.00022939 0.00037374 0.00026111
 0.00026637]
Model epoch 240: train total loss -64.93806205234851, train mean loss 0.00028808400029392436, test mean loss [0.0008195  0.00045265 0.00026178 0.00020337 0.00034408 0.0002551
 0.00025884]
Model epoch 241: train total loss -64.86073787012528, train mean loss 0.00027697430895606986, test mean loss [0.00081134 0.00044723 0.00026791 0.00020289 0.00032482 0.00026471
 0.00026239]
Model epoch 242: train total loss -64.97103226126804, train mean loss 0.00025599127604278624, test mean loss [0.00092363 0.00046952 0.00027354 0.00019984 0.00034393 0.00024228
 0.00026139]
Model epoch 243: train total loss -64.88348833679842, train mean loss 0.0002521641758145013, test mean loss [0.00081347 0.00050191 0.00027615 0.0002239  0.00034971 0.00024613
 0.00025013]
Model epoch 244: train total loss -64.599393797936, train mean loss 0.0003220022358878746, test mean loss [0.00081051 0.00050867 0.00027612 0.00021968 0.00030423 0.00026121
 0.00025855]
Model epoch 245: train total loss -64.65937876335583, train mean loss 0.0002459637735196614, test mean loss [0.00083416 0.00049862 0.00027752 0.00019205 0.00035571 0.00025654
 0.00023782]
Model epoch 246: train total loss -64.87604634065035, train mean loss 0.0003386190337958976, test mean loss [0.00087884 0.00044533 0.00026541 0.00018517 0.00034834 0.00024387
 0.00026154]
Model epoch 247: train total loss -64.8328396183479, train mean loss 0.0002892864403572541, test mean loss [0.00078088 0.0004451  0.00028251 0.00018843 0.00033962 0.00023842
 0.00027779]
Model epoch 248: train total loss -64.88122581634184, train mean loss 0.00032530594900783213, test mean loss [0.00075335 0.00047698 0.00027619 0.00019934 0.00035142 0.00025655
 0.00025593]
Model epoch 249: train total loss -64.9584685809332, train mean loss 0.0002842399742686437, test mean loss [0.00078754 0.00044683 0.00026122 0.00017561 0.00032359 0.00025942
 0.00023752]
Model epoch 250: train total loss -64.80249995036773, train mean loss 0.0002751122919644288, test mean loss [0.00078374 0.00048496 0.00027233 0.00020143 0.00031839 0.00024823
 0.00025848]
Model epoch 251: train total loss -64.74962103670649, train mean loss 0.00025950150062106276, test mean loss [0.00085517 0.00045633 0.0002773  0.0001929  0.00032989 0.0002442
 0.0002501 ]
Model epoch 252: train total loss -64.63863946407827, train mean loss 0.00033814749351428387, test mean loss [0.00078509 0.0005493  0.00025738 0.00018839 0.00033419 0.00024462
 0.00024064]
Model epoch 253: train total loss -64.88841835856557, train mean loss 0.00026989652812445074, test mean loss [0.00075984 0.0004659  0.00026221 0.00019696 0.00031258 0.00023206
 0.00025028]
Model epoch 254: train total loss -64.46306284386124, train mean loss 0.0002568538616224775, test mean loss [0.00077323 0.00047433 0.00026967 0.00020405 0.00033831 0.00024485
 0.00025327]
Model epoch 255: train total loss -64.90437450347194, train mean loss 0.00029619107634440536, test mean loss [0.00080002 0.00048043 0.00026081 0.00017679 0.00032744 0.00023254
 0.00027244]
Model epoch 256: train total loss -64.91688039584544, train mean loss 0.00024634897866766077, test mean loss [0.00085116 0.00047777 0.00026136 0.00017349 0.00033642 0.00025328
 0.00025961]
Model epoch 257: train total loss -64.86470024342577, train mean loss 0.00029171700287804967, test mean loss [0.00077395 0.00047674 0.00026279 0.00018742 0.00032052 0.0002421
 0.00024656]
Model epoch 258: train total loss -64.9038504426729, train mean loss 0.00024933516457435983, test mean loss [0.00082649 0.00042784 0.00026788 0.00018637 0.00031923 0.00022375
 0.00024017]
Model epoch 259: train total loss -64.79206128299904, train mean loss 0.0002400300391342882, test mean loss [0.00075625 0.00045535 0.00026515 0.0001968  0.00032937 0.00023019
 0.00024554]
Model epoch 260: train total loss -64.88774448330979, train mean loss 0.000291262310373611, test mean loss [0.00079788 0.00044433 0.00025824 0.00018519 0.00033346 0.0002456
 0.00025852]
Model epoch 261: train total loss -64.73347416704146, train mean loss 0.0003014223211678429, test mean loss [0.00077843 0.00044318 0.00025121 0.00018925 0.00029142 0.00023242
 0.00023791]
Model epoch 262: train total loss -65.08975076899732, train mean loss 0.00025163263099846654, test mean loss [0.00082327 0.00048756 0.0002552  0.00018269 0.00034509 0.00024171
 0.00025674]
Model epoch 263: train total loss -64.95421695274455, train mean loss 0.00027677619246666203, test mean loss [0.00083609 0.00046695 0.00027827 0.0001978  0.00032323 0.00023334
 0.00024464]
Model epoch 264: train total loss -64.42106147025935, train mean loss 0.0003286616859577588, test mean loss [0.00079029 0.00041109 0.00026389 0.00018708 0.00037862 0.00024382
 0.00025257]
Model epoch 265: train total loss -64.84599991113352, train mean loss 0.0002998811209744504, test mean loss [0.00078781 0.00054227 0.000263   0.00017692 0.00032224 0.00022242
 0.00026873]
Model epoch 266: train total loss -64.63912781093221, train mean loss 0.0002903553323607593, test mean loss [0.0007418  0.00050801 0.00027776 0.00018518 0.00039782 0.00024977
 0.00024504]
Model epoch 267: train total loss -65.25291705826325, train mean loss 0.0002481122450092252, test mean loss [0.00077877 0.00047325 0.0002655  0.00018325 0.00033914 0.00023068
 0.00023556]
Model epoch 268: train total loss -64.90162445919466, train mean loss 0.0002803384180193463, test mean loss [0.00075447 0.00044935 0.00026974 0.0001974  0.00033399 0.00024067
 0.00023782]
Model epoch 269: train total loss -64.8322347497388, train mean loss 0.000264133870146375, test mean loss [0.00073981 0.00043065 0.00027193 0.000177   0.00032982 0.00024086
 0.00024429]
Model epoch 270: train total loss -64.65424428782615, train mean loss 0.0003205470323719157, test mean loss [0.0010768  0.00046089 0.00026112 0.00017831 0.00035719 0.0002251
 0.00025537]
Model epoch 271: train total loss -64.92960593368439, train mean loss 0.00032134886703925826, test mean loss [0.00081994 0.00044447 0.00025693 0.00018751 0.00033104 0.0002314
 0.00024795]
Model epoch 272: train total loss -65.01632431582752, train mean loss 0.0002727825512272109, test mean loss [0.00077952 0.00044584 0.00026559 0.000181   0.00032386 0.00022229
 0.00023705]
Model trained in 273 epochs with 7000 transitions.
[2025-01-24 23:32:46,254][absl][INFO] - {'eval/walltime': 253.94215536117554, 'training/sps': 0.22442573505093044, 'training/walltime': 23712.14438033104, 'training/model_train_time': 2683.0000143051147, 'training/other_time': 1771.9825766086578, 'training/model_horizon': 12, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(8000, dtype=int32), 'model/train_total_loss': Array(-65.01632432, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00027278, dtype=float64), 'model/test_total_loss': Array(-64.19278819, dtype=float64), 'model/test_mean_loss': Array(0.00035074, dtype=float64), 'model/train_epochs': 273, 'model/sec_per_epoch': 9.82016870652363, 'sac/actor_loss': Array(-25.2978915, dtype=float64), 'sac/alpha': Array(0.0260141, dtype=float32), 'sac/alpha_loss': Array(2.17210664e-05, dtype=float64), 'sac/buffer_current_size': Array(400000.03, dtype=float32), 'sac/critic_loss': Array(0.09462481, dtype=float64), 'eval/episode_forward_vel': Array(6.40562536, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-2.00353773, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(15.4734114, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.08233229, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(2.75510768, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(15.58011115, dtype=float64), 'eval/episode_rew_roll': Array(14.24288889, dtype=float64), 'eval/episode_rew_side_motion': Array(21.66481359, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(20.43720807, dtype=float64), 'eval/episode_rew_yaw': Array(21.5034406, dtype=float64), 'eval/episode_rew_z_vel_change': Array(8.7603509, dtype=float64), 'eval/episode_reward': Array(117.62448512, dtype=float64), 'eval/episode_step_count': Array(49455., dtype=float64), 'eval/avg_episode_length': Array(315., dtype=float64), 'eval/epoch_eval_time': 30.116105556488037, 'eval/sps': 33.204824512396684}
Steps / Eval:  8000.0
Reward is  117.62448512191527
Model horizon updated to 14.
Hallucination updates per training step updated to 1000.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -43.79518141708201, train mean loss 0.014040462679240355, test mean loss [0.01478099 0.01286588 0.0123941  0.0161985  0.01365715 0.02133724
 0.01921869]
Model epoch 1: train total loss -51.466976734880916, train mean loss 0.010510270118297575, test mean loss [0.01083491 0.00925531 0.00858047 0.01021553 0.00900467 0.01660548
 0.01335178]
Model epoch 2: train total loss -55.42083569962667, train mean loss 0.0065343309037225955, test mean loss [0.00796376 0.00727174 0.00623184 0.00789967 0.00645217 0.0129762
 0.00972302]
Model epoch 3: train total loss -57.01831345612512, train mean loss 0.006230337804302008, test mean loss [0.00665256 0.00585804 0.00511563 0.00622091 0.00496019 0.0100192
 0.00720657]
Model epoch 4: train total loss -58.335636394413754, train mean loss 0.004307865980179883, test mean loss [0.00555188 0.00496929 0.00430875 0.00507263 0.00404804 0.0082486
 0.00577864]
Model epoch 5: train total loss -59.85496189912461, train mean loss 0.003658041627241773, test mean loss [0.00480802 0.00435405 0.00368068 0.00438214 0.00341855 0.00700589
 0.0047898 ]
Model epoch 6: train total loss -60.16424673137162, train mean loss 0.0038164104200006516, test mean loss [0.00419851 0.00393448 0.00319701 0.00390563 0.00295682 0.00596703
 0.00416014]
Model epoch 7: train total loss -60.84691390196632, train mean loss 0.002626347467208016, test mean loss [0.00379981 0.00357009 0.00286299 0.00345262 0.00267744 0.00514171
 0.00352892]
Model epoch 8: train total loss -61.35788274883497, train mean loss 0.002125535090882771, test mean loss [0.00341938 0.00330758 0.00254094 0.0030716  0.00231809 0.00447198
 0.0031457 ]
Model epoch 9: train total loss -61.57837776625768, train mean loss 0.002221886731539047, test mean loss [0.0030711  0.00312012 0.00233906 0.00281727 0.00204931 0.0040394
 0.00276805]
Model epoch 10: train total loss -61.581494615495174, train mean loss 0.00204828672782994, test mean loss [0.00279259 0.00283677 0.00217049 0.0025993  0.00176589 0.00356175
 0.00250369]
Model epoch 11: train total loss -62.44425201367076, train mean loss 0.00136192351861521, test mean loss [0.0025786  0.00262128 0.0020263  0.00242629 0.00164773 0.00325359
 0.0021723 ]
Model epoch 12: train total loss -62.442283232872796, train mean loss 0.0013441975573612406, test mean loss [0.00238483 0.00242508 0.0018707  0.00221956 0.00150402 0.00292239
 0.00190633]
Model epoch 13: train total loss -62.64867453961828, train mean loss 0.001109857278826559, test mean loss [0.00216817 0.00227458 0.00182034 0.00207283 0.00136204 0.00267361
 0.00177051]
Model epoch 14: train total loss -62.72938005901111, train mean loss 0.0010081138872039008, test mean loss [0.00202564 0.00216534 0.00170134 0.00190006 0.00126865 0.00247386
 0.00162185]
Model epoch 15: train total loss -62.56454856040836, train mean loss 0.00104420031141968, test mean loss [0.0019092  0.0020663  0.00159533 0.00177565 0.0011771  0.00234033
 0.00153298]
Model epoch 16: train total loss -63.09906840059689, train mean loss 0.0009847810042942148, test mean loss [0.00178722 0.00189245 0.00152988 0.00174884 0.00110676 0.0021982
 0.00141389]
Model epoch 17: train total loss -63.14200371280945, train mean loss 0.0007816410687013365, test mean loss [0.00165551 0.00184758 0.00150127 0.00161676 0.00101732 0.00205692
 0.00136328]
Model epoch 18: train total loss -63.23933030077273, train mean loss 0.0008520350199104012, test mean loss [0.00156042 0.00176787 0.00143402 0.00152824 0.00103205 0.00190946
 0.00135041]
Model epoch 19: train total loss -63.342081907579626, train mean loss 0.0007799116683245511, test mean loss [0.00148323 0.00165495 0.00133682 0.00143693 0.0009995  0.00176666
 0.00126836]
Model epoch 20: train total loss -63.282056385339494, train mean loss 0.0007106036920531079, test mean loss [0.00142932 0.00156057 0.00143343 0.00141948 0.00092441 0.00170726
 0.00121149]
Model epoch 21: train total loss -63.40917818622001, train mean loss 0.0008811690041988859, test mean loss [0.00141346 0.0015789  0.00125973 0.00131487 0.00085684 0.00160998
 0.0011564 ]
Model epoch 22: train total loss -63.39110108556733, train mean loss 0.0005746910214677846, test mean loss [0.00131874 0.00150052 0.00120641 0.00125875 0.00082688 0.00156204
 0.00109682]
Model epoch 23: train total loss -63.67341773087236, train mean loss 0.0006281119781732337, test mean loss [0.00124597 0.00144736 0.00116251 0.00121572 0.0008394  0.00146731
 0.00105713]
Model epoch 24: train total loss -63.69349265038531, train mean loss 0.0005847539560429425, test mean loss [0.00127192 0.00139381 0.00115538 0.00117977 0.00079637 0.00141657
 0.00103322]
Model epoch 25: train total loss -63.71216165622637, train mean loss 0.0005777823152366347, test mean loss [0.00122985 0.00133815 0.00110698 0.00111584 0.00075337 0.00138995
 0.00099933]
Model epoch 26: train total loss -63.143320520658484, train mean loss 0.0007527760694784972, test mean loss [0.00118851 0.00130412 0.00107991 0.00110541 0.00072671 0.00132734
 0.0009935 ]
Model epoch 27: train total loss -63.470196351010784, train mean loss 0.0006859726801986512, test mean loss [0.0011616  0.00127829 0.0010224  0.00104433 0.00070238 0.00129116
 0.00093558]
Model epoch 28: train total loss -63.88604285619494, train mean loss 0.0005641751577837279, test mean loss [0.00111656 0.00122959 0.00109745 0.00103763 0.00067774 0.00122628
 0.00091705]
Model epoch 29: train total loss -63.902248523219235, train mean loss 0.00039248742017362854, test mean loss [0.00105722 0.00122583 0.00102315 0.00100105 0.00068441 0.00120845
 0.00095684]
Model epoch 30: train total loss -63.71608410894852, train mean loss 0.0004597779173715393, test mean loss [0.00106531 0.00114792 0.00097951 0.00098293 0.00064774 0.00120791
 0.00090548]
Model epoch 31: train total loss -63.81246294123888, train mean loss 0.000600491330344902, test mean loss [0.00106068 0.00112175 0.00094809 0.00095487 0.00062489 0.00118865
 0.00087065]
Model epoch 32: train total loss -63.88237099823625, train mean loss 0.0006348406479541844, test mean loss [0.00103358 0.00114511 0.00091905 0.00091671 0.00061951 0.00113954
 0.00086671]
Model epoch 33: train total loss -63.888056681674215, train mean loss 0.00043604269186076517, test mean loss [0.00102993 0.00109285 0.00092862 0.00086501 0.000612   0.0011075
 0.00085256]
Model epoch 34: train total loss -63.73535888311476, train mean loss 0.0006180286420498812, test mean loss [0.00098784 0.00106766 0.0009343  0.00089097 0.0005682  0.00110828
 0.00083646]
Model epoch 35: train total loss -63.92284194256977, train mean loss 0.00045113375938199874, test mean loss [0.00096164 0.00103441 0.00086279 0.00085238 0.00060143 0.00108226
 0.00081954]
Model epoch 36: train total loss -63.98623751376118, train mean loss 0.000502332077770308, test mean loss [0.00096047 0.00105172 0.00085313 0.00083801 0.00058675 0.00102587
 0.0007891 ]
Model epoch 37: train total loss -63.8358306676259, train mean loss 0.00046756782405778393, test mean loss [0.00094419 0.00102857 0.00084461 0.00082241 0.00058631 0.00100977
 0.0008007 ]
Model epoch 38: train total loss -64.07463779951233, train mean loss 0.00035844476579108075, test mean loss [0.00095225 0.00101071 0.00081066 0.00080942 0.00058124 0.00103342
 0.00076738]
Model epoch 39: train total loss -64.0236774815237, train mean loss 0.0003337932105536398, test mean loss [0.00092042 0.0010025  0.00079459 0.00081074 0.00053903 0.00099863
 0.00077391]
Model epoch 40: train total loss -63.96113687133692, train mean loss 0.0004294745488719476, test mean loss [0.00092911 0.00098367 0.00079492 0.00077791 0.00054354 0.00096923
 0.00075788]
Model epoch 41: train total loss -64.00184905651172, train mean loss 0.00043768285419722847, test mean loss [0.00091456 0.00095301 0.00076721 0.000744   0.00055854 0.00096379
 0.00074408]
Model epoch 42: train total loss -64.01808211415455, train mean loss 0.00046024959218171515, test mean loss [0.00089333 0.00097504 0.00080564 0.00077748 0.00053195 0.00093395
 0.00075253]
Model epoch 43: train total loss -63.99693601159573, train mean loss 0.00038395242520991726, test mean loss [0.00087536 0.0009649  0.00075002 0.00079073 0.00050796 0.00090148
 0.00091867]
Model epoch 44: train total loss -63.96166397319626, train mean loss 0.00035196645776152215, test mean loss [0.00086239 0.00094485 0.00075551 0.00076635 0.00051321 0.00090334
 0.00072786]
Model epoch 45: train total loss -64.31681735877874, train mean loss 0.00041729667326872197, test mean loss [0.00083678 0.00093128 0.00078177 0.0007508  0.00049572 0.00094827
 0.00070653]
Model epoch 46: train total loss -64.26961541531514, train mean loss 0.0004310780409094402, test mean loss [0.000835   0.00091011 0.00073216 0.00071152 0.00048937 0.0008864
 0.00070062]
Model epoch 47: train total loss -63.75921777526642, train mean loss 0.0003236016744879558, test mean loss [0.00084503 0.00091776 0.00073793 0.00070653 0.00047358 0.00090091
 0.00068713]
Model epoch 48: train total loss -64.35375605962786, train mean loss 0.0002961712022057041, test mean loss [0.00082157 0.00088822 0.00070361 0.0007005  0.00048886 0.00085067
 0.0006795 ]
Model epoch 49: train total loss -64.22231644962842, train mean loss 0.0003705708484961856, test mean loss [0.00084481 0.00088957 0.00068324 0.00072117 0.00045895 0.00084387
 0.00070259]
Model epoch 50: train total loss -64.00975263293105, train mean loss 0.0005178674143538364, test mean loss [0.00084383 0.0008742  0.00067829 0.00066298 0.00044704 0.00083683
 0.00067292]
Model epoch 51: train total loss -63.875372267847546, train mean loss 0.00031808022481717843, test mean loss [0.00081615 0.00088321 0.00067687 0.00067456 0.00044607 0.0008214
 0.00073813]
Model epoch 52: train total loss -64.27832505308095, train mean loss 0.00030091593934848605, test mean loss [0.0008083  0.00084619 0.0006793  0.00066161 0.00045959 0.00082672
 0.00066767]
Model epoch 53: train total loss -64.18912760657491, train mean loss 0.00036114949774078214, test mean loss [0.00079005 0.00086718 0.00065157 0.00067429 0.00044125 0.00082232
 0.00065522]
Model epoch 54: train total loss -64.36435317836693, train mean loss 0.0005036063716312741, test mean loss [0.000798   0.00084813 0.0006506  0.00064819 0.00042734 0.00082053
 0.00064793]
Model epoch 55: train total loss -64.17836016784226, train mean loss 0.0005413700288119764, test mean loss [0.00079004 0.00083802 0.0006165  0.00062231 0.00042805 0.00081739
 0.00062945]
Model epoch 56: train total loss -63.991687776020996, train mean loss 0.00044759397566809605, test mean loss [0.00078383 0.0008326  0.00062505 0.00064608 0.00041275 0.00078258
 0.00064127]
Model epoch 57: train total loss -64.46378404176619, train mean loss 0.00034652081322345007, test mean loss [0.00074814 0.00081991 0.00063651 0.00063633 0.00043304 0.00077283
 0.00064363]
Model epoch 58: train total loss -64.3029784479452, train mean loss 0.0003722092633481352, test mean loss [0.00076776 0.00082645 0.00062051 0.00062228 0.00039918 0.00076745
 0.00062047]
Model epoch 59: train total loss -64.29088667851111, train mean loss 0.000267258907776847, test mean loss [0.00077324 0.00079131 0.00061504 0.00063249 0.00042137 0.0007761
 0.00059694]
Model epoch 60: train total loss -64.17545352258084, train mean loss 0.0003417698474523429, test mean loss [0.00077326 0.00078231 0.00060316 0.00062298 0.00039867 0.00077338
 0.00059882]
Model epoch 61: train total loss -64.2951852839274, train mean loss 0.00029200990909910234, test mean loss [0.00074409 0.00081625 0.00062182 0.00061585 0.00039888 0.00075719
 0.00060877]
Model epoch 62: train total loss -64.25109565172644, train mean loss 0.0003296131101474102, test mean loss [0.00074693 0.00078248 0.00061586 0.00061082 0.00039841 0.00075915
 0.00060671]
Model epoch 63: train total loss -64.13615529828601, train mean loss 0.0005273000698606366, test mean loss [0.00074936 0.00080929 0.00057121 0.00061827 0.00038478 0.00071638
 0.00057149]
Model epoch 64: train total loss -64.2621113263925, train mean loss 0.0004568636682074201, test mean loss [0.00073361 0.00078133 0.00056937 0.00061267 0.00039902 0.00070668
 0.00059376]
Model epoch 65: train total loss -64.34276833401965, train mean loss 0.00033522590383543003, test mean loss [0.0007394  0.00076325 0.00056066 0.00063726 0.00039403 0.00072502
 0.00059385]
Model epoch 66: train total loss -64.31793601426666, train mean loss 0.00033406750535877556, test mean loss [0.00077465 0.00075788 0.00056164 0.00058212 0.00038445 0.00069929
 0.00059409]
Model epoch 67: train total loss -64.4134943949799, train mean loss 0.0004917626475425122, test mean loss [0.00073462 0.00074269 0.00054245 0.00060903 0.00038631 0.00070541
 0.00057672]
Model epoch 68: train total loss -64.21407527634634, train mean loss 0.0003879527923386928, test mean loss [0.00072001 0.00075471 0.00053366 0.00057609 0.00036255 0.00069182
 0.00058779]
Model epoch 69: train total loss -64.3539002655703, train mean loss 0.00033525892582746494, test mean loss [0.00071734 0.00076906 0.00055315 0.00057678 0.00038921 0.00068599
 0.00058732]
Model epoch 70: train total loss -64.7299817118874, train mean loss 0.00026717598733635685, test mean loss [0.0007178  0.0007782  0.00055869 0.00057451 0.00037363 0.0006689
 0.00058822]
Model epoch 71: train total loss -64.49987387056785, train mean loss 0.0003426825629636553, test mean loss [0.00071343 0.00084706 0.00054951 0.00055324 0.00038979 0.00069347
 0.00055981]
Model epoch 72: train total loss -64.24626336206732, train mean loss 0.00037936016852354736, test mean loss [0.00070149 0.000773   0.00058425 0.00054442 0.00037712 0.00067989
 0.00055707]
Model epoch 73: train total loss -64.37183936511279, train mean loss 0.00034554995997052533, test mean loss [0.00069992 0.00074516 0.00053446 0.00055481 0.00038385 0.00066299
 0.00054237]
Model epoch 74: train total loss -64.17292222374209, train mean loss 0.00047151990789033696, test mean loss [0.00070048 0.00072817 0.0005094  0.00056988 0.00037135 0.00066424
 0.00054603]
Model epoch 75: train total loss -64.08063909270972, train mean loss 0.000311722288950325, test mean loss [0.00066686 0.00072836 0.00051358 0.00056395 0.00037684 0.00065648
 0.0005544 ]
Model epoch 76: train total loss -64.62089020077329, train mean loss 0.0005006381208699332, test mean loss [0.00067519 0.00072394 0.00050993 0.00053894 0.00058491 0.00064055
 0.00053177]
Model epoch 77: train total loss -64.52374240307053, train mean loss 0.0003644520741113955, test mean loss [0.00067089 0.00070678 0.00050755 0.00055639 0.00051469 0.00065037
 0.0005508 ]
Model epoch 78: train total loss -64.3957454176281, train mean loss 0.000349757972261437, test mean loss [0.00068677 0.00068723 0.00050382 0.00055108 0.00044534 0.00061456
 0.0005408 ]
Model epoch 79: train total loss -64.47689220368109, train mean loss 0.0004432443476317657, test mean loss [0.00067785 0.00070394 0.00049547 0.000555   0.00038931 0.00063648
 0.00052721]
Model epoch 80: train total loss -64.18874217943433, train mean loss 0.0002874174607687058, test mean loss [0.0006859  0.00069742 0.00051485 0.00052736 0.00037174 0.00062124
 0.00053399]
Model epoch 81: train total loss -64.56923140914951, train mean loss 0.00027981541221987926, test mean loss [0.00067048 0.00070253 0.00048937 0.00051552 0.00036402 0.00063483
 0.00052156]
Model epoch 82: train total loss -64.11165494117415, train mean loss 0.000325687710382945, test mean loss [0.00066358 0.00070324 0.00048989 0.00052626 0.00034603 0.00062229
 0.00052447]
Model epoch 83: train total loss -64.21888022159132, train mean loss 0.00033963410902129867, test mean loss [0.00065546 0.00069591 0.00047178 0.00054092 0.00033504 0.00059417
 0.00050932]
Model epoch 84: train total loss -64.2207633760861, train mean loss 0.0002513585016329286, test mean loss [0.00064948 0.00067453 0.00047172 0.00054603 0.00034129 0.00058767
 0.00050066]
Model epoch 85: train total loss -64.35598768018944, train mean loss 0.0002833185517496363, test mean loss [0.00063865 0.00067443 0.00047839 0.00050855 0.00032936 0.0005694
 0.00049893]
Model epoch 86: train total loss -64.67251900976073, train mean loss 0.00022341173768812987, test mean loss [0.00064064 0.00067369 0.00048712 0.00048974 0.00033943 0.00059423
 0.00048912]
Model epoch 87: train total loss -64.6041676778417, train mean loss 0.00028278751661350957, test mean loss [0.00064295 0.00065854 0.00047122 0.00051399 0.00032816 0.00060428
 0.00049922]
Model epoch 88: train total loss -64.65621081371191, train mean loss 0.0002399036808898806, test mean loss [0.00063837 0.00069336 0.00047405 0.00051445 0.00032232 0.00059095
 0.00059295]
Model epoch 89: train total loss -64.55991755337442, train mean loss 0.0003490148900213513, test mean loss [0.00063542 0.00066685 0.00045479 0.00050028 0.0003205  0.00058096
 0.00053328]
Model epoch 90: train total loss -64.35338111891407, train mean loss 0.00026756779198657427, test mean loss [0.00061924 0.00068455 0.00046401 0.00051001 0.00033228 0.00057493
 0.00049679]
Model epoch 91: train total loss -64.55209660990866, train mean loss 0.0002506402177000469, test mean loss [0.00060752 0.00066231 0.00046954 0.00051005 0.00034519 0.00058644
 0.00049145]
Model epoch 92: train total loss -64.55962067244556, train mean loss 0.0004048435505487727, test mean loss [0.0006191  0.00066092 0.00046811 0.00049128 0.00033955 0.00054398
 0.00048572]
Model epoch 93: train total loss -64.31812149887621, train mean loss 0.0003087985314129786, test mean loss [0.00063611 0.00064021 0.00048055 0.00047985 0.00033152 0.00055239
 0.00049929]
Model epoch 94: train total loss -64.6988596296888, train mean loss 0.0004028024132795401, test mean loss [0.00061499 0.00065526 0.00049133 0.00047627 0.00033341 0.00056752
 0.00048519]
Model epoch 95: train total loss -64.52622204999027, train mean loss 0.00024483705404609385, test mean loss [0.00060935 0.00064509 0.00044991 0.00048662 0.00032438 0.00054506
 0.00047969]
Model epoch 96: train total loss -64.35218807683344, train mean loss 0.00032697624111871823, test mean loss [0.00060938 0.00062994 0.00044516 0.00047537 0.00032662 0.00054559
 0.00047611]
Model epoch 97: train total loss -64.59767104274401, train mean loss 0.0002900630933626815, test mean loss [0.00060964 0.000613   0.00044173 0.00048589 0.00031075 0.00052316
 0.00048051]
Model epoch 98: train total loss -64.26399192524573, train mean loss 0.0003472488355520487, test mean loss [0.00060389 0.00062353 0.00044591 0.00049948 0.00031522 0.00048917
 0.00046758]
Model epoch 99: train total loss -64.30711895213923, train mean loss 0.00023207045436837313, test mean loss [0.00061913 0.00061296 0.00043626 0.00045905 0.00030461 0.00049641
 0.0004967 ]
Model epoch 100: train total loss -64.26803783215018, train mean loss 0.0002763755275562239, test mean loss [0.00063073 0.00062811 0.00042558 0.00050634 0.00030511 0.00050714
 0.00047252]
Model epoch 101: train total loss -64.24362047015636, train mean loss 0.0003926339088387163, test mean loss [0.00059818 0.00061134 0.0004341  0.00048734 0.00030328 0.00050027
 0.00044874]
Model epoch 102: train total loss -64.67382675870981, train mean loss 0.00026675511126314613, test mean loss [0.00058989 0.00061763 0.00043389 0.00045309 0.00030703 0.00049664
 0.0004663 ]
Model epoch 103: train total loss -64.64193547265879, train mean loss 0.00027020102169129315, test mean loss [0.0005946  0.00060275 0.00042107 0.00046609 0.00033757 0.00049451
 0.00045268]
Model epoch 104: train total loss -64.39700584701988, train mean loss 0.00027693524098904574, test mean loss [0.00058794 0.00061    0.00042868 0.00046268 0.00074689 0.00050963
 0.00044092]
Model epoch 105: train total loss -64.47127223731536, train mean loss 0.00032896082452046297, test mean loss [0.0005925  0.00060031 0.00043371 0.00045054 0.00063827 0.00047416
 0.00045596]
Model epoch 106: train total loss -64.58998320567505, train mean loss 0.00022853753779778703, test mean loss [0.00056859 0.00059695 0.00042073 0.00044574 0.00061912 0.0004889
 0.0004443 ]
Model epoch 107: train total loss -64.39139288006785, train mean loss 0.00031582499278817283, test mean loss [0.00057802 0.000591   0.00042047 0.0004406  0.00054681 0.00048191
 0.00043264]
Model epoch 108: train total loss -64.66246127587675, train mean loss 0.00026656159129029284, test mean loss [0.00058421 0.00058276 0.00041186 0.00043531 0.00049768 0.00047902
 0.00043924]
Model epoch 109: train total loss -64.33506768961819, train mean loss 0.00023884256975611058, test mean loss [0.00055628 0.00059183 0.00043424 0.00045716 0.00042486 0.00047347
 0.00042256]
Model epoch 110: train total loss -64.56700458810457, train mean loss 0.00028487895974048074, test mean loss [0.00057851 0.00058468 0.00040524 0.00044803 0.0004089  0.00046887
 0.00043065]
Model epoch 111: train total loss -64.78553545932871, train mean loss 0.0003411816372454484, test mean loss [0.00057137 0.00062571 0.00040769 0.00043593 0.00038816 0.00046492
 0.00041529]
Model epoch 112: train total loss -64.29247042151778, train mean loss 0.0003970219076220538, test mean loss [0.00057598 0.00057756 0.00041818 0.00044838 0.00035845 0.0004615
 0.00040582]
Model epoch 113: train total loss -64.35810632506714, train mean loss 0.00025487931541745703, test mean loss [0.00056889 0.00059153 0.00040023 0.00046223 0.00034056 0.00045917
 0.00042814]
Model epoch 114: train total loss -64.44585368428511, train mean loss 0.00032244199355627986, test mean loss [0.00055997 0.00058464 0.00039902 0.00043475 0.00033247 0.00046182
 0.00042556]
Model epoch 115: train total loss -64.40523981115903, train mean loss 0.0002425896987636742, test mean loss [0.00055092 0.00056637 0.00041853 0.00043505 0.00033155 0.00046417
 0.00042154]
Model epoch 116: train total loss -64.56271700941075, train mean loss 0.0002704639087253671, test mean loss [0.00056666 0.00059156 0.00041425 0.00043058 0.00029195 0.00047987
 0.00041793]
Model epoch 117: train total loss -64.69868332111713, train mean loss 0.00034036088399687885, test mean loss [0.00055969 0.00055493 0.00042944 0.00046108 0.00030097 0.00045924
 0.00041772]
Model epoch 118: train total loss -64.49470271234061, train mean loss 0.0003648492598469181, test mean loss [0.00053246 0.00054832 0.00039414 0.00044915 0.00029373 0.000449
 0.00041363]
Model epoch 119: train total loss -64.79385138016038, train mean loss 0.0002540329036694314, test mean loss [0.00054516 0.00056557 0.00041515 0.00043582 0.00030102 0.0004239
 0.00041526]
Model epoch 120: train total loss -64.55766810019786, train mean loss 0.00024662680299186447, test mean loss [0.00054924 0.00055151 0.00040834 0.00043054 0.00029019 0.00044439
 0.00042192]
Model epoch 121: train total loss -64.78310167286469, train mean loss 0.00032576604726527797, test mean loss [0.00053453 0.00053977 0.00038811 0.00041168 0.00028352 0.00042171
 0.00041066]
Model epoch 122: train total loss -64.57891831761015, train mean loss 0.0002841957749701545, test mean loss [0.00052348 0.00055106 0.0003896  0.00041962 0.00029794 0.00043655
 0.00040717]
Model epoch 123: train total loss -64.40961209265332, train mean loss 0.00031778589297185483, test mean loss [0.00053563 0.00053276 0.00040099 0.00042062 0.00030318 0.00042353
 0.00040799]
Model epoch 124: train total loss -64.3446133991976, train mean loss 0.0002563388252519996, test mean loss [0.00052541 0.00052959 0.00039742 0.00042021 0.00029214 0.00044395
 0.00039184]
Model epoch 125: train total loss -64.56358967268416, train mean loss 0.0002474538109211268, test mean loss [0.00053244 0.00051972 0.00038905 0.00042124 0.00028342 0.00043806
 0.00039568]
Model epoch 126: train total loss -64.42259580609418, train mean loss 0.0002528434777267089, test mean loss [0.00050829 0.0005549  0.00043883 0.00041786 0.00029482 0.00043481
 0.00039521]
Model epoch 127: train total loss -64.7861334795965, train mean loss 0.00020454795561760495, test mean loss [0.00052352 0.00052058 0.00043079 0.00041802 0.00028669 0.00042865
 0.00039742]
Model epoch 128: train total loss -64.62542201894784, train mean loss 0.0002939286164173159, test mean loss [0.00051998 0.00052999 0.00040446 0.00041479 0.00028508 0.00041915
 0.00039898]
Model epoch 129: train total loss -64.38219411576132, train mean loss 0.0002615579790432468, test mean loss [0.00052468 0.00051799 0.00036427 0.00041108 0.00028521 0.00041897
 0.00039244]
Model epoch 130: train total loss -64.54851926647524, train mean loss 0.0002373742213969931, test mean loss [0.00050416 0.0005089  0.00036976 0.0004011  0.00025979 0.00041649
 0.00040341]
Model epoch 131: train total loss -64.6565783442428, train mean loss 0.00032198756344619994, test mean loss [0.0005039  0.0005315  0.00034745 0.00040074 0.00029456 0.00041311
 0.00038539]
Model epoch 132: train total loss -64.48655603614269, train mean loss 0.00027134357886494004, test mean loss [0.00049237 0.00051895 0.00034748 0.00041435 0.00026469 0.00041417
 0.00038398]
Model epoch 133: train total loss -64.54504498309129, train mean loss 0.00025049162856336107, test mean loss [0.0005191  0.00050289 0.0003893  0.000425   0.00028724 0.00041602
 0.00038409]
Model epoch 134: train total loss -64.29501070529574, train mean loss 0.00024547622233439423, test mean loss [0.00050618 0.00051439 0.00037329 0.00039363 0.00027107 0.00040125
 0.00038406]
Model epoch 135: train total loss -64.74416442192955, train mean loss 0.00022584306264558686, test mean loss [0.00049013 0.00050522 0.00036803 0.00040198 0.00027211 0.00042436
 0.00038882]
Model epoch 136: train total loss -64.62388277050559, train mean loss 0.000284618861667718, test mean loss [0.00052186 0.00048523 0.0003739  0.00041873 0.00027013 0.00040236
 0.00037718]
Model epoch 137: train total loss -64.57024442024712, train mean loss 0.00023564619751036467, test mean loss [0.00049249 0.00050282 0.00035554 0.00039406 0.00028538 0.00040342
 0.00040104]
Model epoch 138: train total loss -64.58320364763763, train mean loss 0.00021361675248580703, test mean loss [0.00047652 0.00050117 0.00035528 0.00039722 0.00028831 0.00041364
 0.00039044]
Model epoch 139: train total loss -64.55133626105881, train mean loss 0.00026311239756707006, test mean loss [0.00048941 0.00049687 0.0003443  0.00040932 0.00026888 0.0004021
 0.00038649]
Model epoch 140: train total loss -64.35450248682096, train mean loss 0.00023087064706495667, test mean loss [0.00049358 0.00049334 0.00032496 0.00039287 0.0002789  0.00038307
 0.00038741]
Model epoch 141: train total loss -64.42522709215523, train mean loss 0.00030248574701645294, test mean loss [0.00047395 0.00049837 0.00033269 0.0003908  0.00026072 0.00039855
 0.00037119]
Model epoch 142: train total loss -64.76799158324002, train mean loss 0.00027613123710386973, test mean loss [0.00046936 0.00048988 0.00032446 0.00038618 0.00027023 0.00039083
 0.00036682]
Model epoch 143: train total loss -64.5079379267959, train mean loss 0.00032755992190075853, test mean loss [0.00047844 0.00049686 0.00033186 0.00037115 0.00026748 0.00039998
 0.0003717 ]
Model epoch 144: train total loss -64.89805414790303, train mean loss 0.00019442447596859012, test mean loss [0.00047229 0.00048374 0.00033553 0.00040528 0.00027406 0.00041422
 0.00037643]
Model epoch 145: train total loss -64.84071518599282, train mean loss 0.00024231509585116202, test mean loss [0.00056144 0.0004942  0.00033789 0.00036975 0.00028587 0.00038058
 0.00037572]
Model epoch 146: train total loss -64.594341572029, train mean loss 0.00019776276630852503, test mean loss [0.00050598 0.00046928 0.00033478 0.00037537 0.00027626 0.00040043
 0.00037029]
Model epoch 147: train total loss -64.90885132574678, train mean loss 0.00023026855063628944, test mean loss [0.00050314 0.00048073 0.00033255 0.00037901 0.00027371 0.00040372
 0.00037717]
Model epoch 148: train total loss -64.74336154691692, train mean loss 0.00029259417563158265, test mean loss [0.00047027 0.00047679 0.00031873 0.0003595  0.0002581  0.00038496
 0.00037269]
Model epoch 149: train total loss -64.40349855920878, train mean loss 0.00029388257501271255, test mean loss [0.00047988 0.00048038 0.00033364 0.0003755  0.00026043 0.00037752
 0.00038547]
Model epoch 150: train total loss -64.78475592299017, train mean loss 0.0002685056883390388, test mean loss [0.00047894 0.00045796 0.00032571 0.0003762  0.00027226 0.00040138
 0.00036113]
Model epoch 151: train total loss -64.86441873541071, train mean loss 0.0001873107153604224, test mean loss [0.00048671 0.00045188 0.00031412 0.00036807 0.0002752  0.00039155
 0.00037125]
Model epoch 152: train total loss -64.77991068917756, train mean loss 0.00034790318152062166, test mean loss [0.00046722 0.00047574 0.00031016 0.00035544 0.00024422 0.00038862
 0.00036214]
Model epoch 153: train total loss -64.66747969977548, train mean loss 0.0003209209723369323, test mean loss [0.00046691 0.00048375 0.00031147 0.00038666 0.00026482 0.00037821
 0.00035887]
Model epoch 154: train total loss -64.6046514003857, train mean loss 0.00023858363197657332, test mean loss [0.00047071 0.00044842 0.00030799 0.00035959 0.00027255 0.00038754
 0.00036105]
Model epoch 155: train total loss -64.59633810065256, train mean loss 0.00026647357861054075, test mean loss [0.00048077 0.00046187 0.0003298  0.00035475 0.00026464 0.00038916
 0.00036086]
Model epoch 156: train total loss -64.72406519923729, train mean loss 0.00021641311885912452, test mean loss [0.00045262 0.00045475 0.00033641 0.00035352 0.00025915 0.00038291
 0.00035657]
Model epoch 157: train total loss -65.00995038973244, train mean loss 0.00023369898505297415, test mean loss [0.00046349 0.00045812 0.00031622 0.00035423 0.00026821 0.00037871
 0.00038141]
Model epoch 158: train total loss -64.60046209821361, train mean loss 0.0002523030054695746, test mean loss [0.00044327 0.00045609 0.00034129 0.00036428 0.00027008 0.00036633
 0.00035117]
Model epoch 159: train total loss -64.40823187480585, train mean loss 0.0002481541025574925, test mean loss [0.00044436 0.00044321 0.00030588 0.00036049 0.00026679 0.00037984
 0.00036122]
Model epoch 160: train total loss -64.52947782306315, train mean loss 0.0002775690407864737, test mean loss [0.00043798 0.00046332 0.00030101 0.000349   0.00025607 0.00037144
 0.00035577]
Model epoch 161: train total loss -64.70351828797861, train mean loss 0.0002366961997148473, test mean loss [0.0004468  0.00046116 0.00030712 0.00036396 0.00028207 0.0003773
 0.0003623 ]
Model epoch 162: train total loss -64.60843309284023, train mean loss 0.000268571872949966, test mean loss [0.00047202 0.00045375 0.00033435 0.00035156 0.00026759 0.00036692
 0.00034877]
Model epoch 163: train total loss -64.89784279538459, train mean loss 0.00022525562869826532, test mean loss [0.00045733 0.00045471 0.00029634 0.0003726  0.00026391 0.00036281
 0.00036143]
Model epoch 164: train total loss -64.69782466647467, train mean loss 0.00022206367456858612, test mean loss [0.00044653 0.00045252 0.00028596 0.00035279 0.00025876 0.00036209
 0.00036532]
Model epoch 165: train total loss -64.61613558705511, train mean loss 0.00026771974502949657, test mean loss [0.00043605 0.00044567 0.00029976 0.0003529  0.00027561 0.00036689
 0.00035098]
Model epoch 166: train total loss -64.73187408288005, train mean loss 0.0002086079462295111, test mean loss [0.00044196 0.0004423  0.00029175 0.00033964 0.00026638 0.00036282
 0.00036643]
Model epoch 167: train total loss -64.87225976175759, train mean loss 0.00024640359789303073, test mean loss [0.00043631 0.00043697 0.00029152 0.00033961 0.00027878 0.00037771
 0.00036331]
Model epoch 168: train total loss -64.63044557308895, train mean loss 0.00024580354159751185, test mean loss [0.00043906 0.00043003 0.00027925 0.00033925 0.00027824 0.00036401
 0.00036215]
Model epoch 169: train total loss -64.50809921597822, train mean loss 0.00023275015981767504, test mean loss [0.00042842 0.00042349 0.00028946 0.00035302 0.00026293 0.00035542
 0.0003449 ]
Model epoch 170: train total loss -64.35832247370372, train mean loss 0.00024648043357823114, test mean loss [0.00042629 0.0004201  0.00029244 0.00033994 0.00026598 0.00036563
 0.00035336]
Model epoch 171: train total loss -64.95662060203105, train mean loss 0.000198711474933605, test mean loss [0.00043666 0.00042588 0.00029381 0.00033342 0.00025762 0.00035378
 0.00034425]
Model epoch 172: train total loss -65.03892513301018, train mean loss 0.0002618870125041832, test mean loss [0.00043453 0.00045729 0.00028761 0.00032945 0.00026172 0.00036506
 0.00034874]
Model epoch 173: train total loss -64.74494997385284, train mean loss 0.00026786839175335555, test mean loss [0.00042781 0.00044242 0.00028713 0.00032833 0.00026837 0.00034452
 0.00033864]
Model epoch 174: train total loss -64.43038471918153, train mean loss 0.0002549112392437063, test mean loss [0.00040778 0.00043491 0.00029366 0.00035226 0.00026277 0.00034694
 0.00038024]
Model epoch 175: train total loss -64.6425105052873, train mean loss 0.00023299632910940194, test mean loss [0.00043037 0.00044103 0.00027858 0.0003343  0.00027402 0.00034394
 0.00036778]
Model epoch 176: train total loss -64.73705967980152, train mean loss 0.0002685292282480936, test mean loss [0.00044411 0.00041227 0.00028044 0.00033874 0.00026932 0.00033537
 0.00033929]
Model epoch 177: train total loss -64.61065449216662, train mean loss 0.00023433139078840845, test mean loss [0.00042113 0.00043196 0.00027849 0.0003149  0.00026494 0.00035745
 0.00033832]
Model epoch 178: train total loss -64.68767122617642, train mean loss 0.00033448061959556204, test mean loss [0.00043604 0.00041046 0.00029634 0.00031517 0.00029554 0.00035004
 0.00035404]
Model epoch 179: train total loss -64.73266918897032, train mean loss 0.00022467752285510587, test mean loss [0.00041044 0.00039575 0.00028437 0.00031652 0.00026455 0.00035456
 0.00036226]
Model epoch 180: train total loss -64.89163983294284, train mean loss 0.0002126249228753054, test mean loss [0.00039962 0.0004032  0.00026249 0.00030848 0.00025193 0.00033835
 0.00038538]
Model epoch 181: train total loss -64.65223372528315, train mean loss 0.0002436977468296437, test mean loss [0.00041896 0.00040442 0.00027278 0.00031399 0.00024885 0.00034679
 0.00034945]
Model epoch 182: train total loss -64.4747599974327, train mean loss 0.00021997891313948193, test mean loss [0.00041849 0.00039807 0.00026037 0.00030738 0.0002705  0.00034255
 0.00033857]
Model epoch 183: train total loss -64.65782762536146, train mean loss 0.00024471289381344883, test mean loss [0.00041507 0.0004385  0.00027097 0.0003299  0.00024968 0.00035355
 0.00033611]
Model epoch 184: train total loss -64.81200868297816, train mean loss 0.00023775070857747223, test mean loss [0.00040551 0.00040541 0.00025696 0.00032381 0.00026603 0.00034887
 0.00032632]
Model epoch 185: train total loss -64.54901307015302, train mean loss 0.00022074493436923846, test mean loss [0.00040876 0.00039539 0.0002565  0.00031623 0.00025612 0.00035175
 0.0003481 ]
Model epoch 186: train total loss -64.7162648025756, train mean loss 0.00025727691736808896, test mean loss [0.00040503 0.00039169 0.00027318 0.00031741 0.00026499 0.00035218
 0.00034038]
Model epoch 187: train total loss -64.85852636668807, train mean loss 0.00022839060993532339, test mean loss [0.00040906 0.00040892 0.00027303 0.00032343 0.00028374 0.00035285
 0.00033421]
Model epoch 188: train total loss -64.81647480682821, train mean loss 0.00022611168338741098, test mean loss [0.00040585 0.00038848 0.00026804 0.00030289 0.00026003 0.00034796
 0.00033302]
Model epoch 189: train total loss -64.76360447501739, train mean loss 0.00025123514918426546, test mean loss [0.00039403 0.00037128 0.00027474 0.00030613 0.00025321 0.00033277
 0.00033962]
Model epoch 190: train total loss -65.17238588921315, train mean loss 0.00023763425747954964, test mean loss [0.00040049 0.00038857 0.00027803 0.00030049 0.00024747 0.00033256
 0.00032883]
Model epoch 191: train total loss -65.0130669764192, train mean loss 0.00025552240629653683, test mean loss [0.00039902 0.0003835  0.00027828 0.00028807 0.00027899 0.00033644
 0.00033836]
Model epoch 192: train total loss -65.07194186076597, train mean loss 0.00021153841216864166, test mean loss [0.00040442 0.00040027 0.00026127 0.00030906 0.00026257 0.00034933
 0.00035158]
Model epoch 193: train total loss -64.42834185750964, train mean loss 0.00022617897757550403, test mean loss [0.00039592 0.00039519 0.00030829 0.00030029 0.00025486 0.00033035
 0.00032574]
Model epoch 194: train total loss -64.75676471613255, train mean loss 0.00021293285984357992, test mean loss [0.00039874 0.00037351 0.00028783 0.00027784 0.0002583  0.00033387
 0.00033731]
Model epoch 195: train total loss -64.7220228928393, train mean loss 0.00027703407889880573, test mean loss [0.00038956 0.00038565 0.00025493 0.00028489 0.00025074 0.00032623
 0.00031319]
Model epoch 196: train total loss -64.73950886652673, train mean loss 0.0002418723616737066, test mean loss [0.00038979 0.00036684 0.00025293 0.000286   0.00024599 0.00033245
 0.00036103]
Model epoch 197: train total loss -64.6817098132276, train mean loss 0.00022228177177322503, test mean loss [0.00037792 0.00036484 0.00025806 0.00029708 0.00024912 0.00034569
 0.00034571]
Model epoch 198: train total loss -64.81523199896718, train mean loss 0.00025327801212748024, test mean loss [0.00039799 0.00037266 0.00024942 0.00028676 0.00025796 0.00033077
 0.00040505]
Model epoch 199: train total loss -64.82485921880499, train mean loss 0.00025646253171562606, test mean loss [0.00039355 0.00036369 0.0002518  0.0002957  0.0002687  0.00034468
 0.00041728]
Model epoch 200: train total loss -64.61713018215077, train mean loss 0.00020616020701978675, test mean loss [0.00038909 0.00035539 0.00024384 0.00027601 0.0002617  0.00033275
 0.00038734]
Model epoch 201: train total loss -64.89426288757176, train mean loss 0.00019972361121960746, test mean loss [0.00038234 0.00037943 0.00026335 0.00029614 0.00026532 0.00034518
 0.00034086]
Model epoch 202: train total loss -64.45103954071999, train mean loss 0.0002493998289367047, test mean loss [0.0003914  0.00038401 0.00028753 0.00028762 0.00024212 0.00033433
 0.00033146]
Model epoch 203: train total loss -64.68729899605191, train mean loss 0.00023090560514419436, test mean loss [0.00036977 0.00038437 0.0002826  0.00028884 0.00026233 0.00033383
 0.0003224 ]
Model epoch 204: train total loss -64.77890794867784, train mean loss 0.0002179881704083431, test mean loss [0.00037928 0.00035528 0.00026476 0.00030123 0.00025234 0.00031525
 0.00032131]
Model epoch 205: train total loss -64.68207507822609, train mean loss 0.00022731677179737994, test mean loss [0.00038717 0.0003691  0.00026019 0.00035966 0.0002494  0.00031743
 0.00034262]
Model epoch 206: train total loss -64.87214720862592, train mean loss 0.00022972212703751063, test mean loss [0.000387   0.00034287 0.0002557  0.00033641 0.00024566 0.00032247
 0.00033027]
Model epoch 207: train total loss -64.67865259914406, train mean loss 0.00020882780889249622, test mean loss [0.00038605 0.0003453  0.00027766 0.00030546 0.00025369 0.0003457
 0.00031866]
Model epoch 208: train total loss -64.84689868368879, train mean loss 0.000268365630636504, test mean loss [0.00037426 0.00038083 0.00028654 0.00029606 0.00024407 0.00031418
 0.00033246]
Model epoch 209: train total loss -64.68332019304542, train mean loss 0.0002678152915898202, test mean loss [0.0003741  0.00035233 0.00029429 0.00029126 0.0002415  0.00032794
 0.00031085]
Model epoch 210: train total loss -64.60120382659994, train mean loss 0.00020203377421589371, test mean loss [0.0003811  0.00034444 0.00027419 0.00029819 0.00024773 0.00032256
 0.00032021]
Model epoch 211: train total loss -64.8993848653228, train mean loss 0.00020582723453577267, test mean loss [0.00036933 0.00034208 0.00025334 0.0002961  0.00026485 0.00031139
 0.00031144]
Model epoch 212: train total loss -64.52566417415446, train mean loss 0.0002294086403499697, test mean loss [0.0003663  0.00035083 0.00027644 0.00029109 0.00026867 0.00031663
 0.00031636]
Model epoch 213: train total loss -64.76387063638313, train mean loss 0.00026535236992234574, test mean loss [0.00037962 0.00032672 0.00025231 0.00029324 0.00029    0.00032233
 0.0003219 ]
Model epoch 214: train total loss -64.9614666986829, train mean loss 0.0002187820364491719, test mean loss [0.00036124 0.00034394 0.00025051 0.00027357 0.00025268 0.00031545
 0.0003152 ]
Model epoch 215: train total loss -64.7474335623325, train mean loss 0.0002497335908706094, test mean loss [0.00036961 0.00032775 0.00024772 0.00027334 0.00025889 0.0003133
 0.00032287]
Model epoch 216: train total loss -64.87223077504889, train mean loss 0.00025254326247855824, test mean loss [0.00036567 0.00032792 0.0002617  0.00027765 0.00024237 0.0003217
 0.00030315]
Model epoch 217: train total loss -64.7635644031357, train mean loss 0.0002331152622143488, test mean loss [0.00036149 0.00031882 0.0002484  0.00027022 0.00024074 0.0003184
 0.00032214]
Model epoch 218: train total loss -64.83108097608651, train mean loss 0.00023530034147315837, test mean loss [0.00036771 0.00033569 0.00028054 0.00024892 0.00025732 0.00031174
 0.00034089]
Model epoch 219: train total loss -64.60890806206866, train mean loss 0.00027627419563521096, test mean loss [0.00037002 0.00032137 0.00026489 0.00027856 0.00026132 0.00031771
 0.00033381]
Model epoch 220: train total loss -64.68350404113689, train mean loss 0.00024351851298425555, test mean loss [0.00036809 0.00035594 0.00026969 0.00025044 0.00024123 0.00030783
 0.0003175 ]
Model epoch 221: train total loss -64.53948877507416, train mean loss 0.00024325878022460817, test mean loss [0.00039297 0.00033652 0.00023637 0.00026828 0.00024683 0.00032156
 0.00034772]
Model epoch 222: train total loss -64.94401009035286, train mean loss 0.00019186893395491963, test mean loss [0.00038059 0.00032364 0.00024938 0.00026728 0.00026073 0.00030686
 0.00033136]
Model epoch 223: train total loss -64.95241555576874, train mean loss 0.00024536283197347866, test mean loss [0.00036812 0.00031912 0.00025571 0.00025744 0.00025332 0.00030124
 0.00030593]
Model epoch 224: train total loss -64.90356727955668, train mean loss 0.00023023068814462434, test mean loss [0.00036854 0.00031956 0.00024274 0.00025883 0.00025239 0.00030185
 0.00030798]
Model epoch 225: train total loss -64.94854281751746, train mean loss 0.00021236951889024095, test mean loss [0.00035763 0.00031327 0.00023954 0.00024835 0.0002487  0.00029901
 0.00033956]
Model epoch 226: train total loss -64.72203820175848, train mean loss 0.00021265972307346002, test mean loss [0.00037959 0.00032896 0.00024883 0.00026398 0.00024823 0.000318
 0.00031035]
Model epoch 227: train total loss -65.02645176519613, train mean loss 0.00019941147234199286, test mean loss [0.00036448 0.00031109 0.00025167 0.00023993 0.00025881 0.00029624
 0.0003032 ]
Model epoch 228: train total loss -64.8161118174619, train mean loss 0.0002531967885660589, test mean loss [0.00037125 0.0003187  0.00025325 0.00025495 0.00026491 0.00029148
 0.00029607]
Model epoch 229: train total loss -64.57985872381339, train mean loss 0.000225230577843861, test mean loss [0.00039295 0.00032235 0.00024456 0.00026883 0.00025421 0.00029434
 0.00036246]
Model epoch 230: train total loss -64.90455434397002, train mean loss 0.00017698702660386148, test mean loss [0.00039758 0.00030953 0.00025457 0.00024215 0.00024318 0.00029216
 0.00031565]
Model epoch 231: train total loss -64.35597468877923, train mean loss 0.0002470011929208349, test mean loss [0.00050899 0.00030371 0.00025251 0.00026371 0.00025053 0.00030629
 0.00030437]
Model epoch 232: train total loss -65.03228805209127, train mean loss 0.00020474582534685989, test mean loss [0.00042185 0.00030662 0.00025284 0.00026819 0.00024447 0.0003038
 0.00031086]
Model epoch 233: train total loss -64.8838406788584, train mean loss 0.0002357416211989067, test mean loss [0.0003801  0.00030823 0.00025227 0.00025059 0.00023421 0.00029429
 0.00030671]
Model epoch 234: train total loss -64.63632143731363, train mean loss 0.0002561077928762107, test mean loss [0.00036673 0.00029592 0.00026201 0.00025313 0.00026106 0.00030811
 0.00029182]
Model epoch 235: train total loss -65.00084079833638, train mean loss 0.0002159290207835547, test mean loss [0.00035374 0.00030699 0.00025125 0.0002405  0.00024225 0.00029755
 0.00030619]
Model epoch 236: train total loss -64.55141154053989, train mean loss 0.00023826654147969593, test mean loss [0.00036842 0.00030169 0.00040964 0.00024411 0.00026078 0.00030673
 0.00029815]
Model epoch 237: train total loss -64.79151826858634, train mean loss 0.00021209113261325054, test mean loss [0.00036063 0.00031918 0.00034941 0.00025925 0.0002602  0.00030038
 0.00031691]
Model epoch 238: train total loss -64.84674963796891, train mean loss 0.0002534499249127326, test mean loss [0.00035457 0.00030237 0.00029289 0.00024515 0.0002553  0.00029017
 0.00030044]
Model epoch 239: train total loss -65.17513550746222, train mean loss 0.0002127952616579548, test mean loss [0.00035144 0.00030847 0.00026182 0.00023974 0.00024236 0.0002819
 0.00030081]
Model epoch 240: train total loss -64.84697973439394, train mean loss 0.00019345529033895506, test mean loss [0.00034737 0.00031171 0.00024679 0.00026096 0.00025704 0.00028
 0.00029543]
Model epoch 241: train total loss -64.66601927239779, train mean loss 0.00022861510707215433, test mean loss [0.00035405 0.00028017 0.00026553 0.00024539 0.0002431  0.00028532
 0.0002929 ]
Model epoch 242: train total loss -64.86858166922214, train mean loss 0.00022940500934523654, test mean loss [0.00034805 0.00029432 0.00025521 0.00025655 0.00023799 0.00029329
 0.00029218]
Model epoch 243: train total loss -65.0636639749052, train mean loss 0.00023485220773638064, test mean loss [0.00033746 0.00029386 0.00024477 0.00025397 0.00023516 0.00028821
 0.00028999]
Model epoch 244: train total loss -64.84436166205779, train mean loss 0.00024897879194862914, test mean loss [0.00035405 0.00029263 0.00024315 0.00025336 0.00024453 0.000284
 0.00030656]
Model epoch 245: train total loss -65.09141740140967, train mean loss 0.0002462609118177945, test mean loss [0.00034034 0.00030152 0.00025293 0.00022517 0.00025411 0.00030603
 0.00032059]
Model epoch 246: train total loss -64.77918084161871, train mean loss 0.0002619343048202707, test mean loss [0.00035564 0.00029705 0.00023282 0.0002465  0.00025116 0.00028526
 0.00029372]
Model epoch 247: train total loss -64.69401954939202, train mean loss 0.00020445384198534917, test mean loss [0.00034402 0.00035617 0.00025921 0.00025364 0.00023705 0.00028717
 0.00030483]
Model epoch 248: train total loss -64.83743446186723, train mean loss 0.000234686121615596, test mean loss [0.00034303 0.00031753 0.00023303 0.00024601 0.00025993 0.00027677
 0.00030826]
Model epoch 249: train total loss -64.86792960375871, train mean loss 0.00021349571300784413, test mean loss [0.00034156 0.00030293 0.0002473  0.00024227 0.00026322 0.00028879
 0.00030115]
Model epoch 250: train total loss -64.87021598620474, train mean loss 0.00021939418580837236, test mean loss [0.00035631 0.00029381 0.00024279 0.00024628 0.00025587 0.00028969
 0.00030435]
Model epoch 251: train total loss -64.97978200360248, train mean loss 0.0001991094701090991, test mean loss [0.00034366 0.00028327 0.00023994 0.00025213 0.00025533 0.0002811
 0.00028711]
Model epoch 252: train total loss -65.03227555039703, train mean loss 0.00020349589890210888, test mean loss [0.00033104 0.00027251 0.0002838  0.00025961 0.00024318 0.00029531
 0.00028782]
Model epoch 253: train total loss -64.65094595643865, train mean loss 0.00020444310384486875, test mean loss [0.00034392 0.00028601 0.00023903 0.00025619 0.00024991 0.00029984
 0.00029399]
Model epoch 254: train total loss -64.91848336981033, train mean loss 0.0002071551776549683, test mean loss [0.00032931 0.00028742 0.00023622 0.00023992 0.00024012 0.00028331
 0.00030303]
Model epoch 255: train total loss -64.83820316114388, train mean loss 0.00020479649290719958, test mean loss [0.00033901 0.00029837 0.0002561  0.00024499 0.00023559 0.00027679
 0.00030062]
Model epoch 256: train total loss -64.79972413887104, train mean loss 0.00020510652480064102, test mean loss [0.00034096 0.00030125 0.00024004 0.00025158 0.00024997 0.00030696
 0.00030396]
Model epoch 257: train total loss -64.9159083757386, train mean loss 0.00021403428103360412, test mean loss [0.00034724 0.00031815 0.00024407 0.00024437 0.00024537 0.00029676
 0.00029343]
Model epoch 258: train total loss -64.96088296313953, train mean loss 0.0002483835970562524, test mean loss [0.00032993 0.00028176 0.00022892 0.00023704 0.00024536 0.00027656
 0.0002934 ]
Model epoch 259: train total loss -64.93609903918063, train mean loss 0.00021637217239319997, test mean loss [0.00032838 0.00027655 0.00023641 0.0002481  0.00029107 0.00027448
 0.00029916]
Model epoch 260: train total loss -64.9803943506828, train mean loss 0.00018778400020172338, test mean loss [0.00034545 0.00027869 0.00024601 0.00025741 0.00025773 0.00027855
 0.00030555]
Model epoch 261: train total loss -64.82422010074997, train mean loss 0.0002496202050815719, test mean loss [0.00034482 0.00025684 0.00023172 0.00023973 0.00025617 0.00027038
 0.00028831]
Model epoch 262: train total loss -64.75138109424964, train mean loss 0.00023817178342633885, test mean loss [0.00034136 0.00028179 0.00023792 0.00025585 0.00023274 0.000295
 0.00028321]
Model epoch 263: train total loss -65.0328385392426, train mean loss 0.00022323405893128514, test mean loss [0.00032772 0.00027412 0.00022756 0.00024813 0.00024317 0.00028166
 0.00029553]
Model epoch 264: train total loss -64.88164027899614, train mean loss 0.00020473867931985204, test mean loss [0.00033078 0.00028002 0.00024189 0.00025999 0.00024185 0.00028342
 0.00029273]
Model epoch 265: train total loss -64.78548389676389, train mean loss 0.00020069725422130675, test mean loss [0.00032326 0.00027165 0.00023726 0.00024595 0.00023873 0.00026958
 0.00031034]
Model epoch 266: train total loss -64.82682321862623, train mean loss 0.00021210232580410612, test mean loss [0.00034387 0.00028716 0.00022548 0.00025678 0.00025425 0.00027696
 0.00029795]
Model epoch 267: train total loss -64.76964254550961, train mean loss 0.0002179638518647046, test mean loss [0.00033473 0.00027654 0.00023647 0.0002661  0.00023798 0.00026799
 0.00028868]
Model epoch 268: train total loss -64.99382090249418, train mean loss 0.00021644476109294625, test mean loss [0.00031844 0.00027885 0.00023611 0.00026545 0.0002415  0.00026548
 0.0002948 ]
Model epoch 269: train total loss -64.80843334570106, train mean loss 0.00022666500199875744, test mean loss [0.00032995 0.00026862 0.00023822 0.00024181 0.0002631  0.00027126
 0.0002916 ]
Model epoch 270: train total loss -64.9226797813231, train mean loss 0.00023765993165049908, test mean loss [0.0003237  0.00038288 0.00023421 0.00026187 0.00024495 0.00025541
 0.00028365]
Model epoch 271: train total loss -64.96337602928962, train mean loss 0.0002853741215599408, test mean loss [0.00032894 0.00034661 0.00024599 0.00023941 0.00023803 0.00029058
 0.00029416]
Model epoch 272: train total loss -64.8736020617822, train mean loss 0.00024246385007849325, test mean loss [0.0003292  0.00033662 0.00040484 0.00023321 0.00024225 0.00027781
 0.00028434]
Model epoch 273: train total loss -65.06225516849122, train mean loss 0.0002481142682823123, test mean loss [0.00033039 0.0003058  0.00031681 0.0002393  0.00024875 0.00026688
 0.00029368]
Model epoch 274: train total loss -65.14489900797976, train mean loss 0.00019631009514310574, test mean loss [0.00032182 0.00029193 0.00026957 0.00024563 0.00025905 0.00026565
 0.00030667]
Model epoch 275: train total loss -65.06630568301478, train mean loss 0.0002518913636547588, test mean loss [0.00031684 0.0002709  0.00025126 0.00026123 0.00023789 0.00027346
 0.00029047]
Model epoch 276: train total loss -64.81377487198559, train mean loss 0.00025297154017594846, test mean loss [0.00031973 0.00026141 0.00023991 0.00025988 0.00023733 0.0002696
 0.00029734]
Model trained in 277 epochs with 8000 transitions.
[2025-01-25 00:56:13,760][absl][INFO] - {'eval/walltime': 283.9422426223755, 'training/sps': 0.20090476438158889, 'training/walltime': 28689.627134799957, 'training/model_train_time': 3109.0916311740875, 'training/other_time': 1867.5565476417542, 'training/model_horizon': 14, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(9000, dtype=int32), 'model/train_total_loss': Array(-64.81377487, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00025297, dtype=float64), 'model/test_total_loss': Array(-64.53157503, dtype=float64), 'model/test_mean_loss': Array(0.00026931, dtype=float64), 'model/train_epochs': 277, 'model/sec_per_epoch': 11.216788739503937, 'sac/actor_loss': Array(-25.41027838, dtype=float64), 'sac/alpha': Array(0.02546479, dtype=float32), 'sac/alpha_loss': Array(-2.14862543e-05, dtype=float64), 'sac/buffer_current_size': Array(400000.03, dtype=float32), 'sac/critic_loss': Array(0.0813, dtype=float64), 'eval/episode_forward_vel': Array(35.42879457, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-0.61638517, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(3.92691703, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.00241438, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(15.23819121, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(3.50711513, dtype=float64), 'eval/episode_rew_roll': Array(3.70991943, dtype=float64), 'eval/episode_rew_side_motion': Array(3.204241, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(3.39533507, dtype=float64), 'eval/episode_rew_yaw': Array(5.96860229, dtype=float64), 'eval/episode_rew_z_vel_change': Array(2.46718303, dtype=float64), 'eval/episode_reward': Array(40.21590479, dtype=float64), 'eval/episode_step_count': Array(3570., dtype=float64), 'eval/avg_episode_length': Array(85., dtype=float64), 'eval/epoch_eval_time': 30.00008726119995, 'eval/sps': 33.33323637672652}
Steps / Eval:  9000.0
Reward is  40.2159047861965
Model horizon updated to 16.
Hallucination updates per training step updated to 1000.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -49.4441307305131, train mean loss 0.009412003749785394, test mean loss [0.00955968 0.00867489 0.00690991 0.01196383 0.00994457 0.01189332
 0.01024847]
Model epoch 1: train total loss -54.941251245841194, train mean loss 0.006928281100485054, test mean loss [0.00572324 0.00577367 0.00465159 0.00899602 0.00673926 0.0089734
 0.00678838]
Model epoch 2: train total loss -57.97518593923079, train mean loss 0.005298803090665731, test mean loss [0.00525208 0.00444169 0.00358639 0.00710136 0.00501254 0.00691203
 0.00523994]
Model epoch 3: train total loss -59.4618260013284, train mean loss 0.0034119551160052297, test mean loss [0.0041695  0.00359334 0.00304599 0.00573756 0.00406019 0.00557295
 0.00423422]
Model epoch 4: train total loss -60.286413482754575, train mean loss 0.0031999005284053294, test mean loss [0.00360341 0.00394819 0.00279692 0.00482641 0.00349746 0.00469196
 0.00365503]
Model epoch 5: train total loss -60.86855347667073, train mean loss 0.0025777687743140983, test mean loss [0.00326277 0.00331659 0.00254855 0.00413062 0.00301124 0.00401461
 0.00328689]
Model epoch 6: train total loss -61.50277858010104, train mean loss 0.002760192830809137, test mean loss [0.00296811 0.00297521 0.00230075 0.00370531 0.00269627 0.00356211
 0.00295679]
Model epoch 7: train total loss -61.666551663605695, train mean loss 0.0020471087642648807, test mean loss [0.00274609 0.00272865 0.00212579 0.0032738  0.00248103 0.00315773
 0.00270175]
Model epoch 8: train total loss -62.04116236333895, train mean loss 0.001990508407093058, test mean loss [0.0025087  0.0024876  0.00196949 0.0030117  0.00224291 0.00284891
 0.00247338]
Model epoch 9: train total loss -62.28301200341489, train mean loss 0.0020690574091276354, test mean loss [0.00235871 0.00228953 0.00184363 0.00270452 0.00202607 0.00260622
 0.00225532]
Model epoch 10: train total loss -62.55835466682302, train mean loss 0.0020475338762371152, test mean loss [0.00222003 0.0020938  0.00173775 0.00248218 0.00187724 0.00238906
 0.00208204]
Model epoch 11: train total loss -62.65813184921703, train mean loss 0.0014748513799898019, test mean loss [0.00208028 0.00192221 0.00164085 0.0023058  0.00170516 0.00217678
 0.00191646]
Model epoch 12: train total loss -62.648095900024636, train mean loss 0.0015595733582649427, test mean loss [0.00195007 0.00184877 0.00149202 0.00212712 0.00156716 0.00201131
 0.00177375]
Model epoch 13: train total loss -63.22852029746534, train mean loss 0.0012900037970595345, test mean loss [0.00186309 0.00169941 0.00141683 0.00201157 0.00144507 0.0018266
 0.00159159]
Model epoch 14: train total loss -63.25779483778178, train mean loss 0.0011150879711243752, test mean loss [0.00172992 0.00163913 0.00136571 0.00187492 0.00132441 0.00165802
 0.00151278]
Model epoch 15: train total loss -63.00310344985084, train mean loss 0.0011536502138133917, test mean loss [0.001669   0.00149922 0.00127938 0.00177254 0.00125198 0.00153572
 0.00141566]
Model epoch 16: train total loss -63.35697162645077, train mean loss 0.0011723618150026923, test mean loss [0.00156329 0.00146034 0.0011997  0.00168458 0.00117613 0.00149848
 0.00132434]
Model epoch 17: train total loss -63.35664687866762, train mean loss 0.0010234161297103539, test mean loss [0.00148811 0.00135507 0.00116328 0.00157403 0.00112583 0.00135786
 0.00125845]
Model epoch 18: train total loss -63.57347465020241, train mean loss 0.0009008571242020191, test mean loss [0.00143723 0.00128627 0.00110295 0.00151006 0.0010689  0.00131002
 0.0011938 ]
Model epoch 19: train total loss -63.34528138626041, train mean loss 0.000967078010329125, test mean loss [0.00135338 0.00121942 0.00112023 0.00144737 0.00102079 0.00123985
 0.00110874]
Model epoch 20: train total loss -63.53785629928459, train mean loss 0.000662925608937565, test mean loss [0.00126794 0.00113667 0.00104837 0.00135239 0.00096244 0.00119163
 0.0011029 ]
Model epoch 21: train total loss -63.20701172448594, train mean loss 0.0008161397375481493, test mean loss [0.00119816 0.0010951  0.00097056 0.00134771 0.00092379 0.00113929
 0.0010393 ]
Model epoch 22: train total loss -63.663201485356986, train mean loss 0.0008166811638082291, test mean loss [0.0011485  0.00106473 0.00095152 0.00124273 0.00087803 0.00109522
 0.00097434]
Model epoch 23: train total loss -63.520582921590155, train mean loss 0.001002750481386392, test mean loss [0.00111071 0.00100605 0.00091968 0.00120073 0.00086579 0.00101485
 0.00097099]
Model epoch 24: train total loss -63.49570614280838, train mean loss 0.0007352082892257272, test mean loss [0.00104608 0.00096659 0.0009094  0.00116012 0.00081238 0.00096366
 0.00095735]
Model epoch 25: train total loss -63.709275843983896, train mean loss 0.0007288699420305517, test mean loss [0.00101159 0.00095639 0.00086454 0.00112169 0.00081288 0.00094927
 0.00094462]
Model epoch 26: train total loss -64.08106981351703, train mean loss 0.0005898396926450242, test mean loss [0.00098072 0.00090016 0.00086664 0.00111835 0.0008113  0.00090793
 0.00089688]
Model epoch 27: train total loss -63.994982758845325, train mean loss 0.0006303088867848363, test mean loss [0.00095599 0.00088499 0.00080336 0.00107394 0.00077235 0.00088526
 0.00086454]
Model epoch 28: train total loss -63.664052692935186, train mean loss 0.0006496307610177648, test mean loss [0.00091499 0.00087335 0.00080034 0.00106558 0.00074324 0.0008987
 0.00084912]
Model epoch 29: train total loss -63.97140082033519, train mean loss 0.0006433646842540654, test mean loss [0.00089506 0.00084142 0.0007737  0.00102228 0.0007073  0.00083159
 0.00083292]
Model epoch 30: train total loss -64.09782199184761, train mean loss 0.0005407317241792978, test mean loss [0.00088902 0.00081484 0.00075524 0.00100232 0.00070282 0.0007975
 0.00081315]
Model epoch 31: train total loss -64.06699721121221, train mean loss 0.000676578121300589, test mean loss [0.00083744 0.0007938  0.00074926 0.00098136 0.00066345 0.00078441
 0.00083836]
Model epoch 32: train total loss -64.04767678018004, train mean loss 0.00041948583812703944, test mean loss [0.00079516 0.00079264 0.00073211 0.00095093 0.00066347 0.00081375
 0.0007953 ]
Model epoch 33: train total loss -63.96892906484871, train mean loss 0.0006699430638698309, test mean loss [0.00079584 0.00078391 0.00072337 0.0009569  0.00063093 0.00074975
 0.00077289]
Model epoch 34: train total loss -64.0506902842643, train mean loss 0.00044819503363290134, test mean loss [0.00077981 0.00074417 0.00070893 0.00091741 0.00065081 0.00075896
 0.00076545]
Model epoch 35: train total loss -63.91836662825254, train mean loss 0.0006200228485309832, test mean loss [0.00076626 0.00075147 0.00068847 0.00089904 0.00061093 0.00076128
 0.00074398]
Model epoch 36: train total loss -64.17434589343299, train mean loss 0.0004277225694142357, test mean loss [0.00073267 0.00071018 0.00066203 0.00088921 0.0006605  0.00071723
 0.0007516 ]
Model epoch 37: train total loss -64.15536558665181, train mean loss 0.0003663428497137655, test mean loss [0.00072024 0.00072119 0.0006472  0.00088695 0.00061974 0.00069402
 0.00071966]
Model epoch 38: train total loss -63.89706469014388, train mean loss 0.0007054911648329502, test mean loss [0.00070337 0.00069688 0.00065478 0.00085295 0.00059153 0.00067518
 0.00069763]
Model epoch 39: train total loss -64.08109773939204, train mean loss 0.0005540003837185169, test mean loss [0.0006869  0.0006608  0.00061729 0.00085413 0.00056725 0.00064429
 0.00070736]
Model epoch 40: train total loss -64.05757162870547, train mean loss 0.00047242552132789324, test mean loss [0.00066919 0.00069988 0.00061598 0.00083464 0.00055893 0.00063455
 0.00071638]
Model epoch 41: train total loss -63.90757701540482, train mean loss 0.0005157660117378976, test mean loss [0.00066552 0.00066061 0.0006198  0.0008846  0.00056601 0.00063959
 0.00070417]
Model epoch 42: train total loss -63.99110513865756, train mean loss 0.00045240464048384874, test mean loss [0.00065758 0.00066839 0.00058446 0.00081698 0.00053667 0.00063678
 0.00068197]
Model epoch 43: train total loss -64.35928290144649, train mean loss 0.00034386349137008587, test mean loss [0.00064534 0.00063497 0.00058352 0.00078737 0.00054258 0.00062081
 0.00066667]
Model epoch 44: train total loss -64.051232359127, train mean loss 0.0004121792016026746, test mean loss [0.00062718 0.00065043 0.00058091 0.0008074  0.00051577 0.0006224
 0.00069536]
Model epoch 45: train total loss -64.15249552607861, train mean loss 0.0003019914124059706, test mean loss [0.00061668 0.00059099 0.00058798 0.00080463 0.00050824 0.00059431
 0.00065705]
Model epoch 46: train total loss -64.187996594764, train mean loss 0.0004768179214211712, test mean loss [0.00061071 0.0005854  0.00054401 0.00076215 0.00052373 0.00059156
 0.00066296]
Model epoch 47: train total loss -64.22707659608842, train mean loss 0.0005490967764084789, test mean loss [0.00060617 0.00057825 0.00055133 0.0007608  0.00051428 0.00056734
 0.00064123]
Model epoch 48: train total loss -64.51383776972676, train mean loss 0.0003042255293681904, test mean loss [0.00058642 0.00058486 0.00054245 0.00077309 0.00050948 0.00056307
 0.0006685 ]
Model epoch 49: train total loss -64.19391105353824, train mean loss 0.0003703191851544944, test mean loss [0.00059127 0.00061417 0.00054605 0.00076275 0.00051616 0.00055361
 0.00063668]
Model epoch 50: train total loss -64.18260439704555, train mean loss 0.00041068068267983743, test mean loss [0.00058241 0.00058241 0.00053108 0.00072714 0.00051354 0.00055587
 0.00063153]
Model epoch 51: train total loss -64.32212667737082, train mean loss 0.0005180390381941946, test mean loss [0.00056504 0.00055271 0.0005263  0.00074448 0.00050833 0.00057411
 0.00063183]
Model epoch 52: train total loss -64.01243026058852, train mean loss 0.0003664834958105977, test mean loss [0.00057279 0.00057155 0.00054462 0.00072345 0.0004815  0.00054188
 0.00061754]
Model epoch 53: train total loss -64.1664051135776, train mean loss 0.0004237369115177123, test mean loss [0.00056479 0.00055217 0.00052507 0.00070663 0.00047346 0.00053235
 0.00061508]
Model epoch 54: train total loss -64.26516439779327, train mean loss 0.0004016097259662345, test mean loss [0.00054767 0.00053447 0.00051518 0.00071824 0.00046836 0.00051964
 0.00061711]
Model epoch 55: train total loss -64.04780931641737, train mean loss 0.0005767572824576967, test mean loss [0.00055026 0.00052329 0.00051092 0.00069904 0.00045308 0.00051031
 0.00060455]
Model epoch 56: train total loss -64.14565463973211, train mean loss 0.0003336946024474327, test mean loss [0.00053704 0.00050931 0.00048707 0.00071004 0.00047268 0.00052068
 0.00059241]
Model epoch 57: train total loss -64.35367122846662, train mean loss 0.00041670185514506577, test mean loss [0.0005438  0.00053227 0.00047797 0.0007071  0.00047068 0.00051756
 0.00059273]
Model epoch 58: train total loss -64.51502716213945, train mean loss 0.0004240880712510087, test mean loss [0.00054717 0.00051624 0.000493   0.00066373 0.00044804 0.00049604
 0.00062885]
Model epoch 59: train total loss -64.24488212392474, train mean loss 0.0003775172597103323, test mean loss [0.00051821 0.00052409 0.00049842 0.0006844  0.00046053 0.00048343
 0.00061121]
Model epoch 60: train total loss -64.38049393133221, train mean loss 0.0004193679519032044, test mean loss [0.00050312 0.00052072 0.00049978 0.00068582 0.00046771 0.00047043
 0.00061649]
Model epoch 61: train total loss -64.17826839949272, train mean loss 0.00045281807325884426, test mean loss [0.00052109 0.00049743 0.00048154 0.00065954 0.00041998 0.00046305
 0.00060484]
Model epoch 62: train total loss -64.34563400714855, train mean loss 0.0003353559076150247, test mean loss [0.00052875 0.00049016 0.00048467 0.00067659 0.00042666 0.00047412
 0.00060792]
Model epoch 63: train total loss -64.34196513239374, train mean loss 0.0003564935494441738, test mean loss [0.00050599 0.00048999 0.00046104 0.00065677 0.00041388 0.0004583
 0.00060068]
Model epoch 64: train total loss -64.1489848131943, train mean loss 0.00034023359177611797, test mean loss [0.00050834 0.00047982 0.00046453 0.00066805 0.00041406 0.00044285
 0.00058302]
Model epoch 65: train total loss -64.41220567371458, train mean loss 0.0002906626805293443, test mean loss [0.00050529 0.0004667  0.00044828 0.00066345 0.00040377 0.00047049
 0.00064729]
Model epoch 66: train total loss -64.25076514124865, train mean loss 0.00038822009978777, test mean loss [0.00050441 0.00047065 0.00047688 0.00065064 0.00042498 0.00043411
 0.00063287]
Model epoch 67: train total loss -64.27575003958076, train mean loss 0.00033341429065965523, test mean loss [0.00049729 0.0005046  0.00048366 0.00063116 0.00043297 0.00043189
 0.00058434]
Model epoch 68: train total loss -64.31811889095522, train mean loss 0.00033538970532300157, test mean loss [0.00050794 0.00047441 0.0004606  0.00062479 0.00041466 0.00044938
 0.00058915]
Model epoch 69: train total loss -64.36130877921946, train mean loss 0.00031479117483206346, test mean loss [0.00049933 0.0004523  0.00043267 0.00062218 0.00039948 0.0004414
 0.00060045]
Model epoch 70: train total loss -64.30529817541674, train mean loss 0.00035574727661587653, test mean loss [0.00049835 0.00047157 0.00044848 0.00062791 0.0004075  0.00045226
 0.00057757]
Model epoch 71: train total loss -64.16198573082556, train mean loss 0.0003294952813748942, test mean loss [0.00049469 0.0004424  0.00044891 0.00062434 0.00038317 0.00043851
 0.00056164]
Model epoch 72: train total loss -64.33421459819073, train mean loss 0.0003318441118246143, test mean loss [0.00050898 0.00042665 0.00044106 0.00062099 0.00039853 0.00042004
 0.00059575]
Model epoch 73: train total loss -64.37191610999356, train mean loss 0.0003544153242804155, test mean loss [0.00049915 0.00047443 0.00042853 0.0006528  0.00041302 0.00044231
 0.00056611]
Model epoch 74: train total loss -64.52099346749858, train mean loss 0.0003849499297467493, test mean loss [0.00048582 0.00043173 0.00042465 0.00060829 0.00041556 0.00042635
 0.0005596 ]
Model epoch 75: train total loss -64.25439095927418, train mean loss 0.0002889897569156505, test mean loss [0.00048241 0.00043081 0.00041668 0.00060408 0.00040496 0.00041671
 0.00053603]
Model epoch 76: train total loss -64.53290615998249, train mean loss 0.00041636671653402037, test mean loss [0.00049253 0.00042726 0.00041751 0.00060759 0.00039486 0.00039676
 0.00056423]
Model epoch 77: train total loss -64.13307018543485, train mean loss 0.0004191448450545085, test mean loss [0.00046898 0.00040557 0.00047012 0.00063122 0.00038536 0.00038038
 0.00054453]
Model epoch 78: train total loss -64.36546664386611, train mean loss 0.0004121540682962808, test mean loss [0.00046427 0.00042594 0.00042305 0.0006413  0.00037701 0.00039154
 0.00056159]
Model epoch 79: train total loss -64.28667398949405, train mean loss 0.00039032532955947917, test mean loss [0.00045998 0.0004026  0.00041101 0.00063334 0.00037479 0.00040104
 0.0005547 ]
Model epoch 80: train total loss -64.43970707383515, train mean loss 0.000379683113924096, test mean loss [0.00048015 0.00042212 0.00040094 0.00061682 0.0003916  0.00039192
 0.00054235]
Model epoch 81: train total loss -64.36514239056879, train mean loss 0.00025502399008326434, test mean loss [0.00045938 0.00040391 0.00039239 0.00061501 0.00038464 0.00038843
 0.00055542]
Model epoch 82: train total loss -64.39620380586089, train mean loss 0.00032555581297725935, test mean loss [0.00047053 0.00040525 0.00039359 0.00059558 0.00038044 0.00040154
 0.00056465]
Model epoch 83: train total loss -64.72912263633471, train mean loss 0.00025787026813928996, test mean loss [0.00044916 0.00040296 0.00039116 0.00059581 0.00037756 0.00039113
 0.00054518]
Model epoch 84: train total loss -64.58964910516679, train mean loss 0.000254725010827309, test mean loss [0.00045201 0.00039724 0.00038632 0.00060946 0.00038556 0.0003839
 0.00054558]
Model epoch 85: train total loss -64.71321024689406, train mean loss 0.0002642552387872328, test mean loss [0.00046231 0.00040206 0.00036946 0.00058683 0.0003938  0.00037348
 0.00053456]
Model epoch 86: train total loss -64.26535734882907, train mean loss 0.0002534465783298504, test mean loss [0.00046239 0.00038484 0.00038168 0.00057975 0.00037528 0.00038732
 0.00055358]
Model epoch 87: train total loss -64.43689912524869, train mean loss 0.0002248107041099414, test mean loss [0.00046718 0.00039154 0.00039261 0.00057004 0.0003566  0.0003811
 0.00055072]
Model epoch 88: train total loss -64.52636789432101, train mean loss 0.000297920486579049, test mean loss [0.00044383 0.00036033 0.00039945 0.00060255 0.00037562 0.00035763
 0.00053463]
Model epoch 89: train total loss -64.50061479230536, train mean loss 0.000286631455255179, test mean loss [0.00046639 0.00035864 0.00040801 0.00057706 0.00035454 0.00036605
 0.00053915]
Model epoch 90: train total loss -64.51161773855463, train mean loss 0.00026427543574322076, test mean loss [0.0004286  0.00036211 0.00038144 0.00060368 0.00037434 0.00037745
 0.00052378]
Model epoch 91: train total loss -64.4026460695538, train mean loss 0.0003366281733676593, test mean loss [0.00042732 0.00037456 0.00037408 0.00056048 0.00035643 0.00035968
 0.00054173]
Model epoch 92: train total loss -64.5576107199939, train mean loss 0.00032322869368306217, test mean loss [0.00042609 0.00037625 0.00037012 0.00056038 0.0003524  0.00036181
 0.00056146]
Model epoch 93: train total loss -64.48137013853768, train mean loss 0.0002520658394111008, test mean loss [0.00042561 0.00036931 0.00036964 0.00057781 0.00034094 0.00034913
 0.00052212]
Model epoch 94: train total loss -64.64958359344315, train mean loss 0.0003620357581189771, test mean loss [0.00042206 0.00035675 0.00036358 0.00058635 0.00035629 0.00034536
 0.00051608]
Model epoch 95: train total loss -64.46898578765472, train mean loss 0.00038212032294413336, test mean loss [0.00042311 0.00034495 0.00036673 0.00056217 0.00033783 0.00035111
 0.00051635]
Model epoch 96: train total loss -64.55827440059076, train mean loss 0.0003210103801396659, test mean loss [0.00044716 0.00037467 0.0003686  0.00056393 0.00033406 0.00035614
 0.00054084]
Model epoch 97: train total loss -64.54490774455398, train mean loss 0.00030332797226849634, test mean loss [0.00041525 0.00037335 0.00037128 0.00056227 0.00035386 0.00035261
 0.00052488]
Model epoch 98: train total loss -64.41969673211364, train mean loss 0.0003433327227750079, test mean loss [0.00042438 0.00034855 0.00035712 0.00057109 0.00036966 0.00033956
 0.00051724]
Model epoch 99: train total loss -64.44431640419566, train mean loss 0.0002814635016959017, test mean loss [0.00040895 0.00034883 0.00035428 0.00054961 0.00034058 0.00033422
 0.00052101]
Model epoch 100: train total loss -64.34487559813485, train mean loss 0.0002311116216655194, test mean loss [0.00042395 0.00036471 0.0003671  0.00055042 0.00034364 0.00035164
 0.00051045]
Model epoch 101: train total loss -64.55934273628941, train mean loss 0.00022895549349449237, test mean loss [0.00040395 0.00034038 0.00034991 0.00054522 0.00035528 0.00032538
 0.00050934]
Model epoch 102: train total loss -64.42956686638423, train mean loss 0.0002746945276458885, test mean loss [0.00041475 0.00033738 0.00034786 0.00053959 0.00033394 0.00034189
 0.00048413]
Model epoch 103: train total loss -64.68539792538901, train mean loss 0.0003636665630145459, test mean loss [0.00042212 0.0003292  0.00035873 0.00056054 0.00034377 0.00033525
 0.00053342]
Model epoch 104: train total loss -64.57647473659732, train mean loss 0.0003411956548107263, test mean loss [0.00042297 0.00036108 0.00035345 0.00054322 0.00034783 0.000318
 0.00050595]
Model epoch 105: train total loss -64.37305148781708, train mean loss 0.00028608892698729534, test mean loss [0.0004119  0.00035137 0.00035626 0.00054858 0.00034683 0.00033553
 0.00050608]
Model epoch 106: train total loss -64.67862776659196, train mean loss 0.00029787955969280737, test mean loss [0.00041721 0.00034491 0.00034506 0.00055799 0.00034553 0.00033775
 0.00048697]
Model epoch 107: train total loss -64.84787036805113, train mean loss 0.0002771485699749121, test mean loss [0.00041895 0.00034211 0.00034631 0.00054385 0.00032782 0.00034606
 0.00051826]
Model epoch 108: train total loss -64.61645517330217, train mean loss 0.00026646617386120346, test mean loss [0.00039592 0.00033595 0.00033492 0.00053735 0.00030738 0.00033232
 0.00048903]
Model epoch 109: train total loss -64.45779120329642, train mean loss 0.00027630811487572917, test mean loss [0.00042664 0.00034319 0.00032281 0.00053656 0.00033276 0.00034137
 0.00050279]
Model epoch 110: train total loss -64.41468859291778, train mean loss 0.0002649915759120138, test mean loss [0.00040085 0.00033636 0.0003289  0.00054527 0.00033318 0.00036184
 0.00050261]
Model epoch 111: train total loss -64.65292845624931, train mean loss 0.0003920146716071607, test mean loss [0.0004085  0.00034021 0.00033462 0.00055537 0.00031308 0.00032775
 0.00051555]
Model epoch 112: train total loss -64.65904537266191, train mean loss 0.00026692777313204957, test mean loss [0.00040234 0.00033346 0.00033918 0.00053776 0.00031343 0.00032236
 0.00049754]
Model epoch 113: train total loss -64.51387676141223, train mean loss 0.00021685378943842287, test mean loss [0.00039078 0.0003235  0.00034078 0.00053547 0.00030664 0.00030384
 0.00050871]
Model epoch 114: train total loss -64.81478912969179, train mean loss 0.00037078870071154357, test mean loss [0.00039351 0.00033254 0.00034032 0.0005195  0.00032251 0.00033285
 0.00049974]
Model epoch 115: train total loss -64.60568676660677, train mean loss 0.0003461060548916109, test mean loss [0.00039419 0.00032762 0.0003307  0.00053289 0.00031251 0.0003059
 0.00051623]
Model epoch 116: train total loss -64.69760821253098, train mean loss 0.00027541250077495736, test mean loss [0.0004097  0.00030977 0.0003303  0.0005381  0.00031507 0.00032595
 0.00050654]
Model epoch 117: train total loss -64.7408905853967, train mean loss 0.00022232409619833893, test mean loss [0.00039216 0.00032396 0.00031671 0.00056766 0.00031444 0.00031305
 0.00048565]
Model epoch 118: train total loss -64.66649137658557, train mean loss 0.00022900607843900493, test mean loss [0.00040072 0.00031059 0.00032147 0.00053551 0.00031922 0.00030918
 0.0004872 ]
Model epoch 119: train total loss -64.43212440290081, train mean loss 0.00024835182095819916, test mean loss [0.00038905 0.00034452 0.00032107 0.00054792 0.00035035 0.00033714
 0.00048862]
Model epoch 120: train total loss -64.70387343134772, train mean loss 0.0003368220225605119, test mean loss [0.00038256 0.000314   0.0003261  0.00052929 0.00030884 0.00031101
 0.00047709]
Model epoch 121: train total loss -64.66365982264257, train mean loss 0.0003004854763673529, test mean loss [0.0003878  0.0003257  0.00032798 0.00054801 0.00031846 0.00030922
 0.00047333]
Model epoch 122: train total loss -64.68479317502124, train mean loss 0.0003252499817930435, test mean loss [0.00037995 0.00030679 0.00032751 0.00052471 0.0003169  0.00030648
 0.0004601 ]
Model epoch 123: train total loss -64.8653914209976, train mean loss 0.00025533900625594833, test mean loss [0.00038816 0.00030675 0.00031588 0.00052782 0.00032186 0.0002972
 0.00048577]
Model epoch 124: train total loss -64.80306493722082, train mean loss 0.00022506317619345824, test mean loss [0.00037869 0.00028535 0.00031744 0.00053506 0.00031535 0.00029997
 0.00048949]
Model epoch 125: train total loss -64.36896433296127, train mean loss 0.00024445627742731603, test mean loss [0.0003808  0.00031117 0.00032673 0.00053314 0.00030805 0.00029884
 0.00055747]
Model epoch 126: train total loss -64.7012460701203, train mean loss 0.00021528870341964117, test mean loss [0.00046868 0.00030493 0.00032922 0.0005093  0.00030187 0.00031048
 0.00049357]
Model epoch 127: train total loss -64.84277366597726, train mean loss 0.00023201622952359984, test mean loss [0.00043744 0.00031137 0.00032461 0.00049655 0.00030962 0.00030101
 0.00049362]
Model epoch 128: train total loss -64.53427582370772, train mean loss 0.00021536839732348264, test mean loss [0.00039437 0.00030257 0.00032021 0.00050997 0.00030874 0.00031761
 0.00046749]
Model epoch 129: train total loss -64.75782041712428, train mean loss 0.00023007915551091556, test mean loss [0.00039405 0.00030379 0.00032826 0.00050036 0.00029097 0.00031248
 0.00046646]
Model epoch 130: train total loss -64.46193817271168, train mean loss 0.0002358438257958482, test mean loss [0.00039588 0.00030169 0.00030642 0.00049077 0.00030149 0.00029964
 0.00046426]
Model epoch 131: train total loss -64.92596286795484, train mean loss 0.00024801561524125587, test mean loss [0.00039467 0.00029421 0.00031451 0.00050037 0.00029861 0.00029009
 0.00045743]
Model epoch 132: train total loss -64.69954939573779, train mean loss 0.0002224868000838854, test mean loss [0.00038624 0.00030589 0.00032925 0.00050923 0.000357   0.00029043
 0.00045166]
Model epoch 133: train total loss -64.92272112509994, train mean loss 0.00021173704158441916, test mean loss [0.0003872  0.00030063 0.00031182 0.00050368 0.00030066 0.00028962
 0.0004881 ]
Model epoch 134: train total loss -64.53781547691571, train mean loss 0.0002491254486612296, test mean loss [0.00037497 0.00029585 0.00033386 0.00050075 0.00032502 0.00027718
 0.00045985]
Model epoch 135: train total loss -64.61109002097551, train mean loss 0.00022940860874969365, test mean loss [0.00038854 0.00029476 0.00033851 0.0005005  0.00030647 0.00028435
 0.00046536]
Model epoch 136: train total loss -64.71881502078261, train mean loss 0.0002455861319159025, test mean loss [0.00038841 0.00028616 0.00030992 0.00048958 0.000299   0.00028985
 0.00046738]
Model epoch 137: train total loss -64.52958382166769, train mean loss 0.0002804927077904759, test mean loss [0.00039053 0.00027826 0.00031916 0.0005059  0.00029964 0.00027443
 0.00044706]
Model epoch 138: train total loss -64.66099045885143, train mean loss 0.0002283626846498772, test mean loss [0.00039399 0.00029066 0.00032605 0.00049607 0.0002958  0.0002815
 0.00046126]
Model epoch 139: train total loss -64.7517877018018, train mean loss 0.00027925459797565976, test mean loss [0.00037243 0.00029249 0.00030942 0.00049862 0.00029858 0.0002827
 0.00044247]
Model epoch 140: train total loss -64.55289651068266, train mean loss 0.00024468876534028427, test mean loss [0.0003776  0.00031292 0.00032541 0.00051016 0.0002928  0.00028697
 0.00046917]
Model epoch 141: train total loss -64.78325835180863, train mean loss 0.0002697307720469989, test mean loss [0.00037129 0.0003049  0.00030845 0.00050744 0.00027937 0.00027884
 0.00045476]
Model epoch 142: train total loss -64.65148977325823, train mean loss 0.00024501664864534195, test mean loss [0.00037785 0.00030344 0.00029781 0.0005144  0.00031377 0.000293
 0.00045212]
Model epoch 143: train total loss -64.91128148205348, train mean loss 0.00028028501957770097, test mean loss [0.00036981 0.000302   0.00029623 0.00051693 0.00027953 0.00028129
 0.00045598]
Model epoch 144: train total loss -64.5440005289251, train mean loss 0.0002105742064612935, test mean loss [0.00036539 0.00029959 0.00031382 0.00048666 0.00029627 0.00027018
 0.00047377]
Model epoch 145: train total loss -64.58896435881863, train mean loss 0.00021558207313647008, test mean loss [0.00037037 0.00030727 0.00030283 0.00049134 0.00029594 0.00026158
 0.00047695]
Model epoch 146: train total loss -64.83445545592706, train mean loss 0.0002597425279618056, test mean loss [0.00036796 0.00030829 0.00031245 0.00047541 0.00029794 0.00026695
 0.00046523]
Model epoch 147: train total loss -64.64093377295924, train mean loss 0.00024641077777238086, test mean loss [0.00036247 0.0003041  0.00036365 0.00049957 0.00030084 0.00030724
 0.0004656 ]
Model epoch 148: train total loss -64.78214931990293, train mean loss 0.0002296879140665069, test mean loss [0.00038462 0.00028813 0.0003075  0.0004734  0.00028748 0.00028127
 0.00042431]
Model epoch 149: train total loss -64.81484013731905, train mean loss 0.00022907040766099584, test mean loss [0.0003703  0.00031587 0.00032002 0.00050696 0.00027949 0.00028161
 0.00042688]
Model epoch 150: train total loss -64.8189907288362, train mean loss 0.0003465834853156447, test mean loss [0.00036754 0.00029822 0.00031063 0.00046929 0.00029266 0.00027897
 0.00045075]
Model epoch 151: train total loss -64.76902929325873, train mean loss 0.00024561715270058054, test mean loss [0.00036715 0.0003094  0.00029827 0.00050034 0.00029641 0.0002643
 0.00043322]
Model epoch 152: train total loss -64.67318737459438, train mean loss 0.0003401767247678045, test mean loss [0.00035559 0.00028344 0.00030379 0.00048667 0.00030418 0.00027944
 0.00043134]
Model epoch 153: train total loss -64.80897757337068, train mean loss 0.00023698801224003143, test mean loss [0.00036642 0.00033004 0.00030551 0.0004581  0.00029554 0.00027094
 0.00043182]
Model epoch 154: train total loss -64.69294468392268, train mean loss 0.0002069382386304336, test mean loss [0.00034952 0.00028393 0.00029423 0.00049192 0.00029016 0.00026553
 0.00042969]
Model epoch 155: train total loss -64.5391532545622, train mean loss 0.0003083402332681497, test mean loss [0.00035911 0.0002937  0.00030302 0.00048585 0.0002848  0.00030525
 0.00041728]
Model epoch 156: train total loss -64.68426308379182, train mean loss 0.0002395509543248608, test mean loss [0.00036993 0.00028066 0.00029128 0.00046566 0.00030745 0.00029628
 0.00042053]
Model epoch 157: train total loss -64.96193703226903, train mean loss 0.0002297469169607378, test mean loss [0.00036253 0.00029241 0.00029814 0.00048195 0.00028772 0.00026622
 0.0004149 ]
Model epoch 158: train total loss -64.60344610722964, train mean loss 0.0002347694537543244, test mean loss [0.00035083 0.00029232 0.00030882 0.00051049 0.00028353 0.00026306
 0.00042325]
Model epoch 159: train total loss -64.98591426549663, train mean loss 0.00038101694569834464, test mean loss [0.00036144 0.00028947 0.0002946  0.00048448 0.00029004 0.00026669
 0.00043124]
Model epoch 160: train total loss -64.81509368431252, train mean loss 0.00022338032876208436, test mean loss [0.00034782 0.00028703 0.00030215 0.00047007 0.00029041 0.00027454
 0.00043477]
Model epoch 161: train total loss -64.48896819103032, train mean loss 0.00022967499427842465, test mean loss [0.00036734 0.00027628 0.0002865  0.00048129 0.00030766 0.00027233
 0.00040926]
Model epoch 162: train total loss -64.70194727561011, train mean loss 0.00023179226569354356, test mean loss [0.00034048 0.00028262 0.00030178 0.00047086 0.0002848  0.00027501
 0.00042613]
Model epoch 163: train total loss -64.62930081841077, train mean loss 0.0003085482139751441, test mean loss [0.00034976 0.00029595 0.00031364 0.00046396 0.0002832  0.00026651
 0.00041982]
Model epoch 164: train total loss -64.86294660535296, train mean loss 0.0002538392000327189, test mean loss [0.00035126 0.00027752 0.00029926 0.00049462 0.00028889 0.00026475
 0.00041556]
Model epoch 165: train total loss -64.77393456560547, train mean loss 0.0002743175725421951, test mean loss [0.00035484 0.00032435 0.00030691 0.00047605 0.00027558 0.00026611
 0.00040323]
Model epoch 166: train total loss -64.86400960897264, train mean loss 0.0002303707638033546, test mean loss [0.00035595 0.0002819  0.00030909 0.00047752 0.0002798  0.0002666
 0.0004042 ]
Model epoch 167: train total loss -65.04254912786419, train mean loss 0.00025772115930569465, test mean loss [0.00035272 0.00028981 0.00029017 0.00046696 0.00027687 0.00025663
 0.00039608]
Model epoch 168: train total loss -64.79514826269876, train mean loss 0.0002544381010543733, test mean loss [0.00035118 0.00029224 0.0003067  0.00045809 0.00027708 0.00033124
 0.00039669]
Model epoch 169: train total loss -64.28442327170515, train mean loss 0.000284049596819221, test mean loss [0.00035318 0.00027816 0.00030644 0.00046073 0.00026623 0.00025379
 0.0004191 ]
Model epoch 170: train total loss -64.68625356849869, train mean loss 0.0002539958004089449, test mean loss [0.00034981 0.00027469 0.00028909 0.00045915 0.0002864  0.00025245
 0.00042802]
Model epoch 171: train total loss -64.64385804400068, train mean loss 0.00022205983543270466, test mean loss [0.00033858 0.00028274 0.00028296 0.00048843 0.00027306 0.00024831
 0.00041654]
Model epoch 172: train total loss -64.45493076761204, train mean loss 0.00022093755634132207, test mean loss [0.00036282 0.0002873  0.00029548 0.00046173 0.00026183 0.00026204
 0.00040806]
Model epoch 173: train total loss -64.67153633708513, train mean loss 0.0002384171863738057, test mean loss [0.0003429  0.00026715 0.00029537 0.00046005 0.0002698  0.00025199
 0.000423  ]
Model epoch 174: train total loss -64.80946623456236, train mean loss 0.00020310904704112873, test mean loss [0.00034474 0.00027364 0.00028969 0.00043857 0.00028799 0.00025336
 0.00042123]
Model epoch 175: train total loss -64.8386314184132, train mean loss 0.00029630708467105933, test mean loss [0.00036946 0.00029087 0.0002857  0.00044031 0.0002829  0.00025131
 0.00041863]
Model epoch 176: train total loss -64.80663504715328, train mean loss 0.0002144479372415565, test mean loss [0.00034621 0.00029284 0.00028611 0.00045455 0.0002784  0.00027318
 0.00040806]
Model epoch 177: train total loss -64.86298466760668, train mean loss 0.0002295691812972926, test mean loss [0.00034566 0.00028208 0.0002699  0.00045724 0.0002746  0.00025049
 0.00040689]
Model epoch 178: train total loss -64.58920662814197, train mean loss 0.00023006724026643382, test mean loss [0.00032557 0.00028136 0.00029161 0.00044997 0.00028574 0.00024304
 0.00040421]
Model epoch 179: train total loss -64.59188580639811, train mean loss 0.00022945119708473382, test mean loss [0.00034395 0.00027586 0.00028205 0.0004456  0.00027499 0.00025367
 0.00041167]
Model epoch 180: train total loss -64.82105987280731, train mean loss 0.00023432393524065194, test mean loss [0.00032863 0.00027418 0.00027485 0.00045644 0.00027461 0.00024401
 0.00042067]
Model epoch 181: train total loss -64.90861310495738, train mean loss 0.0002403793657931923, test mean loss [0.00032994 0.00028256 0.00029539 0.00045238 0.0002711  0.00024833
 0.00038765]
Model epoch 182: train total loss -64.5990537436307, train mean loss 0.00036636847311205545, test mean loss [0.00033356 0.00026527 0.00029951 0.00046658 0.00028306 0.00024236
 0.00041375]
Model epoch 183: train total loss -64.84433090913537, train mean loss 0.0002319568082620238, test mean loss [0.000319   0.00027307 0.00030791 0.00045623 0.00028062 0.00025402
 0.00039191]
Model epoch 184: train total loss -64.85684203869795, train mean loss 0.00023726460690225713, test mean loss [0.00034153 0.00027757 0.00028939 0.00044559 0.00027388 0.00025074
 0.00039503]
Model epoch 185: train total loss -64.74129973608854, train mean loss 0.0002241883178603681, test mean loss [0.00033759 0.00027085 0.00029166 0.00043869 0.00028713 0.00023973
 0.00038249]
Model epoch 186: train total loss -64.53600555586193, train mean loss 0.0002460021305069827, test mean loss [0.00032389 0.00027901 0.00029372 0.00045458 0.00027116 0.00024312
 0.00038827]
Model epoch 187: train total loss -64.86761761936248, train mean loss 0.0002083967923025813, test mean loss [0.00033206 0.00028542 0.00028292 0.00044514 0.0002812  0.00023695
 0.00038536]
Model epoch 188: train total loss -64.6981867260345, train mean loss 0.00024679809821771765, test mean loss [0.00032578 0.00027593 0.00029726 0.0004346  0.00027346 0.00024843
 0.00040442]
Model epoch 189: train total loss -64.65748892712156, train mean loss 0.00022008061844410362, test mean loss [0.00033391 0.0002799  0.00027825 0.00043537 0.00025951 0.00023057
 0.00039257]
Model epoch 190: train total loss -64.63379372792855, train mean loss 0.00022864850053216625, test mean loss [0.00033034 0.00027843 0.00027191 0.00043101 0.00026472 0.0002538
 0.00039311]
Model epoch 191: train total loss -64.95338931541306, train mean loss 0.00021180463799483058, test mean loss [0.00033924 0.00027229 0.00027799 0.00045189 0.00026926 0.00023219
 0.00039036]
Model epoch 192: train total loss -64.97096665644561, train mean loss 0.00019119533712961376, test mean loss [0.00032581 0.00027363 0.00027838 0.00044836 0.00027561 0.00024101
 0.00039099]
Model epoch 193: train total loss -64.78908458390507, train mean loss 0.000289305198617296, test mean loss [0.0003365  0.00035657 0.00027306 0.00044629 0.00026878 0.00023934
 0.00037877]
Model epoch 194: train total loss -64.97316783803794, train mean loss 0.00025692699781009197, test mean loss [0.00034477 0.0002689  0.00028707 0.00043705 0.00026065 0.0002494
 0.00038247]
Model epoch 195: train total loss -64.72397075851536, train mean loss 0.00027548663332083514, test mean loss [0.00033366 0.00026854 0.00029105 0.00042344 0.00027417 0.00025884
 0.00038192]
Model epoch 196: train total loss -64.76635148128271, train mean loss 0.00027586560110169715, test mean loss [0.00032462 0.00026425 0.00028    0.00042407 0.00025798 0.00024874
 0.00038261]
Model epoch 197: train total loss -64.68258177156821, train mean loss 0.00024390220984455663, test mean loss [0.00032338 0.00026409 0.00027465 0.00045431 0.00026624 0.00025923
 0.00037652]
Model epoch 198: train total loss -64.91573765799033, train mean loss 0.00021673936666128784, test mean loss [0.0003288  0.00024482 0.00027651 0.00043579 0.00026621 0.00024272
 0.00037235]
Model epoch 199: train total loss -64.76633105215313, train mean loss 0.0002684650616766893, test mean loss [0.00034387 0.00027992 0.00026909 0.00042261 0.00026394 0.00023931
 0.00039079]
Model epoch 200: train total loss -64.93466766026108, train mean loss 0.00021992790391920774, test mean loss [0.00034    0.00028514 0.00027279 0.00043378 0.00026082 0.00022711
 0.00037573]
Model epoch 201: train total loss -64.83462914334895, train mean loss 0.00020438154731423745, test mean loss [0.00032472 0.00028617 0.00028175 0.00042129 0.00025993 0.00025011
 0.00037972]
Model epoch 202: train total loss -64.59209504502455, train mean loss 0.00020788469139676322, test mean loss [0.00031789 0.00026053 0.0002846  0.00044535 0.00025735 0.00024524
 0.00038572]
Model epoch 203: train total loss -64.8053846315056, train mean loss 0.0001969573416406813, test mean loss [0.00032582 0.00027388 0.00028928 0.00042838 0.0002526  0.0002384
 0.00041909]
Model epoch 204: train total loss -64.87978270914374, train mean loss 0.0002740394377651919, test mean loss [0.00032506 0.00026218 0.0002806  0.00042915 0.00026073 0.00024961
 0.00039038]
Model epoch 205: train total loss -64.72461347302173, train mean loss 0.0002387058998734552, test mean loss [0.00031918 0.00026217 0.00026409 0.00042565 0.00025889 0.00023874
 0.00051931]
Model epoch 206: train total loss -64.79147750359198, train mean loss 0.00028341379773282104, test mean loss [0.0003314  0.00026229 0.00028471 0.00043221 0.00027598 0.00024321
 0.00048814]
Model epoch 207: train total loss -64.74467704098298, train mean loss 0.0002651884390443207, test mean loss [0.00031142 0.00026405 0.0002825  0.00043812 0.00026742 0.00023972
 0.00044326]
Model epoch 208: train total loss -64.82940851356112, train mean loss 0.00029272027143931704, test mean loss [0.00031785 0.00026709 0.0002682  0.00043456 0.00026113 0.00024932
 0.00049083]
Model epoch 209: train total loss -64.63687283018702, train mean loss 0.0002848705287468438, test mean loss [0.00037258 0.00027734 0.0002642  0.00043241 0.00026783 0.00024231
 0.00043569]
Model epoch 210: train total loss -64.73340378975352, train mean loss 0.0002078828542648288, test mean loss [0.00036428 0.00028316 0.00028205 0.00042602 0.00025918 0.00025757
 0.00044964]
Model epoch 211: train total loss -64.83142230945067, train mean loss 0.00020243300321836876, test mean loss [0.00033619 0.00026705 0.00027143 0.00041204 0.00025669 0.00024998
 0.00043264]
Model epoch 212: train total loss -64.64467630724158, train mean loss 0.0002614618719273694, test mean loss [0.00033693 0.00027437 0.00026286 0.00043055 0.00024711 0.00026235
 0.00042255]
Model epoch 213: train total loss -65.13829138448658, train mean loss 0.0003094894316635539, test mean loss [0.00033629 0.00026554 0.00026689 0.00041708 0.00025202 0.00023115
 0.00041469]
Model epoch 214: train total loss -64.99801627424428, train mean loss 0.00028488945544329183, test mean loss [0.00031466 0.0002752  0.000267   0.00042035 0.0002549  0.00024192
 0.00042253]
Model epoch 215: train total loss -64.87596067721975, train mean loss 0.0002143672507185966, test mean loss [0.00031856 0.0002717  0.00026456 0.00042815 0.00024888 0.00023945
 0.00040657]
Model epoch 216: train total loss -64.78722326676146, train mean loss 0.0002514749763798086, test mean loss [0.00031017 0.00027237 0.00026495 0.00040493 0.00024587 0.00024293
 0.00038353]
Model epoch 217: train total loss -64.55835658442753, train mean loss 0.0002071510185744093, test mean loss [0.00031144 0.00026343 0.00026347 0.00041257 0.0002587  0.00023647
 0.00038913]
Model epoch 218: train total loss -64.71152420401333, train mean loss 0.0002386791396076058, test mean loss [0.00030898 0.0002645  0.00027867 0.00042235 0.00025372 0.00023272
 0.00039764]
Model epoch 219: train total loss -64.75567513590939, train mean loss 0.00023846344731848852, test mean loss [0.00031739 0.00027542 0.00025411 0.00040718 0.00025673 0.00023518
 0.00038995]
Model epoch 220: train total loss -65.00779647590122, train mean loss 0.00028766916417733725, test mean loss [0.00031173 0.00026912 0.00026902 0.00042276 0.00024751 0.00023281
 0.00037639]
Model epoch 221: train total loss -65.00854395980114, train mean loss 0.00020869947430431508, test mean loss [0.00032114 0.00026522 0.00027621 0.00041917 0.00025359 0.00022248
 0.0003792 ]
Model epoch 222: train total loss -64.86938466956208, train mean loss 0.00017996922216498515, test mean loss [0.00031582 0.00026629 0.00026429 0.0004122  0.00024504 0.00023864
 0.00041166]
Model epoch 223: train total loss -65.02139697321329, train mean loss 0.0002402103732483355, test mean loss [0.00031535 0.0002527  0.00026286 0.00041541 0.00025546 0.00023593
 0.00038432]
Model epoch 224: train total loss -64.69720639758951, train mean loss 0.00022576410920306439, test mean loss [0.0003039  0.00027313 0.00027798 0.00041017 0.0002499  0.00024173
 0.00037013]
Model epoch 225: train total loss -64.92838397950764, train mean loss 0.00023487706525286172, test mean loss [0.00030047 0.00027033 0.00025942 0.00039946 0.00025734 0.00022982
 0.00038436]
Model epoch 226: train total loss -64.72355483915412, train mean loss 0.00026133253790276543, test mean loss [0.00033867 0.0002636  0.00025921 0.00040313 0.00025175 0.00024074
 0.00036985]
Model epoch 227: train total loss -64.7872402061338, train mean loss 0.00027095976628533996, test mean loss [0.00030503 0.00025371 0.00027498 0.00040014 0.00023737 0.00023262
 0.00038244]
Model epoch 228: train total loss -64.8249805612415, train mean loss 0.0003022609824634441, test mean loss [0.00030257 0.0002645  0.00027109 0.00040718 0.00024881 0.00023503
 0.00036697]
Model epoch 229: train total loss -64.80672227892892, train mean loss 0.00019002393994341408, test mean loss [0.00030213 0.00026029 0.00026295 0.00041985 0.00025284 0.00023457
 0.00037405]
Model epoch 230: train total loss -64.71762879520449, train mean loss 0.00021885880565232258, test mean loss [0.00029402 0.00026414 0.00025283 0.00040685 0.00025118 0.00024027
 0.00035732]
Model epoch 231: train total loss -64.78337656732462, train mean loss 0.00023658972286996703, test mean loss [0.00029762 0.0002617  0.00027204 0.00038072 0.00024656 0.00021978
 0.00037976]
Model epoch 232: train total loss -64.79818483392218, train mean loss 0.00021692797175421302, test mean loss [0.00030584 0.0002559  0.00025799 0.00040057 0.00025127 0.00023508
 0.00036049]
Model epoch 233: train total loss -64.90935222565129, train mean loss 0.00022159731270533295, test mean loss [0.00028776 0.00025367 0.00026604 0.00039364 0.00025701 0.00023716
 0.00036291]
Model epoch 234: train total loss -64.75060290046781, train mean loss 0.00021237300050253394, test mean loss [0.0003023  0.00025216 0.0002603  0.00040463 0.00024226 0.00023048
 0.00039009]
Model epoch 235: train total loss -64.97273099390537, train mean loss 0.00019786559481878025, test mean loss [0.00029438 0.00024462 0.00026088 0.00039482 0.00025989 0.00023378
 0.00037728]
Model epoch 236: train total loss -64.88863800740745, train mean loss 0.0002175476404825598, test mean loss [0.00028838 0.00025461 0.00027698 0.00039697 0.00024833 0.00023019
 0.00037492]
Model epoch 237: train total loss -64.88002209455792, train mean loss 0.00025541845180046237, test mean loss [0.00028852 0.00024771 0.00025903 0.00037439 0.00025659 0.00023591
 0.00035873]
Model epoch 238: train total loss -64.75960828982102, train mean loss 0.00021115363507621254, test mean loss [0.00029823 0.00024677 0.00024381 0.00040411 0.00025154 0.00023925
 0.00037815]
Model epoch 239: train total loss -64.9688726514022, train mean loss 0.00021195548544246436, test mean loss [0.00029675 0.00025998 0.00025699 0.00039148 0.00025023 0.00024092
 0.00034224]
Model epoch 240: train total loss -65.05500396604964, train mean loss 0.00022142569113282223, test mean loss [0.00030097 0.00026758 0.0002548  0.00037393 0.00024942 0.00022848
 0.00034983]
Model epoch 241: train total loss -65.21073636750546, train mean loss 0.00020050620563408542, test mean loss [0.00028419 0.00024426 0.00026948 0.00039483 0.00025207 0.00023286
 0.00033954]
Model epoch 242: train total loss -64.72716664594616, train mean loss 0.0002140324505600261, test mean loss [0.00029748 0.00024575 0.00026851 0.00039241 0.00024711 0.00026084
 0.00036257]
Model epoch 243: train total loss -64.99963979722861, train mean loss 0.00024653475538125117, test mean loss [0.00028568 0.00025822 0.00024716 0.00039131 0.00025709 0.00022569
 0.00034165]
Model epoch 244: train total loss -65.09185137304995, train mean loss 0.00018518148518435884, test mean loss [0.00028848 0.00025908 0.00025099 0.00038937 0.00025856 0.00022603
 0.00036799]
Model epoch 245: train total loss -64.97912810999757, train mean loss 0.0002008342407995031, test mean loss [0.00027299 0.00024333 0.00025735 0.00039189 0.00024525 0.00023474
 0.00041044]
Model epoch 246: train total loss -64.8559025601293, train mean loss 0.0002859174077742299, test mean loss [0.00031384 0.00024363 0.00024777 0.00039687 0.00023529 0.00023422
 0.00033084]
Model epoch 247: train total loss -65.07476747276434, train mean loss 0.000246001546184235, test mean loss [0.00029643 0.00024582 0.00024363 0.00039836 0.00023772 0.00023352
 0.00034318]
Model epoch 248: train total loss -64.91484220307913, train mean loss 0.0002401963218921781, test mean loss [0.00028905 0.0002521  0.00026272 0.00043179 0.00024336 0.00025328
 0.00036029]
Model epoch 249: train total loss -64.81378959500906, train mean loss 0.00021343037799361036, test mean loss [0.00029809 0.0002587  0.00025881 0.00036467 0.00024176 0.00022701
 0.00035785]
Model epoch 250: train total loss -64.8696671929372, train mean loss 0.0002807824270923871, test mean loss [0.00030074 0.00025255 0.0002562  0.00038566 0.00024168 0.00023191
 0.00033327]
Model epoch 251: train total loss -64.9426765121882, train mean loss 0.0001943258591818988, test mean loss [0.00029341 0.00025507 0.00025578 0.00038812 0.0002401  0.00022164
 0.00033039]
Model epoch 252: train total loss -64.65307435543079, train mean loss 0.00021267636794811625, test mean loss [0.00027331 0.00025286 0.00024872 0.0003902  0.00023373 0.00023057
 0.0003622 ]
Model epoch 253: train total loss -64.72341077121743, train mean loss 0.0002089139023611019, test mean loss [0.00027973 0.00024341 0.00024935 0.00038661 0.00025152 0.0002227
 0.00035631]
Model epoch 254: train total loss -64.87941980184102, train mean loss 0.00020454647753483042, test mean loss [0.00027534 0.00024972 0.00027362 0.0003955  0.00024701 0.00023697
 0.00034134]
Model epoch 255: train total loss -64.99704776143923, train mean loss 0.000272470341556668, test mean loss [0.00027267 0.00025011 0.00023914 0.00039566 0.00024263 0.00022954
 0.00034107]
Model epoch 256: train total loss -64.81390767245408, train mean loss 0.000207016640057711, test mean loss [0.00028081 0.0002543  0.00024354 0.00039683 0.00025277 0.00023827
 0.00033362]
Model epoch 257: train total loss -64.77809331294503, train mean loss 0.00024164787110187629, test mean loss [0.00029707 0.00024275 0.0002393  0.00037726 0.00024633 0.00023646
 0.00033452]
Model epoch 258: train total loss -64.63001477208508, train mean loss 0.00022921657729065877, test mean loss [0.00026818 0.00024482 0.00025538 0.00037375 0.00024567 0.00022798
 0.00033472]
Model epoch 259: train total loss -64.89122574375618, train mean loss 0.00021705084909946683, test mean loss [0.00029747 0.0002592  0.00024777 0.00036739 0.00023661 0.00023075
 0.00032618]
Model epoch 260: train total loss -64.82753348741895, train mean loss 0.00023472124745343433, test mean loss [0.00029041 0.00024306 0.00026683 0.00037311 0.00024347 0.000221
 0.000332  ]
Model epoch 261: train total loss -64.67228218983671, train mean loss 0.0002324750422935193, test mean loss [0.00028338 0.00024503 0.0002445  0.00038672 0.00024968 0.00024198
 0.00033413]
Model epoch 262: train total loss -64.68265523204248, train mean loss 0.00023836257512108803, test mean loss [0.00029568 0.00023528 0.00024667 0.00036305 0.00024597 0.00023302
 0.00037728]
Model epoch 263: train total loss -64.64517108167767, train mean loss 0.0002293347251638558, test mean loss [0.00028148 0.00023374 0.00023107 0.0003853  0.00024489 0.00023362
 0.00034253]
Model epoch 264: train total loss -64.88563800601702, train mean loss 0.00020497183751937297, test mean loss [0.0002875  0.00023875 0.00025539 0.00036869 0.00026365 0.00023055
 0.00034084]
Model epoch 265: train total loss -64.7819737244339, train mean loss 0.00018443912907994186, test mean loss [0.00028032 0.00025555 0.00023776 0.00037008 0.00025019 0.00022783
 0.00033326]
Model epoch 266: train total loss -64.87876917752877, train mean loss 0.0002189453833532952, test mean loss [0.00028063 0.00024856 0.00024146 0.00038682 0.0002388  0.00022779
 0.00034813]
Model epoch 267: train total loss -64.92205375442853, train mean loss 0.0002068815730523521, test mean loss [0.00028616 0.00025776 0.00024614 0.00036733 0.00024764 0.00022254
 0.00034348]
Model epoch 268: train total loss -65.00622195766286, train mean loss 0.0002266021737350386, test mean loss [0.00027444 0.00024504 0.00025308 0.00036927 0.00023932 0.00021657
 0.00033242]
Model epoch 269: train total loss -65.20535827506471, train mean loss 0.0002525773917422729, test mean loss [0.00027392 0.00025625 0.00024362 0.00036702 0.00024845 0.00023487
 0.00033766]
Model epoch 270: train total loss -64.93216784577905, train mean loss 0.00020824627288149256, test mean loss [0.00027262 0.00026048 0.00027241 0.00038509 0.00024418 0.0002269
 0.00035368]
Model epoch 271: train total loss -65.22080895528143, train mean loss 0.0002121445968653865, test mean loss [0.00027876 0.00024333 0.00025386 0.00037005 0.00024663 0.00021752
 0.00035664]
Model epoch 272: train total loss -65.06243067351635, train mean loss 0.00019870069788565967, test mean loss [0.00027352 0.00024449 0.00023608 0.00037948 0.00024459 0.0002314
 0.00033971]
Model epoch 273: train total loss -64.59996276200287, train mean loss 0.00021661863423534747, test mean loss [0.00029054 0.00024388 0.00023347 0.00037025 0.00024789 0.00023365
 0.00033183]
Model epoch 274: train total loss -64.97724534217026, train mean loss 0.00019028017348834934, test mean loss [0.00026763 0.00025152 0.00023567 0.00037184 0.00024632 0.00022838
 0.00033731]
Model trained in 275 epochs with 9000 transitions.
[2025-01-25 02:27:05,805][absl][INFO] - {'eval/walltime': 313.9011461734772, 'training/sps': 0.1844317169009308, 'training/walltime': 34111.68802976608, 'training/model_train_time': 3470.73433637619, 'training/other_time': 1950.4969050884247, 'training/model_horizon': 16, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(10000, dtype=int32), 'model/train_total_loss': Array(-64.97724534, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00019028, dtype=float64), 'model/test_total_loss': Array(-64.45448971, dtype=float64), 'model/test_mean_loss': Array(0.00027695, dtype=float64), 'model/train_epochs': 275, 'model/sec_per_epoch': 12.61245704390786, 'sac/actor_loss': Array(-26.15285064, dtype=float64), 'sac/alpha': Array(0.02640074, dtype=float32), 'sac/alpha_loss': Array(6.57027329e-06, dtype=float64), 'sac/buffer_current_size': Array(400000.03, dtype=float32), 'sac/critic_loss': Array(0.0895633, dtype=float64), 'eval/episode_forward_vel': Array(176.85676647, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-2.49206571, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(24.74413672, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.02779513, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(76.06742644, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(27.19457668, dtype=float64), 'eval/episode_rew_roll': Array(24.98013652, dtype=float64), 'eval/episode_rew_side_motion': Array(25.67823277, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(20.25308979, dtype=float64), 'eval/episode_rew_yaw': Array(39.99167502, dtype=float64), 'eval/episode_rew_z_vel_change': Array(14.01412941, dtype=float64), 'eval/episode_reward': Array(249.96838565, dtype=float64), 'eval/episode_step_count': Array(138075., dtype=float64), 'eval/avg_episode_length': Array(526., dtype=float64), 'eval/epoch_eval_time': 29.958903551101685, 'eval/sps': 33.379058692661225}
Steps / Eval:  10000.0
Reward is  249.96838565183356
Model horizon updated to 18.
Hallucination updates per training step updated to 1000.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -48.93193212709014, train mean loss 0.01091361564437611, test mean loss [0.00697178 0.01219984 0.00937801 0.00878037 0.01000339 0.01283483
 0.0132949 ]
Model epoch 1: train total loss -55.12373488446462, train mean loss 0.007851191374124608, test mean loss [0.00341074 0.0076032  0.00660825 0.00530935 0.00636342 0.00889171
 0.00925719]
Model epoch 2: train total loss -58.24776454859688, train mean loss 0.00463325234677598, test mean loss [0.00257098 0.00502981 0.0053163  0.00348101 0.00442024 0.00708242
 0.00742028]
Model epoch 3: train total loss -59.21545288580153, train mean loss 0.004412536101376435, test mean loss [0.00197851 0.0037526  0.00428718 0.00256101 0.00333167 0.00587935
 0.0056105 ]
Model epoch 4: train total loss -60.56604973440778, train mean loss 0.0036007193222003346, test mean loss [0.00160489 0.00302061 0.00357045 0.00208316 0.00268583 0.00492334
 0.00434728]
Model epoch 5: train total loss -61.35708550104901, train mean loss 0.0030959663971051477, test mean loss [0.00143072 0.00243571 0.00301639 0.00173569 0.00231181 0.00419373
 0.00356749]
Model epoch 6: train total loss -61.78841718886826, train mean loss 0.0023946330780059014, test mean loss [0.00123069 0.002028   0.00258842 0.0015111  0.00197863 0.00360027
 0.00299355]
Model epoch 7: train total loss -62.04390924592932, train mean loss 0.00246318746895885, test mean loss [0.00105604 0.00167817 0.0022089  0.00136536 0.00173619 0.00313926
 0.00268326]
Model epoch 8: train total loss -62.23872468920436, train mean loss 0.001974432027900744, test mean loss [0.00098776 0.00145642 0.00184926 0.00119246 0.00153771 0.00276213
 0.00232413]
Model epoch 9: train total loss -62.744131109034775, train mean loss 0.0019478053808871145, test mean loss [0.00089703 0.00123465 0.0015929  0.00107094 0.00138968 0.00236796
 0.00211656]
Model epoch 10: train total loss -62.68462360387725, train mean loss 0.0017979037095877497, test mean loss [0.00083771 0.00111274 0.00139948 0.00094734 0.00128003 0.00207579
 0.00183685]
Model epoch 11: train total loss -62.71954266513329, train mean loss 0.0016234355009654227, test mean loss [0.0007916  0.00099651 0.00124142 0.00091093 0.00117739 0.00192113
 0.00167917]
Model epoch 12: train total loss -63.36293316868268, train mean loss 0.0010266433162995701, test mean loss [0.00075715 0.00087817 0.0010646  0.00076717 0.00104817 0.00177515
 0.00148427]
Model epoch 13: train total loss -63.38378769063943, train mean loss 0.0009861411891823185, test mean loss [0.00074243 0.00081242 0.0009633  0.00073134 0.00102332 0.00162665
 0.00131061]
Model epoch 14: train total loss -63.36306187110341, train mean loss 0.0010745131984544372, test mean loss [0.00067693 0.00080521 0.00087921 0.00067885 0.0009417  0.00151219
 0.00125473]
Model epoch 15: train total loss -62.96969867388538, train mean loss 0.0011244728369995327, test mean loss [0.00067457 0.00076474 0.00079356 0.00062664 0.00088058 0.00141669
 0.00112624]
Model epoch 16: train total loss -63.18665272496014, train mean loss 0.0009397676991769147, test mean loss [0.00063215 0.00069198 0.00074156 0.00058831 0.00084416 0.00134072
 0.00105847]
Model epoch 17: train total loss -63.29098891979161, train mean loss 0.0012694570321819239, test mean loss [0.00060749 0.00065736 0.00073618 0.0005957  0.00079839 0.00122985
 0.00098182]
Model epoch 18: train total loss -63.631427477944165, train mean loss 0.000904077685052187, test mean loss [0.00058969 0.00063089 0.00068637 0.00056293 0.00076485 0.00130777
 0.00091969]
Model epoch 19: train total loss -63.7912525536934, train mean loss 0.0009074640806488776, test mean loss [0.00056535 0.0006     0.00066726 0.00055211 0.00075097 0.00116365
 0.00085297]
Model epoch 20: train total loss -63.577863609454795, train mean loss 0.0009181625799395184, test mean loss [0.00056173 0.00059016 0.00065695 0.00051734 0.00072175 0.00108658
 0.00082836]
Model epoch 21: train total loss -63.9691230306826, train mean loss 0.0007710676813838613, test mean loss [0.0005566  0.00054724 0.00060956 0.00050822 0.00067932 0.00103627
 0.00079549]
Model epoch 22: train total loss -63.84798276697761, train mean loss 0.0008057208376683906, test mean loss [0.00053622 0.00053715 0.00058996 0.00050263 0.00065541 0.0010084
 0.00074233]
Model epoch 23: train total loss -63.649427876297636, train mean loss 0.0008718831239063305, test mean loss [0.00053769 0.0005493  0.00058945 0.00049555 0.00064127 0.0009626
 0.00071865]
Model epoch 24: train total loss -63.699825897645624, train mean loss 0.0008063498688963436, test mean loss [0.00052241 0.00049692 0.00055953 0.00048644 0.00061799 0.00094014
 0.00069201]
Model epoch 25: train total loss -63.93185707262035, train mean loss 0.000651475436940999, test mean loss [0.00050161 0.00048311 0.00053831 0.00047981 0.00058105 0.00087927
 0.00067955]
Model epoch 26: train total loss -63.8468375785874, train mean loss 0.0004786305216278303, test mean loss [0.00049237 0.00048947 0.0005339  0.00046003 0.00055808 0.00084583
 0.00066161]
Error executing job with overrides: ['wandb.entity=an-tsaritsin-itmo-university', 'wandb.log_ssrl=true', 'render_epoch_interval=10']
Traceback (most recent call last):
  File "/home/ant/ssrl/ssrl/scripts/go1_train.py", line 199, in train_go1
    state = train_fn(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 263, in train
    env_state) = sim_training_epoch_with_timing(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 947, in sim_training_epoch_with_timing
    training_state, model_metrics = train_model(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 661, in train_model
    test_total_loss, test_mean_loss) = model_training_epoch(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 745, in model_training_epoch
    test_total_losses, test_mean_losses) = model_training_epoch_jit(
ValueError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2097194232 bytes.
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.