run_name: null
sweep_name: null
env: Go1GoFast
algo: ssrl
gpus: '0'
num_seeds: 1
ssrl_dynamics_fn: contact_integrate_only
render_during_training: true
render_epoch_interval: 10
render_seed: 0
common:
  action_repeat: 1
  obs_history_length: 5
  normalize_observations: false
  forces_in_q_coords: true
actor_network:
  hidden_layers: 2
  hidden_size: 512
  activation: swish
  max_std: null
critic_network:
  hidden_layers: 5
  hidden_size: 256
env_common:
  policy_repeat: 4
  forward_vel_rew_weight: 2.0
  turn_rew_weight: 0.5
  pitch_rew_weight: 0.25
  roll_rew_weight: 0.25
  yaw_rew_weight: 0.5
  side_motion_rew_weight: 0.5
  z_vel_change_rew_weight: 0.15
  ang_vel_rew_weight: 0.0
  ang_change_rew_weight: 0.25
  joint_lim_rew_weight: 0.0
  torque_lim_rew_weight: 0.0
  joint_acc_rew_weight: 0.0
  action_rew_weight: 0.0
  cosmetic_rew_weight: 0.0
  energy_rew_weight: 0.25
  foot_z_rew_weight: 0.0
  torque_lim_penalty_weight: 0.1
  fallen_roll: 0.785
  fallen_pitch: 0.785
  include_height_in_obs: false
  gains_in_action_space: false
  reward_type: normalized
env_sac:
  policy_repeat: ${env_common.policy_repeat}
  forward_cmd_vel_type: constant
  forward_cmd_vel_range: 0.0
  forward_cmd_vel_period_range:
  - 40.0
  - 40.0
  turn_cmd_rate_range:
  - -0.0
  - 0.0
  initial_yaw_range:
  - -0.0
  - 0.0
  contact_time_const: 0.02
  contact_damping_ratio: 1.0
  friction_range:
  - 0.6
  - 0.6
  ground_roll_range:
  - 0.0
  - 0.0
  ground_pitch_range:
  - 0.0
  - 0.0
  joint_damping_perc_range:
  - 1.0
  - 1.0
  joint_gain_range:
  - 1.0
  - 1.0
  link_mass_perc_range:
  - 1.0
  - 1.0
  forward_vel_rew_weight: ${env_common.forward_vel_rew_weight}
  turn_rew_weight: ${env_common.turn_rew_weight}
  pitch_rew_weight: ${env_common.pitch_rew_weight}
  roll_rew_weight: ${env_common.roll_rew_weight}
  yaw_rew_weight: ${env_common.yaw_rew_weight}
  side_motion_rew_weight: ${env_common.side_motion_rew_weight}
  z_vel_change_rew_weight: ${env_common.z_vel_change_rew_weight}
  ang_vel_rew_weight: ${env_common.ang_vel_rew_weight}
  ang_change_rew_weight: ${env_common.ang_change_rew_weight}
  joint_lim_rew_weight: ${env_common.joint_lim_rew_weight}
  torque_lim_rew_weight: ${env_common.torque_lim_rew_weight}
  joint_acc_rew_weight: ${env_common.joint_acc_rew_weight}
  action_rew_weight: ${env_common.action_rew_weight}
  cosmetic_rew_weight: ${env_common.cosmetic_rew_weight}
  energy_rew_weight: ${env_common.energy_rew_weight}
  foot_z_rew_weight: ${env_common.foot_z_rew_weight}
  torque_lim_penalty_weight: ${env_common.torque_lim_penalty_weight}
  fallen_roll: ${env_common.fallen_roll}
  fallen_pitch: ${env_common.fallen_pitch}
  forces_in_q_coords: ${common.forces_in_q_coords}
  include_height_in_obs: ${env_common.include_height_in_obs}
  gains_in_action_space: ${env_common.gains_in_action_space}
  reward_type: ${env_common.reward_type}
sac:
  num_timesteps: 10000000
  episode_length: 1000
  action_repeat: ${common.action_repeat}
  obs_history_length: ${common.obs_history_length}
  num_envs: 1
  num_eval_envs: 500
  learning_rate: 0.0001
  discounting: 0.99
  seed: 0
  batch_size: 200
  num_evals: 10
  normalize_observations: ${common.normalize_observations}
  reward_scaling: 1
  tau: 0.001
  min_replay_size: 10000
  max_replay_size: 200000
  grad_updates_per_step: 20
  deterministic_eval: true
env_ssrl:
  policy_repeat: ${env_common.policy_repeat}
  forward_cmd_vel_type: constant
  forward_cmd_vel_range: 0.0
  forward_cmd_vel_period_range:
  - 40.0
  - 40.0
  turn_cmd_rate_range:
  - -0.0
  - 0.0
  initial_yaw_range:
  - -0.0
  - 0.0
  contact_time_const: 0.02
  contact_damping_ratio: 1.0
  friction_range:
  - 0.6
  - 0.6
  ground_roll_range:
  - 0.0
  - 0.0
  ground_pitch_range:
  - 0.0
  - 0.0
  joint_damping_perc_range:
  - 1.0
  - 1.0
  joint_gain_range:
  - 1.0
  - 1.0
  link_mass_perc_range:
  - 1.0
  - 1.0
  forward_vel_rew_weight: ${env_common.forward_vel_rew_weight}
  turn_rew_weight: ${env_common.turn_rew_weight}
  pitch_rew_weight: ${env_common.pitch_rew_weight}
  roll_rew_weight: ${env_common.roll_rew_weight}
  yaw_rew_weight: ${env_common.yaw_rew_weight}
  side_motion_rew_weight: ${env_common.side_motion_rew_weight}
  z_vel_change_rew_weight: ${env_common.z_vel_change_rew_weight}
  ang_vel_rew_weight: ${env_common.ang_vel_rew_weight}
  ang_change_rew_weight: ${env_common.ang_change_rew_weight}
  joint_lim_rew_weight: ${env_common.joint_lim_rew_weight}
  torque_lim_rew_weight: ${env_common.torque_lim_rew_weight}
  joint_acc_rew_weight: ${env_common.joint_acc_rew_weight}
  action_rew_weight: ${env_common.action_rew_weight}
  cosmetic_rew_weight: ${env_common.cosmetic_rew_weight}
  energy_rew_weight: ${env_common.energy_rew_weight}
  foot_z_rew_weight: ${env_common.foot_z_rew_weight}
  torque_lim_penalty_weight: ${env_common.torque_lim_penalty_weight}
  fallen_roll: ${env_common.fallen_roll}
  fallen_pitch: ${env_common.fallen_pitch}
  forces_in_q_coords: ${common.forces_in_q_coords}
  include_height_in_obs: ${env_common.include_height_in_obs}
  body_height_in_action_space: true
  gains_in_action_space: ${env_common.gains_in_action_space}
  reward_type: ${env_common.reward_type}
  healthy_delta_radius: 2.0
  healthy_delta_yaw: 1.57
ssrl_start_with_sac: false
ssrl:
  episode_length: 1000
  policy_repeat: 1
  num_epochs: 40
  model_trains_per_epoch: 1
  training_steps_per_model_train: 1
  env_steps_per_training_step: 1000
  model_rollouts_per_hallucination_update: 400
  sac_grad_updates_per_hallucination_update: 60
  init_exploration_steps: 1000
  clear_model_buffer_after_model_train: false
  action_repeat: ${common.action_repeat}
  obs_history_length: ${common.obs_history_length}
  num_envs: 1
  num_evals: 41
  num_eval_envs: 1
  policy_normalize_observations: ${common.normalize_observations}
  model_learning_rate: 0.001
  model_training_batch_size: 200
  model_training_max_sgd_steps_per_epoch: null
  model_training_max_epochs: 1000
  model_training_convergence_criteria: 0.01
  model_training_consec_converged_epochs: 6
  model_training_abs_criteria: null
  model_training_test_ratio: 0.2
  model_training_weight_decay: true
  model_training_stop_gradient: false
  model_loss_horizon: 4
  model_check_done_condition: true
  max_env_buffer_size: 15000
  max_model_buffer_size: 400000
  sac_learning_rate: 0.0002
  sac_discounting: 0.99
  sac_batch_size: 256
  real_ratio: 0.06
  sac_reward_scaling: 1.0
  sac_tau: 0.001
  sac_fixed_alpha: None
  seed: 2
  deterministic_in_env: true
  deterministic_eval: true
  hallucination_max_std: -1.0
  zero_final_layer_of_policy: false
ssrl_model:
  hidden_size: 400
  ensemble_size: 7
  num_elites: 5
  probabilistic: true
ssrl_linear_threshold_fn:
  start_epoch: 0
  end_epoch: 10
  start_model_horizon: 1
  end_model_horizon: 20
ssrl_hupts_fn:
  start_epoch: 0
  end_epoch: 4
  start_hupts: 10
  end_hupts: 1000
render:
  policy: ssrl
wandb:
  entity: an-tsaritsin-itmo-university
  log_sac: false
  log_ssrl: true
save_policy:
  sac: false
  sac_all: false
  ssrl: true
  ssrl_all: true
torque_validate:
  hardware_data: true
Running on GPU 0
[2025-01-24 02:07:05,279][root][INFO] - Converting mesh (2720492074706923416, 311694823105776305) into convex hull.
[2025-01-24 02:07:10,434][root][INFO] - Converting mesh (-8798617497265737032, -2428524042856965737) into convex hull.
[2025-01-24 02:07:13,118][root][INFO] - Converting mesh (5756975082938897352, 4073268312731887624) into convex hull.
[2025-01-24 02:07:17,730][root][INFO] - Converting mesh (-2260537939347463495, 3936176219489199877) into convex hull.
[2025-01-24 02:07:21,587][root][INFO] - Converting mesh (-84152602086071243, 7832556248418955142) into convex hull.
[2025-01-24 02:08:12,008][absl][INFO] - {'eval/walltime': 42.21608757972717, 'eval/episode_forward_vel': Array(-108.60923714, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-0.10797279, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(52.49267436, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.4366862, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-46.71365038, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(53.27323164, dtype=float64), 'eval/episode_rew_roll': Array(52.95435189, dtype=float64), 'eval/episode_rew_side_motion': Array(60.45251734, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(65.55468316, dtype=float64), 'eval/episode_rew_yaw': Array(6.67671905, dtype=float64), 'eval/episode_rew_z_vel_change': Array(26.43004902, dtype=float64), 'eval/episode_reward': Array(271.56760586, dtype=float64), 'eval/episode_step_count': Array(499500., dtype=float64), 'eval/avg_episode_length': Array(1000., dtype=float64), 'eval/epoch_eval_time': 42.21608757972717, 'eval/sps': 23.68765220394833}
Steps / Eval:  0
Reward is  271.56760586399474
Total reward is  273.4330967352106
[2025-01-24 02:10:25,942][absl][INFO] - env buffer size after init exploration 1000
Model epoch 0: train total loss -2.434156810841157, train mean loss 0.08013446479477382, test mean loss [0.09025636 0.09028357 0.09026907 0.09023168 0.09027065 0.0902684
 0.09024942]
Model epoch 1: train total loss -3.5150311426757836, train mean loss 0.07819110916251995, test mean loss [0.08775434 0.08852553 0.0877817  0.08724078 0.08810119 0.087923
 0.08735046]
Model epoch 2: train total loss -10.379474502784122, train mean loss 0.0714346425866256, test mean loss [0.08049413 0.07945981 0.07791929 0.07880503 0.07950901 0.07953743
 0.07874728]
Model epoch 3: train total loss -23.282542971094212, train mean loss 0.07123693341207497, test mean loss [0.07995232 0.07827973 0.07784226 0.08096788 0.07649793 0.07796062
 0.08177638]
Model epoch 4: train total loss -32.10820764024794, train mean loss 0.07025129207345322, test mean loss [0.07702917 0.07853281 0.07750399 0.08040131 0.07807521 0.07696585
 0.08052214]
Model epoch 5: train total loss -34.79094854878272, train mean loss 0.07070840864715935, test mean loss [0.07772028 0.07829526 0.07756141 0.0782955  0.07749919 0.07783644
 0.07839121]
Model epoch 6: train total loss -35.57739259031619, train mean loss 0.0688607808161754, test mean loss [0.07673132 0.07746699 0.0754902  0.07699344 0.0754649  0.07626858
 0.07760613]
Model epoch 7: train total loss -36.62733542783069, train mean loss 0.06806294759155666, test mean loss [0.07502316 0.07600756 0.07389292 0.07572393 0.07541439 0.07559082
 0.07741188]
Model epoch 8: train total loss -37.521571874688476, train mean loss 0.06604260923403708, test mean loss [0.07344443 0.07509412 0.07328681 0.07460208 0.07602714 0.07431597
 0.0764568 ]
Model epoch 9: train total loss -38.0608820623224, train mean loss 0.06509918651065204, test mean loss [0.07273812 0.07364116 0.0734252  0.07465221 0.07557293 0.07213162
 0.07584729]
Model epoch 10: train total loss -38.48413822192768, train mean loss 0.06405149427223517, test mean loss [0.07158652 0.07113218 0.07023436 0.07515903 0.07211988 0.06805279
 0.07451183]
Model epoch 11: train total loss -39.07724608226563, train mean loss 0.062032102769549825, test mean loss [0.06786678 0.06769928 0.06664617 0.07507184 0.06866019 0.06376542
 0.07378898]
Model epoch 12: train total loss -39.55969133165739, train mean loss 0.060055406220115355, test mean loss [0.06407749 0.0645531  0.06313401 0.07377016 0.06515745 0.05976554
 0.07231182]
Model epoch 13: train total loss -40.190655103836775, train mean loss 0.057974682697409796, test mean loss [0.06149585 0.06021267 0.05812919 0.07105875 0.06075244 0.05478737
 0.07058201]
Model epoch 14: train total loss -40.98298583869289, train mean loss 0.05298235074422806, test mean loss [0.05939334 0.05600568 0.05329125 0.06751752 0.05658727 0.05098819
 0.06905312]
Model epoch 15: train total loss -41.75121682201803, train mean loss 0.05103428028211338, test mean loss [0.05764233 0.05170984 0.04883544 0.06350427 0.05406649 0.0474445
 0.06751067]
Model epoch 16: train total loss -42.42759571340038, train mean loss 0.048714983646049446, test mean loss [0.05654681 0.04882071 0.04558414 0.05972833 0.04859357 0.04241795
 0.0651738 ]
Model epoch 17: train total loss -43.111009460582856, train mean loss 0.04547305543074594, test mean loss [0.05301723 0.04628614 0.04103756 0.05748313 0.04705754 0.03928715
 0.06145281]
Model epoch 18: train total loss -43.71345709224554, train mean loss 0.043361231177519034, test mean loss [0.04827436 0.0445713  0.03956573 0.0539958  0.04454659 0.03883488
 0.0571624 ]
Model epoch 19: train total loss -44.12761876896814, train mean loss 0.04111256627458985, test mean loss [0.04497896 0.0433648  0.03794082 0.05122684 0.04395769 0.03594572
 0.05294845]
Model epoch 20: train total loss -44.71615883171454, train mean loss 0.03914683824255355, test mean loss [0.04290178 0.04252501 0.03563676 0.04806559 0.04190875 0.03616376
 0.04927788]
Model epoch 21: train total loss -45.11772423230786, train mean loss 0.037621170351569026, test mean loss [0.04081478 0.04101317 0.03464748 0.04602061 0.03911961 0.03430109
 0.04643186]
Model epoch 22: train total loss -45.58435461579876, train mean loss 0.0361163524883841, test mean loss [0.0387009  0.03895863 0.03353442 0.04382939 0.03769219 0.03326474
 0.04350489]
Model epoch 23: train total loss -45.97651049423597, train mean loss 0.03395157469207502, test mean loss [0.03712331 0.03652913 0.03387121 0.04265308 0.0355092  0.03222751
 0.04126812]
Model epoch 24: train total loss -46.22103613305997, train mean loss 0.03345078120546138, test mean loss [0.035945   0.03483754 0.03300828 0.04116917 0.03541501 0.03096627
 0.03894295]
Model epoch 25: train total loss -46.626117275844294, train mean loss 0.03271018244394263, test mean loss [0.034517   0.03318239 0.03125303 0.04004582 0.0346968  0.03082682
 0.03710937]
Model epoch 26: train total loss -46.95326931970548, train mean loss 0.031532621725742824, test mean loss [0.03456606 0.03194169 0.03094495 0.03928226 0.0331336  0.03002144
 0.03548781]
Model epoch 27: train total loss -47.30585629575349, train mean loss 0.030720286373311406, test mean loss [0.03280435 0.03125357 0.03008887 0.03814693 0.03233386 0.02903102
 0.03382674]
Model epoch 28: train total loss -47.598181703738426, train mean loss 0.02995977557943653, test mean loss [0.03207303 0.03104112 0.0293272  0.03665328 0.0312935  0.02870712
 0.03298516]
Model epoch 29: train total loss -47.82754033298481, train mean loss 0.02938166259784084, test mean loss [0.03053464 0.03019241 0.03046431 0.03603481 0.03019197 0.02728237
 0.0327862 ]
Model epoch 30: train total loss -48.161807788519035, train mean loss 0.028509914683840957, test mean loss [0.03004611 0.02891347 0.02921402 0.03455711 0.02996492 0.02651362
 0.03120053]
Model epoch 31: train total loss -48.23918134040154, train mean loss 0.028105670584956798, test mean loss [0.03001919 0.02812174 0.02895126 0.03394484 0.02903847 0.02653618
 0.03049024]
Model epoch 32: train total loss -48.670682788114384, train mean loss 0.027547922468585, test mean loss [0.02961635 0.02730638 0.02809787 0.03314975 0.02852039 0.02568354
 0.0293337 ]
Model epoch 33: train total loss -48.44188372484636, train mean loss 0.02680494021888456, test mean loss [0.02855767 0.02711346 0.02777738 0.03274221 0.02866433 0.02528312
 0.02816129]
Model epoch 34: train total loss -48.953303487916806, train mean loss 0.026418665994681075, test mean loss [0.02816846 0.02649808 0.02694697 0.03457946 0.02736088 0.02463899
 0.02755194]
Model epoch 35: train total loss -49.1504830065911, train mean loss 0.02645698880521916, test mean loss [0.02788052 0.02600891 0.02622916 0.03359879 0.02674558 0.02374456
 0.02781153]
Model epoch 36: train total loss -49.57585941510252, train mean loss 0.025078557994785734, test mean loss [0.02689137 0.02597802 0.02564645 0.03216351 0.02661043 0.02324768
 0.02712795]
Model epoch 37: train total loss -49.92055217778848, train mean loss 0.024799049363460352, test mean loss [0.02599361 0.02559174 0.02541096 0.03145006 0.02609047 0.02262523
 0.0261386 ]
Model epoch 38: train total loss -50.09289426486854, train mean loss 0.024455140921272444, test mean loss [0.02522716 0.02476971 0.02458128 0.03112024 0.02503121 0.02250065
 0.02557049]
Model epoch 39: train total loss -50.39552564527135, train mean loss 0.0236294806608942, test mean loss [0.02456283 0.02456313 0.02485111 0.03060506 0.02459802 0.02205296
 0.02507856]
Model epoch 40: train total loss -50.68060718494499, train mean loss 0.02323136523500193, test mean loss [0.02433966 0.02427167 0.02386343 0.02964884 0.02398847 0.02196716
 0.02412425]
Model epoch 41: train total loss -50.875896905760676, train mean loss 0.022752221444903284, test mean loss [0.02383017 0.02399949 0.02354548 0.02885413 0.02403319 0.02185952
 0.02372881]
Model epoch 42: train total loss -50.962294330020036, train mean loss 0.022629079626775055, test mean loss [0.02350007 0.02367638 0.02314025 0.02848858 0.02414202 0.02139792
 0.02349015]
Model epoch 43: train total loss -51.21338686712968, train mean loss 0.0225515503291729, test mean loss [0.02329035 0.02326871 0.02287187 0.02748889 0.02346821 0.02126379
 0.02322117]
Model epoch 44: train total loss -51.44557330799169, train mean loss 0.02174297774109511, test mean loss [0.02279838 0.02316824 0.0224014  0.02722952 0.02317943 0.0207144
 0.02212903]
Model epoch 45: train total loss -51.71549935917162, train mean loss 0.02151476398482473, test mean loss [0.02254644 0.02289402 0.02226481 0.02659201 0.02305146 0.02052979
 0.02187436]
Model epoch 46: train total loss -51.49510603717918, train mean loss 0.021822980412626772, test mean loss [0.02214955 0.02276785 0.02246937 0.02622152 0.02309529 0.02024641
 0.02097545]
Model epoch 47: train total loss -51.82791677925951, train mean loss 0.02097221512884388, test mean loss [0.02250353 0.02230802 0.02170248 0.02552794 0.02291679 0.02020149
 0.02070717]
Model epoch 48: train total loss -51.860375939875006, train mean loss 0.020727749298016563, test mean loss [0.02213503 0.02198373 0.02185141 0.02499368 0.02260956 0.02002321
 0.02013229]
Model epoch 49: train total loss -52.05715218770515, train mean loss 0.020370367346465777, test mean loss [0.02174663 0.02164421 0.0216077  0.02497341 0.02200755 0.01950907
 0.01987076]
Model epoch 50: train total loss -52.29407977756488, train mean loss 0.02057411869318275, test mean loss [0.02152624 0.0212     0.02157642 0.02498309 0.02175488 0.01949805
 0.0195843 ]
Model epoch 51: train total loss -52.17136906510892, train mean loss 0.020133421873921063, test mean loss [0.0214691  0.02082741 0.02121459 0.02448274 0.02136666 0.01936748
 0.01963581]
Model epoch 52: train total loss -52.58848381615892, train mean loss 0.019505960904856356, test mean loss [0.0210726  0.02078524 0.02125968 0.02392818 0.02114549 0.01899869
 0.0193652 ]
Model epoch 53: train total loss -52.70771579875939, train mean loss 0.019526151248463217, test mean loss [0.02076995 0.02016746 0.02070317 0.0238148  0.02058548 0.01853734
 0.01911599]
Model epoch 54: train total loss -52.84938562065815, train mean loss 0.019274429104232448, test mean loss [0.02041986 0.0201149  0.02069902 0.02328102 0.02013585 0.01829003
 0.0190764 ]
Model epoch 55: train total loss -52.876724099175334, train mean loss 0.01924998836145237, test mean loss [0.0196824  0.01981092 0.02009732 0.02297143 0.02015844 0.01807353
 0.01834687]
Model epoch 56: train total loss -53.096640508873016, train mean loss 0.0191131117520989, test mean loss [0.01944643 0.01945558 0.0200739  0.02283266 0.02024755 0.01787822
 0.01815838]
Model epoch 57: train total loss -53.36074551949902, train mean loss 0.01863204131240327, test mean loss [0.01893393 0.01927653 0.01990929 0.02243807 0.01971892 0.01748958
 0.01794663]
Model epoch 58: train total loss -53.25179890955862, train mean loss 0.018641116232641863, test mean loss [0.01900512 0.01825443 0.01969206 0.02245824 0.01979132 0.01717223
 0.01759143]
Model epoch 59: train total loss -53.33061103515823, train mean loss 0.018279425788244586, test mean loss [0.01924599 0.01844971 0.01929132 0.02195702 0.01917636 0.01724532
 0.01721293]
Model epoch 60: train total loss -53.43589852169824, train mean loss 0.018150554524066, test mean loss [0.01857764 0.01796215 0.01924732 0.02213814 0.0194069  0.01704013
 0.01754106]
Model epoch 61: train total loss -53.523013337718304, train mean loss 0.01802947675175129, test mean loss [0.01868843 0.01796486 0.01911916 0.02183486 0.0191553  0.01698758
 0.01689756]
Model epoch 62: train total loss -53.64939550236787, train mean loss 0.017730686750821914, test mean loss [0.01836821 0.01800064 0.01918139 0.02126136 0.0187676  0.01651601
 0.01692679]
Model epoch 63: train total loss -53.869057858284236, train mean loss 0.017062244128367668, test mean loss [0.01804847 0.0176331  0.01857933 0.02099663 0.01799825 0.01614413
 0.0167844 ]
Model epoch 64: train total loss -53.821298410094236, train mean loss 0.017084711410960098, test mean loss [0.0179079  0.01703634 0.01841267 0.02080426 0.01840513 0.01575175
 0.01608637]
Model epoch 65: train total loss -53.95953262717798, train mean loss 0.016652001881455103, test mean loss [0.01752508 0.01727349 0.01812622 0.02065187 0.01793606 0.0154909
 0.01587196]
Model epoch 66: train total loss -54.1591281258169, train mean loss 0.016552665962629085, test mean loss [0.01723092 0.01669926 0.01824248 0.02049535 0.01787418 0.01498389
 0.01558641]
Model epoch 67: train total loss -54.11279349026687, train mean loss 0.016698804660622086, test mean loss [0.01682059 0.01653786 0.01814635 0.01997477 0.01758565 0.01487987
 0.01580024]
Model epoch 68: train total loss -54.15448198858926, train mean loss 0.015839614784274144, test mean loss [0.01706517 0.01593598 0.01807593 0.01979694 0.01742475 0.01457611
 0.01552926]
Model epoch 69: train total loss -54.22696638451465, train mean loss 0.01617809629102443, test mean loss [0.01707819 0.0157148  0.01739981 0.01959575 0.01737095 0.01449121
 0.01534624]
Model epoch 70: train total loss -54.44108550841213, train mean loss 0.015616121036798344, test mean loss [0.01674043 0.01552499 0.01747496 0.01966584 0.01691813 0.01409181
 0.01490015]
Model epoch 71: train total loss -54.5234919273571, train mean loss 0.015273295495984817, test mean loss [0.0161532  0.01537389 0.01729815 0.01952146 0.01691291 0.01396511
 0.0148409 ]
Model epoch 72: train total loss -54.43792561005725, train mean loss 0.015840803775643977, test mean loss [0.01588968 0.01523861 0.0171877  0.01936921 0.01650596 0.0138213
 0.01435858]
Model epoch 73: train total loss -54.7927378347767, train mean loss 0.01535670480399034, test mean loss [0.01589991 0.01499827 0.01687602 0.01895227 0.01632509 0.01348731
 0.01409134]
Model epoch 74: train total loss -54.973604236106176, train mean loss 0.014932453215434684, test mean loss [0.01578424 0.0145495  0.01656996 0.01876183 0.0160022  0.01322178
 0.01385253]
Model epoch 75: train total loss -54.93816996812063, train mean loss 0.015289673783423812, test mean loss [0.01509993 0.01447883 0.01654688 0.01876397 0.01574252 0.01304031
 0.0136815 ]
Model epoch 76: train total loss -54.926686652820266, train mean loss 0.014861837756111856, test mean loss [0.01495921 0.0140134  0.01667546 0.01861475 0.01595933 0.01271152
 0.01355855]
Model epoch 77: train total loss -55.13337166982008, train mean loss 0.014285806706644876, test mean loss [0.01469466 0.01431889 0.01618443 0.01836159 0.01566981 0.0119351
 0.01338771]
Model epoch 78: train total loss -55.294240418908615, train mean loss 0.014493671757044876, test mean loss [0.01479023 0.01378928 0.01609011 0.01809594 0.01546353 0.01187166
 0.01316568]
Model epoch 79: train total loss -55.337165460199465, train mean loss 0.01412911911822637, test mean loss [0.0145344  0.01375927 0.01587678 0.01782289 0.01517574 0.01201785
 0.01246981]
Model epoch 80: train total loss -55.35297823773812, train mean loss 0.014066446677722399, test mean loss [0.0143989  0.01364095 0.01548901 0.01746392 0.01520985 0.01184039
 0.01261637]
Model epoch 81: train total loss -55.55246057719864, train mean loss 0.013915570207282778, test mean loss [0.01411583 0.01332766 0.01517315 0.01748688 0.01490332 0.01149227
 0.01243228]
Model epoch 82: train total loss -55.754980884340796, train mean loss 0.013323442464042538, test mean loss [0.01363101 0.01285076 0.01503652 0.01725143 0.01493704 0.01131388
 0.01218519]
Model epoch 83: train total loss -55.67561874791027, train mean loss 0.013299457643310371, test mean loss [0.01353681 0.0127434  0.01498889 0.01674173 0.01452484 0.01130454
 0.01206983]
Model epoch 84: train total loss -55.66248634774698, train mean loss 0.013113953726433225, test mean loss [0.01346204 0.01266881 0.01447903 0.01694519 0.0142506  0.01100416
 0.01169657]
Model epoch 85: train total loss -55.8475381940984, train mean loss 0.012851879475007046, test mean loss [0.01350465 0.01254506 0.01481376 0.01704021 0.01399517 0.01062111
 0.01131329]
Model epoch 86: train total loss -55.939939300162585, train mean loss 0.012842839576263995, test mean loss [0.01320429 0.01242369 0.014709   0.01624503 0.01392857 0.01063335
 0.01123008]
Model epoch 87: train total loss -56.03327515504387, train mean loss 0.012578884956193847, test mean loss [0.01307537 0.01215833 0.01432895 0.01622227 0.01394494 0.01063454
 0.0110641 ]
Model epoch 88: train total loss -56.15782363928443, train mean loss 0.012554810250456943, test mean loss [0.01273331 0.01205683 0.01414184 0.01640001 0.0134836  0.00984137
 0.0106133 ]
Model epoch 89: train total loss -56.33462448072483, train mean loss 0.012293695980592653, test mean loss [0.01272111 0.01167968 0.01395081 0.01610201 0.01315922 0.00963167
 0.01024509]
Model epoch 90: train total loss -56.39427528135526, train mean loss 0.011755204057771683, test mean loss [0.01245497 0.01134451 0.01384696 0.01573607 0.0132782  0.00962646
 0.01025916]
Model epoch 91: train total loss -56.4418132279796, train mean loss 0.011816676889405556, test mean loss [0.01235062 0.01139884 0.01352209 0.01575352 0.01300624 0.00945864
 0.00995108]
Model epoch 92: train total loss -56.35649566773841, train mean loss 0.011764450190836585, test mean loss [0.01224213 0.01126589 0.01354691 0.01542559 0.01289943 0.00949485
 0.00983591]
Model epoch 93: train total loss -56.4528023311013, train mean loss 0.011679407017600178, test mean loss [0.01190516 0.01080913 0.01314217 0.01505089 0.01249952 0.0091936
 0.00996262]
Model epoch 94: train total loss -56.52700574621338, train mean loss 0.011550061139724526, test mean loss [0.01166942 0.01059281 0.01325003 0.01486487 0.01259166 0.0089554
 0.00937237]
Model epoch 95: train total loss -56.541333685908135, train mean loss 0.011267900716093423, test mean loss [0.01171397 0.01033896 0.01280026 0.01518386 0.01230717 0.00888612
 0.00949178]
Model epoch 96: train total loss -56.53532114217417, train mean loss 0.011072658020205956, test mean loss [0.01124114 0.01062549 0.01263704 0.01519894 0.01214235 0.00862606
 0.0093806 ]
Model epoch 97: train total loss -56.69948332795847, train mean loss 0.01094822870247531, test mean loss [0.011203   0.01011685 0.01315938 0.01477611 0.01201359 0.00840549
 0.00918021]
Model epoch 98: train total loss -56.71220518390224, train mean loss 0.010556640068760996, test mean loss [0.01090145 0.01026945 0.01236074 0.01466395 0.01199046 0.00814142
 0.00927486]
Model epoch 99: train total loss -56.81334268719267, train mean loss 0.010718273228139154, test mean loss [0.01101385 0.00984062 0.01246967 0.01467936 0.01211964 0.00829266
 0.00897208]
Model epoch 100: train total loss -56.816726995453095, train mean loss 0.010624144024666887, test mean loss [0.01051798 0.00954941 0.01225965 0.01434413 0.01160856 0.00809569
 0.00858599]
Model epoch 101: train total loss -56.88798149667841, train mean loss 0.010609587702320471, test mean loss [0.01078642 0.00930213 0.01193137 0.01407046 0.01182285 0.00808516
 0.0083284 ]
Model epoch 102: train total loss -56.9472896642994, train mean loss 0.010280732435912333, test mean loss [0.01034583 0.00918938 0.01205471 0.01400535 0.01142506 0.00780406
 0.00837636]
Model epoch 103: train total loss -57.16755588784194, train mean loss 0.009800580813195315, test mean loss [0.01015063 0.00896835 0.01165515 0.01365359 0.01138051 0.00754735
 0.00838764]
Model epoch 104: train total loss -57.08843271510701, train mean loss 0.009681168098256707, test mean loss [0.01021633 0.00880787 0.01140354 0.01376261 0.01097543 0.00774302
 0.00794986]
Model epoch 105: train total loss -57.18646227577067, train mean loss 0.009936271542759252, test mean loss [0.01010497 0.00905957 0.01147523 0.01338355 0.01101747 0.00736109
 0.00797754]
Model epoch 106: train total loss -57.236611146677475, train mean loss 0.009580940424175623, test mean loss [0.00992068 0.00890044 0.01146988 0.01343955 0.01076308 0.00705312
 0.00772181]
Model epoch 107: train total loss -57.444445739738356, train mean loss 0.00950903306118285, test mean loss [0.00990074 0.00841509 0.01134336 0.01310895 0.01106359 0.00716229
 0.00731512]
Model epoch 108: train total loss -57.52933642914738, train mean loss 0.009172537113263825, test mean loss [0.00970044 0.00886529 0.0110427  0.01278564 0.01042446 0.00693323
 0.00711974]
Model epoch 109: train total loss -57.46945104978295, train mean loss 0.009265418680567026, test mean loss [0.00958466 0.00890244 0.01086171 0.0124542  0.01023893 0.00689485
 0.00718347]
Model epoch 110: train total loss -57.51527240604786, train mean loss 0.009076653659506743, test mean loss [0.00942589 0.00823158 0.01094422 0.01258738 0.01016415 0.00671665
 0.00699428]
Model epoch 111: train total loss -57.563793753754744, train mean loss 0.008931265761058174, test mean loss [0.00930646 0.00804154 0.01067292 0.01242183 0.0108269  0.00660177
 0.00693117]
Model epoch 112: train total loss -57.57295235428614, train mean loss 0.008755966804639845, test mean loss [0.00920957 0.00794868 0.01020614 0.01231526 0.01050437 0.00647626
 0.0065887 ]
Model epoch 113: train total loss -57.675682665742954, train mean loss 0.008581838258627383, test mean loss [0.00889753 0.00792623 0.01017948 0.01207017 0.01028449 0.00642418
 0.00655152]
Model epoch 114: train total loss -57.74973945751888, train mean loss 0.008639223187413447, test mean loss [0.00885073 0.0077037  0.0103856  0.01212452 0.00975232 0.00622867
 0.00654647]
Model epoch 115: train total loss -57.72973435068894, train mean loss 0.008446244117134856, test mean loss [0.00850996 0.00763272 0.0101795  0.01203514 0.00958911 0.00612122
 0.00655446]
Model epoch 116: train total loss -57.69043941754131, train mean loss 0.00832442462864831, test mean loss [0.00811559 0.00766672 0.0099581  0.01193292 0.00990306 0.00616305
 0.00608944]
Model epoch 117: train total loss -57.81533931305161, train mean loss 0.008221155105936276, test mean loss [0.00821783 0.00744347 0.00995366 0.01161256 0.00942551 0.00585206
 0.00637955]
Model epoch 118: train total loss -57.82900678790994, train mean loss 0.008122300729945724, test mean loss [0.0081499  0.00721473 0.00970851 0.01185224 0.00917134 0.0057264
 0.00600359]
Model epoch 119: train total loss -57.94487230731558, train mean loss 0.007897634036695524, test mean loss [0.00779306 0.00706877 0.00953927 0.01143087 0.00957056 0.00549768
 0.00594935]
Model epoch 120: train total loss -57.95935244073528, train mean loss 0.00775193214678809, test mean loss [0.00753692 0.00707042 0.00957092 0.01103193 0.00902608 0.00553628
 0.00584938]
Model epoch 121: train total loss -57.97117439182237, train mean loss 0.007702093504438928, test mean loss [0.0074623  0.00687465 0.00959766 0.0111796  0.00874132 0.00544021
 0.00587182]
Model epoch 122: train total loss -58.12689818907839, train mean loss 0.007779303031185119, test mean loss [0.00752748 0.00673664 0.00932362 0.01115058 0.00872305 0.00530497
 0.00580293]
Model epoch 123: train total loss -58.191095007975576, train mean loss 0.007499319852162722, test mean loss [0.00737348 0.00677204 0.00911891 0.01099316 0.00859899 0.00517288
 0.00550128]
Model epoch 124: train total loss -58.27308457916623, train mean loss 0.00756691698751495, test mean loss [0.00716629 0.00664251 0.00892888 0.01076979 0.00844139 0.00508174
 0.00551057]
Model epoch 125: train total loss -58.271541666187886, train mean loss 0.006980477119414286, test mean loss [0.00732245 0.00666632 0.00910185 0.01051454 0.00839241 0.00538672
 0.0054202 ]
Model epoch 126: train total loss -58.117632996091366, train mean loss 0.007329568161166028, test mean loss [0.00714716 0.00644358 0.00908609 0.0105477  0.00829647 0.00534079
 0.00519248]
Model epoch 127: train total loss -58.330554895496405, train mean loss 0.0071136850482647895, test mean loss [0.00714419 0.0062712  0.00888788 0.01056757 0.00797698 0.00505159
 0.00499817]
Model epoch 128: train total loss -58.41876523431564, train mean loss 0.006952889993126023, test mean loss [0.00691553 0.00598258 0.0085816  0.01042456 0.00810324 0.00478931
 0.00509442]
Model epoch 129: train total loss -58.47355087012237, train mean loss 0.0069154311718345254, test mean loss [0.00679607 0.00597801 0.00835429 0.01008418 0.00804112 0.00455137
 0.00487391]
Model epoch 130: train total loss -58.60739460201089, train mean loss 0.006648564236374256, test mean loss [0.00675887 0.00575288 0.00837181 0.00992203 0.00784468 0.0044546
 0.0046753 ]
Model epoch 131: train total loss -58.55971816418704, train mean loss 0.006656172547935981, test mean loss [0.00647844 0.00581603 0.00823103 0.01003111 0.00763256 0.00456058
 0.00452825]
Model epoch 132: train total loss -58.69480575284277, train mean loss 0.006761389207220831, test mean loss [0.00639796 0.00585816 0.00815774 0.00971802 0.00750936 0.00422767
 0.00441505]
Model epoch 133: train total loss -58.791184862082744, train mean loss 0.006341102049836957, test mean loss [0.00617455 0.00558925 0.00815789 0.00971598 0.00720468 0.00420922
 0.0043804 ]
Model epoch 134: train total loss -58.79656262199052, train mean loss 0.0061095600526824565, test mean loss [0.0061058  0.00529721 0.0079813  0.00954003 0.0073278  0.00441337
 0.00417907]
Model epoch 135: train total loss -58.792461203210145, train mean loss 0.006333766725694052, test mean loss [0.00591616 0.00537836 0.00775279 0.00942355 0.00686104 0.00396168
 0.00414205]
Model epoch 136: train total loss -58.87417340274127, train mean loss 0.006012723468497945, test mean loss [0.00587337 0.00526616 0.00760563 0.0093509  0.00704569 0.00407823
 0.0040157 ]
Model epoch 137: train total loss -59.06021173508462, train mean loss 0.0059849957080775765, test mean loss [0.00592443 0.00496443 0.00751112 0.00923862 0.00707403 0.004034
 0.00414682]
Model epoch 138: train total loss -59.056441461546235, train mean loss 0.005864216571338875, test mean loss [0.00571411 0.00491591 0.00761177 0.00887767 0.00666982 0.00387798
 0.0037984 ]
Model epoch 139: train total loss -58.869339985296456, train mean loss 0.005840153465348399, test mean loss [0.00557717 0.0049999  0.00742722 0.00895    0.00665119 0.00392255
 0.00366162]
Model epoch 140: train total loss -58.96303942261167, train mean loss 0.005567472927675492, test mean loss [0.00547132 0.00484241 0.0073365  0.00881761 0.00642729 0.00351258
 0.00363875]
Model epoch 141: train total loss -59.07213222216199, train mean loss 0.005502592193378213, test mean loss [0.0054592  0.00457247 0.00713603 0.00861681 0.00634853 0.00400814
 0.00352621]
Model epoch 142: train total loss -58.86759221277434, train mean loss 0.005417779649887795, test mean loss [0.00536506 0.00472686 0.00700393 0.00861189 0.00615223 0.00352897
 0.00343654]
Model epoch 143: train total loss -58.95593733255756, train mean loss 0.005693561829521266, test mean loss [0.00522537 0.00474726 0.00702159 0.008408   0.00625237 0.00339123
 0.0034465 ]
Model epoch 144: train total loss -59.077109245484536, train mean loss 0.005416809570749634, test mean loss [0.00525153 0.00435167 0.00681106 0.0082849  0.00620633 0.00343303
 0.00334826]
Model epoch 145: train total loss -59.22242280460184, train mean loss 0.005329721193649518, test mean loss [0.00508416 0.00439899 0.00670231 0.0082239  0.00606161 0.00341626
 0.00312195]
Model epoch 146: train total loss -59.24231210983586, train mean loss 0.005131841676170272, test mean loss [0.00491418 0.00417064 0.00661543 0.00825321 0.005942   0.00326177
 0.00303073]
Model epoch 147: train total loss -59.23463871828785, train mean loss 0.0050485276613626145, test mean loss [0.00504505 0.00404876 0.00690421 0.00817066 0.0057862  0.00318996
 0.00313299]
Model epoch 148: train total loss -59.20870291776173, train mean loss 0.005153327955133502, test mean loss [0.00467461 0.00380796 0.00655886 0.00797141 0.00583169 0.00323253
 0.00300102]
Model epoch 149: train total loss -59.31294326471254, train mean loss 0.005018774166375742, test mean loss [0.00473119 0.00382798 0.00653916 0.00791805 0.00577341 0.00304192
 0.00291404]
Model epoch 150: train total loss -59.14461931635447, train mean loss 0.004983366978706607, test mean loss [0.00485943 0.00386624 0.00628811 0.00777569 0.00538952 0.00306384
 0.00297857]
Model epoch 151: train total loss -59.30161779537807, train mean loss 0.00466633518958814, test mean loss [0.00438705 0.00365439 0.00620071 0.00775074 0.00526305 0.00303146
 0.00281948]
Model epoch 152: train total loss -59.39998770356413, train mean loss 0.004658550651599286, test mean loss [0.00439761 0.00347937 0.00641946 0.00759851 0.00524844 0.00277317
 0.00267021]
Model epoch 153: train total loss -59.36295259858923, train mean loss 0.00473474382084528, test mean loss [0.00421406 0.00343998 0.00617763 0.00764939 0.00527162 0.0028224
 0.00271678]
Model epoch 154: train total loss -59.4331450600903, train mean loss 0.004686520627102477, test mean loss [0.00434248 0.00332214 0.00621444 0.00729537 0.00517782 0.00280019
 0.0026112 ]
Model epoch 155: train total loss -59.56292923490611, train mean loss 0.004452700008131979, test mean loss [0.00416711 0.00324133 0.00586685 0.00744787 0.00505893 0.00267696
 0.00282732]
Model epoch 156: train total loss -59.03367480980576, train mean loss 0.004477741280286916, test mean loss [0.00424828 0.0031963  0.00577452 0.00721882 0.00609791 0.00257582
 0.0025419 ]
Model epoch 157: train total loss -59.272028534564086, train mean loss 0.004459198038694714, test mean loss [0.00404821 0.00307075 0.00579912 0.00716339 0.00579131 0.00265985
 0.00251278]
Model epoch 158: train total loss -59.42597187308107, train mean loss 0.004466652716354525, test mean loss [0.00400422 0.00297102 0.00559932 0.00707167 0.00558356 0.00263116
 0.00239191]
Model epoch 159: train total loss -59.418235692719286, train mean loss 0.004105491668224067, test mean loss [0.00383183 0.00293395 0.00536887 0.00721042 0.00534063 0.00265599
 0.00236827]
Model epoch 160: train total loss -59.31555865099771, train mean loss 0.00423632546597237, test mean loss [0.00381973 0.00339251 0.00545247 0.00692162 0.00523683 0.00250032
 0.00230568]
Model epoch 161: train total loss -59.45074343764398, train mean loss 0.0041773871778046845, test mean loss [0.00359931 0.00278393 0.00546079 0.00701754 0.0050619  0.00236687
 0.00228414]
Model epoch 162: train total loss -59.60121689368019, train mean loss 0.0041353979403835435, test mean loss [0.00358058 0.00262886 0.00540897 0.00674832 0.0049038  0.0022909
 0.00228654]
Model epoch 163: train total loss -59.69179167425609, train mean loss 0.00393458814205853, test mean loss [0.00346991 0.0025212  0.00551285 0.00680897 0.00457933 0.00226007
 0.00228344]
Model epoch 164: train total loss -59.844146499013, train mean loss 0.004005281079256199, test mean loss [0.00345399 0.00256697 0.00537387 0.00645093 0.00448434 0.00220209
 0.00220158]
Model epoch 165: train total loss -59.7481277521178, train mean loss 0.004023196743906443, test mean loss [0.00345517 0.00239991 0.005136   0.00660403 0.00459973 0.00211881
 0.00221866]
Model epoch 166: train total loss -59.840810343879795, train mean loss 0.0037488125032391784, test mean loss [0.00336497 0.00252393 0.00512701 0.00632543 0.00434565 0.00207803
 0.00219562]
Model epoch 167: train total loss -59.85278028008165, train mean loss 0.003931763760259224, test mean loss [0.00323979 0.0023773  0.00482204 0.0061988  0.00455993 0.00216382
 0.00211853]
Model epoch 168: train total loss -59.703809136710156, train mean loss 0.0038124324071365967, test mean loss [0.00339481 0.00238267 0.00510369 0.00608464 0.00432997 0.00227371
 0.00217745]
Model epoch 169: train total loss -59.838641262469835, train mean loss 0.0036702662023455988, test mean loss [0.00311157 0.00244195 0.00475081 0.00600446 0.00419822 0.00209441
 0.00210648]
Model epoch 170: train total loss -60.03228308453044, train mean loss 0.0033255320898835862, test mean loss [0.00303658 0.00226183 0.00487342 0.00584927 0.00412593 0.00207591
 0.00197946]
Model epoch 171: train total loss -60.00673724957066, train mean loss 0.0035558235411933333, test mean loss [0.00322192 0.00222033 0.00465418 0.00598668 0.00402637 0.00189966
 0.00203553]
Model epoch 172: train total loss -60.19082416609961, train mean loss 0.003453026850971626, test mean loss [0.00296527 0.00216577 0.00442648 0.00604669 0.00392815 0.00188364
 0.00198172]
Model epoch 173: train total loss -60.153798913742946, train mean loss 0.0032844245980959775, test mean loss [0.00289038 0.0020368  0.00452232 0.00567219 0.0038828  0.00217425
 0.00197437]
Model epoch 174: train total loss -60.12681345972615, train mean loss 0.003532576029448844, test mean loss [0.00289836 0.00197693 0.00456529 0.00567743 0.00370899 0.00195138
 0.00188291]
Model epoch 175: train total loss -60.14979285546227, train mean loss 0.0032973376444649276, test mean loss [0.00282687 0.00188154 0.00442945 0.00559246 0.00363807 0.00192574
 0.00185061]
Model epoch 176: train total loss -60.08258066066185, train mean loss 0.0032871051879022066, test mean loss [0.00318717 0.00183925 0.00435428 0.00553021 0.00347213 0.00189782
 0.00185901]
Model epoch 177: train total loss -60.13581024373953, train mean loss 0.0032349201776432513, test mean loss [0.0026964  0.00195798 0.00424    0.00552092 0.00341693 0.00181222
 0.00181218]
Model epoch 178: train total loss -60.268163165895224, train mean loss 0.003027056081762785, test mean loss [0.00274918 0.00182782 0.00420218 0.0053414  0.00348274 0.0017384
 0.00179737]
Model epoch 179: train total loss -60.33430035091401, train mean loss 0.0028652812226643825, test mean loss [0.00274938 0.0017268  0.00412778 0.00532249 0.00337815 0.00171323
 0.00192921]
Model epoch 180: train total loss -60.21039941269894, train mean loss 0.0031681231500859134, test mean loss [0.00276061 0.00184292 0.00403842 0.00539315 0.0032638  0.00169506
 0.0017568 ]
Model epoch 181: train total loss -60.212149518161695, train mean loss 0.002772377750397358, test mean loss [0.00271366 0.00170521 0.00402554 0.00520673 0.00328805 0.00179232
 0.00170689]
Model epoch 182: train total loss -60.324830243386835, train mean loss 0.0029642120351794097, test mean loss [0.00275856 0.00165177 0.00390734 0.00519041 0.00326333 0.00172577
 0.00174291]
Model epoch 183: train total loss -60.32506364665745, train mean loss 0.0028428396138473807, test mean loss [0.00270703 0.00158696 0.00387614 0.00515498 0.00305725 0.0016085
 0.00162604]
Model epoch 184: train total loss -60.348800781129334, train mean loss 0.003120918305699328, test mean loss [0.0025355  0.00162611 0.00381881 0.00503381 0.00318401 0.00162718
 0.00153964]
Model epoch 185: train total loss -60.51751577365368, train mean loss 0.003015583940824341, test mean loss [0.00260253 0.00154767 0.00364291 0.00482601 0.00293709 0.00149563
 0.00165261]
Model epoch 186: train total loss -60.5538067599239, train mean loss 0.002758139718743867, test mean loss [0.00247894 0.00150625 0.0035305  0.00470913 0.00292975 0.00152361
 0.00162912]
Model epoch 187: train total loss -60.61868709738023, train mean loss 0.0027817312292097935, test mean loss [0.00270338 0.00153746 0.00355316 0.00464927 0.00283737 0.0014564
 0.00149135]
Model epoch 188: train total loss -60.5187554622323, train mean loss 0.002803406223838568, test mean loss [0.0025215  0.00148319 0.00339186 0.00459315 0.00272251 0.00148305
 0.00147239]
Model epoch 189: train total loss -60.71336695101197, train mean loss 0.0026371616701751054, test mean loss [0.00242105 0.00152868 0.003257   0.00459896 0.00269329 0.00140669
 0.00147022]
Model epoch 190: train total loss -60.66834185508886, train mean loss 0.002526886729507395, test mean loss [0.00242718 0.0014509  0.00335171 0.00427886 0.0026404  0.00145127
 0.00151353]
Model epoch 191: train total loss -60.84680860855937, train mean loss 0.002440951607376006, test mean loss [0.00231766 0.0013799  0.00327727 0.00430647 0.00260087 0.00139143
 0.00145459]
Model epoch 192: train total loss -60.71557454518617, train mean loss 0.0025931866746716436, test mean loss [0.00227359 0.00136261 0.00320854 0.00419334 0.00265182 0.00137642
 0.00146368]
Model epoch 193: train total loss -60.697241472346434, train mean loss 0.0025000627586369696, test mean loss [0.002243   0.00130648 0.00331105 0.00421173 0.00260474 0.00135085
 0.00143149]
Model epoch 194: train total loss -60.753867540505006, train mean loss 0.002423623662406377, test mean loss [0.00220968 0.00166991 0.00322241 0.00401094 0.00254406 0.00124776
 0.00136926]
Model epoch 195: train total loss -60.39263088805765, train mean loss 0.0025245258795132323, test mean loss [0.00215937 0.00155309 0.00307236 0.00400211 0.00245237 0.00133503
 0.0013771 ]
Model epoch 196: train total loss -60.43838030598197, train mean loss 0.002415288543901123, test mean loss [0.00223498 0.00152703 0.00297737 0.00399274 0.0023632  0.00130113
 0.00134175]
Model epoch 197: train total loss -60.49917803086173, train mean loss 0.0024098100156288277, test mean loss [0.00206418 0.00148728 0.00302203 0.00388849 0.00232402 0.00127255
 0.00133811]
Model epoch 198: train total loss -60.6292035996802, train mean loss 0.0022555368909369586, test mean loss [0.00204096 0.00134994 0.00290061 0.00394249 0.00242238 0.00125243
 0.00132327]
Model epoch 199: train total loss -60.73270870146471, train mean loss 0.002359142687380041, test mean loss [0.00213282 0.00130294 0.00287759 0.00381416 0.00225021 0.00124985
 0.00152854]
Model epoch 200: train total loss -60.581743245966805, train mean loss 0.002318731301616633, test mean loss [0.00206562 0.00127812 0.00272559 0.00370632 0.00257797 0.00124342
 0.00141664]
Model epoch 201: train total loss -60.89116411662523, train mean loss 0.002329641107564804, test mean loss [0.00215621 0.00128407 0.00275301 0.00363185 0.00237417 0.00120778
 0.00128775]
Model epoch 202: train total loss -60.795694654038584, train mean loss 0.0022790278294692206, test mean loss [0.00197951 0.00123159 0.00292018 0.00366935 0.00240969 0.00113169
 0.00123628]
Model epoch 203: train total loss -60.82395196948174, train mean loss 0.002180639140785578, test mean loss [0.00192536 0.00119131 0.00275968 0.00354607 0.00218477 0.00118378
 0.00130359]
Model epoch 204: train total loss -60.9395946854177, train mean loss 0.0022236063794892937, test mean loss [0.00190696 0.00114669 0.00264611 0.00341459 0.0021425  0.00115226
 0.00123343]
Model epoch 205: train total loss -61.04078192203684, train mean loss 0.002098765461815427, test mean loss [0.00190221 0.00115104 0.00249762 0.00336    0.00212242 0.00116072
 0.00120653]
Model epoch 206: train total loss -61.15122580080474, train mean loss 0.0019320962607037794, test mean loss [0.00181359 0.00105079 0.00254231 0.00344974 0.00208041 0.00106092
 0.0012075 ]
Model epoch 207: train total loss -60.97969899302509, train mean loss 0.0019971275468845576, test mean loss [0.00188373 0.00110693 0.00252739 0.0034469  0.00216351 0.00104083
 0.00119003]
Model epoch 208: train total loss -61.07374487408781, train mean loss 0.0020693892877771693, test mean loss [0.00182523 0.00106079 0.00250805 0.00337027 0.00201176 0.00119422
 0.00114748]
Model epoch 209: train total loss -60.84788349331259, train mean loss 0.0021159600395779265, test mean loss [0.00187604 0.00107629 0.00239389 0.0033196  0.00199199 0.00114485
 0.00111341]
Model epoch 210: train total loss -60.94561850732788, train mean loss 0.0019439253639729473, test mean loss [0.00182689 0.0010292  0.00241629 0.00324684 0.00197906 0.00110662
 0.00108427]
Model epoch 211: train total loss -61.280103052535, train mean loss 0.001995076320534511, test mean loss [0.00181172 0.00099368 0.0023834  0.00315279 0.00187894 0.00108774
 0.00111466]
Model epoch 212: train total loss -61.23700709507279, train mean loss 0.0019182412724790614, test mean loss [0.00172757 0.00098329 0.00231605 0.00311682 0.00195265 0.00101426
 0.00110475]
Model epoch 213: train total loss -61.16617616715657, train mean loss 0.0019112377783173852, test mean loss [0.00178508 0.00128652 0.00233857 0.00311315 0.00192914 0.00103739
 0.0010407 ]
Model epoch 214: train total loss -60.95436618450456, train mean loss 0.0019411366300143393, test mean loss [0.0016833  0.00127419 0.00234145 0.00302535 0.00188297 0.00104095
 0.00104066]
Model epoch 215: train total loss -61.13465700499705, train mean loss 0.0018514763485028242, test mean loss [0.00182815 0.0010829  0.00244394 0.00291349 0.00178626 0.00101887
 0.00099389]
Model epoch 216: train total loss -61.16293263297211, train mean loss 0.0019325042280536817, test mean loss [0.00166466 0.00096643 0.00235754 0.00279893 0.00175511 0.0010133
 0.00105938]
Model epoch 217: train total loss -61.33507015850618, train mean loss 0.0016692609339667662, test mean loss [0.001579   0.00093739 0.00231762 0.00283148 0.00178863 0.0009767
 0.00096411]
Model epoch 218: train total loss -61.389121375052085, train mean loss 0.0017778624388659861, test mean loss [0.00163181 0.00094485 0.00222927 0.00280073 0.0017644  0.00092467
 0.00095235]
Model epoch 219: train total loss -61.36954337055392, train mean loss 0.0017854484201237453, test mean loss [0.00158259 0.00098825 0.00216664 0.00267667 0.00172041 0.00092159
 0.00098375]
Model epoch 220: train total loss -61.474055813831896, train mean loss 0.0017417132283782486, test mean loss [0.00159302 0.00095473 0.0021457  0.00270961 0.00166774 0.00087251
 0.00090494]
Model epoch 221: train total loss -61.47906988632137, train mean loss 0.0016881286385207646, test mean loss [0.00159074 0.00084983 0.00218824 0.00265418 0.00167113 0.00087424
 0.00093839]
Model epoch 222: train total loss -61.59301077753095, train mean loss 0.0016840860518424572, test mean loss [0.00158357 0.00088081 0.0021474  0.00259503 0.001703   0.00093518
 0.00088238]
Model epoch 223: train total loss -61.34183047979428, train mean loss 0.0016241994363097856, test mean loss [0.001558   0.00086051 0.00214003 0.00257119 0.0016656  0.0008737
 0.00087084]
Model epoch 224: train total loss -61.323158177595595, train mean loss 0.001679475979346905, test mean loss [0.00154894 0.00084368 0.00209116 0.00255088 0.00168579 0.00087371
 0.00089388]
Model epoch 225: train total loss -61.43966923755126, train mean loss 0.0016676099332364417, test mean loss [0.00152231 0.00084358 0.00206015 0.00249363 0.00164222 0.00086865
 0.00090833]
Model epoch 226: train total loss -61.41023907790841, train mean loss 0.00168180859739447, test mean loss [0.00152018 0.00077001 0.00192024 0.00243468 0.00162143 0.00081311
 0.00087954]
Model epoch 227: train total loss -61.5049553648065, train mean loss 0.001624012094978466, test mean loss [0.00151742 0.00083181 0.00198789 0.00249829 0.00165475 0.00080327
 0.00082025]
Model epoch 228: train total loss -61.646351878186394, train mean loss 0.0015433727863381245, test mean loss [0.00146312 0.00079208 0.00199857 0.00249651 0.00158594 0.00082915
 0.00079585]
Model epoch 229: train total loss -61.544329041423396, train mean loss 0.0015490401390843211, test mean loss [0.00149844 0.00081549 0.00196827 0.00238076 0.00145855 0.00078182
 0.0008044 ]
Model epoch 230: train total loss -61.586885482816285, train mean loss 0.0015234936620343986, test mean loss [0.0014393  0.00079498 0.00184557 0.00235352 0.00144391 0.00078796
 0.00083787]
Model epoch 231: train total loss -61.37511562148727, train mean loss 0.0015484384087109827, test mean loss [0.00146957 0.00074692 0.00186845 0.00227144 0.0020594  0.00084606
 0.00079071]
Model epoch 232: train total loss -61.216334534440236, train mean loss 0.0015448425346560046, test mean loss [0.00146979 0.00080993 0.0018841  0.00239076 0.00184815 0.0007771
 0.00077903]
Model epoch 233: train total loss -61.041624131771215, train mean loss 0.001504397039134118, test mean loss [0.0013967  0.00087051 0.00190684 0.0023009  0.00167075 0.00071856
 0.00074758]
Model epoch 234: train total loss -61.41977193563599, train mean loss 0.0013731742891628894, test mean loss [0.00133838 0.00080385 0.00188963 0.0022431  0.00143816 0.00077165
 0.00078916]
Model epoch 235: train total loss -61.55793007328298, train mean loss 0.0015113844958707795, test mean loss [0.00135848 0.00078286 0.00180466 0.00218701 0.00139698 0.00070602
 0.00072241]
Model epoch 236: train total loss -61.42938195709086, train mean loss 0.001373338772210912, test mean loss [0.00133903 0.00074699 0.0018101  0.00219706 0.00134147 0.00072259
 0.00074074]
Model epoch 237: train total loss -61.67374064851541, train mean loss 0.0015007760043625027, test mean loss [0.00130459 0.00072763 0.00181374 0.00212749 0.00127821 0.00070732
 0.00071385]
Model epoch 238: train total loss -61.8292156692055, train mean loss 0.0014217119484979939, test mean loss [0.00127715 0.00075311 0.00182555 0.0020353  0.00131274 0.00065898
 0.00067951]
Model epoch 239: train total loss -61.8883613294729, train mean loss 0.0014219764261818894, test mean loss [0.00132161 0.0006822  0.00175154 0.00204929 0.0013488  0.00066717
 0.00072274]
Model epoch 240: train total loss -61.70478495666322, train mean loss 0.001350337574187139, test mean loss [0.00135095 0.00070156 0.00184905 0.00210428 0.00127147 0.00066967
 0.00069015]
Model epoch 241: train total loss -61.46810971239246, train mean loss 0.0014143517455568544, test mean loss [0.00146621 0.00070212 0.00188341 0.00206933 0.00132914 0.00066116
 0.00073133]
Model epoch 242: train total loss -61.60822538406662, train mean loss 0.0014002481140222883, test mean loss [0.00127648 0.00067014 0.00183487 0.00213148 0.00120142 0.00071542
 0.00065846]
Model epoch 243: train total loss -61.750351537771664, train mean loss 0.0013669597282750176, test mean loss [0.00124165 0.00066935 0.00182574 0.00196419 0.00122995 0.00070518
 0.00067496]
Model epoch 244: train total loss -61.74169319189008, train mean loss 0.001366996161447681, test mean loss [0.00125288 0.00064569 0.00175684 0.00189019 0.00130778 0.00063465
 0.00070614]
Model epoch 245: train total loss -61.9931635274561, train mean loss 0.0013841898405722397, test mean loss [0.00121927 0.00063994 0.00173644 0.00184394 0.00127019 0.00061568
 0.00066272]
Model epoch 246: train total loss -62.09001980731264, train mean loss 0.001219183279781914, test mean loss [0.00121318 0.00062881 0.00163751 0.00198048 0.00118088 0.00058498
 0.00062176]
Model epoch 247: train total loss -61.887130766212614, train mean loss 0.001245531853785064, test mean loss [0.00118663 0.00063504 0.00176958 0.00192558 0.00112117 0.00075732
 0.00062955]
Model epoch 248: train total loss -61.82837249822896, train mean loss 0.0012141823690391344, test mean loss [0.00118288 0.00060214 0.00179743 0.00185686 0.00117103 0.0007552
 0.00062708]
Model epoch 249: train total loss -61.94752098365588, train mean loss 0.0011770810601026398, test mean loss [0.00116287 0.00060059 0.00176874 0.00194965 0.00109673 0.00069887
 0.00063218]
Model epoch 250: train total loss -61.98176399938132, train mean loss 0.0012498662417728984, test mean loss [0.00116306 0.0006153  0.00167145 0.00188054 0.00112645 0.0006248
 0.00060839]
Model epoch 251: train total loss -62.15654684640647, train mean loss 0.0011819210598317464, test mean loss [0.00115769 0.00059459 0.00159802 0.0018179  0.00111189 0.00062461
 0.00062232]
Model epoch 252: train total loss -61.90424353665753, train mean loss 0.0012470730030095572, test mean loss [0.00113647 0.00059119 0.00161025 0.00181368 0.00115608 0.00058489
 0.00056444]
Model epoch 253: train total loss -62.01711056442056, train mean loss 0.0011570926341946443, test mean loss [0.00112608 0.00059667 0.0016836  0.00177019 0.00107721 0.00058924
 0.00056298]
Model epoch 254: train total loss -62.07970238327058, train mean loss 0.001332470146796714, test mean loss [0.00114096 0.00058164 0.001595   0.00164525 0.00105576 0.00060491
 0.00053952]
Model epoch 255: train total loss -62.0099215335926, train mean loss 0.0011439804873074047, test mean loss [0.00109716 0.0005733  0.00158254 0.00172514 0.00101519 0.00052588
 0.00054207]
Model epoch 256: train total loss -62.18837776309759, train mean loss 0.0011229435245125406, test mean loss [0.00109237 0.00056157 0.00159045 0.00166036 0.00097728 0.00054064
 0.000565  ]
Model epoch 257: train total loss -61.99507695791347, train mean loss 0.0011112583543956475, test mean loss [0.00127623 0.00054772 0.00155724 0.00162949 0.00100224 0.00059446
 0.00055205]
Model epoch 258: train total loss -61.78839642117332, train mean loss 0.0012372148776524387, test mean loss [0.0011375  0.00054282 0.00152568 0.00157569 0.00102397 0.00071709
 0.00054313]
Model epoch 259: train total loss -61.805652971650744, train mean loss 0.0011915448200568305, test mean loss [0.00112541 0.00053839 0.00152879 0.00156725 0.00094409 0.00062192
 0.00052548]
Model epoch 260: train total loss -61.72473807529322, train mean loss 0.0010958022048349733, test mean loss [0.0010733  0.00060267 0.00152362 0.0015787  0.00095707 0.0005487
 0.00054344]
Model epoch 261: train total loss -61.973726743382045, train mean loss 0.001028133802961059, test mean loss [0.0010597  0.00057273 0.00144277 0.00155718 0.00097165 0.00053503
 0.00053716]
Model epoch 262: train total loss -61.98034727405568, train mean loss 0.0010523023184714373, test mean loss [0.00098549 0.00053082 0.00145455 0.00146119 0.00092951 0.00055227
 0.00052562]
Model epoch 263: train total loss -62.106951630639855, train mean loss 0.0010813867688372935, test mean loss [0.00107436 0.00052818 0.00138277 0.00151445 0.00089803 0.00048252
 0.00051857]
Model epoch 264: train total loss -62.244909484725994, train mean loss 0.0011663665087862597, test mean loss [0.00102304 0.00053673 0.00141768 0.00148038 0.00089257 0.00047216
 0.00049122]
Model epoch 265: train total loss -62.30462062028474, train mean loss 0.0010549805124024576, test mean loss [0.0009977  0.00056154 0.00133854 0.00151206 0.00085992 0.0004684
 0.00050659]
Model epoch 266: train total loss -62.09476682984125, train mean loss 0.0010851687143736187, test mean loss [0.00095433 0.00050775 0.00136948 0.00144106 0.00084963 0.00047939
 0.00064866]
Model epoch 267: train total loss -62.1680502321628, train mean loss 0.000985446176832705, test mean loss [0.0009815  0.00051036 0.00134037 0.0014715  0.00084243 0.00043506
 0.00055538]
Model epoch 268: train total loss -62.278206402146445, train mean loss 0.0011031596205529199, test mean loss [0.00094904 0.00051749 0.00135518 0.00139699 0.00080447 0.00044987
 0.00050837]
Model epoch 269: train total loss -62.20952079209234, train mean loss 0.0010379169341021132, test mean loss [0.00094677 0.0005113  0.00130825 0.00168005 0.00080088 0.0004268
 0.00049367]
Model epoch 270: train total loss -62.08440469091717, train mean loss 0.0010812160342643124, test mean loss [0.00095217 0.00049491 0.00129329 0.00158556 0.00078348 0.00041583
 0.00050425]
Model epoch 271: train total loss -62.35383941585851, train mean loss 0.001018280207183504, test mean loss [0.0009709  0.00048927 0.0013379  0.00151234 0.00076489 0.00040163
 0.00048127]
Model epoch 272: train total loss -62.220967691499894, train mean loss 0.0010179844318667336, test mean loss [0.00088779 0.00050554 0.0014377  0.00149606 0.00073302 0.00039342
 0.00050092]
Model epoch 273: train total loss -61.92049734457025, train mean loss 0.001092489074351202, test mean loss [0.00087893 0.00048252 0.00138865 0.00136008 0.00073929 0.00037898
 0.00110606]
Model epoch 274: train total loss -61.57744632540314, train mean loss 0.0012714948174502643, test mean loss [0.00085072 0.00048213 0.00131223 0.00136205 0.00073424 0.00038332
 0.00218326]
Model epoch 275: train total loss -61.81256536815361, train mean loss 0.0010948501066110616, test mean loss [0.00086049 0.00047116 0.00125446 0.00133482 0.00077476 0.00039006
 0.0018429 ]
Model epoch 276: train total loss -61.96267775084155, train mean loss 0.0010991024502167435, test mean loss [0.00085679 0.0005293  0.00122478 0.00132999 0.00084452 0.00039992
 0.00154573]
Model epoch 277: train total loss -61.9029888670299, train mean loss 0.0011139861433291426, test mean loss [0.00085348 0.00049081 0.00124213 0.00131129 0.0008195  0.0003858
 0.00133026]
Model epoch 278: train total loss -62.006947808155815, train mean loss 0.0010664488728530429, test mean loss [0.00085945 0.00049663 0.00118535 0.00127523 0.00070555 0.00040718
 0.00120394]
Model epoch 279: train total loss -61.40701563496463, train mean loss 0.0011857767545990045, test mean loss [0.00085377 0.00216745 0.00130763 0.0012688  0.00064523 0.00038902
 0.00104948]
Model epoch 280: train total loss -61.79071040407487, train mean loss 0.0012573677427377263, test mean loss [0.00082739 0.00297499 0.00120515 0.00123541 0.00060053 0.00037552
 0.00101415]
Model epoch 281: train total loss -61.821510610808595, train mean loss 0.00134628101106714, test mean loss [0.00082697 0.00243312 0.00115832 0.00126756 0.00066122 0.00036721
 0.00098254]
Model epoch 282: train total loss -61.92199545470914, train mean loss 0.001153636933579451, test mean loss [0.00081402 0.00186352 0.00120779 0.00124306 0.00065528 0.00037298
 0.00094384]
Model epoch 283: train total loss -62.23808613538835, train mean loss 0.001114953242126036, test mean loss [0.0007798  0.00150016 0.00130631 0.00118411 0.00061927 0.00036315
 0.0009179 ]
Model epoch 284: train total loss -62.25520050172207, train mean loss 0.0010737045295787942, test mean loss [0.00077421 0.00123791 0.00124513 0.00123609 0.00061781 0.00035445
 0.0008518 ]
Model epoch 285: train total loss -62.28075055939565, train mean loss 0.0010659763419818577, test mean loss [0.0007839  0.00117241 0.00112899 0.0011731  0.00061004 0.00035002
 0.00084817]
Model epoch 286: train total loss -62.384684652363944, train mean loss 0.0009392893138438213, test mean loss [0.00077535 0.00111083 0.00116096 0.00113984 0.00057813 0.00044084
 0.00085165]
Model epoch 287: train total loss -62.282588368627685, train mean loss 0.000983689178993684, test mean loss [0.00073583 0.00109412 0.00117584 0.00111189 0.00056282 0.00038678
 0.00079614]
Model epoch 288: train total loss -62.149554594170155, train mean loss 0.001032085294163066, test mean loss [0.0007509  0.00100994 0.0010982  0.00113993 0.00058251 0.00035167
 0.00079838]
Model epoch 289: train total loss -62.40029280404549, train mean loss 0.0009237899450912461, test mean loss [0.00076033 0.00103532 0.00109387 0.00113474 0.00056956 0.00035978
 0.00079238]
Model epoch 290: train total loss -62.43681901896333, train mean loss 0.0009314725954011839, test mean loss [0.00069887 0.00096132 0.00113319 0.00104857 0.00055177 0.00038312
 0.00074475]
Model epoch 291: train total loss -62.42866203204858, train mean loss 0.0010193181935103505, test mean loss [0.00073699 0.00093562 0.00113869 0.00103445 0.00055013 0.00035633
 0.00074371]
Model epoch 292: train total loss -62.31023037151532, train mean loss 0.0008837740459544424, test mean loss [0.00071488 0.00096057 0.00111894 0.00105858 0.00056432 0.00034252
 0.00073461]
Model epoch 293: train total loss -62.556924098094186, train mean loss 0.0008686661615341661, test mean loss [0.0006939  0.00092735 0.0010719  0.0010382  0.00050966 0.00034098
 0.00068738]
Model epoch 294: train total loss -62.40754995182176, train mean loss 0.0008813280111623132, test mean loss [0.00069051 0.00084477 0.00108375 0.00108005 0.00054451 0.0004819
 0.00070146]
Model epoch 295: train total loss -62.51108436089139, train mean loss 0.0008216327793337436, test mean loss [0.00071064 0.00082996 0.00104573 0.00100627 0.00053037 0.00034437
 0.00068957]
Model epoch 296: train total loss -62.57317907149012, train mean loss 0.0008932194797861985, test mean loss [0.0006607  0.00079621 0.00103614 0.0009845  0.00052402 0.00034183
 0.00067017]
Model epoch 297: train total loss -62.681745061351705, train mean loss 0.0008829217645285916, test mean loss [0.0006855  0.00080603 0.00098934 0.00101986 0.00049855 0.00034566
 0.00063896]
Model epoch 298: train total loss -62.883335235534254, train mean loss 0.0008321730855563516, test mean loss [0.0006434  0.00081476 0.00095747 0.00101749 0.00051679 0.00033481
 0.00065447]
Model epoch 299: train total loss -62.78265668676669, train mean loss 0.0008769637184700392, test mean loss [0.00062106 0.00077925 0.00096939 0.00097616 0.00047393 0.00031746
 0.00061826]
Model epoch 300: train total loss -62.72347333508898, train mean loss 0.0008943403925653825, test mean loss [0.00061732 0.00080114 0.00097263 0.0009288  0.00047869 0.00033061
 0.00063678]
Model epoch 301: train total loss -62.92799797197373, train mean loss 0.0007851610492487098, test mean loss [0.00062286 0.00080407 0.0009601  0.00091135 0.00048813 0.00033404
 0.00057698]
Model epoch 302: train total loss -62.81346700521122, train mean loss 0.0008788434872088099, test mean loss [0.00062059 0.00083471 0.00095829 0.00095302 0.00045535 0.00031717
 0.00055432]
Model epoch 303: train total loss -62.87879883391208, train mean loss 0.0008131595333694175, test mean loss [0.00061697 0.00083034 0.00093927 0.0009303  0.00045107 0.00034555
 0.00049349]
Model epoch 304: train total loss -62.530231686352685, train mean loss 0.0008269791236487373, test mean loss [0.00060235 0.00082896 0.0008939  0.00096951 0.00044183 0.00033171
 0.00051588]
Model epoch 305: train total loss -62.63655584445915, train mean loss 0.0007600606627528948, test mean loss [0.00057377 0.00087387 0.00085326 0.00089666 0.00045006 0.00031643
 0.00045916]
Model epoch 306: train total loss -62.734107913548236, train mean loss 0.0007805696940479429, test mean loss [0.00058983 0.000841   0.00087233 0.00085618 0.00043205 0.00035495
 0.0004504 ]
Model epoch 307: train total loss -62.55706055735029, train mean loss 0.0007822202557409005, test mean loss [0.00091322 0.00073968 0.00088192 0.00090576 0.0004185  0.00033771
 0.00046776]
Model epoch 308: train total loss -62.39790598437901, train mean loss 0.0007756745283143196, test mean loss [0.00072944 0.00071156 0.00087103 0.00089921 0.00043598 0.00032083
 0.00043357]
Model epoch 309: train total loss -62.598634855063565, train mean loss 0.0008611720528505204, test mean loss [0.00068822 0.0006885  0.00085853 0.00084737 0.000415   0.00031876
 0.0004272 ]
Model epoch 310: train total loss -62.59408774027244, train mean loss 0.0008181043639704583, test mean loss [0.00066922 0.00069556 0.00085935 0.0009142  0.00040976 0.00030565
 0.00043554]
Model epoch 311: train total loss -62.44279966351466, train mean loss 0.0007737426234150909, test mean loss [0.00063154 0.00069711 0.000805   0.00083388 0.00042335 0.00030508
 0.00051967]
Model epoch 312: train total loss -62.66752855007647, train mean loss 0.0007349617272907219, test mean loss [0.00060622 0.00062839 0.00082137 0.00081657 0.00042283 0.00031092
 0.00046561]
Model epoch 313: train total loss -62.88163390243354, train mean loss 0.000772604921906327, test mean loss [0.00060206 0.00064994 0.00080313 0.00078307 0.00039043 0.0002885
 0.00044753]
Model epoch 314: train total loss -63.08435095841547, train mean loss 0.0007599194542949626, test mean loss [0.00058049 0.00069955 0.00080627 0.00076707 0.00038802 0.00028139
 0.00042148]
Model epoch 315: train total loss -62.29724641319299, train mean loss 0.0007735317294782386, test mean loss [0.00056728 0.00063172 0.00075459 0.00078403 0.00039502 0.0002934
 0.00065087]
Model epoch 316: train total loss -62.66021631037108, train mean loss 0.0007051325907152054, test mean loss [0.00057579 0.000598   0.00076305 0.0007584  0.00038021 0.00030613
 0.00052346]
Model epoch 317: train total loss -62.664616516350875, train mean loss 0.000700781845503352, test mean loss [0.00057069 0.00055307 0.00079356 0.00079953 0.00038127 0.00031879
 0.00053904]
Model epoch 318: train total loss -62.52769325315542, train mean loss 0.0007064879543087241, test mean loss [0.00056661 0.0005353  0.00077807 0.00077994 0.00039265 0.00030285
 0.00047967]
Model epoch 319: train total loss -62.86041282713247, train mean loss 0.0006336374767410053, test mean loss [0.00052321 0.00056047 0.0007612  0.00071822 0.00037624 0.00029713
 0.00046483]
Model epoch 320: train total loss -62.935767537332296, train mean loss 0.000643675487721759, test mean loss [0.00052482 0.00050248 0.00074351 0.00072839 0.00037971 0.00029175
 0.00047109]
Model epoch 321: train total loss -63.11336921882204, train mean loss 0.0006761138968698375, test mean loss [0.0005308  0.00051572 0.00072525 0.00073542 0.00037604 0.0002871
 0.00045088]
Model epoch 322: train total loss -62.82673527709064, train mean loss 0.0006692589556572992, test mean loss [0.00058008 0.00049182 0.00073646 0.00074345 0.00034743 0.00059145
 0.00045859]
Model epoch 323: train total loss -62.598696267882694, train mean loss 0.0006982941854168569, test mean loss [0.00057235 0.00048385 0.00075013 0.00071736 0.00037255 0.00039977
 0.00045444]
Model epoch 324: train total loss -62.553708418475495, train mean loss 0.0006491746584235623, test mean loss [0.00054795 0.00043506 0.0007096  0.00070164 0.00035219 0.00035821
 0.0004328 ]
Model epoch 325: train total loss -62.81818640303871, train mean loss 0.0006438152500598356, test mean loss [0.00054552 0.00044664 0.00067172 0.00070097 0.00032904 0.00031542
 0.00042364]
Model epoch 326: train total loss -62.472190061865376, train mean loss 0.0007058155708940697, test mean loss [0.00051703 0.00046636 0.00071373 0.0007045  0.0004757  0.0002925
 0.0004168 ]
Model epoch 327: train total loss -62.81772378819604, train mean loss 0.0006771048555815931, test mean loss [0.00049657 0.00044294 0.00071972 0.00069908 0.00038985 0.00030045
 0.00040223]
Model epoch 328: train total loss -62.63341431357393, train mean loss 0.0007151572236084413, test mean loss [0.00048666 0.0003917  0.00064955 0.00072236 0.00036858 0.00029189
 0.00040751]
Model epoch 329: train total loss -62.882687017951405, train mean loss 0.0006579729337452914, test mean loss [0.00049373 0.00038276 0.00061857 0.00065855 0.0003475  0.00030842
 0.00039935]
Model epoch 330: train total loss -62.73239636858978, train mean loss 0.00065180437701357, test mean loss [0.00048127 0.00041202 0.00060701 0.0006445  0.00037349 0.00030843
 0.00038917]
Model epoch 331: train total loss -63.06339877739158, train mean loss 0.0005909567229353206, test mean loss [0.00046878 0.00039606 0.00060588 0.00065837 0.00033707 0.00032874
 0.00039022]
Model epoch 332: train total loss -63.158825805439996, train mean loss 0.0005932352592462967, test mean loss [0.00048296 0.00037533 0.00062447 0.00064166 0.00033015 0.00033097
 0.00038601]
Model epoch 333: train total loss -62.981630269082046, train mean loss 0.0006221908488122364, test mean loss [0.00049969 0.000423   0.00061415 0.00060666 0.00032216 0.00030577
 0.0003811 ]
Model epoch 334: train total loss -62.58513317530806, train mean loss 0.0006109812147220884, test mean loss [0.00046731 0.00038215 0.00060172 0.00060672 0.00040988 0.0002958
 0.00038671]
Model epoch 335: train total loss -62.30825790368624, train mean loss 0.000718343477697906, test mean loss [0.00048043 0.00036438 0.0005665  0.00057441 0.00116917 0.00029
 0.00040448]
Model epoch 336: train total loss -62.3479793865245, train mean loss 0.0006990244672071767, test mean loss [0.00045956 0.00035763 0.00060254 0.00062344 0.0009981  0.0003078
 0.00037655]
Model epoch 337: train total loss -62.196006706136096, train mean loss 0.0007446264954543843, test mean loss [0.00045902 0.00036022 0.00057222 0.00058929 0.00085257 0.00077848
 0.00037182]
Model epoch 338: train total loss -62.408204882504435, train mean loss 0.0006361059449483346, test mean loss [0.00046857 0.00034741 0.0005673  0.00057465 0.00078476 0.00068486
 0.00038269]
Model epoch 339: train total loss -62.371321837405965, train mean loss 0.0006902171668384474, test mean loss [0.00047367 0.00035614 0.00055585 0.00056663 0.00074537 0.00060433
 0.00038299]
Model epoch 340: train total loss -62.64187349873548, train mean loss 0.000762232076994322, test mean loss [0.0004478  0.00035145 0.00055036 0.00057898 0.00068623 0.00048538
 0.00037266]
Model epoch 341: train total loss -62.650014998568174, train mean loss 0.0006241001400695206, test mean loss [0.00047579 0.00033801 0.00055838 0.00055248 0.00060497 0.0004569
 0.00046298]
Model epoch 342: train total loss -62.63890319531959, train mean loss 0.0006171322288146727, test mean loss [0.00044798 0.00035807 0.0005346  0.00053226 0.00053806 0.00043804
 0.00048274]
Model epoch 343: train total loss -62.95625366505491, train mean loss 0.0006168499102380329, test mean loss [0.00044621 0.00033772 0.00052204 0.00057    0.00052435 0.00042105
 0.0004213 ]
Model epoch 344: train total loss -62.97347833980592, train mean loss 0.0006003487261563267, test mean loss [0.00045488 0.00033202 0.00050178 0.00054774 0.00051799 0.0004059
 0.00040423]
Model epoch 345: train total loss -63.181060536314554, train mean loss 0.0005834787842511057, test mean loss [0.00043836 0.00032632 0.00051    0.00053409 0.00045924 0.00041403
 0.00039913]
Model epoch 346: train total loss -63.182829797162206, train mean loss 0.0005953380308766527, test mean loss [0.00046354 0.00035681 0.00048424 0.00050883 0.00044171 0.0003913
 0.00040214]
Model epoch 347: train total loss -63.32976678104206, train mean loss 0.0006052678301782189, test mean loss [0.00043237 0.00033185 0.00048591 0.00051202 0.00045182 0.00038162
 0.00040741]
Model epoch 348: train total loss -63.35175103929551, train mean loss 0.000556025150408256, test mean loss [0.00043805 0.00033051 0.00045683 0.00052726 0.00041735 0.00038574
 0.00039392]
Model epoch 349: train total loss -63.12349913438998, train mean loss 0.0005609463558074139, test mean loss [0.00044143 0.00032762 0.00047795 0.00050781 0.0004127  0.00034878
 0.00042477]
Model epoch 350: train total loss -62.898757764501084, train mean loss 0.000531396011826884, test mean loss [0.00042767 0.00034149 0.0004576  0.00050586 0.00038812 0.00036149
 0.00043076]
Model epoch 351: train total loss -62.95507047967486, train mean loss 0.0005381769646933864, test mean loss [0.00042339 0.00033683 0.00044954 0.00044819 0.0004218  0.00036268
 0.00044762]
Model epoch 352: train total loss -63.14492227467123, train mean loss 0.0005364098457861704, test mean loss [0.00041361 0.00032925 0.00045577 0.0004745  0.0003611  0.00034397
 0.00040688]
Model epoch 353: train total loss -63.275006490946794, train mean loss 0.0005696992995172656, test mean loss [0.00039958 0.00031854 0.00041353 0.00046685 0.00035018 0.00033538
 0.00041614]
Model epoch 354: train total loss -63.388113168169426, train mean loss 0.00047514748295439017, test mean loss [0.00040335 0.00035611 0.00039159 0.00047697 0.00033963 0.00035375
 0.0004098 ]
Model epoch 355: train total loss -63.47064408332969, train mean loss 0.0005229527957749976, test mean loss [0.00040283 0.00034737 0.00039222 0.0004387  0.00034571 0.00033453
 0.00042529]
Model epoch 356: train total loss -63.2724909601483, train mean loss 0.0005036231080815887, test mean loss [0.00040929 0.00033106 0.00044876 0.00049928 0.00045297 0.00033562
 0.00040201]
Model epoch 357: train total loss -63.096476533897174, train mean loss 0.0005826764069497489, test mean loss [0.00044155 0.00034239 0.00041043 0.00048967 0.00036313 0.00029617
 0.00039915]
Model epoch 358: train total loss -63.001806586066465, train mean loss 0.00048540245848345846, test mean loss [0.00043429 0.00033371 0.00038275 0.00046102 0.00034284 0.0002718
 0.00042419]
Model epoch 359: train total loss -62.54364583724779, train mean loss 0.0006404017638083131, test mean loss [0.00040964 0.00041601 0.00037437 0.00045564 0.00033213 0.00026362
 0.00116104]
Model epoch 360: train total loss -62.61462450994902, train mean loss 0.0006393542533408217, test mean loss [0.00041243 0.00040113 0.00038726 0.00040658 0.00031391 0.00026529
 0.00132725]
Model epoch 361: train total loss -62.92540641465469, train mean loss 0.0005579717865474945, test mean loss [0.00041179 0.00037758 0.00038708 0.00040945 0.0004458  0.00025793
 0.00123549]
Model epoch 362: train total loss -62.94250558092117, train mean loss 0.0006218661675144871, test mean loss [0.00040915 0.00036639 0.0003679  0.00040688 0.00033051 0.00025159
 0.00098042]
Model epoch 363: train total loss -63.054724973612025, train mean loss 0.0005553784495832067, test mean loss [0.00040574 0.00036949 0.00038828 0.00042105 0.0003444  0.00024445
 0.0007622 ]
Model epoch 364: train total loss -62.96133786011618, train mean loss 0.0005572858099471248, test mean loss [0.00044271 0.00037337 0.00034486 0.0004112  0.00032175 0.00024998
 0.00072465]
Model epoch 365: train total loss -63.17603797357985, train mean loss 0.0005210999117834799, test mean loss [0.00040443 0.00035445 0.00033851 0.00039641 0.00031142 0.00024853
 0.000654  ]
Model epoch 366: train total loss -62.733918371596125, train mean loss 0.0005012994562471323, test mean loss [0.00038321 0.00032492 0.00032773 0.00038296 0.00041217 0.00024766
 0.00061163]
Model epoch 367: train total loss -62.769340126005346, train mean loss 0.0007933623696568208, test mean loss [0.00040482 0.00031517 0.00031918 0.00038552 0.00370369 0.00024861
 0.00061289]
Model epoch 368: train total loss -62.72684602462717, train mean loss 0.0009945872280385701, test mean loss [0.00038711 0.00032341 0.00031869 0.00037187 0.00492602 0.00024409
 0.00055946]
Model epoch 369: train total loss -62.902910017064315, train mean loss 0.0011947628662600156, test mean loss [0.00039392 0.00031865 0.00030506 0.00038018 0.00475045 0.0002535
 0.00056109]
Model epoch 370: train total loss -63.18972839819351, train mean loss 0.0008910125897890164, test mean loss [0.00038803 0.0003012  0.00031219 0.00036715 0.00408304 0.00023809
 0.00052408]
Model epoch 371: train total loss -63.23239119876074, train mean loss 0.0009181183505304366, test mean loss [0.00037767 0.00030366 0.00029892 0.00037655 0.00361178 0.000253
 0.00051128]
Model epoch 372: train total loss -63.34030051180652, train mean loss 0.0008795273627845044, test mean loss [0.00036792 0.00029862 0.0003006  0.00036281 0.00320713 0.00024956
 0.00049993]
Model epoch 373: train total loss -63.35301147431446, train mean loss 0.0008257930251398284, test mean loss [0.00037552 0.00030591 0.0002953  0.00035347 0.00270215 0.00024645
 0.00047111]
Model epoch 374: train total loss -63.280382758958375, train mean loss 0.000699842841073983, test mean loss [0.00037362 0.00044791 0.00028347 0.0003687  0.00224723 0.00025523
 0.00049143]
Model epoch 375: train total loss -63.275538600710426, train mean loss 0.0006812037843841586, test mean loss [0.00036446 0.00032358 0.0002918  0.00034962 0.00189098 0.00023194
 0.00050139]
Model epoch 376: train total loss -63.454493014197915, train mean loss 0.0006220409267239517, test mean loss [0.0003592  0.00032687 0.00029462 0.00036537 0.0016309  0.00022834
 0.00045542]
Model epoch 377: train total loss -63.56148586167141, train mean loss 0.000621510740972671, test mean loss [0.00035519 0.00032267 0.00026994 0.00034728 0.00136176 0.00023277
 0.00047543]
Model epoch 378: train total loss -63.14320347596156, train mean loss 0.0005382731423944658, test mean loss [0.00036779 0.00031899 0.00026769 0.00036081 0.00114462 0.00026531
 0.00044877]
Model epoch 379: train total loss -63.499715700686615, train mean loss 0.0005528726195876982, test mean loss [0.00038549 0.00032075 0.00028084 0.00033969 0.00101829 0.00025635
 0.00042341]
Model epoch 380: train total loss -63.03881565004471, train mean loss 0.0006546929690519456, test mean loss [0.00035066 0.00031884 0.00141838 0.00036275 0.00097461 0.00024589
 0.00040165]
Model epoch 381: train total loss -62.08175237834795, train mean loss 0.0008369554527207279, test mean loss [0.00036259 0.00334235 0.00176808 0.00034457 0.00092544 0.00024134
 0.00039259]
Model epoch 382: train total loss -62.2828077066325, train mean loss 0.001444391185003327, test mean loss [0.0003688  0.00805602 0.00163008 0.00034351 0.00086772 0.00024345
 0.00037137]
Model epoch 383: train total loss -62.34968944407175, train mean loss 0.0017118519316282825, test mean loss [0.00035425 0.00906907 0.00123631 0.00032813 0.00081271 0.00024332
 0.00036361]
Model epoch 384: train total loss -62.63336802224735, train mean loss 0.0016856872375028763, test mean loss [0.00036012 0.00842752 0.00104224 0.00033613 0.0008025  0.00023499
 0.0003642 ]
Model epoch 385: train total loss -62.863387097189474, train mean loss 0.0014421826352752276, test mean loss [0.00034601 0.00778908 0.00088859 0.00038681 0.00075195 0.00024234
 0.00035233]
Model epoch 386: train total loss -63.042875764830825, train mean loss 0.0012530208730401817, test mean loss [0.00036363 0.00716549 0.00073806 0.00034616 0.0007215  0.00024602
 0.00033375]
Model epoch 387: train total loss -63.024910161013366, train mean loss 0.0013072620814910216, test mean loss [0.0003456  0.00652917 0.00068    0.00035078 0.00069894 0.00023414
 0.00035553]
Model epoch 388: train total loss -63.25747413004905, train mean loss 0.0011882887190938112, test mean loss [0.00033827 0.00583233 0.00061669 0.0003275  0.00066175 0.00023354
 0.00034933]
Model epoch 389: train total loss -63.26475849433081, train mean loss 0.0011835271578621903, test mean loss [0.00033448 0.00516372 0.00060956 0.00034344 0.00065409 0.00024132
 0.00035149]
Model epoch 390: train total loss -63.330616136389594, train mean loss 0.0010067791511157887, test mean loss [0.00035265 0.00451482 0.0005751  0.00037609 0.00064961 0.00023875
 0.00032948]
Model epoch 391: train total loss -63.260006862712785, train mean loss 0.0010580184021410919, test mean loss [0.00034959 0.00389691 0.00054202 0.00051474 0.00061299 0.00023565
 0.00032154]
Model epoch 392: train total loss -63.433319698022004, train mean loss 0.000871418792317398, test mean loss [0.00035434 0.00338433 0.00053428 0.00050975 0.00057674 0.00024081
 0.00031522]
Model epoch 393: train total loss -63.54191300887362, train mean loss 0.0008821055350899782, test mean loss [0.00034159 0.0029569  0.00054577 0.00048959 0.00057443 0.00023093
 0.00030828]
Model epoch 394: train total loss -63.53964917689196, train mean loss 0.0008398348661162963, test mean loss [0.00035112 0.0026383  0.00056228 0.00052259 0.00055721 0.00022541
 0.00030512]
Model epoch 395: train total loss -63.471665375911016, train mean loss 0.0007096136752826859, test mean loss [0.0003561  0.00239015 0.00050564 0.00050895 0.00052775 0.00022671
 0.00031478]
Model epoch 396: train total loss -63.40331164893918, train mean loss 0.0007673855884379546, test mean loss [0.000362   0.00219645 0.00050883 0.00050063 0.00050421 0.00024494
 0.00030915]
Model epoch 397: train total loss -63.629543786676805, train mean loss 0.0007409971574849012, test mean loss [0.00034005 0.0020274  0.00048734 0.00047236 0.00048683 0.00023771
 0.0003195 ]
Model epoch 398: train total loss -63.79705122744831, train mean loss 0.0005919232857817554, test mean loss [0.00034642 0.00190001 0.00048502 0.00045567 0.00043848 0.00022752
 0.00032722]
Model epoch 399: train total loss -63.89409173106245, train mean loss 0.000613191356408983, test mean loss [0.00033348 0.00179661 0.00050651 0.00044345 0.00041471 0.00022684
 0.0003161 ]
Model epoch 400: train total loss -63.6101004498754, train mean loss 0.0006489105681180423, test mean loss [0.00033788 0.00170849 0.00046456 0.00043203 0.00043595 0.00027334
 0.00030567]
Model trained in 401 epochs with 1000 transitions.
[2025-01-24 02:23:04,973][absl][INFO] - {'eval/walltime': 72.29572629928589, 'training/sps': 1.3718418476366907, 'training/walltime': 728.94700050354, 'training/model_train_time': 659.9678814411163, 'training/other_time': 68.14949107170105, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 10, 'training/env_buffer_size': Array(2000, dtype=int32), 'model/train_total_loss': Array(-63.61010045, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00064891, dtype=float64), 'model/test_total_loss': Array(-62.60505894, dtype=float64), 'model/test_mean_loss': Array(0.00056542, dtype=float64), 'model/train_epochs': 401, 'model/sec_per_epoch': 1.6416972004564623, 'sac/actor_loss': Array(-11.74530004, dtype=float64), 'sac/alpha': Array(0.9169318, dtype=float32), 'sac/alpha_loss': Array(9.71433079, dtype=float64), 'sac/buffer_current_size': Array(3600., dtype=float32), 'sac/critic_loss': Array(0.68994298, dtype=float64), 'eval/episode_forward_vel': Array(-203.43869194, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-0.14123559, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(51.32831289, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.8628492, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-87.50051266, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(52.51707408, dtype=float64), 'eval/episode_rew_roll': Array(51.99541345, dtype=float64), 'eval/episode_rew_side_motion': Array(68.93902832, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(70.58854963, dtype=float64), 'eval/episode_rew_yaw': Array(85.44484878, dtype=float64), 'eval/episode_rew_z_vel_change': Array(25.05939784, dtype=float64), 'eval/episode_reward': Array(319.4417322, dtype=float64), 'eval/episode_step_count': Array(499500., dtype=float64), 'eval/avg_episode_length': Array(1000., dtype=float64), 'eval/epoch_eval_time': 30.079638719558716, 'eval/sps': 33.245080146184364}
Steps / Eval:  2000.0
Reward is  319.4417321953254
Model horizon updated to 2.
Hallucination updates per training step updated to 257.
SAC buffer resized to 205600 samples.
Model epoch 0: train total loss -59.874537063218405, train mean loss 0.0008489701812665587, test mean loss [0.00073805 0.00210731 0.00069949 0.00070912 0.00077071 0.00048851
 0.00059183]
Model epoch 1: train total loss -61.54387697663585, train mean loss 0.0007617834742002509, test mean loss [0.0006081  0.00196258 0.00061216 0.00062831 0.00060737 0.00041912
 0.00046657]
Model epoch 2: train total loss -62.166060327934154, train mean loss 0.0006710328756598055, test mean loss [0.00056529 0.0018578  0.00059284 0.00056298 0.00054703 0.00039438
 0.00041556]
Model epoch 3: train total loss -62.44772870888243, train mean loss 0.0006721079541121049, test mean loss [0.00055812 0.00169581 0.00055788 0.00049095 0.00050223 0.00036653
 0.00040847]
Model epoch 4: train total loss -62.953608908150855, train mean loss 0.0006405211883345414, test mean loss [0.00050827 0.00161791 0.00051474 0.00046954 0.00048458 0.00035187
 0.00039434]
Model epoch 5: train total loss -63.06579227308253, train mean loss 0.0006500685805596301, test mean loss [0.00051024 0.00154923 0.00047278 0.00044315 0.00044208 0.00034887
 0.00038773]
Model epoch 6: train total loss -63.2336375189996, train mean loss 0.000586091137106418, test mean loss [0.00049803 0.001441   0.00042927 0.00043634 0.00042211 0.00033956
 0.00037037]
Model epoch 7: train total loss -63.19677160691743, train mean loss 0.0005245693319274967, test mean loss [0.00047192 0.00140074 0.00041331 0.00043104 0.00041693 0.00038849
 0.00037545]
Model epoch 8: train total loss -63.10742402504148, train mean loss 0.0006179866272979241, test mean loss [0.00048059 0.00138677 0.00038015 0.00043357 0.00040176 0.00034415
 0.0003635 ]
Model epoch 9: train total loss -63.25431297820095, train mean loss 0.0005501866162089526, test mean loss [0.00047534 0.00133267 0.00035138 0.00041446 0.00039816 0.00034562
 0.00035523]
Model epoch 10: train total loss -63.256200236156744, train mean loss 0.0005083686030881027, test mean loss [0.00046917 0.00126293 0.00035297 0.00040599 0.00039194 0.00036623
 0.00036421]
Model epoch 11: train total loss -63.45685795285373, train mean loss 0.0005270789932727275, test mean loss [0.00046299 0.00127808 0.00033491 0.00040579 0.00038136 0.00033217
 0.00034722]
Model epoch 12: train total loss -63.28754898479703, train mean loss 0.0005064150914693226, test mean loss [0.00045352 0.00119486 0.00033868 0.00040556 0.00038542 0.00030942
 0.00035354]
Model epoch 13: train total loss -63.34574606974649, train mean loss 0.0005365769685287956, test mean loss [0.00044175 0.00114849 0.0003293  0.00040152 0.00038065 0.00030797
 0.0003401 ]
Model epoch 14: train total loss -63.33857360033807, train mean loss 0.0004995710069780544, test mean loss [0.00044069 0.00112032 0.0003485  0.00040737 0.00037328 0.00031271
 0.00033751]
Model epoch 15: train total loss -63.3004110940996, train mean loss 0.0005109216662038603, test mean loss [0.00045056 0.00108665 0.00032409 0.00041281 0.00038878 0.00030534
 0.00034346]
Model epoch 16: train total loss -63.402644576753865, train mean loss 0.0004848042409339211, test mean loss [0.00043678 0.00107333 0.00031556 0.00039435 0.00036412 0.00029505
 0.00034319]
Model epoch 17: train total loss -63.494104491056554, train mean loss 0.00045348356274407825, test mean loss [0.00043376 0.00102214 0.00032184 0.00039049 0.0003612  0.00029355
 0.00033557]
Model epoch 18: train total loss -63.57470301135713, train mean loss 0.00045287585362804546, test mean loss [0.00043526 0.00099887 0.00031364 0.00038332 0.00035218 0.0003061
 0.00033637]
Model epoch 19: train total loss -63.52980751215933, train mean loss 0.00047133527260782203, test mean loss [0.00042024 0.00094899 0.00036475 0.00038018 0.00034754 0.00029144
 0.00031885]
Model epoch 20: train total loss -63.373624526940525, train mean loss 0.00040449355166260613, test mean loss [0.00042487 0.00090637 0.00030923 0.00037096 0.00035233 0.00029201
 0.00031852]
Model epoch 21: train total loss -63.46957504766472, train mean loss 0.00040477898929196785, test mean loss [0.00041006 0.00085142 0.00032015 0.00037446 0.00035212 0.00029249
 0.00031818]
Model epoch 22: train total loss -63.50625046220367, train mean loss 0.00040155337483903993, test mean loss [0.00042295 0.00084171 0.00030769 0.00037117 0.00034321 0.00029054
 0.00031468]
Model epoch 23: train total loss -63.38564817242027, train mean loss 0.00041561356156287005, test mean loss [0.00042232 0.00078498 0.00029896 0.00036774 0.00034233 0.00028657
 0.00031128]
Model epoch 24: train total loss -63.553317649668955, train mean loss 0.0004203745545312016, test mean loss [0.00041529 0.00073233 0.00031393 0.00036296 0.00033186 0.00028146
 0.00030372]
Model epoch 25: train total loss -63.37049338701765, train mean loss 0.00044285209833906197, test mean loss [0.00040983 0.00067745 0.00029498 0.00036465 0.00045623 0.00028919
 0.00030037]
Model epoch 26: train total loss -62.9682368342931, train mean loss 0.00042562864175261725, test mean loss [0.00045032 0.00068287 0.00035394 0.0003647  0.00038687 0.00027717
 0.00031409]
Model epoch 27: train total loss -63.24153055502966, train mean loss 0.00034836133666789186, test mean loss [0.00042587 0.00060816 0.0003186  0.00041473 0.00035528 0.00028144
 0.00031591]
Model epoch 28: train total loss -62.23355020106927, train mean loss 0.000412453837073995, test mean loss [0.00041614 0.00062844 0.00032286 0.00036649 0.00039808 0.00027402
 0.00031395]
Model epoch 29: train total loss -62.96081772695845, train mean loss 0.0004326309645774312, test mean loss [0.00042757 0.00058012 0.00030722 0.00035139 0.00048813 0.00027975
 0.00036399]
Model epoch 30: train total loss -62.996087524381785, train mean loss 0.00037839922364759206, test mean loss [0.00038962 0.00053294 0.00029523 0.00036609 0.00039585 0.00029708
 0.0003222 ]
Model epoch 31: train total loss -63.42868462725084, train mean loss 0.00037005999169782125, test mean loss [0.00038518 0.00052175 0.00029455 0.00035976 0.00038182 0.0002806
 0.00032007]
Model epoch 32: train total loss -63.191932823618046, train mean loss 0.0003570164636829809, test mean loss [0.00057409 0.0004837  0.00029302 0.00034924 0.00037522 0.00027105
 0.00030509]
Model epoch 33: train total loss -61.83235104353473, train mean loss 0.0010852461127782355, test mean loss [0.00058455 0.00046298 0.00028771 0.00709568 0.00036119 0.00028393
 0.00029615]
Model epoch 34: train total loss -61.71462898974224, train mean loss 0.0025962267501695806, test mean loss [0.00050028 0.0004405  0.0003009  0.01458629 0.00037289 0.000263
 0.00028577]
Model epoch 35: train total loss -62.154945916365925, train mean loss 0.0028935726097089483, test mean loss [0.00045255 0.00044961 0.00028338 0.01423979 0.0003557  0.0002865
 0.00029383]
Model epoch 36: train total loss -62.373752435359236, train mean loss 0.002810727247956, test mean loss [0.00044509 0.00040938 0.00030636 0.01283059 0.00033229 0.00027356
 0.00030029]
Model epoch 37: train total loss -62.80086288598796, train mean loss 0.0023027843173803572, test mean loss [0.00043798 0.00039639 0.0002836  0.01115069 0.00030934 0.00026617
 0.00028322]
Model epoch 38: train total loss -62.98777180127357, train mean loss 0.002271535066948715, test mean loss [0.00042694 0.00037767 0.00027597 0.00971516 0.00030812 0.00026931
 0.00027718]
Model epoch 39: train total loss -62.91671655716424, train mean loss 0.0015506477203601548, test mean loss [0.00041441 0.00038536 0.0002757  0.00826052 0.00030844 0.00026762
 0.00028386]
Model epoch 40: train total loss -62.945657369299866, train mean loss 0.0015406262935422936, test mean loss [0.00040291 0.00038537 0.00027542 0.00684696 0.00029719 0.0002633
 0.0002915 ]
Model epoch 41: train total loss -63.29587598132799, train mean loss 0.0012573212236817498, test mean loss [0.00039299 0.00037352 0.00026645 0.00569552 0.0002939  0.00025561
 0.00028452]
Model epoch 42: train total loss -63.1808966226713, train mean loss 0.0010577447781971473, test mean loss [0.00037955 0.00036844 0.00029312 0.00465149 0.00029326 0.00027852
 0.00027893]
Model epoch 43: train total loss -63.291169777138904, train mean loss 0.001011354957006512, test mean loss [0.00036749 0.00035625 0.00027633 0.0038493  0.00030538 0.00025653
 0.00026858]
Model epoch 44: train total loss -63.34267264065024, train mean loss 0.0008250469921914987, test mean loss [0.00037333 0.00038946 0.00027475 0.00343934 0.00029036 0.0002574
 0.00026875]
Model epoch 45: train total loss -63.60394917958295, train mean loss 0.0008471171077785039, test mean loss [0.00036724 0.00035909 0.00026954 0.00308912 0.00029122 0.00024631
 0.00027412]
Model epoch 46: train total loss -63.6697736759262, train mean loss 0.0006863340331725931, test mean loss [0.0003509  0.00036983 0.00026976 0.00282371 0.00028707 0.00025826
 0.00027493]
Model epoch 47: train total loss -63.67101359937109, train mean loss 0.0006989068304400086, test mean loss [0.00034773 0.00036093 0.00027141 0.00262992 0.00029467 0.00024787
 0.00027981]
Model epoch 48: train total loss -63.74922175492908, train mean loss 0.0006485594907501969, test mean loss [0.00035168 0.0003637  0.00025941 0.00257629 0.00028874 0.00025205
 0.0002727 ]
Model epoch 49: train total loss -63.86775870274435, train mean loss 0.0006815424396184475, test mean loss [0.00034896 0.00035902 0.00027164 0.00244768 0.00029149 0.00024328
 0.00026899]
Model epoch 50: train total loss -63.74788598220634, train mean loss 0.0006146194336941359, test mean loss [0.00038307 0.00034318 0.0002538  0.00227698 0.00028762 0.00025631
 0.00027475]
Model epoch 51: train total loss -63.78192239556652, train mean loss 0.0006417069138625817, test mean loss [0.00035379 0.00035037 0.00025644 0.00210232 0.00029353 0.0002482
 0.00027015]
Model epoch 52: train total loss -63.89169475287779, train mean loss 0.0005370824383222136, test mean loss [0.00033989 0.00034415 0.0002567  0.00197301 0.00028707 0.00023616
 0.00025742]
Model epoch 53: train total loss -63.9903580132226, train mean loss 0.0005387294890518377, test mean loss [0.00037156 0.00033506 0.00025326 0.00184275 0.00027642 0.00025073
 0.00027117]
Model epoch 54: train total loss -63.93744504371112, train mean loss 0.0005493527591787763, test mean loss [0.0003638  0.00033432 0.00025795 0.00169503 0.00028142 0.00024498
 0.00024688]
Model epoch 55: train total loss -63.91553307937236, train mean loss 0.0004984603777129442, test mean loss [0.00035078 0.00034606 0.00026264 0.00161957 0.00027626 0.00024943
 0.00025491]
Model epoch 56: train total loss -63.747288840678, train mean loss 0.0004610777254697504, test mean loss [0.00033564 0.00033858 0.00026801 0.00146018 0.00031487 0.00024436
 0.00026878]
Model epoch 57: train total loss -63.978640437110606, train mean loss 0.0004267331213332346, test mean loss [0.00032929 0.00033236 0.0002585  0.00138951 0.00027833 0.00025597
 0.0002559 ]
Model epoch 58: train total loss -63.9158025425343, train mean loss 0.0004607795432218381, test mean loss [0.00032313 0.00033006 0.00024786 0.0013341  0.0002866  0.00024234
 0.00024892]
Model epoch 59: train total loss -63.91084360118933, train mean loss 0.00041127612328114443, test mean loss [0.00033237 0.00032839 0.00024605 0.00126133 0.00028732 0.00023626
 0.00024816]
Model epoch 60: train total loss -63.90063113212018, train mean loss 0.0004315148993983958, test mean loss [0.00033292 0.00034157 0.00023974 0.00121747 0.00027082 0.00024673
 0.00025383]
Model epoch 61: train total loss -63.9771542044213, train mean loss 0.00045500444982300817, test mean loss [0.00032067 0.00032212 0.00025313 0.00113996 0.00026459 0.00023916
 0.0002474 ]
Model epoch 62: train total loss -64.1728312958233, train mean loss 0.0003750046699561614, test mean loss [0.00033488 0.00032333 0.00025075 0.00110476 0.00026179 0.00023561
 0.00024459]
Model epoch 63: train total loss -64.05416174122576, train mean loss 0.0004019367669366548, test mean loss [0.0003251  0.00031832 0.00025488 0.00107058 0.00026463 0.00023264
 0.00026453]
Model epoch 64: train total loss -64.0131475346593, train mean loss 0.00039387324043278164, test mean loss [0.00033803 0.00031134 0.00025006 0.00106026 0.0002621  0.00026031
 0.00024324]
Model epoch 65: train total loss -63.928255099750096, train mean loss 0.00036749803398150637, test mean loss [0.00031491 0.00031647 0.00024676 0.00099459 0.00025797 0.00024062
 0.00023604]
Model epoch 66: train total loss -64.03178817212539, train mean loss 0.00043415467179331224, test mean loss [0.00031409 0.00031817 0.00023547 0.00107438 0.0002518  0.00023997
 0.00025419]
Model epoch 67: train total loss -64.14936126604408, train mean loss 0.00036814362894320424, test mean loss [0.00030664 0.00031261 0.0002376  0.00094459 0.00027357 0.00023613
 0.00023897]
Model epoch 68: train total loss -64.06082730210386, train mean loss 0.00034069863482889974, test mean loss [0.00030601 0.00031234 0.00024338 0.0009243  0.00025432 0.00025567
 0.00023793]
Model epoch 69: train total loss -64.07262790503191, train mean loss 0.00038142266115584103, test mean loss [0.00030757 0.00032842 0.00024853 0.00088242 0.00025723 0.0002376
 0.00023878]
Model epoch 70: train total loss -63.92538913825646, train mean loss 0.0003569567141377285, test mean loss [0.00030312 0.00032109 0.00025783 0.00086105 0.00029015 0.00022791
 0.00023685]
Model epoch 71: train total loss -64.00388758065054, train mean loss 0.0003305208156858411, test mean loss [0.00030575 0.00032707 0.00024013 0.00080324 0.00025977 0.00022606
 0.00025542]
Model epoch 72: train total loss -64.09943323594658, train mean loss 0.0003684098996780419, test mean loss [0.00030443 0.00031831 0.00024095 0.00077581 0.00025935 0.000232
 0.00023679]
Model epoch 73: train total loss -64.16041831795997, train mean loss 0.0003454975535305087, test mean loss [0.00030488 0.00032302 0.00025765 0.00078146 0.00025543 0.00022229
 0.00023643]
Model epoch 74: train total loss -64.304909812918, train mean loss 0.00032164810676413004, test mean loss [0.00030063 0.00029568 0.00023362 0.00070759 0.00026443 0.00024584
 0.00022545]
Model epoch 75: train total loss -61.86255321282422, train mean loss 0.0003709866668578489, test mean loss [0.0003011  0.00036258 0.00030132 0.00072076 0.00025572 0.00022412
 0.0002259 ]
Model epoch 76: train total loss -63.35803918587813, train mean loss 0.0004317873068507744, test mean loss [0.00028915 0.00033803 0.00066244 0.00065533 0.00024604 0.00024149
 0.00022067]
Model epoch 77: train total loss -63.46834936317283, train mean loss 0.0003562874190853163, test mean loss [0.00029564 0.00031026 0.00040359 0.00062881 0.00029526 0.00021253
 0.00022563]
Model epoch 78: train total loss -63.46100954493017, train mean loss 0.000385398360197863, test mean loss [0.00030097 0.00038711 0.0003507  0.00058887 0.00026548 0.00022669
 0.00023126]
Model epoch 79: train total loss -63.891247392482235, train mean loss 0.0003207114759236174, test mean loss [0.00029512 0.00032449 0.00032463 0.00055638 0.00025931 0.00023256
 0.00022403]
Model epoch 80: train total loss -63.97392930107041, train mean loss 0.00033536595937677487, test mean loss [0.00028961 0.00033302 0.00031026 0.0005217  0.00024633 0.00022776
 0.00023156]
Model epoch 81: train total loss -64.22412391277203, train mean loss 0.0003408907201355876, test mean loss [0.00030552 0.00032306 0.00028838 0.00050553 0.00023536 0.00022335
 0.00021912]
Model epoch 82: train total loss -64.33838596751656, train mean loss 0.00028506266138132405, test mean loss [0.0002886  0.00030642 0.00026647 0.00045129 0.00024287 0.00021664
 0.00021637]
Model epoch 83: train total loss -64.34396228795508, train mean loss 0.00027994181314171224, test mean loss [0.00028955 0.00030904 0.00026464 0.00044241 0.00025166 0.00021796
 0.0002217 ]
Model epoch 84: train total loss -64.09414579791974, train mean loss 0.00027346604964164365, test mean loss [0.00029558 0.00032235 0.00028263 0.0003961  0.00023673 0.00022547
 0.00022384]
Model epoch 85: train total loss -63.689142203463696, train mean loss 0.00026517405367955306, test mean loss [0.00028393 0.00031518 0.00024683 0.00039012 0.00023644 0.00022221
 0.00023248]
Model epoch 86: train total loss -63.92102940301284, train mean loss 0.0002818238905804889, test mean loss [0.00028482 0.00029809 0.00024376 0.00035592 0.0002442  0.00023458
 0.00023344]
Model epoch 87: train total loss -64.1222614395511, train mean loss 0.00025856124378690834, test mean loss [0.00028126 0.00030498 0.00024428 0.00035363 0.00023756 0.000226
 0.00022161]
Model epoch 88: train total loss -64.1998991307872, train mean loss 0.0002613438617045716, test mean loss [0.00027616 0.00030394 0.00024989 0.00033618 0.00024253 0.00023667
 0.00021701]
Model epoch 89: train total loss -64.20588221134703, train mean loss 0.00023817924026452086, test mean loss [0.00028107 0.00028788 0.00023012 0.00031819 0.00024048 0.00022665
 0.00022268]
Model epoch 90: train total loss -64.38933221292497, train mean loss 0.0002471977761388678, test mean loss [0.00028096 0.0002801  0.00023076 0.00031413 0.00023882 0.00022094
 0.00021788]
Model epoch 91: train total loss -64.41491850332075, train mean loss 0.00022590370636310238, test mean loss [0.00027777 0.00028296 0.00023395 0.00030047 0.00023952 0.00022404
 0.00022596]
Model epoch 92: train total loss -64.16021847699288, train mean loss 0.00024337459696139116, test mean loss [0.00028128 0.00028027 0.00024708 0.00029996 0.00023053 0.00021551
 0.00023742]
Model epoch 93: train total loss -64.21670338777344, train mean loss 0.00024894917226104873, test mean loss [0.00027066 0.0002788  0.00023259 0.00030193 0.00025289 0.00022019
 0.00023498]
Model epoch 94: train total loss -64.42290567050037, train mean loss 0.00024784003503310856, test mean loss [0.00026553 0.00027588 0.0002237  0.00029655 0.00023896 0.00021444
 0.00023372]
Model epoch 95: train total loss -64.38867231235714, train mean loss 0.0002504830440984579, test mean loss [0.00026431 0.00027506 0.00023455 0.00029329 0.00022641 0.00021207
 0.00022134]
Model epoch 96: train total loss -64.42173749088101, train mean loss 0.00022021432299941746, test mean loss [0.00027134 0.00027485 0.0002298  0.0002853  0.00022676 0.00021698
 0.00022614]
Model epoch 97: train total loss -64.38943827237108, train mean loss 0.00023067994343132473, test mean loss [0.00027811 0.00027476 0.00022322 0.00028818 0.00025188 0.00020883
 0.00020758]
Model epoch 98: train total loss -64.41258473895545, train mean loss 0.00021074140575822083, test mean loss [0.00027245 0.00027178 0.0002156  0.00029106 0.00023358 0.00026022
 0.00024648]
Model epoch 99: train total loss -64.23264293129301, train mean loss 0.0002227390255710268, test mean loss [0.00026596 0.00027062 0.00025229 0.0002875  0.00022231 0.00021344
 0.00021602]
Model epoch 100: train total loss -64.45857844940932, train mean loss 0.00022114502282222313, test mean loss [0.00027177 0.00026238 0.00022654 0.00027744 0.00022644 0.00021423
 0.00020866]
Model epoch 101: train total loss -64.48725332269092, train mean loss 0.0002353037924024348, test mean loss [0.00028549 0.00026511 0.00022002 0.00027528 0.00021647 0.00025016
 0.00020542]
Model epoch 102: train total loss -62.77919378999618, train mean loss 0.00024139494169823775, test mean loss [0.00027303 0.00026791 0.00020866 0.00027467 0.00021929 0.00029834
 0.00075499]
Model epoch 103: train total loss -63.22640060443268, train mean loss 0.0008002325370769029, test mean loss [0.00034258 0.0002634  0.00022024 0.00027136 0.00021595 0.00026925
 0.00462823]
Model epoch 104: train total loss -63.2635270945647, train mean loss 0.001000937502819298, test mean loss [0.00031104 0.00027695 0.00021618 0.00040011 0.00022351 0.00024266
 0.00435799]
Model epoch 105: train total loss -63.354943436637114, train mean loss 0.0007584778159482736, test mean loss [0.00031627 0.00026253 0.00021201 0.00032787 0.00022946 0.00022269
 0.00363648]
Model epoch 106: train total loss -63.8783209205811, train mean loss 0.0005982085900842897, test mean loss [0.00029112 0.00026074 0.00020839 0.00028682 0.00021913 0.0002182
 0.00275987]
Model epoch 107: train total loss -64.23780681688491, train mean loss 0.0005005293816957218, test mean loss [0.00027623 0.00025838 0.00022804 0.00027562 0.00021156 0.00021926
 0.00217503]
Model epoch 108: train total loss -63.97377106503999, train mean loss 0.00048342744064330584, test mean loss [0.0002783  0.00025685 0.00021492 0.00027385 0.00025231 0.00020875
 0.00179674]
Model epoch 109: train total loss -63.959781138005056, train mean loss 0.0005296347850662202, test mean loss [0.00026412 0.00025944 0.00022942 0.00027306 0.00098444 0.00021628
 0.00161837]
Model epoch 110: train total loss -64.13824796880611, train mean loss 0.0005379419953862481, test mean loss [0.00026519 0.00026037 0.00020505 0.00026827 0.00070429 0.000206
 0.00150285]
Model epoch 111: train total loss -64.35551132823666, train mean loss 0.00037281210056362934, test mean loss [0.00025359 0.00026606 0.00020298 0.00027422 0.00051615 0.00021018
 0.00137738]
Model epoch 112: train total loss -64.49991569653302, train mean loss 0.00040415311576987077, test mean loss [0.00025091 0.00026229 0.00020075 0.00027319 0.00045242 0.0002085
 0.00129304]
Model epoch 113: train total loss -64.43052517836054, train mean loss 0.00038073260688881345, test mean loss [0.00024972 0.00025807 0.00021314 0.000276   0.00044649 0.00021892
 0.00119533]
Model epoch 114: train total loss -64.50572662290361, train mean loss 0.00039197539717408477, test mean loss [0.00025445 0.00026338 0.00020525 0.00026242 0.00040637 0.00021887
 0.00117473]
Model epoch 115: train total loss -64.30561305882752, train mean loss 0.0003601328384355365, test mean loss [0.00025416 0.00025734 0.00019913 0.00027589 0.0004446  0.00020395
 0.00112004]
Model epoch 116: train total loss -64.30713373882513, train mean loss 0.0003568090658092087, test mean loss [0.00025128 0.00025112 0.00019646 0.00026692 0.00039237 0.00021298
 0.00108511]
Model epoch 117: train total loss -64.64714670544099, train mean loss 0.00036292542748662926, test mean loss [0.00024878 0.00025261 0.00020126 0.00026393 0.00038356 0.00021133
 0.0010568 ]
Model epoch 118: train total loss -64.73782693553018, train mean loss 0.0003414550242989152, test mean loss [0.00024135 0.00025408 0.00019985 0.00026352 0.00037577 0.00020331
 0.00099602]
Model epoch 119: train total loss -64.68961274101285, train mean loss 0.00033307454392515534, test mean loss [0.00025232 0.00024566 0.000201   0.00026244 0.00036292 0.00020867
 0.00096416]
Model epoch 120: train total loss -64.6761635166776, train mean loss 0.0003272445920283514, test mean loss [0.00025306 0.00024965 0.00020684 0.00026405 0.00034015 0.00019812
 0.00094461]
Model epoch 121: train total loss -64.45358986288645, train mean loss 0.00032585720641503934, test mean loss [0.00026182 0.00024043 0.00020548 0.00025053 0.00035055 0.0002047
 0.00091664]
Model epoch 122: train total loss -64.49411323304635, train mean loss 0.00034700357105475825, test mean loss [0.00024228 0.00024218 0.00019761 0.00025911 0.00033136 0.00020299
 0.00090701]
Model epoch 123: train total loss -64.66502723675795, train mean loss 0.00033757118696089777, test mean loss [0.00024739 0.00023788 0.00020507 0.00026053 0.00032585 0.00020034
 0.00085485]
Model epoch 124: train total loss -64.79171921742343, train mean loss 0.0002954715441485472, test mean loss [0.00024385 0.00024371 0.00019478 0.00025267 0.00030507 0.00021219
 0.00085124]
Model epoch 125: train total loss -64.78149331995328, train mean loss 0.0002874408400252997, test mean loss [0.00025179 0.00024322 0.00020807 0.00025282 0.00027991 0.0001967
 0.0008411 ]
Model epoch 126: train total loss -64.45538932774178, train mean loss 0.00032529015490666676, test mean loss [0.00026367 0.00025112 0.00020383 0.00025581 0.0002724  0.00019903
 0.00083114]
Model epoch 127: train total loss -64.62491759604886, train mean loss 0.0003104575166957553, test mean loss [0.00025283 0.00023814 0.00019964 0.00024875 0.00025793 0.00019835
 0.00081276]
Model epoch 128: train total loss -64.73530149485696, train mean loss 0.0002867087403024451, test mean loss [0.00024845 0.00023734 0.00019898 0.00024906 0.00024198 0.00019666
 0.00075012]
Model epoch 129: train total loss -64.76361351738417, train mean loss 0.00029706644765465983, test mean loss [0.00023668 0.00023744 0.00019973 0.00024724 0.00021872 0.00018983
 0.00074678]
Model epoch 130: train total loss -64.66026556393834, train mean loss 0.0002772192137625855, test mean loss [0.00024066 0.00022958 0.00019807 0.00026022 0.00020261 0.00019635
 0.00073175]
Model epoch 131: train total loss -64.69359566801351, train mean loss 0.00027014333040467755, test mean loss [0.00025612 0.00023969 0.00020006 0.00025281 0.00019937 0.00018998
 0.00069783]
Model epoch 132: train total loss -64.64228152026047, train mean loss 0.0002768818185234753, test mean loss [0.00025134 0.00023236 0.00019899 0.00024362 0.00020548 0.00019397
 0.00067879]
Model epoch 133: train total loss -64.46097160846844, train mean loss 0.00026816948635829604, test mean loss [0.0002457  0.00023656 0.00020291 0.00027375 0.00020212 0.00019469
 0.00070444]
Model epoch 134: train total loss -64.70269863097228, train mean loss 0.0002530825111428229, test mean loss [0.00024503 0.00023701 0.00019481 0.00024618 0.00019813 0.00019589
 0.00066873]
Model epoch 135: train total loss -64.8636762051264, train mean loss 0.0002425731874003382, test mean loss [0.00025259 0.00023429 0.00019625 0.00024245 0.00019297 0.00021189
 0.00064166]
Model epoch 136: train total loss -64.87795132221582, train mean loss 0.0002665692231636377, test mean loss [0.00022862 0.00024735 0.00019376 0.00024402 0.00018972 0.00019155
 0.00064968]
Model epoch 137: train total loss -64.79012719520544, train mean loss 0.0002624880450502569, test mean loss [0.00024119 0.00023152 0.00020422 0.00023211 0.00019192 0.0001859
 0.00063974]
Model epoch 138: train total loss -64.93622918288199, train mean loss 0.00024265971573747514, test mean loss [0.00023371 0.00022897 0.00018367 0.0002409  0.0001978  0.00019456
 0.00060247]
Model epoch 139: train total loss -64.80662970474759, train mean loss 0.0002707738158572691, test mean loss [0.00023921 0.00022451 0.00019271 0.00024229 0.00019597 0.00019016
 0.00060555]
Model epoch 140: train total loss -64.02901492488814, train mean loss 0.0002781333595168315, test mean loss [0.00023272 0.00047638 0.00019196 0.00024496 0.00018903 0.00019063
 0.00057047]
Model epoch 141: train total loss -64.26978491563221, train mean loss 0.0002985784997076952, test mean loss [0.00023063 0.00042526 0.00019739 0.00024099 0.00019272 0.00019215
 0.00059709]
Model epoch 142: train total loss -64.64313074425333, train mean loss 0.0002727702456504664, test mean loss [0.0002268  0.0003148  0.00019692 0.00022584 0.00018871 0.00019768
 0.00059481]
Model epoch 143: train total loss -64.730480497645, train mean loss 0.00022995324150805943, test mean loss [0.00024769 0.00026241 0.00019273 0.00022912 0.00018606 0.00018498
 0.00056769]
Model epoch 144: train total loss -64.88954952717229, train mean loss 0.0002460323565883692, test mean loss [0.00022647 0.00025507 0.00019703 0.00022571 0.00019187 0.00019341
 0.00055159]
Model epoch 145: train total loss -64.90432973089001, train mean loss 0.00024252244163805266, test mean loss [0.00023729 0.00023878 0.00019181 0.00023519 0.00018713 0.00018476
 0.00053267]
Model epoch 146: train total loss -64.92158343191188, train mean loss 0.00024684225860713684, test mean loss [0.00023835 0.0002352  0.00018626 0.00022976 0.00018122 0.00018531
 0.00050997]
Model epoch 147: train total loss -65.05500867864907, train mean loss 0.0002339365813612583, test mean loss [0.00023833 0.00024036 0.00019245 0.00022876 0.00019008 0.00018285
 0.00048489]
Model epoch 148: train total loss -64.91765215027218, train mean loss 0.0002135562644773004, test mean loss [0.00023093 0.00023226 0.00019227 0.00024185 0.00018416 0.00018292
 0.00047205]
Model epoch 149: train total loss -64.82059237579098, train mean loss 0.0002207278311574056, test mean loss [0.00022733 0.00023643 0.0001814  0.00023991 0.00018724 0.00020618
 0.00047321]
Model epoch 150: train total loss -64.64983759325686, train mean loss 0.00022424959638250616, test mean loss [0.00022653 0.00023238 0.00018722 0.00022441 0.00018517 0.00021254
 0.00044296]
Model epoch 151: train total loss -64.74793149420394, train mean loss 0.0002142005690439268, test mean loss [0.00023028 0.0002428  0.0001956  0.00024559 0.00018606 0.00018224
 0.00042106]
Model epoch 152: train total loss -64.78186149980512, train mean loss 0.00022795194858183705, test mean loss [0.00024293 0.00025748 0.00018353 0.00022792 0.00018274 0.00019024
 0.00042079]
Model epoch 153: train total loss -64.90231059015782, train mean loss 0.00019916264856291305, test mean loss [0.00023402 0.00023501 0.00018537 0.00022929 0.00018925 0.00018519
 0.00038877]
Model epoch 154: train total loss -64.72178288057516, train mean loss 0.00021678598001216066, test mean loss [0.00021861 0.00023345 0.0001866  0.00022474 0.00018919 0.00030054
 0.00036153]
Model epoch 155: train total loss -64.53684001549826, train mean loss 0.0002268852935346198, test mean loss [0.00022865 0.00023673 0.00018069 0.00022249 0.0001917  0.00024165
 0.00034252]
Model epoch 156: train total loss -64.73742095287504, train mean loss 0.00022113548925898344, test mean loss [0.00023915 0.00024042 0.0001793  0.00022012 0.00018388 0.00020295
 0.00035306]
Model epoch 157: train total loss -64.95596305863049, train mean loss 0.00022671250724937549, test mean loss [0.00022168 0.0002287  0.00018022 0.00021733 0.00018248 0.00019161
 0.00032118]
Model epoch 158: train total loss -64.73577316022909, train mean loss 0.00021417361282698844, test mean loss [0.0002215  0.00023319 0.00020917 0.00021681 0.00018349 0.00018276
 0.0002949 ]
Model epoch 159: train total loss -64.41714020949173, train mean loss 0.00024210529184672382, test mean loss [0.00022631 0.00023073 0.00018123 0.0002228  0.00019303 0.00035648
 0.00027939]
Model epoch 160: train total loss -64.49287223197304, train mean loss 0.00021878774915142906, test mean loss [0.0002269  0.000236   0.00017826 0.00021722 0.00018177 0.00024907
 0.00026538]
Model epoch 161: train total loss -64.59205870125885, train mean loss 0.00020121948631381998, test mean loss [0.00022791 0.00022394 0.00021373 0.00022114 0.0001816  0.00020828
 0.00025737]
Model epoch 162: train total loss -64.86471678510313, train mean loss 0.00021679592897896275, test mean loss [0.00022368 0.00022737 0.00018739 0.00021601 0.00018095 0.00019587
 0.00024867]
Model epoch 163: train total loss -64.95904621673176, train mean loss 0.00018801466618961017, test mean loss [0.00021794 0.00021601 0.00018193 0.00022533 0.00017907 0.0001941
 0.00022787]
Model epoch 164: train total loss -65.06271666601016, train mean loss 0.00016729680679747222, test mean loss [0.00022044 0.00021472 0.00018105 0.00021988 0.00018316 0.00018934
 0.00021895]
Model epoch 165: train total loss -65.12985224242716, train mean loss 0.00017404031173022367, test mean loss [0.00021471 0.00020695 0.00017469 0.00021597 0.00017837 0.00018825
 0.00020533]
Model epoch 166: train total loss -64.95211413623531, train mean loss 0.00017139220371103012, test mean loss [0.00025117 0.00020125 0.00017722 0.00021244 0.00017146 0.00024792
 0.00020215]
Model epoch 167: train total loss -64.57476840555329, train mean loss 0.0001692893874460183, test mean loss [0.00022454 0.00020025 0.00017973 0.00020972 0.00018397 0.00025268
 0.00018654]
Model epoch 168: train total loss -64.67364971405033, train mean loss 0.0001972054909325918, test mean loss [0.00022452 0.00020108 0.00017836 0.00021611 0.00017786 0.00021891
 0.00018373]
Model epoch 169: train total loss -64.76582326921624, train mean loss 0.0001797011422593635, test mean loss [0.00021785 0.00022581 0.00020053 0.00021414 0.00018378 0.00019572
 0.00018303]
Model epoch 170: train total loss -64.90542105598014, train mean loss 0.0001798651744824457, test mean loss [0.00021504 0.00021358 0.0001764  0.00021118 0.00018277 0.00018743
 0.00017478]
Model epoch 171: train total loss -65.12843063163866, train mean loss 0.0001595883516920278, test mean loss [0.00021837 0.00020153 0.00017426 0.0002124  0.00017963 0.00018655
 0.00017745]
Model epoch 172: train total loss -64.89544215059672, train mean loss 0.00017540238616206425, test mean loss [0.00021329 0.00019693 0.00018628 0.00020193 0.00018459 0.00020415
 0.00018437]
Model epoch 173: train total loss -65.07277741921895, train mean loss 0.00017082394984575577, test mean loss [0.00020832 0.00019728 0.00017608 0.00020705 0.00017023 0.00018929
 0.00018195]
Model epoch 174: train total loss -64.99654192942694, train mean loss 0.00017006801841492757, test mean loss [0.00020649 0.00019348 0.00017232 0.00020218 0.00017126 0.00018679
 0.00018496]
Model epoch 175: train total loss -65.06938414854228, train mean loss 0.00017780258958063265, test mean loss [0.00022006 0.00019499 0.00017319 0.00021575 0.00017174 0.00017583
 0.00019248]
Model epoch 176: train total loss -65.1176464614211, train mean loss 0.000169614821212256, test mean loss [0.00020962 0.0001901  0.00016948 0.00021168 0.00017172 0.0001776
 0.00019058]
Model epoch 177: train total loss -65.25032419874209, train mean loss 0.00017205381277040735, test mean loss [0.00020881 0.00021862 0.00017514 0.00020386 0.0001727  0.00018902
 0.00018051]
Model epoch 178: train total loss -65.10755039755072, train mean loss 0.0001714771836038802, test mean loss [0.00020809 0.00019926 0.00016938 0.00020698 0.00016677 0.00018784
 0.00023231]
Model epoch 179: train total loss -65.07115640014818, train mean loss 0.0001748501980012366, test mean loss [0.0002116  0.00019037 0.00018671 0.00021182 0.00017163 0.00017406
 0.00022038]
Model epoch 180: train total loss -65.09293295173067, train mean loss 0.00015537940129736432, test mean loss [0.00020846 0.00018952 0.00018383 0.00020957 0.00017251 0.00017007
 0.00019663]
Model epoch 181: train total loss -64.97553945690953, train mean loss 0.00017017721796727916, test mean loss [0.00022557 0.00020103 0.00017451 0.000202   0.00017084 0.0001754
 0.00019706]
Model epoch 182: train total loss -65.075299562992, train mean loss 0.00017677494960731738, test mean loss [0.00020602 0.00021104 0.00016749 0.00020812 0.00016939 0.00017515
 0.0001887 ]
Model epoch 183: train total loss -65.17856939634345, train mean loss 0.00018070905339799518, test mean loss [0.00020385 0.00019941 0.00017386 0.00020886 0.00016542 0.00017874
 0.00017582]
Model epoch 184: train total loss -65.23750933087298, train mean loss 0.00016119012480279906, test mean loss [0.00020833 0.00018609 0.00017201 0.00020309 0.00017273 0.00016972
 0.00017645]
Model epoch 185: train total loss -65.19790384327568, train mean loss 0.00016126377094298735, test mean loss [0.00021216 0.00019499 0.0001871  0.00020946 0.00016671 0.00016973
 0.00017313]
Model epoch 186: train total loss -65.27357856986251, train mean loss 0.00016960249651318073, test mean loss [0.00020716 0.00019339 0.00017053 0.00021556 0.00016273 0.00016952
 0.00017768]
Model epoch 187: train total loss -65.1896429957285, train mean loss 0.00016873998744762757, test mean loss [0.00020377 0.00018319 0.00017639 0.00020184 0.00017308 0.00017485
 0.000176  ]
Model epoch 188: train total loss -65.24117700593905, train mean loss 0.00016859665962181542, test mean loss [0.00021434 0.00018908 0.00016765 0.00019637 0.00017376 0.00018153
 0.00017256]
Model epoch 189: train total loss -65.22190280434813, train mean loss 0.00016069906890513403, test mean loss [0.00021741 0.00018533 0.0001679  0.00019985 0.00018124 0.00016869
 0.00017414]
Model epoch 190: train total loss -65.3192915633355, train mean loss 0.00015434416194542771, test mean loss [0.00021471 0.00018487 0.00017243 0.00019846 0.00016686 0.00017645
 0.00018255]
Model epoch 191: train total loss -65.16313663537173, train mean loss 0.0001666034674640397, test mean loss [0.00020771 0.00020053 0.00017182 0.00019693 0.00017268 0.0001716
 0.00017029]
Model epoch 192: train total loss -65.2312033271429, train mean loss 0.00016757922200924332, test mean loss [0.00020472 0.00019117 0.00017207 0.00019567 0.00017284 0.00016922
 0.00017296]
Model epoch 193: train total loss -65.36194574869103, train mean loss 0.00015833452642153832, test mean loss [0.00020693 0.00018656 0.0001698  0.00019284 0.0001576  0.0001694
 0.0001807 ]
Model epoch 194: train total loss -65.30985400381618, train mean loss 0.00015373000540896335, test mean loss [0.00020392 0.00018153 0.00016524 0.00019103 0.00016001 0.00016686
 0.00016896]
Model epoch 195: train total loss -64.87434008215182, train mean loss 0.00017288504022676713, test mean loss [0.00019818 0.00029937 0.00017948 0.00019732 0.00017544 0.00016879
 0.00017876]
Model epoch 196: train total loss -64.9150070445472, train mean loss 0.00017515241682285169, test mean loss [0.00020127 0.00022183 0.00015903 0.00021139 0.00016862 0.00017438
 0.00019068]
Model epoch 197: train total loss -65.05375844249097, train mean loss 0.0001685361923240426, test mean loss [0.00020674 0.00020016 0.00016927 0.00019062 0.00016102 0.00017366
 0.00017639]
Model epoch 198: train total loss -65.13473704496866, train mean loss 0.00017643188091395865, test mean loss [0.00020831 0.00018548 0.00016429 0.00019303 0.00016681 0.00017127
 0.00017077]
Model epoch 199: train total loss -65.31656046167164, train mean loss 0.00016067812638840152, test mean loss [0.00020294 0.00018607 0.00016625 0.00019523 0.0001718  0.00016762
 0.0001752 ]
Model epoch 200: train total loss -65.12260799681853, train mean loss 0.0001574129456476633, test mean loss [0.00020035 0.0002059  0.00016122 0.00019267 0.00015992 0.00015842
 0.00018532]
Model epoch 201: train total loss -65.43103832155283, train mean loss 0.00014993068741577163, test mean loss [0.00019711 0.00019373 0.00016034 0.00019012 0.00015728 0.00016741
 0.00016859]
Model epoch 202: train total loss -65.46144750815041, train mean loss 0.00014716158594309643, test mean loss [0.00020959 0.00018672 0.00016187 0.00018435 0.00016304 0.00015999
 0.00017113]
Model epoch 203: train total loss -65.38029433462077, train mean loss 0.00015990391535841998, test mean loss [0.00020408 0.00017688 0.00016523 0.0001986  0.00018507 0.00016869
 0.00017263]
Model epoch 204: train total loss -64.16664885710112, train mean loss 0.00017541074040375572, test mean loss [0.00020254 0.00026065 0.00016479 0.0001881  0.00016764 0.00019272
 0.00018031]
Model epoch 205: train total loss -64.83142362053472, train mean loss 0.00017779801803182908, test mean loss [0.00019645 0.00034355 0.00016223 0.00019428 0.00016312 0.00018893
 0.00020026]
Model epoch 206: train total loss -64.99541521976451, train mean loss 0.0001789380645578239, test mean loss [0.00019443 0.00029064 0.00016776 0.00018639 0.00017118 0.00016672
 0.00017516]
Model epoch 207: train total loss -65.11430049965057, train mean loss 0.00016306761770128257, test mean loss [0.00019826 0.00028132 0.00016483 0.00019043 0.00016575 0.00017684
 0.00017637]
Model epoch 208: train total loss -65.0410478660398, train mean loss 0.0001613368769505635, test mean loss [0.00020418 0.00027344 0.00016865 0.00018311 0.00016391 0.00016478
 0.00017443]
Model epoch 209: train total loss -65.18951586740232, train mean loss 0.00016319276883450747, test mean loss [0.0001954  0.00022679 0.00017532 0.00018439 0.00015825 0.00016364
 0.00017222]
Model epoch 210: train total loss -65.27812988904527, train mean loss 0.00015384925540918405, test mean loss [0.00020148 0.00022601 0.00015786 0.00017837 0.00018422 0.00016812
 0.00016835]
Model epoch 211: train total loss -64.43750038115047, train mean loss 0.0002897663517318108, test mean loss [0.00019529 0.00022172 0.00016034 0.00018221 0.00075421 0.00016781
 0.00016628]
Model epoch 212: train total loss -64.63520410665784, train mean loss 0.00025701794523663203, test mean loss [0.00019053 0.00021088 0.0001533  0.00017942 0.00071243 0.00016514
 0.0001699 ]
Model epoch 213: train total loss -64.63042157364403, train mean loss 0.0002342343998890243, test mean loss [0.00019988 0.00020732 0.00019396 0.00018216 0.00051529 0.00016285
 0.00016843]
Model epoch 214: train total loss -64.82948950022913, train mean loss 0.00019965514337823143, test mean loss [0.00020092 0.00019747 0.00017311 0.00021086 0.00039346 0.00016912
 0.00016712]
Model epoch 215: train total loss -64.94758522331186, train mean loss 0.00019271845001378042, test mean loss [0.0002049  0.00019685 0.00016224 0.00017875 0.00033857 0.00018074
 0.00016479]
Model epoch 216: train total loss -65.066670485918, train mean loss 0.00017269085031078077, test mean loss [0.00020223 0.00019644 0.00016118 0.00020036 0.00030897 0.00017094
 0.00016656]
Model epoch 217: train total loss -65.19219049394299, train mean loss 0.0001742897524445669, test mean loss [0.00019528 0.00019685 0.00016038 0.00019735 0.00029403 0.0001751
 0.00016854]
Model epoch 218: train total loss -65.23937669251163, train mean loss 0.00017253501770444514, test mean loss [0.00020285 0.00018881 0.00015756 0.00018821 0.00026272 0.00017342
 0.00016547]
Model trained in 219 epochs with 2000 transitions.
[2025-01-24 02:40:01,129][absl][INFO] - {'eval/walltime': 102.26871109008789, 'training/sps': 1.014136432305903, 'training/walltime': 1715.0076212882996, 'training/model_train_time': 627.0150790214539, 'training/other_time': 358.2134122848511, 'training/model_horizon': 2, 'training/hallucination_updates_per_training_step': 257, 'training/env_buffer_size': Array(3000, dtype=int32), 'model/train_total_loss': Array(-65.23937669, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00017254, dtype=float64), 'model/test_total_loss': Array(-64.64762985, dtype=float64), 'model/test_mean_loss': Array(0.00019129, dtype=float64), 'model/train_epochs': 219, 'model/sec_per_epoch': 2.8548776210715237, 'sac/actor_loss': Array(-12.44320264, dtype=float64), 'sac/alpha': Array(0.23597883, dtype=float32), 'sac/alpha_loss': Array(1.97938466, dtype=float64), 'sac/buffer_current_size': Array(108129.18, dtype=float32), 'sac/critic_loss': Array(0.12360026, dtype=float64), 'eval/episode_forward_vel': Array(-178.46101341, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-16.14433402, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(50.01078673, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.41716822, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-76.75742512, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(51.81795035, dtype=float64), 'eval/episode_rew_roll': Array(48.42056804, dtype=float64), 'eval/episode_rew_side_motion': Array(36.43642332, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(47.41188516, dtype=float64), 'eval/episode_rew_yaw': Array(4.22982185, dtype=float64), 'eval/episode_rew_z_vel_change': Array(25.57539661, dtype=float64), 'eval/episode_reward': Array(171.55303963, dtype=float64), 'eval/episode_step_count': Array(499500., dtype=float64), 'eval/avg_episode_length': Array(1000., dtype=float64), 'eval/epoch_eval_time': 29.972984790802002, 'eval/sps': 33.36337728723221}
Steps / Eval:  3000.0
Reward is  171.55303963394968
Model horizon updated to 4.
Hallucination updates per training step updated to 505.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -29.04283338063914, train mean loss 0.032938769090990444, test mean loss [0.02971148 0.02845923 0.02769832 0.03250943 0.03245246 0.03510496
 0.03201294]
Model epoch 1: train total loss -35.47875783512123, train mean loss 0.028647924989203773, test mean loss [0.02635691 0.02467134 0.02338197 0.03264924 0.02867313 0.02917686
 0.02584581]
Model epoch 2: train total loss -39.70640315659845, train mean loss 0.025596377417274583, test mean loss [0.02318597 0.02323549 0.01927391 0.03090677 0.02594134 0.02696277
 0.02264227]
Model epoch 3: train total loss -43.29024079802549, train mean loss 0.023828892890884284, test mean loss [0.02111079 0.0220727  0.01696735 0.02761088 0.02405276 0.02422339
 0.02147498]
Model epoch 4: train total loss -45.967752327136886, train mean loss 0.02165829011193092, test mean loss [0.01967206 0.02093725 0.0160341  0.02464107 0.0216468  0.02142341
 0.02028968]
Model epoch 5: train total loss -48.53041752661746, train mean loss 0.019257394182158716, test mean loss [0.01817502 0.01870634 0.01539485 0.01977936 0.01911979 0.01895229
 0.01867383]
Model epoch 6: train total loss -50.731970807730264, train mean loss 0.016142757089713147, test mean loss [0.01666013 0.01628904 0.01431444 0.01634611 0.01690272 0.01644062
 0.01667326]
Model epoch 7: train total loss -52.29188761962873, train mean loss 0.014593015497408532, test mean loss [0.01448316 0.01429378 0.0132871  0.0133636  0.01487688 0.01456126
 0.01486538]
Model epoch 8: train total loss -53.612591540408744, train mean loss 0.012753567495881253, test mean loss [0.01332268 0.0122108  0.01240977 0.01123556 0.0135438  0.01283473
 0.01335448]
Model epoch 9: train total loss -54.69725926222993, train mean loss 0.011649499714130276, test mean loss [0.01208958 0.01054532 0.01165495 0.00992578 0.01232923 0.01142286
 0.01157518]
Model epoch 10: train total loss -55.382630135181586, train mean loss 0.010228491673234722, test mean loss [0.01086981 0.00893061 0.0107633  0.00918505 0.01130445 0.01020037
 0.01015999]
Model epoch 11: train total loss -55.99030353459205, train mean loss 0.009568574349724515, test mean loss [0.0095302  0.00770896 0.00995032 0.00868099 0.01038807 0.00920552
 0.00911383]
Model epoch 12: train total loss -56.775022183920626, train mean loss 0.00856548296310289, test mean loss [0.00852479 0.00689188 0.00933538 0.00801716 0.0096482  0.00805622
 0.00811843]
Model epoch 13: train total loss -57.20485571129954, train mean loss 0.007842169877713042, test mean loss [0.00747415 0.00615559 0.00873756 0.00734441 0.00905238 0.00721217
 0.00712752]
Model epoch 14: train total loss -57.65030814113392, train mean loss 0.007086003770082173, test mean loss [0.006514   0.00539332 0.00817451 0.00687704 0.00841937 0.00637137
 0.00621213]
Model epoch 15: train total loss -57.943300210931326, train mean loss 0.0065005959644091355, test mean loss [0.00557127 0.00472795 0.00761931 0.00647041 0.00799252 0.00562602
 0.00564086]
Model epoch 16: train total loss -58.352460620625294, train mean loss 0.005679410534135338, test mean loss [0.00497721 0.00418581 0.00695928 0.00593522 0.00752877 0.00496264
 0.00499734]
Model epoch 17: train total loss -58.39082466599175, train mean loss 0.005317613750523065, test mean loss [0.00446029 0.00371634 0.0064571  0.00561463 0.00700281 0.00443089
 0.00438004]
Model epoch 18: train total loss -58.643244879076065, train mean loss 0.004958214750964783, test mean loss [0.00398752 0.00337828 0.00606627 0.00508645 0.00657294 0.00386654
 0.00384397]
Model epoch 19: train total loss -59.125907282749125, train mean loss 0.004352154504526597, test mean loss [0.00346749 0.00299768 0.00571558 0.00473839 0.00620467 0.00339943
 0.0033921 ]
Model epoch 20: train total loss -59.27975493079802, train mean loss 0.004070757510991082, test mean loss [0.00304943 0.00275624 0.00539918 0.00447707 0.00577528 0.00303133
 0.00307095]
Model epoch 21: train total loss -59.627836830470066, train mean loss 0.0036621991963395177, test mean loss [0.00275944 0.00258021 0.00502477 0.00412612 0.00538297 0.00262286
 0.00278109]
Model epoch 22: train total loss -59.764579855763316, train mean loss 0.0033486462227885036, test mean loss [0.00242096 0.00237415 0.00471359 0.00371825 0.00499221 0.00221603
 0.00242277]
Model epoch 23: train total loss -60.05324514383551, train mean loss 0.0028259683691775153, test mean loss [0.00214888 0.00210128 0.00435928 0.00330586 0.00464761 0.00185414
 0.00221061]
Model epoch 24: train total loss -60.17509873926548, train mean loss 0.0027337562128602584, test mean loss [0.00193786 0.00195178 0.00400573 0.00297969 0.00423731 0.00162603
 0.00202388]
Model epoch 25: train total loss -60.33562895556936, train mean loss 0.0024141215754661183, test mean loss [0.00175823 0.00179342 0.00368144 0.00262613 0.00396928 0.00138666
 0.00184327]
Model epoch 26: train total loss -60.57991965559698, train mean loss 0.0020907499578965475, test mean loss [0.0016411  0.00165035 0.00342021 0.00243556 0.00353255 0.00126203
 0.00165685]
Model epoch 27: train total loss -60.59753787649491, train mean loss 0.0020310216632745503, test mean loss [0.00146783 0.00153538 0.00311712 0.00204836 0.00321574 0.00117216
 0.00155433]
Model epoch 28: train total loss -60.840775562650784, train mean loss 0.0017976306703505218, test mean loss [0.0014111  0.00136311 0.00284506 0.00182025 0.00287632 0.00110921
 0.00148697]
Model epoch 29: train total loss -60.91821795804561, train mean loss 0.001630866029080314, test mean loss [0.00136516 0.00125173 0.00254518 0.00161994 0.00263096 0.00103414
 0.00141576]
Model epoch 30: train total loss -60.95935926163082, train mean loss 0.0014919985194872297, test mean loss [0.00125268 0.00121629 0.00227511 0.00145642 0.0023585  0.00097855
 0.0013053 ]
Model epoch 31: train total loss -61.187900281637226, train mean loss 0.0013890870315430054, test mean loss [0.0011628  0.00114284 0.00198283 0.00131865 0.0021916  0.00094493
 0.00119658]
Model epoch 32: train total loss -61.32854737104861, train mean loss 0.0012521111762696642, test mean loss [0.0011273  0.00113349 0.00180974 0.00123897 0.00194251 0.00093319
 0.00118665]
Model epoch 33: train total loss -61.585016401466966, train mean loss 0.001050183466887714, test mean loss [0.00104888 0.00107368 0.00159226 0.00114151 0.0017734  0.00088301
 0.00113526]
Model epoch 34: train total loss -61.57793990851258, train mean loss 0.0009985598995050583, test mean loss [0.00100735 0.00104058 0.00155014 0.00111879 0.00163641 0.0008561
 0.00108075]
Model epoch 35: train total loss -61.71726537279431, train mean loss 0.0010365693711814475, test mean loss [0.00093575 0.00101942 0.00140721 0.00102529 0.00144683 0.0008456
 0.00105309]
Model epoch 36: train total loss -61.71459177304687, train mean loss 0.0009859605479648982, test mean loss [0.00091653 0.00098931 0.00129913 0.00097475 0.0013337  0.0008134
 0.00102751]
Model epoch 37: train total loss -61.925165354323106, train mean loss 0.0009371438305899015, test mean loss [0.00088084 0.00096518 0.00120366 0.00093545 0.00115756 0.00079586
 0.00100835]
Model epoch 38: train total loss -61.9117255163616, train mean loss 0.000856168468504493, test mean loss [0.00085832 0.00094494 0.00111281 0.00090289 0.0010514  0.00077026
 0.00098216]
Model epoch 39: train total loss -62.17035031903655, train mean loss 0.0007534118083559466, test mean loss [0.00080386 0.0009402  0.0010327  0.00093511 0.00096333 0.00076349
 0.00094768]
Model epoch 40: train total loss -61.992772872032994, train mean loss 0.0007373146780727799, test mean loss [0.0007733  0.00093247 0.00099537 0.00088764 0.00089484 0.00073068
 0.00091832]
Model epoch 41: train total loss -62.210366263586685, train mean loss 0.0006122232833226421, test mean loss [0.00074293 0.00090161 0.00094638 0.00086023 0.0008237  0.0007282
 0.00090039]
Model epoch 42: train total loss -62.284582463688366, train mean loss 0.00065475475328608, test mean loss [0.00073091 0.00088713 0.00091075 0.0008361  0.00075197 0.00070526
 0.0009025 ]
Model epoch 43: train total loss -62.37337867457574, train mean loss 0.0007214734564071208, test mean loss [0.00071293 0.00088003 0.00088031 0.00080674 0.00071821 0.00071005
 0.00087767]
Model epoch 44: train total loss -62.56381793671667, train mean loss 0.0006063737729007519, test mean loss [0.00069544 0.00086045 0.00087363 0.00080752 0.00069132 0.00068012
 0.00085427]
Model epoch 45: train total loss -62.45829157046528, train mean loss 0.0006283563325547816, test mean loss [0.00068187 0.00083835 0.00083134 0.00078465 0.00064103 0.00067366
 0.00084282]
Model epoch 46: train total loss -62.59327325998505, train mean loss 0.0006204411537266218, test mean loss [0.00067326 0.00083012 0.00081601 0.00076799 0.00063099 0.00065863
 0.000813  ]
Model epoch 47: train total loss -62.54716262288519, train mean loss 0.000556354514715408, test mean loss [0.00066944 0.00080763 0.00080242 0.00075392 0.00062334 0.00064749
 0.0008085 ]
Model epoch 48: train total loss -62.37624967328337, train mean loss 0.0006330286588605653, test mean loss [0.00062685 0.00080517 0.00078696 0.00075908 0.00060906 0.00065936
 0.00078964]
Model epoch 49: train total loss -62.84210570697616, train mean loss 0.000565550074775498, test mean loss [0.00063873 0.00078948 0.00076461 0.00073484 0.00058418 0.00063638
 0.00077055]
Model epoch 50: train total loss -62.86114453148501, train mean loss 0.0005556742129256115, test mean loss [0.00061457 0.00077559 0.00075934 0.0007231  0.00056346 0.00062342
 0.00074783]
Model epoch 51: train total loss -62.90645738353732, train mean loss 0.0005323682334629231, test mean loss [0.0006078  0.00078626 0.00073917 0.00070474 0.00056968 0.0006254
 0.00076197]
Model epoch 52: train total loss -62.83363691467943, train mean loss 0.0005253094405940693, test mean loss [0.00060969 0.00076494 0.00071647 0.00071232 0.00054984 0.00060097
 0.00072383]
Model epoch 53: train total loss -63.00917772958488, train mean loss 0.0004892429661387954, test mean loss [0.00061379 0.0007562  0.00071898 0.0006807  0.00053548 0.0006112
 0.00075251]
Model epoch 54: train total loss -62.82762935602447, train mean loss 0.0005657957788340341, test mean loss [0.00058709 0.00073583 0.00069656 0.00069498 0.0005308  0.00058781
 0.00070805]
Model epoch 55: train total loss -62.79573021068688, train mean loss 0.0005242851044985024, test mean loss [0.00058096 0.00072513 0.00070347 0.00066733 0.00053167 0.00058099
 0.00070253]
Model epoch 56: train total loss -62.976812854028665, train mean loss 0.00046509396236742016, test mean loss [0.00058266 0.00071118 0.00067726 0.00066341 0.00053689 0.00057353
 0.00069796]
Model epoch 57: train total loss -62.94535613589456, train mean loss 0.00046755172939149617, test mean loss [0.00055834 0.00071417 0.00070946 0.00065691 0.00051624 0.00056294
 0.00067166]
Model epoch 58: train total loss -63.05528828051485, train mean loss 0.0005171885138118996, test mean loss [0.00055858 0.00070225 0.00066883 0.00064955 0.0004927  0.00054871
 0.00067159]
Model epoch 59: train total loss -63.268562183611486, train mean loss 0.0004781239174414993, test mean loss [0.00055813 0.00068936 0.00065901 0.00062308 0.00048922 0.00054441
 0.00066652]
Model epoch 60: train total loss -62.966678040754935, train mean loss 0.0004953056669373798, test mean loss [0.00054488 0.00069181 0.00063572 0.00063113 0.00048211 0.00054348
 0.000792  ]
Model epoch 61: train total loss -62.91879771172257, train mean loss 0.0004585943235241274, test mean loss [0.00054004 0.00067661 0.00064191 0.00062871 0.00047046 0.00053689
 0.00068095]
Model epoch 62: train total loss -63.17788490050262, train mean loss 0.00047235214375971875, test mean loss [0.00051883 0.00067327 0.00062021 0.00061001 0.00047815 0.00052425
 0.00064092]
Model epoch 63: train total loss -63.12992478381026, train mean loss 0.0003983688898110167, test mean loss [0.00052314 0.00067303 0.00061375 0.00063666 0.00045544 0.00053193
 0.00062055]
Model epoch 64: train total loss -63.31723300128964, train mean loss 0.0004149422470958823, test mean loss [0.00053673 0.00064957 0.00061321 0.00058759 0.00045018 0.00051121
 0.00062081]
Model epoch 65: train total loss -63.27674349533595, train mean loss 0.0004087709172515717, test mean loss [0.00051343 0.00064234 0.00059824 0.00058682 0.00045618 0.00051914
 0.00061206]
Model epoch 66: train total loss -63.261586603022565, train mean loss 0.0004364879804444002, test mean loss [0.00051078 0.00062955 0.00058753 0.00057903 0.00044378 0.00051176
 0.00059702]
Model epoch 67: train total loss -63.25767703386806, train mean loss 0.00048080510371982006, test mean loss [0.00051225 0.00062747 0.00058454 0.00057405 0.00043889 0.00050013
 0.00058841]
Model epoch 68: train total loss -63.29035601978645, train mean loss 0.000459500975523105, test mean loss [0.00050918 0.00062419 0.0005749  0.0005639  0.0004336  0.00049736
 0.00058529]
Model epoch 69: train total loss -63.43550156417296, train mean loss 0.0004377599337077777, test mean loss [0.00052319 0.00061444 0.00057345 0.00056392 0.00041931 0.00048958
 0.00058378]
Model epoch 70: train total loss -63.589981107841844, train mean loss 0.00043611273514071507, test mean loss [0.00048829 0.00060275 0.00055454 0.00055464 0.00041993 0.00047732
 0.00057775]
Model epoch 71: train total loss -63.57095302610487, train mean loss 0.00043507684890714397, test mean loss [0.00048393 0.00060015 0.00055697 0.00055185 0.00042051 0.0004769
 0.00058743]
Model epoch 72: train total loss -63.44812072595778, train mean loss 0.0003835730219112433, test mean loss [0.00048203 0.00060114 0.00055193 0.00056273 0.00041266 0.00047936
 0.00056313]
Model epoch 73: train total loss -63.543273104299246, train mean loss 0.0003797334852262284, test mean loss [0.0004683  0.00057209 0.00054297 0.00055512 0.00042202 0.00047348
 0.00054774]
Model epoch 74: train total loss -63.60291158337207, train mean loss 0.00038215119663398596, test mean loss [0.00047464 0.00057375 0.00054766 0.00053406 0.00041029 0.00046234
 0.00054321]
Model epoch 75: train total loss -63.669661922781714, train mean loss 0.0003329069230235452, test mean loss [0.00046441 0.00059032 0.00053031 0.0005603  0.00039661 0.0004689
 0.00053568]
Model epoch 76: train total loss -63.636815970033936, train mean loss 0.0004261729643780603, test mean loss [0.00046115 0.00056414 0.00053055 0.00052162 0.00039364 0.00046016
 0.00054022]
Model epoch 77: train total loss -63.615793540994765, train mean loss 0.0003849228796948897, test mean loss [0.00045125 0.00057335 0.00052524 0.00051994 0.00039002 0.00045031
 0.00054587]
Model epoch 78: train total loss -63.64157887488843, train mean loss 0.0003499036814333739, test mean loss [0.00044632 0.00057571 0.00051579 0.00051586 0.00040323 0.00043882
 0.0005328 ]
Model epoch 79: train total loss -63.75148805826368, train mean loss 0.00036801592412408614, test mean loss [0.00043618 0.00056298 0.00051541 0.00050498 0.00038109 0.00045527
 0.0005239 ]
Model epoch 80: train total loss -63.62194719450776, train mean loss 0.0003974138156674266, test mean loss [0.00043452 0.00055306 0.00049877 0.00050187 0.00038739 0.00044071
 0.00052199]
Model epoch 81: train total loss -63.61180686282942, train mean loss 0.00033660906346883124, test mean loss [0.00044258 0.00053975 0.00049887 0.0004962  0.00037462 0.00044136
 0.00051524]
Model epoch 82: train total loss -63.83518346887935, train mean loss 0.00039538668285235036, test mean loss [0.00044415 0.00052704 0.00049023 0.00048839 0.00036897 0.00044092
 0.00050476]
Model epoch 83: train total loss -63.81282713997827, train mean loss 0.0003676961554748482, test mean loss [0.00042295 0.00051878 0.00049742 0.00048547 0.00036768 0.00042307
 0.00052851]
Model epoch 84: train total loss -63.87710874795618, train mean loss 0.0003435774192368015, test mean loss [0.00042426 0.00051703 0.00048966 0.0004863  0.00037451 0.00041631
 0.0005012 ]
Model epoch 85: train total loss -63.81889459026795, train mean loss 0.00035636646303406513, test mean loss [0.00041974 0.00052099 0.00047832 0.00048316 0.00037092 0.00040912
 0.00049717]
Model epoch 86: train total loss -64.10864637397054, train mean loss 0.00030370607190941895, test mean loss [0.00041954 0.00052107 0.00047912 0.0004707  0.00036422 0.00040655
 0.00048185]
Model epoch 87: train total loss -63.84822608406522, train mean loss 0.00035103290147785963, test mean loss [0.00041302 0.00051662 0.00048498 0.00046191 0.00036232 0.00041279
 0.00048544]
Model epoch 88: train total loss -63.95181324729977, train mean loss 0.0002990454360483281, test mean loss [0.00040917 0.00051464 0.00047856 0.00046807 0.00035888 0.00040662
 0.00048073]
Model epoch 89: train total loss -63.85700937417202, train mean loss 0.00034257247361400595, test mean loss [0.00040608 0.00049534 0.00046368 0.00045937 0.00035927 0.00042049
 0.00047439]
Model epoch 90: train total loss -63.97197291193665, train mean loss 0.00032862749765068033, test mean loss [0.00040872 0.00048485 0.00045843 0.00045916 0.00034823 0.00039005
 0.00046219]
Model epoch 91: train total loss -63.56028583104738, train mean loss 0.0003117309031221585, test mean loss [0.00041101 0.00049743 0.00047057 0.00045206 0.00034434 0.00040324
 0.00046219]
Model epoch 92: train total loss -64.01558416516943, train mean loss 0.00030901756678540065, test mean loss [0.00040577 0.00048511 0.00046247 0.00045267 0.00033684 0.00038336
 0.00044887]
Model epoch 93: train total loss -64.10955976780976, train mean loss 0.0003570287132670467, test mean loss [0.00039808 0.00048278 0.00045446 0.00043493 0.00033702 0.00039358
 0.00046212]
Model epoch 94: train total loss -64.06119060609049, train mean loss 0.00028917889257057183, test mean loss [0.00039365 0.00048583 0.00045459 0.00044171 0.00033771 0.00037589
 0.00044741]
Model epoch 95: train total loss -64.22129314599474, train mean loss 0.00030513930964908237, test mean loss [0.00039429 0.00047529 0.00044858 0.00044804 0.00033661 0.00038585
 0.00043812]
Model epoch 96: train total loss -63.93499627074931, train mean loss 0.0003236726720897958, test mean loss [0.00040163 0.00049315 0.0004627  0.00043554 0.00033268 0.00037546
 0.00042736]
Model epoch 97: train total loss -64.02719873159113, train mean loss 0.00031073593074125216, test mean loss [0.00038185 0.00046498 0.00044384 0.0004256  0.00032789 0.00037309
 0.00043914]
Model epoch 98: train total loss -64.15365520992952, train mean loss 0.0002568145954037468, test mean loss [0.00037968 0.00045759 0.00044373 0.00042271 0.00032814 0.00038657
 0.0004332 ]
Model epoch 99: train total loss -64.24015090254049, train mean loss 0.00030134353881423897, test mean loss [0.0003867  0.00046291 0.00042736 0.00041511 0.00032861 0.00036862
 0.00041802]
Model epoch 100: train total loss -63.96235644419722, train mean loss 0.0003391599595465729, test mean loss [0.00037636 0.00045159 0.00044172 0.00041922 0.00031796 0.0003638
 0.00042912]
Model epoch 101: train total loss -64.08018815466686, train mean loss 0.00028596347808970864, test mean loss [0.00037466 0.00044547 0.00042469 0.00042459 0.00032502 0.00036044
 0.00042138]
Model epoch 102: train total loss -64.01049676399356, train mean loss 0.00031954806595185206, test mean loss [0.00037071 0.00044317 0.0004245  0.00040252 0.00032063 0.00035935
 0.00040795]
Model epoch 103: train total loss -64.26673824138378, train mean loss 0.0002695430193361597, test mean loss [0.00036036 0.00044304 0.00042412 0.00041271 0.00032102 0.00037101
 0.00040883]
Model epoch 104: train total loss -64.04305239969237, train mean loss 0.00027738019748928364, test mean loss [0.00036605 0.00043654 0.00041899 0.00040818 0.00031539 0.00035516
 0.00040005]
Model epoch 105: train total loss -64.34093127778488, train mean loss 0.00031869690081514105, test mean loss [0.00035963 0.0004411  0.00041619 0.0003987  0.00029973 0.00034834
 0.00042262]
Model epoch 106: train total loss -64.38295751964094, train mean loss 0.00026424534404554463, test mean loss [0.00037459 0.00042739 0.00041453 0.00039282 0.0003098  0.00035115
 0.00040173]
Model epoch 107: train total loss -64.11844227794776, train mean loss 0.0003155792011178716, test mean loss [0.0003621  0.00042112 0.00041056 0.00038929 0.00031289 0.00034788
 0.00039734]
Model epoch 108: train total loss -64.12819302702823, train mean loss 0.00028280024872966793, test mean loss [0.00035906 0.00041544 0.00043485 0.00038602 0.00031005 0.00034697
 0.00038963]
Model epoch 109: train total loss -64.1559948845509, train mean loss 0.00032099056900069373, test mean loss [0.00035207 0.00041864 0.00040702 0.00038483 0.00030089 0.0003343
 0.00038678]
Model epoch 110: train total loss -64.16350040414596, train mean loss 0.0003030688920312059, test mean loss [0.00035422 0.00042003 0.00041408 0.00037855 0.00031405 0.00034994
 0.00040048]
Model epoch 111: train total loss -64.32447318044109, train mean loss 0.00026615447787781956, test mean loss [0.00034034 0.00040887 0.00040044 0.00038459 0.00031144 0.00034408
 0.00037954]
Model epoch 112: train total loss -64.045993924552, train mean loss 0.00029432079841976383, test mean loss [0.00034602 0.00041059 0.00040717 0.00037884 0.0003002  0.0003315
 0.00037899]
Model epoch 113: train total loss -64.47068276594797, train mean loss 0.00028582133474066787, test mean loss [0.00033661 0.00040096 0.00039767 0.00037008 0.00029834 0.00032531
 0.00038987]
Model epoch 114: train total loss -64.36351699779715, train mean loss 0.0003053132010523175, test mean loss [0.00033514 0.00040862 0.00040778 0.00037357 0.00029932 0.00035398
 0.00037762]
Model epoch 115: train total loss -64.1112859491269, train mean loss 0.0002615640382661152, test mean loss [0.0003369  0.00040434 0.00042605 0.00037209 0.00028943 0.00033058
 0.00038504]
Model epoch 116: train total loss -64.37181323451578, train mean loss 0.0002825393681309873, test mean loss [0.00033591 0.00040061 0.00038526 0.00036304 0.00029328 0.00033123
 0.00038709]
Model epoch 117: train total loss -64.48806195424527, train mean loss 0.0002978933404381648, test mean loss [0.00033185 0.00039242 0.00039824 0.00036797 0.00028646 0.00032748
 0.00037294]
Model epoch 118: train total loss -64.22191660588787, train mean loss 0.00028391866413396476, test mean loss [0.00033062 0.00039302 0.00038621 0.00036802 0.00028615 0.00033502
 0.00036554]
Model epoch 119: train total loss -64.3701427408966, train mean loss 0.00029360133846617734, test mean loss [0.00032621 0.00039435 0.00037872 0.00036892 0.00028271 0.00032332
 0.00036283]
Model epoch 120: train total loss -64.53815481153225, train mean loss 0.0002508423396130693, test mean loss [0.00032458 0.00037166 0.00037989 0.00035699 0.00028762 0.00033462
 0.00036356]
Model epoch 121: train total loss -64.45909859774572, train mean loss 0.00028010423997243617, test mean loss [0.00033298 0.00037602 0.00037016 0.00034505 0.00027523 0.00031797
 0.00035409]
Model epoch 122: train total loss -64.36762226545618, train mean loss 0.00027214985908657663, test mean loss [0.00033859 0.00037681 0.00037286 0.00035821 0.00028583 0.00031188
 0.00035375]
Model epoch 123: train total loss -64.56129977412623, train mean loss 0.00024517330215080064, test mean loss [0.0003223  0.0003786  0.00035584 0.00035644 0.00028047 0.00032091
 0.00035264]
Model epoch 124: train total loss -64.5568976287519, train mean loss 0.000240591270293279, test mean loss [0.00032755 0.00036518 0.00036673 0.00034771 0.00028158 0.00031053
 0.00035571]
Model epoch 125: train total loss -64.44769018357344, train mean loss 0.00023257572732567633, test mean loss [0.00032445 0.00036902 0.00036322 0.00034507 0.00027258 0.00030738
 0.00034986]
Model epoch 126: train total loss -64.52343033377035, train mean loss 0.00024500435674768673, test mean loss [0.00032123 0.00037792 0.00036005 0.00034364 0.00027088 0.00031745
 0.00034206]
Model epoch 127: train total loss -64.48490524399998, train mean loss 0.00024561881544601526, test mean loss [0.00031494 0.00037245 0.00036344 0.00033587 0.00027332 0.00030381
 0.00033922]
Model epoch 128: train total loss -64.56602582594728, train mean loss 0.00029936805937796934, test mean loss [0.00031253 0.00036471 0.00036561 0.00034129 0.00027034 0.00031863
 0.00033857]
Model epoch 129: train total loss -64.55698382631793, train mean loss 0.00022850422910572482, test mean loss [0.00030516 0.00035845 0.0003575  0.00033463 0.00026995 0.00030324
 0.00033616]
Model epoch 130: train total loss -64.59651084187107, train mean loss 0.0002122957628150178, test mean loss [0.0003111  0.00035484 0.00035781 0.00033173 0.00026711 0.00030414
 0.00033389]
Model epoch 131: train total loss -64.68017709989094, train mean loss 0.00023551309866866915, test mean loss [0.00031869 0.00035689 0.00035502 0.00032898 0.00026167 0.0003037
 0.00033228]
Model epoch 132: train total loss -64.56108192101262, train mean loss 0.00022813863242687908, test mean loss [0.00030231 0.00036248 0.00035204 0.00032789 0.0002745  0.00029629
 0.00032953]
Model epoch 133: train total loss -64.54799090358995, train mean loss 0.00021963120881415992, test mean loss [0.00030444 0.00034974 0.00036249 0.00032405 0.00026641 0.00030088
 0.00032047]
Model epoch 134: train total loss -64.65610286251595, train mean loss 0.00022181007193859884, test mean loss [0.0003046  0.00034775 0.00035335 0.00031478 0.00026568 0.00031558
 0.00032765]
Model epoch 135: train total loss -64.55768592776082, train mean loss 0.00027815603820190567, test mean loss [0.00030352 0.00033421 0.00034313 0.00032332 0.00025766 0.00030028
 0.00032716]
Model epoch 136: train total loss -64.70043683086959, train mean loss 0.000229086194685169, test mean loss [0.00030218 0.00033576 0.00034599 0.00031616 0.00026218 0.00029386
 0.00032216]
Model epoch 137: train total loss -64.71767875371354, train mean loss 0.0002281523090371567, test mean loss [0.00029946 0.00035001 0.00034019 0.00031843 0.00025579 0.000296
 0.00032122]
Model epoch 138: train total loss -64.77512132636005, train mean loss 0.00021297221177135213, test mean loss [0.0002973  0.00032793 0.00034104 0.00031155 0.00026176 0.00029229
 0.00031951]
Model epoch 139: train total loss -64.63968622084256, train mean loss 0.0002310288718963132, test mean loss [0.0002974  0.00033416 0.0003424  0.00031447 0.00025625 0.00027917
 0.00031571]
Model epoch 140: train total loss -64.60105273828894, train mean loss 0.0002314407647710057, test mean loss [0.00028972 0.00032692 0.00034423 0.00031496 0.00027378 0.00028237
 0.00032765]
Model epoch 141: train total loss -64.64672112397587, train mean loss 0.00020936141301547707, test mean loss [0.00029825 0.0003261  0.00033876 0.00031324 0.00025931 0.00029817
 0.00031788]
Model epoch 142: train total loss -64.72024606537096, train mean loss 0.00022088560903352046, test mean loss [0.00029421 0.00033682 0.00033621 0.00030791 0.00025396 0.00027557
 0.00030328]
Model epoch 143: train total loss -65.03147316081125, train mean loss 0.00023854729610270223, test mean loss [0.00029128 0.00033317 0.00033589 0.00029647 0.00024906 0.00028575
 0.00031387]
Model epoch 144: train total loss -64.67658951664193, train mean loss 0.0002450586832908047, test mean loss [0.0002849  0.00032362 0.00032695 0.00030038 0.00025552 0.00028911
 0.00030065]
Model epoch 145: train total loss -64.74911159172443, train mean loss 0.00019701522592073604, test mean loss [0.00029259 0.00032481 0.00032376 0.00029477 0.00024814 0.00027582
 0.00030319]
Model epoch 146: train total loss -64.59580854870727, train mean loss 0.00021125302489320117, test mean loss [0.00028304 0.0003196  0.0003276  0.0002938  0.00025571 0.00028711
 0.00030112]
Model epoch 147: train total loss -64.70073662251679, train mean loss 0.0001871546634596422, test mean loss [0.0002939  0.00031496 0.00032548 0.00030576 0.00025302 0.00028122
 0.00030118]
Model epoch 148: train total loss -64.69775444200378, train mean loss 0.00022547162379219543, test mean loss [0.00029152 0.00031908 0.00033378 0.00029066 0.00025466 0.00027843
 0.00031711]
Model epoch 149: train total loss -64.792204331055, train mean loss 0.00022622543588836778, test mean loss [0.0002854  0.00031283 0.00031867 0.00029614 0.000259   0.00028045
 0.00029751]
Model epoch 150: train total loss -64.7106828974964, train mean loss 0.00018816089486008833, test mean loss [0.00028446 0.0003138  0.00032189 0.00029257 0.00024897 0.00026496
 0.00029402]
Model epoch 151: train total loss -64.6774759615137, train mean loss 0.00021742012381620546, test mean loss [0.00027179 0.00032753 0.0003143  0.00028481 0.00024806 0.00027387
 0.00029184]
Model epoch 152: train total loss -64.70278526685438, train mean loss 0.00021729019533927164, test mean loss [0.00027936 0.00031029 0.00032485 0.00029939 0.00024681 0.00027263
 0.00029157]
Model epoch 153: train total loss -64.8933107311846, train mean loss 0.00017614139692880994, test mean loss [0.00027051 0.00030407 0.00030945 0.00029078 0.00024175 0.00026818
 0.00028743]
Model epoch 154: train total loss -64.63420614046754, train mean loss 0.00020130948490671287, test mean loss [0.00028282 0.00029842 0.00031744 0.00028131 0.00025267 0.00026294
 0.00028536]
Model epoch 155: train total loss -64.96047217493884, train mean loss 0.00018645449064483345, test mean loss [0.00027407 0.00029749 0.00031386 0.00029722 0.00024247 0.00026552
 0.00028339]
Model epoch 156: train total loss -64.85968690445273, train mean loss 0.00020863160119375393, test mean loss [0.0002642  0.0003007  0.00030758 0.00028198 0.00024746 0.0002653
 0.00028458]
Model epoch 157: train total loss -64.68770619393149, train mean loss 0.00021888547483450455, test mean loss [0.00026767 0.00029963 0.00034167 0.00028831 0.00024554 0.00025657
 0.0002805 ]
Model epoch 158: train total loss -64.61305359684214, train mean loss 0.00023422738075274405, test mean loss [0.00028083 0.00030427 0.0003146  0.00027815 0.0002443  0.00026231
 0.0002748 ]
Model epoch 159: train total loss -64.89162003319704, train mean loss 0.00018754369938434355, test mean loss [0.00026958 0.00030287 0.00030675 0.00028765 0.00024572 0.00025182
 0.00028336]
Model epoch 160: train total loss -64.85981501773031, train mean loss 0.00020782972377750555, test mean loss [0.00027088 0.00030219 0.00030389 0.00027689 0.00024526 0.00024845
 0.00028798]
Model epoch 161: train total loss -64.87596370089486, train mean loss 0.00022849692439903444, test mean loss [0.00026858 0.00029393 0.00030779 0.00028843 0.00024739 0.00025873
 0.00028174]
Model epoch 162: train total loss -64.72331276176314, train mean loss 0.00020528062955511698, test mean loss [0.00026675 0.00029235 0.00030975 0.00026862 0.00024566 0.0002636
 0.00027762]
Model epoch 163: train total loss -64.87216631094923, train mean loss 0.0002023392761018791, test mean loss [0.0002578  0.00028853 0.00029485 0.00027948 0.00024475 0.00026234
 0.00027476]
Model epoch 164: train total loss -64.88358436780189, train mean loss 0.0002352425196598153, test mean loss [0.00026364 0.00028671 0.00030324 0.00027544 0.00023297 0.00026963
 0.00028037]
Model epoch 165: train total loss -64.84990343061372, train mean loss 0.00020688324694246652, test mean loss [0.00026068 0.00028249 0.00029423 0.00027096 0.0002397  0.00025184
 0.00026905]
Model epoch 166: train total loss -64.93368143099491, train mean loss 0.00019791663122476193, test mean loss [0.00027    0.0002853  0.00029647 0.00027101 0.00023413 0.00025073
 0.00027551]
Model epoch 167: train total loss -65.03684667523828, train mean loss 0.00017635989643259253, test mean loss [0.00025972 0.00028013 0.00028874 0.00027251 0.00023892 0.00025196
 0.00027041]
Model epoch 168: train total loss -65.07925400923654, train mean loss 0.00016946751854571255, test mean loss [0.00025864 0.00027486 0.00029569 0.00026689 0.00022977 0.00024648
 0.00026366]
Model epoch 169: train total loss -64.99180746523265, train mean loss 0.00020765334411696872, test mean loss [0.00026126 0.00027641 0.00029381 0.00027275 0.00023047 0.00024919
 0.00026398]
Model epoch 170: train total loss -64.89060232279395, train mean loss 0.0001904421622448915, test mean loss [0.00025214 0.00028421 0.00029699 0.00027667 0.00023127 0.00024849
 0.00026517]
Model epoch 171: train total loss -64.85065459749796, train mean loss 0.00022985631278669966, test mean loss [0.00025338 0.00028417 0.00029591 0.00027176 0.00023433 0.00024835
 0.0002613 ]
Model epoch 172: train total loss -65.00155032149763, train mean loss 0.00019908302015739267, test mean loss [0.00025268 0.00028949 0.00028125 0.00025712 0.00022636 0.00025314
 0.00026282]
Model epoch 173: train total loss -64.93620757843459, train mean loss 0.00021191824939118578, test mean loss [0.00025351 0.00027971 0.00028285 0.00026766 0.00022375 0.00024203
 0.00026478]
Model epoch 174: train total loss -65.03925567042093, train mean loss 0.0001701695997278641, test mean loss [0.00024899 0.00026748 0.00029196 0.00025748 0.00022976 0.00024316
 0.00026299]
Model epoch 175: train total loss -65.09510170035355, train mean loss 0.00017881255834757524, test mean loss [0.00025019 0.00026995 0.00028216 0.00025866 0.00022053 0.00024493
 0.00025672]
Model epoch 176: train total loss -65.00768325389024, train mean loss 0.00021480518453142187, test mean loss [0.00025586 0.00026585 0.00028575 0.00025468 0.00022508 0.00024632
 0.00026613]
Model epoch 177: train total loss -65.18999791415692, train mean loss 0.0001637550473099232, test mean loss [0.00025291 0.00026898 0.00028106 0.00025529 0.00022291 0.00024429
 0.00025132]
Model epoch 178: train total loss -65.22270130088262, train mean loss 0.00017178587309591735, test mean loss [0.00024684 0.00027223 0.0002842  0.00027666 0.0002311  0.00024665
 0.00026366]
Model epoch 179: train total loss -65.16854999832975, train mean loss 0.00016139136679556464, test mean loss [0.00024689 0.00026343 0.000277   0.00025445 0.00021758 0.0002392
 0.00025744]
Model epoch 180: train total loss -65.06368225160506, train mean loss 0.00020470188463259345, test mean loss [0.00024381 0.00026568 0.00027969 0.00025169 0.00022075 0.00024425
 0.00026117]
Model epoch 181: train total loss -65.06212320367578, train mean loss 0.00021467039943374175, test mean loss [0.00024878 0.00025868 0.00027991 0.00025741 0.000222   0.00023589
 0.00025356]
Model epoch 182: train total loss -64.95297739512006, train mean loss 0.00016865497271735473, test mean loss [0.00025409 0.00025352 0.00027212 0.00025167 0.00022128 0.00024106
 0.00025767]
Model epoch 183: train total loss -65.04572294138308, train mean loss 0.0001826592125781982, test mean loss [0.00024237 0.00027258 0.00027377 0.00024354 0.00022524 0.00023526
 0.00025521]
Model epoch 184: train total loss -64.96991902230228, train mean loss 0.00020806041066294347, test mean loss [0.00024514 0.00026735 0.0002733  0.00025272 0.00021928 0.00023059
 0.000266  ]
Model epoch 185: train total loss -65.05285901059831, train mean loss 0.0001817184400081524, test mean loss [0.00024185 0.00027342 0.00027338 0.00024233 0.00022033 0.00022594
 0.0002486 ]
Model epoch 186: train total loss -65.12417724466339, train mean loss 0.0001627293198109295, test mean loss [0.00024322 0.00025709 0.00027734 0.00024253 0.00022016 0.00023048
 0.00025157]
Model epoch 187: train total loss -65.1437885880447, train mean loss 0.00019508283467291256, test mean loss [0.00025262 0.00025364 0.00027124 0.00023732 0.0002227  0.00022635
 0.00024711]
Model epoch 188: train total loss -65.27204392820833, train mean loss 0.00015869603968524812, test mean loss [0.00024418 0.00026287 0.00027526 0.00024164 0.00021671 0.00022567
 0.00024215]
Model epoch 189: train total loss -65.13661776151547, train mean loss 0.00016755479011440106, test mean loss [0.00024099 0.0002524  0.00027231 0.00024092 0.00021839 0.00022541
 0.00026078]
Model epoch 190: train total loss -65.21624364201631, train mean loss 0.00016859682834052773, test mean loss [0.00023477 0.0002488  0.00026147 0.00024617 0.00022248 0.00022435
 0.0002496 ]
Model epoch 191: train total loss -65.25445534398827, train mean loss 0.00016558216129987095, test mean loss [0.00023698 0.00025403 0.00026488 0.00024816 0.00021672 0.00024167
 0.0002513 ]
Model epoch 192: train total loss -65.17316656178411, train mean loss 0.00017662611060128243, test mean loss [0.00024208 0.00025602 0.00027342 0.00024899 0.00021262 0.00023191
 0.00025612]
Model epoch 193: train total loss -65.15939355346748, train mean loss 0.00018159198175597268, test mean loss [0.00023095 0.00025654 0.00026636 0.00023764 0.00022825 0.00023072
 0.0002428 ]
Model epoch 194: train total loss -65.29410127648106, train mean loss 0.0001652029090354788, test mean loss [0.00023499 0.0002431  0.00026344 0.00023766 0.00021523 0.00022247
 0.00023784]
Model epoch 195: train total loss -65.20715437855867, train mean loss 0.00017331513292617674, test mean loss [0.00023327 0.00025132 0.00026122 0.00023753 0.00021084 0.00023006
 0.00023895]
Model epoch 196: train total loss -65.16068474452963, train mean loss 0.0001563601921895071, test mean loss [0.00023748 0.00024799 0.00026197 0.000237   0.00023385 0.00022694
 0.00023272]
Model epoch 197: train total loss -65.2337461330761, train mean loss 0.0001646819588473929, test mean loss [0.00022711 0.00024329 0.00026766 0.00023337 0.00021511 0.00021631
 0.00025125]
Model epoch 198: train total loss -65.21526428925415, train mean loss 0.0001584632385477144, test mean loss [0.00024101 0.00025074 0.00025943 0.00023588 0.00021084 0.00022421
 0.0002327 ]
Model epoch 199: train total loss -65.36437384395923, train mean loss 0.00015186364777721503, test mean loss [0.00022805 0.0002417  0.00026069 0.0002343  0.00020569 0.00022248
 0.00023833]
Model epoch 200: train total loss -65.21778031621726, train mean loss 0.0001595553774949642, test mean loss [0.00023034 0.00024954 0.0002495  0.00022755 0.00021181 0.00021694
 0.00024475]
Model epoch 201: train total loss -65.102869498501, train mean loss 0.0001816186095318327, test mean loss [0.00024373 0.00024627 0.00026411 0.00022849 0.0002099  0.00022112
 0.00024223]
Model epoch 202: train total loss -65.08990349794136, train mean loss 0.00016218504384868675, test mean loss [0.00022572 0.00024054 0.00025648 0.0002318  0.000211   0.00023636
 0.00023334]
Model epoch 203: train total loss -65.33859864750943, train mean loss 0.0001608231504032533, test mean loss [0.00022938 0.00023875 0.00025713 0.00023452 0.00021221 0.00022187
 0.00023729]
Model epoch 204: train total loss -65.01147182763269, train mean loss 0.00017819766490707124, test mean loss [0.00022267 0.00024134 0.00026516 0.00022978 0.00021143 0.00022199
 0.00024428]
Model epoch 205: train total loss -65.27368175781793, train mean loss 0.00018422794706232564, test mean loss [0.00023045 0.00023669 0.00025309 0.00022676 0.00020722 0.000211
 0.00023149]
Model epoch 206: train total loss -64.99215272722175, train mean loss 0.0001854138803806153, test mean loss [0.00022619 0.00022862 0.00026509 0.000228   0.00020545 0.0002116
 0.00023133]
Model epoch 207: train total loss -65.19484041727273, train mean loss 0.00016899988820456402, test mean loss [0.00023349 0.00023237 0.00025573 0.00022354 0.00020696 0.00020999
 0.00022508]
Model epoch 208: train total loss -65.40949163938282, train mean loss 0.00016717004990887276, test mean loss [0.00022536 0.00024154 0.00026138 0.00022184 0.00020648 0.00020754
 0.000226  ]
Model epoch 209: train total loss -65.41495091865103, train mean loss 0.0001586796233516217, test mean loss [0.00022164 0.00024125 0.00025219 0.00022577 0.00019819 0.00021749
 0.00022696]
Model epoch 210: train total loss -65.25669263034591, train mean loss 0.00018743537029071707, test mean loss [0.00022754 0.00023942 0.00025307 0.00022566 0.00019941 0.00022758
 0.00023221]
Model epoch 211: train total loss -65.50830858370648, train mean loss 0.0001477871342066055, test mean loss [0.00022383 0.00023529 0.00026326 0.00022011 0.0001967  0.00020786
 0.00022795]
Model epoch 212: train total loss -65.4831681785111, train mean loss 0.00016407610793252805, test mean loss [0.00021741 0.00022786 0.00024439 0.00021401 0.00019031 0.00020749
 0.00022102]
Model epoch 213: train total loss -65.34937363793969, train mean loss 0.00016491188920595508, test mean loss [0.00022105 0.0002208  0.00024627 0.00022958 0.00019527 0.00022009
 0.00022216]
Model epoch 214: train total loss -65.2295916462766, train mean loss 0.00016869682621190163, test mean loss [0.00022606 0.00022584 0.00024074 0.0002209  0.0002092  0.00020979
 0.00022474]
Model epoch 215: train total loss -65.1802445465143, train mean loss 0.0001827968032818821, test mean loss [0.00022665 0.00022823 0.00024236 0.00024833 0.00019197 0.00020409
 0.00023349]
Model epoch 216: train total loss -65.21973723477632, train mean loss 0.00016636341976994154, test mean loss [0.00023595 0.0002236  0.00024716 0.0002188  0.0002006  0.00020399
 0.0002168 ]
Model epoch 217: train total loss -65.39260143500168, train mean loss 0.00014467666501126876, test mean loss [0.00021926 0.00022626 0.00024129 0.00023176 0.00020171 0.00020662
 0.0002264 ]
Model epoch 218: train total loss -65.4237975688031, train mean loss 0.00016046619932340745, test mean loss [0.00022322 0.00023317 0.00024089 0.00022985 0.0001954  0.00020276
 0.00021413]
Model epoch 219: train total loss -65.17445387299786, train mean loss 0.00016981541960445673, test mean loss [0.000222   0.00022335 0.00023773 0.00022809 0.00020144 0.00020131
 0.0002189 ]
Model epoch 220: train total loss -65.36479556689817, train mean loss 0.00015439003760461128, test mean loss [0.00021803 0.00021969 0.00023539 0.00021738 0.00021041 0.00020203
 0.00021417]
Model epoch 221: train total loss -65.41273135994787, train mean loss 0.00016720405910999523, test mean loss [0.00022294 0.00021868 0.00023801 0.00021798 0.00019317 0.00020563
 0.00021995]
Model epoch 222: train total loss -65.37084772029556, train mean loss 0.00016133445136056772, test mean loss [0.00021847 0.00022064 0.00024173 0.00020889 0.00019585 0.00020803
 0.00022614]
Model epoch 223: train total loss -65.38798469268187, train mean loss 0.0001543993354542894, test mean loss [0.00022698 0.00022314 0.00024564 0.00021239 0.00019832 0.00020472
 0.00021724]
Model epoch 224: train total loss -65.40657511600395, train mean loss 0.00015191678683102965, test mean loss [0.00021977 0.00021932 0.00023916 0.00021963 0.00019585 0.00020224
 0.00021341]
Model epoch 225: train total loss -65.40205335173677, train mean loss 0.0001631497996285323, test mean loss [0.0002182  0.00021672 0.00023806 0.00021945 0.00019364 0.00021257
 0.00021279]
Model epoch 226: train total loss -65.35341077489446, train mean loss 0.00013809811742693451, test mean loss [0.00020777 0.00022126 0.00023212 0.00021327 0.00019349 0.00020001
 0.00021098]
Model epoch 227: train total loss -65.2661358614708, train mean loss 0.00015221658114524512, test mean loss [0.00021673 0.00021554 0.00023293 0.00021197 0.00019497 0.00020024
 0.00021864]
Model epoch 228: train total loss -65.43260547060677, train mean loss 0.0001406701377942782, test mean loss [0.00021347 0.00021037 0.00023611 0.00021198 0.00019358 0.0002029
 0.00021031]
Model epoch 229: train total loss -65.33441724801128, train mean loss 0.00014906738247271104, test mean loss [0.00021452 0.00021589 0.00022593 0.00020246 0.00019674 0.00019972
 0.00020877]
Model epoch 230: train total loss -65.33803016486374, train mean loss 0.00014917485540903383, test mean loss [0.00021342 0.00022602 0.00024513 0.00021576 0.00020061 0.00019361
 0.00020783]
Model epoch 231: train total loss -65.3891244222433, train mean loss 0.00016103081691839707, test mean loss [0.00021494 0.0002264  0.00023049 0.0002079  0.00019176 0.00019069
 0.00020778]
Model epoch 232: train total loss -65.39521121415919, train mean loss 0.00014291280654439746, test mean loss [0.00020933 0.00021828 0.00023355 0.00021275 0.0001869  0.00019631
 0.00020741]
Model epoch 233: train total loss -65.15849415293697, train mean loss 0.00015929791009275138, test mean loss [0.00020948 0.00021058 0.000273   0.00021968 0.00019322 0.00019757
 0.00020704]
Model epoch 234: train total loss -65.15812526181634, train mean loss 0.00014182130834627005, test mean loss [0.00022166 0.00021987 0.00023959 0.00022169 0.00018452 0.00018863
 0.0002336 ]
Model epoch 235: train total loss -65.36055269448853, train mean loss 0.0001459397944346549, test mean loss [0.00020801 0.00020642 0.00023289 0.00020753 0.00018573 0.00020524
 0.00022313]
Model epoch 236: train total loss -65.32472156101012, train mean loss 0.00015075480423474118, test mean loss [0.00021056 0.00020943 0.00022092 0.00020586 0.00019696 0.0001909
 0.00021167]
Model epoch 237: train total loss -65.22166489646528, train mean loss 0.00015132919337696352, test mean loss [0.0002043  0.00020723 0.0002228  0.0002054  0.00019074 0.00019807
 0.00023127]
Model epoch 238: train total loss -65.49428266150179, train mean loss 0.0001604494731852519, test mean loss [0.00020314 0.00021178 0.00023152 0.00021751 0.00019096 0.00019263
 0.00021324]
Model epoch 239: train total loss -65.44685066627635, train mean loss 0.00014433512643930292, test mean loss [0.00020469 0.00020861 0.00022267 0.00020105 0.00019096 0.00020333
 0.00020605]
Model epoch 240: train total loss -65.31956179093966, train mean loss 0.0001609435082236703, test mean loss [0.00020999 0.00020096 0.00021558 0.00020203 0.0001866  0.00019859
 0.00025173]
Model epoch 241: train total loss -65.31841013243846, train mean loss 0.00013588543359524706, test mean loss [0.00020889 0.00020726 0.00022174 0.00020445 0.00018286 0.00020031
 0.00021311]
Model epoch 242: train total loss -65.37352315191653, train mean loss 0.00015416200703312593, test mean loss [0.00020863 0.00021446 0.00021718 0.00019524 0.00018118 0.00018627
 0.00021123]
Model epoch 243: train total loss -65.36292516949891, train mean loss 0.00014656166886993472, test mean loss [0.000206   0.0002039  0.00021611 0.00019932 0.00019597 0.00018571
 0.0002111 ]
Model epoch 244: train total loss -65.55851490271897, train mean loss 0.00014440502168029104, test mean loss [0.00020236 0.00020419 0.00021671 0.00020035 0.00018756 0.00018672
 0.000207  ]
Model epoch 245: train total loss -65.48586917040411, train mean loss 0.00014542753557874493, test mean loss [0.00019857 0.00020754 0.00021472 0.00019714 0.00018889 0.00019172
 0.00019757]
Model epoch 246: train total loss -65.51112907983881, train mean loss 0.00015820920151339273, test mean loss [0.00019658 0.00019733 0.00021382 0.00020278 0.00018864 0.00019161
 0.00020364]
Model epoch 247: train total loss -65.49838761049422, train mean loss 0.00014722219134954742, test mean loss [0.00020417 0.00020789 0.00022111 0.00021456 0.00018203 0.00019009
 0.00019647]
Model epoch 248: train total loss -64.99786295963263, train mean loss 0.0001691439691419688, test mean loss [0.00020146 0.00019837 0.00022107 0.00019711 0.00028974 0.00020071
 0.00020438]
Model epoch 249: train total loss -65.29674411678609, train mean loss 0.00017129038323971462, test mean loss [0.0001967  0.00020434 0.00021552 0.00019749 0.00029324 0.00019044
 0.00020676]
Model epoch 250: train total loss -65.44091432290637, train mean loss 0.00015422496766820298, test mean loss [0.0001955  0.00020238 0.0002172  0.00019939 0.00023232 0.00019296
 0.00019826]
Model epoch 251: train total loss -64.99396371606683, train mean loss 0.0001452743825831205, test mean loss [0.00019811 0.00019903 0.0002101  0.0001964  0.00036667 0.00018892
 0.00019655]
Model epoch 252: train total loss -64.08879157511916, train mean loss 0.000987954939302934, test mean loss [0.00019843 0.0002016  0.00021532 0.00020609 0.00630077 0.00019289
 0.00020112]
Model epoch 253: train total loss -64.51884498616376, train mean loss 0.0011972779599546625, test mean loss [0.00019508 0.00020459 0.00021005 0.00019013 0.00612774 0.00018681
 0.00019984]
Model epoch 254: train total loss -64.76685027520854, train mean loss 0.0009750740871891123, test mean loss [0.00019326 0.00019471 0.00021347 0.00019287 0.00485161 0.00019608
 0.00019697]
Model epoch 255: train total loss -64.7622752868049, train mean loss 0.0007159339817970542, test mean loss [0.00019455 0.00019915 0.00022105 0.00020377 0.00373924 0.00018193
 0.00019618]
Model epoch 256: train total loss -65.03356319247344, train mean loss 0.0006337635635975067, test mean loss [0.00019878 0.00020054 0.00021402 0.0001935  0.003006   0.00018634
 0.00019782]
Model epoch 257: train total loss -65.18425880554754, train mean loss 0.0005952439531265601, test mean loss [0.00018874 0.00019471 0.00020934 0.00019601 0.00249427 0.00018474
 0.00019248]
Model epoch 258: train total loss -65.22496256183182, train mean loss 0.0004377444244546175, test mean loss [0.00019142 0.00019108 0.00020372 0.00019248 0.00207275 0.00017887
 0.00020067]
Model epoch 259: train total loss -65.24986682602994, train mean loss 0.00036109245202051144, test mean loss [0.00019462 0.00019504 0.00020706 0.00018819 0.00174835 0.00018649
 0.00019798]
Model epoch 260: train total loss -65.34617098652102, train mean loss 0.0004304816432047564, test mean loss [0.00019331 0.0001978  0.00020329 0.00018902 0.00148123 0.00017925
 0.00019208]
Model epoch 261: train total loss -65.53706449080184, train mean loss 0.0003416277248018282, test mean loss [0.00019155 0.00019544 0.00020455 0.00018534 0.00129211 0.00017999
 0.00018962]
Model epoch 262: train total loss -64.93582572065719, train mean loss 0.00035122084324785426, test mean loss [0.00019057 0.00019413 0.00020562 0.00019755 0.00112625 0.00035404
 0.00018857]
Model epoch 263: train total loss -65.08359748614032, train mean loss 0.0002999596043414127, test mean loss [0.00019899 0.00019304 0.0002055  0.00019077 0.00097048 0.00023376
 0.00019727]
Model epoch 264: train total loss -65.34679419646255, train mean loss 0.0002757923280829046, test mean loss [0.00019353 0.00019881 0.00020412 0.00019033 0.00084393 0.00019589
 0.00019063]
Model epoch 265: train total loss -65.29900998012748, train mean loss 0.00025798746712121437, test mean loss [0.00019032 0.00019389 0.00020274 0.00019448 0.00077383 0.0001938
 0.00019207]
Model epoch 266: train total loss -65.36137506337708, train mean loss 0.00025550170271209635, test mean loss [0.00019435 0.00019346 0.00020224 0.00018979 0.00071444 0.00018528
 0.00019182]
Model epoch 267: train total loss -65.45204833609651, train mean loss 0.0002596364621095868, test mean loss [0.00018794 0.00019125 0.00020216 0.00019444 0.00067298 0.00018351
 0.00019881]
Model trained in 268 epochs with 3000 transitions.
[2025-01-24 03:11:21,059][absl][INFO] - {'eval/walltime': 132.2743103504181, 'training/sps': 0.5405968246794698, 'training/walltime': 3564.815008878708, 'training/model_train_time': 1139.7819609642029, 'training/other_time': 709.1914601325989, 'training/model_horizon': 4, 'training/hallucination_updates_per_training_step': 505, 'training/env_buffer_size': Array(4000, dtype=int32), 'model/train_total_loss': Array(-65.45204834, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00025964, dtype=float64), 'model/test_total_loss': Array(-64.74084308, dtype=float64), 'model/test_mean_loss': Array(0.00026158, dtype=float64), 'model/train_epochs': 268, 'model/sec_per_epoch': 4.245546722590034, 'sac/actor_loss': Array(-10.30430929, dtype=float64), 'sac/alpha': Array(0.03935115, dtype=float32), 'sac/alpha_loss': Array(0.00084167, dtype=float64), 'sac/buffer_current_size': Array(377045.56, dtype=float32), 'sac/critic_loss': Array(0.02114462, dtype=float64), 'eval/episode_forward_vel': Array(24.9694104, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-6.96483391, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(13.0195163, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.03462072, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(10.73953135, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(13.59647409, dtype=float64), 'eval/episode_rew_roll': Array(11.3206759, dtype=float64), 'eval/episode_rew_side_motion': Array(13.179536, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(13.52348561, dtype=float64), 'eval/episode_rew_yaw': Array(11.02106059, dtype=float64), 'eval/episode_rew_z_vel_change': Array(7.18656427, dtype=float64), 'eval/episode_reward': Array(85.83405942, dtype=float64), 'eval/episode_step_count': Array(37675., dtype=float64), 'eval/avg_episode_length': Array(275., dtype=float64), 'eval/epoch_eval_time': 30.0055992603302, 'eval/sps': 33.32711309392444}
Steps / Eval:  4000.0
Reward is  85.8340594165526
Error executing job with overrides: ['wandb.entity=an-tsaritsin-itmo-university', 'wandb.log_ssrl=true', 'render_epoch_interval=10']
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/home/ant/ssrl/ssrl/scripts/go1_train.py", line 199, in train_go1
    state = train_fn(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 259, in train
    ms = update_model_horizon(ms, epoch)
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 1302, in update_model_horizon
    data=sac_buffer_state.data.at[:current_size].set(current_data),
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/jax/_src/numpy/array_methods.py", line 493, in set
    return scatter._scatter_update(self.array, self.index, values, lax.scatter,
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/jax/_src/ops/scatter.py", line 80, in _scatter_update
    return _scatter_impl(x, y, scatter_op, treedef, static_idx, dynamic_idx,
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/jax/_src/ops/scatter.py", line 131, in _scatter_impl
    out = scatter_op(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/jax/_src/lax/slicing.py", line 680, in scatter
    return scatter_p.bind(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/jax/_src/core.py", line 416, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/jax/_src/core.py", line 420, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/jax/_src/core.py", line 921, in process_primitive
    return primitive.impl(*tracers, **params)
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/jax/_src/dispatch.py", line 87, in apply_primitive
    outs = fun(*args)
jaxlib.xla_extension.XlaRuntimeError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1190400000 bytes.
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.