run_name: null
sweep_name: null
env: Go1GoFast
algo: ssrl
gpus: '0'
num_seeds: 1
ssrl_dynamics_fn: contact_integrate_only
render_during_training: true
render_epoch_interval: 1
render_seed: 0
common:
  action_repeat: 1
  obs_history_length: 5
  normalize_observations: false
  forces_in_q_coords: true
actor_network:
  hidden_layers: 2
  hidden_size: 512
  activation: swish
  max_std: null
critic_network:
  hidden_layers: 5
  hidden_size: 256
env_common:
  policy_repeat: 4
  forward_vel_rew_weight: 2.0
  turn_rew_weight: 0.5
  pitch_rew_weight: 0.25
  roll_rew_weight: 0.25
  yaw_rew_weight: 0.5
  side_motion_rew_weight: 0.5
  z_vel_change_rew_weight: 0.15
  ang_vel_rew_weight: 0.0
  ang_change_rew_weight: 0.25
  joint_lim_rew_weight: 0.0
  torque_lim_rew_weight: 0.0
  joint_acc_rew_weight: 0.0
  action_rew_weight: 0.0
  cosmetic_rew_weight: 0.0
  energy_rew_weight: 0.25
  foot_z_rew_weight: 0.0
  torque_lim_penalty_weight: 0.1
  fallen_roll: 0.785
  fallen_pitch: 0.785
  include_height_in_obs: false
  gains_in_action_space: false
  reward_type: normalized
env_sac:
  policy_repeat: ${env_common.policy_repeat}
  forward_cmd_vel_type: constant
  forward_cmd_vel_range: 0.0
  forward_cmd_vel_period_range:
  - 40.0
  - 40.0
  turn_cmd_rate_range:
  - -0.0
  - 0.0
  initial_yaw_range:
  - -0.0
  - 0.0
  contact_time_const: 0.02
  contact_damping_ratio: 1.0
  friction_range:
  - 0.6
  - 0.6
  ground_roll_range:
  - 0.0
  - 0.0
  ground_pitch_range:
  - 0.0
  - 0.0
  joint_damping_perc_range:
  - 1.0
  - 1.0
  joint_gain_range:
  - 1.0
  - 1.0
  link_mass_perc_range:
  - 1.0
  - 1.0
  forward_vel_rew_weight: ${env_common.forward_vel_rew_weight}
  turn_rew_weight: ${env_common.turn_rew_weight}
  pitch_rew_weight: ${env_common.pitch_rew_weight}
  roll_rew_weight: ${env_common.roll_rew_weight}
  yaw_rew_weight: ${env_common.yaw_rew_weight}
  side_motion_rew_weight: ${env_common.side_motion_rew_weight}
  z_vel_change_rew_weight: ${env_common.z_vel_change_rew_weight}
  ang_vel_rew_weight: ${env_common.ang_vel_rew_weight}
  ang_change_rew_weight: ${env_common.ang_change_rew_weight}
  joint_lim_rew_weight: ${env_common.joint_lim_rew_weight}
  torque_lim_rew_weight: ${env_common.torque_lim_rew_weight}
  joint_acc_rew_weight: ${env_common.joint_acc_rew_weight}
  action_rew_weight: ${env_common.action_rew_weight}
  cosmetic_rew_weight: ${env_common.cosmetic_rew_weight}
  energy_rew_weight: ${env_common.energy_rew_weight}
  foot_z_rew_weight: ${env_common.foot_z_rew_weight}
  torque_lim_penalty_weight: ${env_common.torque_lim_penalty_weight}
  fallen_roll: ${env_common.fallen_roll}
  fallen_pitch: ${env_common.fallen_pitch}
  forces_in_q_coords: ${common.forces_in_q_coords}
  include_height_in_obs: ${env_common.include_height_in_obs}
  gains_in_action_space: ${env_common.gains_in_action_space}
  reward_type: ${env_common.reward_type}
sac:
  num_timesteps: 10000000
  episode_length: 1000
  action_repeat: ${common.action_repeat}
  obs_history_length: ${common.obs_history_length}
  num_envs: 1
  num_eval_envs: 500
  learning_rate: 0.0001
  discounting: 0.99
  seed: 0
  batch_size: 200
  num_evals: 10
  normalize_observations: ${common.normalize_observations}
  reward_scaling: 1
  tau: 0.001
  min_replay_size: 10000
  max_replay_size: 200000
  grad_updates_per_step: 20
  deterministic_eval: true
env_ssrl:
  policy_repeat: ${env_common.policy_repeat}
  forward_cmd_vel_type: constant
  forward_cmd_vel_range: 0.0
  forward_cmd_vel_period_range:
  - 40.0
  - 40.0
  turn_cmd_rate_range:
  - -0.0
  - 0.0
  initial_yaw_range:
  - -0.0
  - 0.0
  contact_time_const: 0.02
  contact_damping_ratio: 1.0
  friction_range:
  - 0.6
  - 0.6
  ground_roll_range:
  - 0.0
  - 0.0
  ground_pitch_range:
  - 0.0
  - 0.0
  joint_damping_perc_range:
  - 1.0
  - 1.0
  joint_gain_range:
  - 1.0
  - 1.0
  link_mass_perc_range:
  - 1.0
  - 1.0
  forward_vel_rew_weight: ${env_common.forward_vel_rew_weight}
  turn_rew_weight: ${env_common.turn_rew_weight}
  pitch_rew_weight: ${env_common.pitch_rew_weight}
  roll_rew_weight: ${env_common.roll_rew_weight}
  yaw_rew_weight: ${env_common.yaw_rew_weight}
  side_motion_rew_weight: ${env_common.side_motion_rew_weight}
  z_vel_change_rew_weight: ${env_common.z_vel_change_rew_weight}
  ang_vel_rew_weight: ${env_common.ang_vel_rew_weight}
  ang_change_rew_weight: ${env_common.ang_change_rew_weight}
  joint_lim_rew_weight: ${env_common.joint_lim_rew_weight}
  torque_lim_rew_weight: ${env_common.torque_lim_rew_weight}
  joint_acc_rew_weight: ${env_common.joint_acc_rew_weight}
  action_rew_weight: ${env_common.action_rew_weight}
  cosmetic_rew_weight: ${env_common.cosmetic_rew_weight}
  energy_rew_weight: ${env_common.energy_rew_weight}
  foot_z_rew_weight: ${env_common.foot_z_rew_weight}
  torque_lim_penalty_weight: ${env_common.torque_lim_penalty_weight}
  fallen_roll: ${env_common.fallen_roll}
  fallen_pitch: ${env_common.fallen_pitch}
  forces_in_q_coords: ${common.forces_in_q_coords}
  include_height_in_obs: ${env_common.include_height_in_obs}
  body_height_in_action_space: true
  gains_in_action_space: ${env_common.gains_in_action_space}
  reward_type: ${env_common.reward_type}
  healthy_delta_radius: 2.0
  healthy_delta_yaw: 1.57
ssrl_start_with_sac: false
ssrl:
  episode_length: 1000
  policy_repeat: 1
  num_epochs: 40
  model_trains_per_epoch: 1
  training_steps_per_model_train: 1
  env_steps_per_training_step: 1000
  model_rollouts_per_hallucination_update: 400
  sac_grad_updates_per_hallucination_update: 60
  init_exploration_steps: 1000
  clear_model_buffer_after_model_train: false
  action_repeat: ${common.action_repeat}
  obs_history_length: ${common.obs_history_length}
  num_envs: 1
  num_evals: 41
  num_eval_envs: 1
  policy_normalize_observations: ${common.normalize_observations}
  model_learning_rate: 0.001
  model_training_batch_size: 200
  model_training_max_sgd_steps_per_epoch: null
  model_training_max_epochs: 1000
  model_training_convergence_criteria: 0.01
  model_training_consec_converged_epochs: 6
  model_training_abs_criteria: null
  model_training_test_ratio: 0.2
  model_training_weight_decay: true
  model_training_stop_gradient: false
  model_loss_horizon: 4
  model_check_done_condition: true
  max_env_buffer_size: 15000
  max_model_buffer_size: 400000
  sac_learning_rate: 0.0002
  sac_discounting: 0.99
  sac_batch_size: 256
  real_ratio: 0.06
  sac_reward_scaling: 1.0
  sac_tau: 0.001
  sac_fixed_alpha: None
  seed: 2
  deterministic_in_env: true
  deterministic_eval: true
  hallucination_max_std: -1.0
  zero_final_layer_of_policy: false
ssrl_model:
  hidden_size: 400
  ensemble_size: 7
  num_elites: 5
  probabilistic: true
ssrl_linear_threshold_fn:
  start_epoch: 0
  end_epoch: 10
  start_model_horizon: 1
  end_model_horizon: 20
ssrl_hupts_fn:
  start_epoch: 0
  end_epoch: 4
  start_hupts: 10
  end_hupts: 1000
render:
  policy: ssrl
wandb:
  entity: an-tsaritsin-itmo-university
  log_sac: true
  log_ssrl: true
save_policy:
  sac: true
  sac_all: true
  ssrl: true
  ssrl_all: true
torque_validate:
  hardware_data: true
Running on GPU 0
[2025-02-04 16:58:58,283][root][INFO] - Converting mesh (-211983413843261293, 4962157424932640162) into convex hull.
[2025-02-04 16:59:02,004][root][INFO] - Converting mesh (1116717476491130172, -4907164435061487897) into convex hull.
[2025-02-04 16:59:02,406][root][INFO] - Converting mesh (-3681313371548595800, -7926055404713010868) into convex hull.
[2025-02-04 16:59:03,586][root][INFO] - Converting mesh (4000321723504779659, 7058784686849243891) into convex hull.
[2025-02-04 16:59:04,493][root][INFO] - Converting mesh (6346826235371589722, -3125788492321771633) into convex hull.
[2025-02-04 17:00:04,601][absl][INFO] - {'eval/walltime': 53.540180683135986, 'eval/episode_forward_vel': Array(-63.3573703, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-0.00082207, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(10.95750307, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.92424886, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-27.25048185, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(10.03892178, dtype=float64), 'eval/episode_rew_roll': Array(9.84072294, dtype=float64), 'eval/episode_rew_side_motion': Array(10.70388446, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(7.5595437, dtype=float64), 'eval/episode_rew_yaw': Array(21.86132657, dtype=float64), 'eval/episode_rew_z_vel_change': Array(6.38586286, dtype=float64), 'eval/episode_reward': Array(49.87941442, dtype=float64), 'eval/episode_step_count': Array(21945., dtype=float64), 'eval/avg_episode_length': Array(210., dtype=float64), 'eval/epoch_eval_time': 53.540180683135986, 'eval/sps': 18.67756117444293}
Steps / Eval:  0
Reward is  49.879414415329144
Total reward is  245.9253434252435
Error executing job with overrides: ['render_epoch_interval=1']
Traceback (most recent call last):
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/jax/_src/lax/slicing.py", line 1824, in _gather_lower
    dnums = hlo.GatherDimensionNumbers.get(
KeyboardInterrupt
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/home/ant/ssrl/ssrl/scripts/aliengo_train.py", line 248, in <module>
    train_go1()
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/ant/ssrl/ssrl/scripts/aliengo_train.py", line 199, in train_go1
    state = train_fn(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 174, in train
    metrics = ms.evaluator.run_evaluation(
  File "/home/ant/ssrl/ssrl/brax/training/acting.py", line 125, in run_evaluation
    eval_state = self._generate_eval_unroll(policy_params, unroll_key)
  File "/home/ant/ssrl/ssrl/brax/training/acting.py", line 106, in generate_eval_unroll
    eval_first_state = eval_env.reset(reset_keys)
  File "/home/ant/ssrl/ssrl/brax/envs/wrappers/training.py", line 223, in reset
    reset_state = self.env.reset(rng)
  File "/home/ant/ssrl/ssrl/brax/envs/wrappers/training.py", line 171, in reset
    state = self.env.reset(rng)
  File "/home/ant/ssrl/ssrl/brax/envs/wrappers/training.py", line 113, in reset
    return jax.vmap(self.env.reset)(rng)
  File "/home/ant/ssrl/ssrl/brax/envs/wrappers/training.py", line 143, in reset
    state = self.env.reset(rng)
  File "/home/ant/ssrl/ssrl/brax/envs/wrappers/training.py", line 63, in reset
    nstate = self.env.reset(rng)
  File "/home/ant/ssrl/ssrl/brax/envs/aliengo_go_fast.py", line 338, in reset
    pipeline_state = self.pipeline_init(q, qd)
  File "/home/ant/ssrl/ssrl/brax/envs/base.py", line 116, in pipeline_init
    return self._pipeline.init(self.sys, q, qd, self._debug)
  File "/home/ant/ssrl/ssrl/brax/generalized/pipeline.py", line 45, in init
    x, xd = kinematics.forward(sys, q, qd)
  File "/home/ant/ssrl/ssrl/brax/kinematics.py", line 85, in forward
    anchor = Transform.create(rot=j.rot).vmap().do(sys.link.joint)
  File "/home/ant/ssrl/ssrl/brax/base.py", line 125, in do
    return _transform_do(o, self)
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/functools.py", line 888, in wrapper
    return dispatch(args[0].__class__)(*args, **kw)
  File "/home/ant/ssrl/ssrl/brax/base.py", line 642, in _
    pos = self.pos + math.rotate(t.pos, self.rot)
  File "/home/ant/ssrl/ssrl/brax/math.py", line 39, in rotate
    r = r + 2 * s * jp.cross(u, vec)
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py", line 5520, in cross
    b0 = b[..., 0]
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/jax/_src/numpy/array_methods.py", line 739, in op
    return getattr(self.aval, f"_{name}")(self, *args)
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/jax/_src/numpy/array_methods.py", line 352, in _getitem
    return lax_numpy._rewriting_take(self, item)
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py", line 6594, in _rewriting_take
    return _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py", line 6624, in _gather
    y = lax.gather(
jax._src.source_info_util.JaxStackTraceBeforeTransformation: TypeError: get(): incompatible function arguments. The following argument types are supported:
    1. (cls: object, offset_dims: List[int], collapsed_slice_dims: List[int], operand_batching_dims: List[int], start_indices_batching_dims: List[int], start_index_map: List[int], index_vector_dim: int, context: MlirContext = None) -> object
Invoked with: <class 'importlib._bootstrap.GatherDimensionNumbers'>; kwargs: collapsed_slice_dims=[2], index_vector_dim=0, offset_dims=[0, 1], start_index_map=[2]
The preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.
--------------------
The above exception was the direct cause of the following exception:
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/home/ant/ssrl/ssrl/scripts/aliengo_train.py", line 199, in train_go1
    state = train_fn(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 237, in train
    env_state = ms.env.reset(env_keys)
  File "/home/ant/ssrl/ssrl/brax/envs/wrappers/training.py", line 171, in reset
    state = self.env.reset(rng)
  File "/home/ant/ssrl/ssrl/brax/envs/wrappers/training.py", line 113, in reset
    return jax.vmap(self.env.reset)(rng)
  File "/home/ant/ssrl/ssrl/brax/envs/wrappers/training.py", line 143, in reset
    state = self.env.reset(rng)
  File "/home/ant/ssrl/ssrl/brax/envs/wrappers/training.py", line 63, in reset
    nstate = self.env.reset(rng)
  File "/home/ant/ssrl/ssrl/brax/envs/aliengo_go_fast.py", line 338, in reset
    pipeline_state = self.pipeline_init(q, qd)
  File "/home/ant/ssrl/ssrl/brax/envs/base.py", line 116, in pipeline_init
    return self._pipeline.init(self.sys, q, qd, self._debug)
  File "/home/ant/ssrl/ssrl/brax/generalized/pipeline.py", line 47, in init
    state = dynamics.transform_com(sys, state)
  File "/home/ant/ssrl/ssrl/brax/generalized/dynamics.py", line 132, in transform_com
    cdofd = scan.link_types(sys, cdofd_fn, 'ldd', 'd', cd_p, cdof, cdof_qd)
  File "/home/ant/ssrl/ssrl/brax/scan.py", line 175, in link_types
    ys.append(f(typ, *in_args))
  File "/home/ant/ssrl/ssrl/brax/generalized/dynamics.py", line 127, in cdofd_fn
    cdofd = cd.vmap().cross(cdof)
  File "/home/ant/ssrl/ssrl/brax/base.py", line 173, in cross
    return _motion_cross(other, self)
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/functools.py", line 888, in wrapper
    return dispatch(args[0].__class__)(*args, **kw)
  File "/home/ant/ssrl/ssrl/brax/base.py", line 687, in _
    vel = jp.cross(self.ang, m.vel) + jp.cross(self.vel, m.ang)
TypeError: get(): incompatible function arguments. The following argument types are supported:
    1. (cls: object, offset_dims: List[int], collapsed_slice_dims: List[int], operand_batching_dims: List[int], start_indices_batching_dims: List[int], start_index_map: List[int], index_vector_dim: int, context: MlirContext = None) -> object
Invoked with: <class 'importlib._bootstrap.GatherDimensionNumbers'>; kwargs: collapsed_slice_dims=[2], index_vector_dim=0, offset_dims=[0, 1], start_index_map=[2]
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.