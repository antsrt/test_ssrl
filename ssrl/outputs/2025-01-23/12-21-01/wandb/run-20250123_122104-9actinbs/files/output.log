run_name: null
sweep_name: null
env: Go1GoFast
algo: ssrl
gpus: '0'
num_seeds: 1
ssrl_dynamics_fn: contact_integrate_only
render_during_training: true
render_epoch_interval: 15
render_seed: 0
common:
  action_repeat: 1
  obs_history_length: 5
  normalize_observations: false
  forces_in_q_coords: true
actor_network:
  hidden_layers: 2
  hidden_size: 512
  activation: swish
  max_std: null
critic_network:
  hidden_layers: 5
  hidden_size: 256
env_common:
  policy_repeat: 4
  forward_vel_rew_weight: 2.0
  turn_rew_weight: 0.5
  pitch_rew_weight: 0.25
  roll_rew_weight: 0.25
  yaw_rew_weight: 0.5
  side_motion_rew_weight: 0.5
  z_vel_change_rew_weight: 0.15
  ang_vel_rew_weight: 0.0
  ang_change_rew_weight: 0.25
  joint_lim_rew_weight: 0.0
  torque_lim_rew_weight: 0.0
  joint_acc_rew_weight: 0.0
  action_rew_weight: 0.0
  cosmetic_rew_weight: 0.0
  energy_rew_weight: 0.25
  foot_z_rew_weight: 0.0
  torque_lim_penalty_weight: 0.1
  fallen_roll: 0.785
  fallen_pitch: 0.785
  include_height_in_obs: false
  gains_in_action_space: false
  reward_type: normalized
env_sac:
  policy_repeat: ${env_common.policy_repeat}
  forward_cmd_vel_type: constant
  forward_cmd_vel_range: 0.0
  forward_cmd_vel_period_range:
  - 40.0
  - 40.0
  turn_cmd_rate_range:
  - -0.0
  - 0.0
  initial_yaw_range:
  - -0.0
  - 0.0
  contact_time_const: 0.02
  contact_damping_ratio: 1.0
  friction_range:
  - 0.6
  - 0.6
  ground_roll_range:
  - 0.0
  - 0.0
  ground_pitch_range:
  - 0.0
  - 0.0
  joint_damping_perc_range:
  - 1.0
  - 1.0
  joint_gain_range:
  - 1.0
  - 1.0
  link_mass_perc_range:
  - 1.0
  - 1.0
  forward_vel_rew_weight: ${env_common.forward_vel_rew_weight}
  turn_rew_weight: ${env_common.turn_rew_weight}
  pitch_rew_weight: ${env_common.pitch_rew_weight}
  roll_rew_weight: ${env_common.roll_rew_weight}
  yaw_rew_weight: ${env_common.yaw_rew_weight}
  side_motion_rew_weight: ${env_common.side_motion_rew_weight}
  z_vel_change_rew_weight: ${env_common.z_vel_change_rew_weight}
  ang_vel_rew_weight: ${env_common.ang_vel_rew_weight}
  ang_change_rew_weight: ${env_common.ang_change_rew_weight}
  joint_lim_rew_weight: ${env_common.joint_lim_rew_weight}
  torque_lim_rew_weight: ${env_common.torque_lim_rew_weight}
  joint_acc_rew_weight: ${env_common.joint_acc_rew_weight}
  action_rew_weight: ${env_common.action_rew_weight}
  cosmetic_rew_weight: ${env_common.cosmetic_rew_weight}
  energy_rew_weight: ${env_common.energy_rew_weight}
  foot_z_rew_weight: ${env_common.foot_z_rew_weight}
  torque_lim_penalty_weight: ${env_common.torque_lim_penalty_weight}
  fallen_roll: ${env_common.fallen_roll}
  fallen_pitch: ${env_common.fallen_pitch}
  forces_in_q_coords: ${common.forces_in_q_coords}
  include_height_in_obs: ${env_common.include_height_in_obs}
  gains_in_action_space: ${env_common.gains_in_action_space}
  reward_type: ${env_common.reward_type}
sac:
  num_timesteps: 10000000
  episode_length: 1000
  action_repeat: ${common.action_repeat}
  obs_history_length: ${common.obs_history_length}
  num_envs: 1
  num_eval_envs: 500
  learning_rate: 0.0001
  discounting: 0.99
  seed: 0
  batch_size: 200
  num_evals: 10
  normalize_observations: ${common.normalize_observations}
  reward_scaling: 1
  tau: 0.001
  min_replay_size: 10000
  max_replay_size: 200000
  grad_updates_per_step: 20
  deterministic_eval: true
env_ssrl:
  policy_repeat: ${env_common.policy_repeat}
  forward_cmd_vel_type: constant
  forward_cmd_vel_range: 0.0
  forward_cmd_vel_period_range:
  - 40.0
  - 40.0
  turn_cmd_rate_range:
  - -0.0
  - 0.0
  initial_yaw_range:
  - -0.0
  - 0.0
  contact_time_const: 0.02
  contact_damping_ratio: 1.0
  friction_range:
  - 0.6
  - 0.6
  ground_roll_range:
  - 0.0
  - 0.0
  ground_pitch_range:
  - 0.0
  - 0.0
  joint_damping_perc_range:
  - 1.0
  - 1.0
  joint_gain_range:
  - 1.0
  - 1.0
  link_mass_perc_range:
  - 1.0
  - 1.0
  forward_vel_rew_weight: ${env_common.forward_vel_rew_weight}
  turn_rew_weight: ${env_common.turn_rew_weight}
  pitch_rew_weight: ${env_common.pitch_rew_weight}
  roll_rew_weight: ${env_common.roll_rew_weight}
  yaw_rew_weight: ${env_common.yaw_rew_weight}
  side_motion_rew_weight: ${env_common.side_motion_rew_weight}
  z_vel_change_rew_weight: ${env_common.z_vel_change_rew_weight}
  ang_vel_rew_weight: ${env_common.ang_vel_rew_weight}
  ang_change_rew_weight: ${env_common.ang_change_rew_weight}
  joint_lim_rew_weight: ${env_common.joint_lim_rew_weight}
  torque_lim_rew_weight: ${env_common.torque_lim_rew_weight}
  joint_acc_rew_weight: ${env_common.joint_acc_rew_weight}
  action_rew_weight: ${env_common.action_rew_weight}
  cosmetic_rew_weight: ${env_common.cosmetic_rew_weight}
  energy_rew_weight: ${env_common.energy_rew_weight}
  foot_z_rew_weight: ${env_common.foot_z_rew_weight}
  torque_lim_penalty_weight: ${env_common.torque_lim_penalty_weight}
  fallen_roll: ${env_common.fallen_roll}
  fallen_pitch: ${env_common.fallen_pitch}
  forces_in_q_coords: ${common.forces_in_q_coords}
  include_height_in_obs: ${env_common.include_height_in_obs}
  body_height_in_action_space: true
  gains_in_action_space: ${env_common.gains_in_action_space}
  reward_type: ${env_common.reward_type}
  healthy_delta_radius: 2.0
  healthy_delta_yaw: 1.57
ssrl_start_with_sac: false
ssrl:
  episode_length: 1000
  policy_repeat: 1
  num_epochs: 40
  model_trains_per_epoch: 1
  training_steps_per_model_train: 1
  env_steps_per_training_step: 1000
  model_rollouts_per_hallucination_update: 400
  sac_grad_updates_per_hallucination_update: 60
  init_exploration_steps: 1000
  clear_model_buffer_after_model_train: false
  action_repeat: ${common.action_repeat}
  obs_history_length: ${common.obs_history_length}
  num_envs: 1
  num_evals: 41
  num_eval_envs: 1
  policy_normalize_observations: ${common.normalize_observations}
  model_learning_rate: 0.001
  model_training_batch_size: 200
  model_training_max_sgd_steps_per_epoch: null
  model_training_max_epochs: 1000
  model_training_convergence_criteria: 0.01
  model_training_consec_converged_epochs: 6
  model_training_abs_criteria: null
  model_training_test_ratio: 0.2
  model_training_weight_decay: true
  model_training_stop_gradient: false
  model_loss_horizon: 4
  model_check_done_condition: true
  max_env_buffer_size: 15000
  max_model_buffer_size: 400000
  sac_learning_rate: 0.0002
  sac_discounting: 0.99
  sac_batch_size: 256
  real_ratio: 0.06
  sac_reward_scaling: 1.0
  sac_tau: 0.001
  sac_fixed_alpha: None
  seed: 2
  deterministic_in_env: true
  deterministic_eval: true
  hallucination_max_std: -1.0
  zero_final_layer_of_policy: false
ssrl_model:
  hidden_size: 400
  ensemble_size: 7
  num_elites: 5
  probabilistic: true
ssrl_linear_threshold_fn:
  start_epoch: 0
  end_epoch: 10
  start_model_horizon: 1
  end_model_horizon: 20
ssrl_hupts_fn:
  start_epoch: 0
  end_epoch: 4
  start_hupts: 10
  end_hupts: 1000
render:
  policy: ssrl
wandb:
  entity: an-tsaritsin-itmo-university
  log_sac: false
  log_ssrl: true
save_policy:
  sac: false
  sac_all: false
  ssrl: false
  ssrl_all: false
torque_validate:
  hardware_data: true
Running on GPU 0
[2025-01-23 12:21:07,106][root][INFO] - Converting mesh (-3504117852864702019, 4824774534521404615) into convex hull.
[2025-01-23 12:21:13,847][root][INFO] - Converting mesh (-6804805487107472944, -105511687330258360) into convex hull.
[2025-01-23 12:21:16,698][root][INFO] - Converting mesh (5838023230490797361, 582165513621580246) into convex hull.
[2025-01-23 12:21:21,341][root][INFO] - Converting mesh (757213808687365753, -6299383376459713420) into convex hull.
[2025-01-23 12:21:25,651][root][INFO] - Converting mesh (-5848459167695189311, 5267000443826020045) into convex hull.
[2025-01-23 12:22:18,288][absl][INFO] - {'eval/walltime': 43.4778847694397, 'eval/episode_forward_vel': Array(-108.06761314, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-0.10795299, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(52.4840151, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.41374784, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-46.48069382, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(53.2687941, dtype=float64), 'eval/episode_rew_roll': Array(52.93924206, dtype=float64), 'eval/episode_rew_side_motion': Array(60.95221138, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(65.55126338, dtype=float64), 'eval/episode_rew_yaw': Array(6.68244079, dtype=float64), 'eval/episode_rew_z_vel_change': Array(26.42382521, dtype=float64), 'eval/episode_reward': Array(272.24928151, dtype=float64), 'eval/episode_step_count': Array(499500., dtype=float64), 'eval/avg_episode_length': Array(1000., dtype=float64), 'eval/epoch_eval_time': 43.4778847694397, 'eval/sps': 23.000198958687452}
Steps / Eval:  0
Reward is  272.24928150712003
Total reward is  271.76916479776787
[2025-01-23 12:24:36,109][absl][INFO] - env buffer size after init exploration 1000
Model epoch 0: train total loss -2.4319144024013193, train mean loss 0.08032993559518649, test mean loss [0.09042943 0.0904565  0.09044143 0.09040472 0.09044374 0.090441
 0.09042174]
Model epoch 1: train total loss -3.509569426707342, train mean loss 0.07843210117999427, test mean loss [0.08794202 0.08871119 0.08796481 0.08742892 0.08828626 0.08810298
 0.08752648]
Model epoch 2: train total loss -10.400117368302125, train mean loss 0.07170714570365472, test mean loss [0.08072796 0.07964426 0.07804771 0.07899258 0.07972798 0.07974538
 0.07890628]
Model epoch 3: train total loss -23.27376596286868, train mean loss 0.0714728453595046, test mean loss [0.08009753 0.07843326 0.07801206 0.08107292 0.07669165 0.07821238
 0.08194912]
Model epoch 4: train total loss -32.11485148915489, train mean loss 0.07045114806847762, test mean loss [0.07726948 0.07866761 0.07758866 0.08042426 0.0781971  0.07714733
 0.08063581]
Model epoch 5: train total loss -34.771014331075904, train mean loss 0.07090866542738412, test mean loss [0.07791703 0.07846536 0.07756339 0.07847617 0.07776658 0.07796556
 0.07848958]
Model epoch 6: train total loss -35.55591618258783, train mean loss 0.06905536003280394, test mean loss [0.07681792 0.07769177 0.07544756 0.07719245 0.07570995 0.07642937
 0.07768781]
Model epoch 7: train total loss -36.626324442969526, train mean loss 0.06824694790777353, test mean loss [0.07513372 0.07638745 0.07394193 0.07582324 0.07569689 0.0758839
 0.0774871 ]
Model epoch 8: train total loss -37.49948765221762, train mean loss 0.06628167342836595, test mean loss [0.07367052 0.07549282 0.07339709 0.074838   0.07628307 0.07459684
 0.07652859]
Model epoch 9: train total loss -38.060503123534765, train mean loss 0.06535025626762798, test mean loss [0.07309278 0.07393473 0.07320249 0.07492195 0.07579256 0.07242377
 0.07586252]
Model epoch 10: train total loss -38.49394167548788, train mean loss 0.06417825722853351, test mean loss [0.07180348 0.07149187 0.06971249 0.07535261 0.07226895 0.06842304
 0.07442044]
Model epoch 11: train total loss -39.0903763631466, train mean loss 0.062217142682408105, test mean loss [0.06779679 0.0682854  0.06619946 0.07514725 0.06882521 0.06424686
 0.07380101]
Model epoch 12: train total loss -39.59235919870202, train mean loss 0.060177080313844465, test mean loss [0.06408197 0.06561859 0.06238323 0.07317507 0.06532245 0.06055658
 0.07218849]
Model epoch 13: train total loss -40.23566992754249, train mean loss 0.058058756246623364, test mean loss [0.06143995 0.06137721 0.05751628 0.07019262 0.06096842 0.05552328
 0.07041215]
Model epoch 14: train total loss -41.02493381347958, train mean loss 0.05305848753805424, test mean loss [0.05917305 0.05735222 0.05236454 0.06657728 0.05697919 0.05158109
 0.06888188]
Model epoch 15: train total loss -41.76254680059175, train mean loss 0.05118705897225565, test mean loss [0.05754732 0.05330617 0.0484546  0.06256343 0.05430535 0.04835578
 0.06735732]
Model epoch 16: train total loss -42.44631771986588, train mean loss 0.04874510263574236, test mean loss [0.05556809 0.0499344  0.04515493 0.05964493 0.04868686 0.04307532
 0.06468425]
Model epoch 17: train total loss -43.054507032310276, train mean loss 0.04552322750605316, test mean loss [0.0512702  0.04739253 0.04087776 0.05708743 0.048294   0.03976583
 0.06133121]
Model epoch 18: train total loss -43.66523958071363, train mean loss 0.043234381455554666, test mean loss [0.04658074 0.04524895 0.03938287 0.05368879 0.04547702 0.03930149
 0.05707474]
Model epoch 19: train total loss -44.081641823728525, train mean loss 0.041056500567142495, test mean loss [0.0438456  0.04349375 0.037832   0.05108226 0.04336861 0.0367699
 0.05318318]
Model epoch 20: train total loss -44.718020825239435, train mean loss 0.03895480661068986, test mean loss [0.04189485 0.04223546 0.03518314 0.04827826 0.04142523 0.03647685
 0.04947586]
Model epoch 21: train total loss -45.06546935806931, train mean loss 0.037439523787297584, test mean loss [0.03939664 0.04123814 0.03453165 0.04640214 0.03906581 0.03427422
 0.046311  ]
Model epoch 22: train total loss -45.522812839320096, train mean loss 0.036034581345755684, test mean loss [0.03723053 0.03865667 0.03368406 0.04432745 0.03718325 0.03476423
 0.04321912]
Model epoch 23: train total loss -45.94617102421014, train mean loss 0.034011090030642156, test mean loss [0.03629515 0.03674249 0.03271725 0.04312426 0.03600034 0.03300803
 0.04124058]
Model epoch 24: train total loss -45.95303240071221, train mean loss 0.0334821127977123, test mean loss [0.03550265 0.03496871 0.03246442 0.04257999 0.03423064 0.03274365
 0.03942233]
Model epoch 25: train total loss -46.4038850445731, train mean loss 0.03301610594386504, test mean loss [0.03422408 0.03327759 0.03135027 0.04252695 0.03301367 0.03244669
 0.03772354]
Model epoch 26: train total loss -46.777322314142204, train mean loss 0.03156202954010766, test mean loss [0.03293005 0.03255177 0.03013174 0.04083598 0.03238615 0.03130743
 0.03590004]
Model epoch 27: train total loss -47.133176493788014, train mean loss 0.031011056751616917, test mean loss [0.03278834 0.03146134 0.03002457 0.03971958 0.03199592 0.0303699
 0.03432819]
Model epoch 28: train total loss -47.61541884090459, train mean loss 0.030046371408240364, test mean loss [0.0318096  0.0298251  0.02962465 0.03811009 0.03114485 0.03020729
 0.03352418]
Model epoch 29: train total loss -47.89006620022335, train mean loss 0.02934601515761164, test mean loss [0.0306253  0.0293867  0.02933598 0.03688476 0.03023248 0.02891168
 0.03259014]
Model epoch 30: train total loss -48.11623700752684, train mean loss 0.02878101671981137, test mean loss [0.03001678 0.02933627 0.02851679 0.03556664 0.02977428 0.027704
 0.0312894 ]
Model epoch 31: train total loss -48.4104502205634, train mean loss 0.02821716740619377, test mean loss [0.02907744 0.02949978 0.02776609 0.03450542 0.02887742 0.02676677
 0.03064605]
Model epoch 32: train total loss -48.650627908078334, train mean loss 0.027816153994380026, test mean loss [0.02825172 0.0284869  0.02740909 0.03395463 0.02815843 0.02602027
 0.03331632]
Model epoch 33: train total loss -48.64490380148718, train mean loss 0.02724498925616907, test mean loss [0.02796537 0.02735238 0.02681014 0.03426377 0.02760178 0.02549258
 0.03248759]
Model epoch 34: train total loss -48.93773086428894, train mean loss 0.02653659329401071, test mean loss [0.02677829 0.02737712 0.02657136 0.03369977 0.0268369  0.02496783
 0.03062343]
Model epoch 35: train total loss -49.263826560903624, train mean loss 0.026432076933461432, test mean loss [0.02674288 0.02652196 0.02585629 0.03299175 0.0263194  0.02430669
 0.02943604]
Model epoch 36: train total loss -49.39852559293681, train mean loss 0.025220879298527996, test mean loss [0.02705143 0.02625844 0.02602775 0.03233763 0.02604853 0.0235744
 0.02793374]
Model epoch 37: train total loss -49.79478621222892, train mean loss 0.024953772428256055, test mean loss [0.02566783 0.02589074 0.02545742 0.0312047  0.02578326 0.02292774
 0.02702373]
Model epoch 38: train total loss -49.878590229342585, train mean loss 0.024624091969183682, test mean loss [0.02529096 0.02552281 0.02450832 0.03026152 0.02501059 0.02286318
 0.02696154]
Model epoch 39: train total loss -50.39433022306237, train mean loss 0.023707550107897213, test mean loss [0.02489751 0.02502712 0.02406917 0.03009315 0.02438463 0.0223357
 0.02621813]
Model epoch 40: train total loss -50.491193507898465, train mean loss 0.02313992576301064, test mean loss [0.02458722 0.02423521 0.02286702 0.02926553 0.02438776 0.02216088
 0.02533973]
Model epoch 41: train total loss -50.78728889480626, train mean loss 0.02276523680818047, test mean loss [0.02416431 0.02395007 0.02280365 0.02804676 0.0242835  0.02204782
 0.02491484]
Model epoch 42: train total loss -50.995332030603095, train mean loss 0.022664040105388427, test mean loss [0.02366825 0.02386876 0.02268026 0.02777699 0.02369295 0.02187795
 0.02414983]
Model epoch 43: train total loss -51.177553350090285, train mean loss 0.022453462294204845, test mean loss [0.02343718 0.02373393 0.02208862 0.02709883 0.02337452 0.02125278
 0.02347982]
Model epoch 44: train total loss -51.27912047663362, train mean loss 0.0217441780467658, test mean loss [0.02293103 0.0234592  0.02191158 0.02670554 0.02279738 0.02144768
 0.02271142]
Model epoch 45: train total loss -51.49780786860736, train mean loss 0.02151282670346158, test mean loss [0.02242479 0.02338228 0.02169273 0.02645487 0.02268911 0.02102257
 0.02217339]
Model epoch 46: train total loss -51.49038255978815, train mean loss 0.021848757045776757, test mean loss [0.02196878 0.02315278 0.02201078 0.02593561 0.02274051 0.02083162
 0.02152766]
Model epoch 47: train total loss -51.67395090894612, train mean loss 0.020971489821542174, test mean loss [0.02215604 0.02262171 0.02199776 0.02555373 0.02230398 0.02067013
 0.02072292]
Model epoch 48: train total loss -51.80493924907223, train mean loss 0.02084457771658932, test mean loss [0.02188586 0.02201509 0.02164843 0.02505173 0.0219806  0.02093457
 0.0209331 ]
Model epoch 49: train total loss -52.010139059158995, train mean loss 0.020487729967126136, test mean loss [0.02144648 0.02223555 0.02141842 0.02466935 0.02190521 0.02026145
 0.02077011]
Model epoch 50: train total loss -52.16330482985125, train mean loss 0.02050266418810563, test mean loss [0.02114386 0.02166257 0.02120396 0.02437925 0.021765   0.02005458
 0.02055817]
Model epoch 51: train total loss -52.346934977158654, train mean loss 0.020154966034658994, test mean loss [0.02106459 0.02138296 0.02077293 0.02408515 0.0212225  0.01960647
 0.01997634]
Model epoch 52: train total loss -52.413762600408845, train mean loss 0.019544720702785314, test mean loss [0.02061509 0.02105932 0.02053802 0.02341885 0.02146911 0.01989367
 0.01977866]
Model epoch 53: train total loss -52.56250509342523, train mean loss 0.019619199964939417, test mean loss [0.02055708 0.02051297 0.02045513 0.0231449  0.02128573 0.01926103
 0.01963596]
Model epoch 54: train total loss -52.69741886671813, train mean loss 0.019257415512689308, test mean loss [0.02012696 0.02034954 0.01978559 0.02303792 0.02066119 0.01936687
 0.01924062]
Model epoch 55: train total loss -52.821363438851, train mean loss 0.019294008711056698, test mean loss [0.01973503 0.02010989 0.0196131  0.02257159 0.02024562 0.0190304
 0.01890196]
Model epoch 56: train total loss -52.87566849019655, train mean loss 0.019176923353342052, test mean loss [0.01922948 0.01971744 0.01939031 0.02283811 0.0203168  0.01877713
 0.0187874 ]
Model epoch 57: train total loss -53.1238598725004, train mean loss 0.018695056778055597, test mean loss [0.01920887 0.01939468 0.01934241 0.02282797 0.01995098 0.01810443
 0.01845604]
Model epoch 58: train total loss -53.174576677882044, train mean loss 0.018672890614998838, test mean loss [0.01917545 0.01882337 0.01919329 0.02249847 0.01949038 0.01816948
 0.01793997]
Model epoch 59: train total loss -53.343240798543334, train mean loss 0.018350702018977774, test mean loss [0.01894573 0.01856533 0.0187468  0.02229236 0.01931399 0.01805287
 0.01762101]
Model epoch 60: train total loss -53.41570480396157, train mean loss 0.018075110940192953, test mean loss [0.01846927 0.01858808 0.01860839 0.02191975 0.01933686 0.01754829
 0.01738658]
Model epoch 61: train total loss -53.47988504804105, train mean loss 0.017921732078401927, test mean loss [0.01820723 0.01848133 0.01847544 0.02159166 0.01907675 0.01766632
 0.01686367]
Model epoch 62: train total loss -53.57396341330246, train mean loss 0.017666165730163625, test mean loss [0.0178343  0.01800541 0.0183344  0.02145654 0.01888271 0.0171979
 0.01709323]
Model epoch 63: train total loss -53.66705716355524, train mean loss 0.017132412462285824, test mean loss [0.01806063 0.01750856 0.01798204 0.02083656 0.01831968 0.01683326
 0.01695923]
Model epoch 64: train total loss -53.71191657912745, train mean loss 0.017100825325144738, test mean loss [0.01786166 0.01699425 0.01764803 0.02075782 0.01840464 0.01649316
 0.01666761]
Model epoch 65: train total loss -53.69061564328147, train mean loss 0.016596183065657882, test mean loss [0.01751625 0.01689568 0.01736245 0.02079012 0.01806115 0.01668104
 0.01658694]
Model epoch 66: train total loss -54.127875915094144, train mean loss 0.016596357014768946, test mean loss [0.01728498 0.01638548 0.01731181 0.02059927 0.01778494 0.01618321
 0.01634489]
Model epoch 67: train total loss -53.972243753979335, train mean loss 0.01664135136178797, test mean loss [0.01683813 0.01630068 0.01715301 0.0204042  0.01740156 0.01572575
 0.01588369]
Model epoch 68: train total loss -54.15299151238951, train mean loss 0.015822309324439343, test mean loss [0.01686718 0.01618067 0.01718993 0.02017996 0.01723296 0.01534442
 0.01544199]
Model epoch 69: train total loss -54.26565976537581, train mean loss 0.016166182007123178, test mean loss [0.016809   0.01596397 0.01691265 0.01988566 0.01693658 0.01513067
 0.01516319]
Model epoch 70: train total loss -54.4332233641248, train mean loss 0.01554060677052005, test mean loss [0.01633988 0.01566529 0.01687879 0.01965259 0.01698866 0.01475572
 0.01491541]
Model epoch 71: train total loss -54.531067772320185, train mean loss 0.015223829176844625, test mean loss [0.01613797 0.01546076 0.01673049 0.01916484 0.01700547 0.01445156
 0.01482636]
Model epoch 72: train total loss -54.52130262696972, train mean loss 0.015682943435265346, test mean loss [0.01584934 0.01525514 0.01626008 0.01907592 0.01689166 0.01407937
 0.0141443 ]
Model epoch 73: train total loss -54.6514759073527, train mean loss 0.015192734195645187, test mean loss [0.01582904 0.01494548 0.01602448 0.01898046 0.0164584  0.01400608
 0.01421848]
Model epoch 74: train total loss -54.84122600828358, train mean loss 0.014743679260224562, test mean loss [0.01516802 0.01453821 0.0158941  0.0187714  0.01625616 0.01383022
 0.01384661]
Model epoch 75: train total loss -54.749982165444415, train mean loss 0.015274620895327534, test mean loss [0.01485471 0.01431907 0.01547529 0.01873097 0.01601465 0.01374829
 0.01398359]
Model epoch 76: train total loss -54.881409141459116, train mean loss 0.014720944502120142, test mean loss [0.01472657 0.01400637 0.01537924 0.01838823 0.01600376 0.01342807
 0.01369197]
Model epoch 77: train total loss -55.03356640415873, train mean loss 0.014089002041452997, test mean loss [0.0146296  0.01380478 0.01499434 0.01834543 0.01582308 0.01298798
 0.01348299]
Model epoch 78: train total loss -55.108420622519674, train mean loss 0.014312905021457175, test mean loss [0.0144661  0.01370415 0.01470291 0.01831028 0.01585287 0.01248871
 0.01341716]
Model epoch 79: train total loss -55.184396720449755, train mean loss 0.013931496766121057, test mean loss [0.01437662 0.0135191  0.01501915 0.01786972 0.01537497 0.01243374
 0.01293   ]
Model epoch 80: train total loss -55.210506463662774, train mean loss 0.013950330168830946, test mean loss [0.01421188 0.01339276 0.0148211  0.01738786 0.01515487 0.01202567
 0.01282547]
Model epoch 81: train total loss -55.368379973936555, train mean loss 0.01371995121684798, test mean loss [0.01408886 0.01300148 0.01431099 0.01771615 0.01491028 0.01223679
 0.01254878]
Model epoch 82: train total loss -55.472468509751025, train mean loss 0.013339435846448186, test mean loss [0.01365463 0.01274945 0.01426779 0.01737869 0.01482719 0.01188326
 0.01243564]
Model epoch 83: train total loss -55.60694556540301, train mean loss 0.013134955304183415, test mean loss [0.0135798  0.0125721  0.01385571 0.01708816 0.01458359 0.01155287
 0.01243049]
Model epoch 84: train total loss -55.55870647831621, train mean loss 0.01305771820211198, test mean loss [0.01323822 0.01215793 0.01355716 0.01693061 0.01419312 0.01141475
 0.01188185]
Model epoch 85: train total loss -55.754720647695514, train mean loss 0.012694160965936424, test mean loss [0.01335709 0.01203732 0.01368438 0.01696871 0.01436554 0.01124425
 0.01157087]
Model epoch 86: train total loss -55.74588964739425, train mean loss 0.012649169680872657, test mean loss [0.01295345 0.01175622 0.01364644 0.01670268 0.01408518 0.0115001
 0.01146089]
Model epoch 87: train total loss -55.90968882488839, train mean loss 0.012394225159707065, test mean loss [0.01252886 0.01152546 0.01315482 0.01640962 0.01391782 0.0111814
 0.01141626]
Model epoch 88: train total loss -56.0111060119766, train mean loss 0.012381396873731043, test mean loss [0.01249291 0.0114749  0.0129108  0.01626274 0.01354406 0.01071779
 0.01093078]
Model epoch 89: train total loss -56.15511944475899, train mean loss 0.012096520872595957, test mean loss [0.01208878 0.01119068 0.01319241 0.01632571 0.01332671 0.01067963
 0.01072939]
Model epoch 90: train total loss -56.12865407243227, train mean loss 0.01160278575288131, test mean loss [0.0120547  0.01085798 0.01281768 0.01578278 0.01293503 0.01033761
 0.01058265]
Model epoch 91: train total loss -56.211288091913154, train mean loss 0.011606108911068454, test mean loss [0.01205251 0.01105727 0.01241827 0.0157338  0.01307829 0.01025252
 0.01036882]
Model epoch 92: train total loss -56.1182809435876, train mean loss 0.011579620941279645, test mean loss [0.01184462 0.01060361 0.01229082 0.01552765 0.01276916 0.00998261
 0.01020354]
Model epoch 93: train total loss -56.22926131572211, train mean loss 0.011464034539407315, test mean loss [0.01152399 0.01054077 0.01196819 0.01521045 0.01258292 0.00955052
 0.01037408]
Model epoch 94: train total loss -56.29674539772764, train mean loss 0.011378153536418693, test mean loss [0.01147741 0.01023897 0.0118706  0.01530826 0.01266255 0.00949537
 0.00998144]
Model epoch 95: train total loss -56.452289131013714, train mean loss 0.01110743999357245, test mean loss [0.01127312 0.00980249 0.01166263 0.01527939 0.01241036 0.00953858
 0.0100599 ]
Model epoch 96: train total loss -56.37958930301983, train mean loss 0.01091503709805732, test mean loss [0.01117195 0.0103198  0.01142409 0.01544382 0.01234087 0.00917596
 0.00978985]
Model epoch 97: train total loss -56.529726842136085, train mean loss 0.010672496958230946, test mean loss [0.0109183  0.00997206 0.01150412 0.01511272 0.01228568 0.00920494
 0.00944835]
Model epoch 98: train total loss -56.50327247196364, train mean loss 0.010253706111646933, test mean loss [0.01120228 0.00952769 0.01148175 0.01484052 0.01197765 0.00845715
 0.00941418]
Model epoch 99: train total loss -56.54506517251128, train mean loss 0.010421355184002069, test mean loss [0.01104334 0.00929921 0.01116503 0.01474048 0.0118908  0.00861065
 0.00898995]
Model epoch 100: train total loss -56.692228495067845, train mean loss 0.010291198382486101, test mean loss [0.01056032 0.00900003 0.01094947 0.01464885 0.01146617 0.0084734
 0.00878575]
Model epoch 101: train total loss -56.71810410655346, train mean loss 0.010181862750279616, test mean loss [0.01074906 0.00903556 0.01065247 0.01429466 0.01155358 0.00830451
 0.00858189]
Model epoch 102: train total loss -56.85412437438789, train mean loss 0.01003494473439061, test mean loss [0.01032297 0.00863834 0.0107499  0.01408018 0.01139153 0.00808825
 0.00840011]
Model epoch 103: train total loss -57.010534435266706, train mean loss 0.009519782254501051, test mean loss [0.01022497 0.00855576 0.01052212 0.01380269 0.01103314 0.00800664
 0.00801749]
Model epoch 104: train total loss -56.931216615375796, train mean loss 0.009501111296416294, test mean loss [0.01003113 0.00850519 0.01030977 0.01398124 0.01065131 0.00797944
 0.00796783]
Model epoch 105: train total loss -57.00404053233869, train mean loss 0.00969244326209988, test mean loss [0.00995639 0.00817299 0.01000404 0.01346371 0.01072393 0.00789353
 0.00834449]
Model epoch 106: train total loss -57.18569915761805, train mean loss 0.00925981977698408, test mean loss [0.00956219 0.00780077 0.01007904 0.01348162 0.01060677 0.00737809
 0.00788919]
Model epoch 107: train total loss -57.20280286468092, train mean loss 0.009251309177178958, test mean loss [0.00932417 0.00788984 0.01018975 0.01330548 0.01049117 0.00767723
 0.00787028]
Model epoch 108: train total loss -57.3663325624899, train mean loss 0.008953387764021048, test mean loss [0.00926026 0.00764744 0.00985202 0.01307537 0.0101959  0.00730199
 0.00748288]
Model epoch 109: train total loss -57.344449298055764, train mean loss 0.00896479063001949, test mean loss [0.00921522 0.00778591 0.00948509 0.01291451 0.01006156 0.00724258
 0.00737288]
Model epoch 110: train total loss -57.33862445180369, train mean loss 0.008739402479332505, test mean loss [0.00916591 0.007595   0.00922852 0.01259586 0.01024297 0.00747523
 0.00734888]
Model epoch 111: train total loss -57.32148772074102, train mean loss 0.008585343965019263, test mean loss [0.00879881 0.00747136 0.00930941 0.01244984 0.01005441 0.00724775
 0.00711003]
Model epoch 112: train total loss -57.40509332342768, train mean loss 0.008410384494013703, test mean loss [0.00881681 0.0071324  0.00900285 0.01223056 0.01004043 0.00716339
 0.00688993]
Model epoch 113: train total loss -57.32918986477363, train mean loss 0.008346742226444152, test mean loss [0.0089514  0.0067559  0.00935347 0.01234933 0.00990597 0.00704226
 0.00648658]
Model epoch 114: train total loss -57.540752677863026, train mean loss 0.008264893191085499, test mean loss [0.00852894 0.00679149 0.00916329 0.01214051 0.0097869  0.00687538
 0.0064003 ]
Model epoch 115: train total loss -57.53224999918177, train mean loss 0.008115688325795048, test mean loss [0.00840116 0.00670712 0.00879675 0.01239125 0.00953037 0.00676182
 0.0063698 ]
Model epoch 116: train total loss -57.56608978462137, train mean loss 0.008127002120011622, test mean loss [0.00823213 0.00638759 0.00867622 0.01220524 0.00927265 0.00680978
 0.00609069]
Model epoch 117: train total loss -57.79784134734834, train mean loss 0.0078053263873480725, test mean loss [0.00816629 0.00604872 0.00862244 0.01172588 0.00918068 0.00649482
 0.00611671]
Model epoch 118: train total loss -57.79094001605572, train mean loss 0.007816120589461836, test mean loss [0.00787644 0.00616468 0.00832648 0.01194564 0.00906226 0.00634214
 0.00600917]
Model epoch 119: train total loss -57.86520891384687, train mean loss 0.00746758700513317, test mean loss [0.00779185 0.00629423 0.00815397 0.01183867 0.00894944 0.00597357
 0.00580866]
Model epoch 120: train total loss -57.89221412892737, train mean loss 0.007351273141568091, test mean loss [0.00753007 0.00594366 0.00831551 0.01162067 0.00857832 0.0059395
 0.00562372]
Model epoch 121: train total loss -57.871083708153385, train mean loss 0.007304808334771932, test mean loss [0.00728966 0.0059222  0.00798069 0.01148744 0.00845758 0.00602854
 0.00542882]
Model epoch 122: train total loss -58.08399927077228, train mean loss 0.0073451302505020705, test mean loss [0.00710271 0.0056755  0.008024   0.01158428 0.00848327 0.00563531
 0.0052198 ]
Model epoch 123: train total loss -58.15104216755949, train mean loss 0.007023147932649732, test mean loss [0.00709077 0.00565185 0.00769569 0.01102888 0.00844288 0.00567129
 0.0052757 ]
Model epoch 124: train total loss -58.16097193990718, train mean loss 0.007161113494519684, test mean loss [0.00700819 0.00529311 0.00754061 0.01105975 0.00800217 0.00550311
 0.00509713]
Model epoch 125: train total loss -58.066331898151454, train mean loss 0.006627086715406428, test mean loss [0.00701789 0.00525271 0.00746789 0.01079506 0.00836389 0.00573018
 0.00475859]
Model epoch 126: train total loss -58.05011663453454, train mean loss 0.006850466938160746, test mean loss [0.00736242 0.00510522 0.00764577 0.01091376 0.00806433 0.00533842
 0.00494363]
Model epoch 127: train total loss -58.148276069295854, train mean loss 0.006655861642714634, test mean loss [0.00703    0.00507495 0.00745815 0.01075075 0.00772749 0.0053939
 0.00470001]
Model epoch 128: train total loss -58.262399850893814, train mean loss 0.006569198427756634, test mean loss [0.00682645 0.00476655 0.007146   0.01094232 0.00775513 0.00516438
 0.00467597]
Model epoch 129: train total loss -58.06959171696081, train mean loss 0.006533744686537524, test mean loss [0.00702277 0.00492579 0.00715186 0.01040055 0.00763597 0.00494773
 0.00456925]
Model epoch 130: train total loss -58.47343290608527, train mean loss 0.006392869323871267, test mean loss [0.00670341 0.00460443 0.0069783  0.01018644 0.00740278 0.00479938
 0.00436265]
Model epoch 131: train total loss -58.32656566281596, train mean loss 0.0064226570952737455, test mean loss [0.00671001 0.00465331 0.00683994 0.01019187 0.0074029  0.00481161
 0.00461237]
Model epoch 132: train total loss -58.422575470019375, train mean loss 0.006315168124886542, test mean loss [0.00651066 0.00459089 0.00670189 0.00988267 0.00707833 0.00473829
 0.00446138]
Model epoch 133: train total loss -58.618598240829314, train mean loss 0.005955047360811234, test mean loss [0.00624614 0.00437422 0.00674233 0.00973565 0.00690335 0.00446998
 0.00389329]
Model epoch 134: train total loss -58.60115338070817, train mean loss 0.00572368940112989, test mean loss [0.00608855 0.00410561 0.00658028 0.00958557 0.00706745 0.00473416
 0.00398555]
Model epoch 135: train total loss -58.540358139333016, train mean loss 0.006011510188728311, test mean loss [0.00595708 0.00427912 0.00650772 0.00941235 0.0067631  0.00473341
 0.003948  ]
Model epoch 136: train total loss -58.82499566279871, train mean loss 0.005660745489187288, test mean loss [0.00586875 0.00400689 0.00618649 0.00946652 0.00667393 0.0047014
 0.00368533]
Model epoch 137: train total loss -58.87169233095402, train mean loss 0.005678644406857279, test mean loss [0.00586994 0.00386018 0.00619951 0.00938688 0.00661516 0.00428198
 0.0037747 ]
Model epoch 138: train total loss -58.75352124135981, train mean loss 0.005547991040188668, test mean loss [0.00584211 0.00395391 0.00638192 0.00908109 0.00653227 0.00426067
 0.00352524]
Model epoch 139: train total loss -58.74102062143, train mean loss 0.005521074716231624, test mean loss [0.00595159 0.00365535 0.00607864 0.00901612 0.00620487 0.00422647
 0.00340553]
Model epoch 140: train total loss -58.91254010371227, train mean loss 0.00522510617936223, test mean loss [0.00545338 0.00355479 0.00618386 0.0092577  0.00630573 0.00412885
 0.00348504]
Model epoch 141: train total loss -58.81676660110174, train mean loss 0.005251749129369969, test mean loss [0.00543968 0.00323743 0.00593631 0.00890722 0.00599268 0.00426169
 0.00329801]
Model epoch 142: train total loss -58.79918113034665, train mean loss 0.005015407834654667, test mean loss [0.00535654 0.00349703 0.0057651  0.00889344 0.00622481 0.00418399
 0.00317746]
Model epoch 143: train total loss -58.754126611338855, train mean loss 0.005428102612837008, test mean loss [0.00517531 0.00347868 0.00567959 0.00859905 0.00628332 0.00393054
 0.00311797]
Model epoch 144: train total loss -58.920943950157664, train mean loss 0.005061836469653164, test mean loss [0.00534892 0.0033716  0.00543569 0.00834519 0.00626058 0.00408728
 0.00298732]
Model epoch 145: train total loss -58.99717027861105, train mean loss 0.005036818449301529, test mean loss [0.0051007  0.00336939 0.00549583 0.00828623 0.00592426 0.00382987
 0.00306738]
Model epoch 146: train total loss -59.178352110042454, train mean loss 0.004847388835087702, test mean loss [0.00497321 0.0032216  0.0054754  0.00822501 0.00567187 0.00373106
 0.00285592]
Model epoch 147: train total loss -59.02289914804805, train mean loss 0.004839860877028495, test mean loss [0.00485533 0.00322789 0.0052781  0.00831389 0.00593132 0.00371971
 0.00290296]
Model epoch 148: train total loss -59.03180849542872, train mean loss 0.004980226603773133, test mean loss [0.00493227 0.00300176 0.00532754 0.00810483 0.0056753  0.00354784
 0.00280416]
Model epoch 149: train total loss -59.133775096945854, train mean loss 0.0047022284384124384, test mean loss [0.00477027 0.00286929 0.00518124 0.00817611 0.00565476 0.00351931
 0.00281198]
Model epoch 150: train total loss -59.30168124898789, train mean loss 0.004670646345717851, test mean loss [0.00451123 0.00284492 0.00488786 0.00802182 0.00530701 0.00346579
 0.0026328 ]
Model epoch 151: train total loss -59.07671545532866, train mean loss 0.004504063813413216, test mean loss [0.00450464 0.00338593 0.00484564 0.00788522 0.00520254 0.00321098
 0.00308053]
Model epoch 152: train total loss -59.15508707078494, train mean loss 0.004431449406680337, test mean loss [0.00441531 0.00305799 0.00493256 0.00789518 0.00518245 0.00324356
 0.0027442 ]
Model epoch 153: train total loss -59.07767445157925, train mean loss 0.0045126044832611584, test mean loss [0.00439596 0.00271062 0.00477728 0.00781366 0.0051952  0.00334215
 0.00260417]
Model epoch 154: train total loss -59.286928287921945, train mean loss 0.004490870749652434, test mean loss [0.00432275 0.00264679 0.00474507 0.00749597 0.00511203 0.00322559
 0.00257319]
Model epoch 155: train total loss -59.480140115411345, train mean loss 0.004214894225252758, test mean loss [0.00428918 0.002704   0.00470359 0.00739054 0.00494179 0.00326424
 0.00264726]
Model epoch 156: train total loss -59.478820074281145, train mean loss 0.004099114743499479, test mean loss [0.00422398 0.00267779 0.00468053 0.00728615 0.00468754 0.00312521
 0.00258408]
Model epoch 157: train total loss -59.45852958402711, train mean loss 0.0041281186218280865, test mean loss [0.00417071 0.0024934  0.00458485 0.00702462 0.00475461 0.00296145
 0.00244443]
Model epoch 158: train total loss -59.48126141561315, train mean loss 0.004112948727312034, test mean loss [0.00411506 0.00233664 0.00456624 0.00690875 0.00446888 0.00306594
 0.00231479]
Model epoch 159: train total loss -59.400690093144, train mean loss 0.003909967167679595, test mean loss [0.00393019 0.00228541 0.00442123 0.00687202 0.00462049 0.00308378
 0.00242101]
Model epoch 160: train total loss -59.56923970602042, train mean loss 0.0039544315621238375, test mean loss [0.00390038 0.00232556 0.00438424 0.00677189 0.00441239 0.00290446
 0.0023545 ]
Model epoch 161: train total loss -59.70072840473081, train mean loss 0.003927233472237439, test mean loss [0.00394105 0.00225246 0.0044316  0.00672043 0.0041163  0.00296737
 0.00227167]
Model epoch 162: train total loss -59.635345918149085, train mean loss 0.003859783987742062, test mean loss [0.00386602 0.00216909 0.00429429 0.00643217 0.00422206 0.00283957
 0.0022345 ]
Model epoch 163: train total loss -59.610353601494154, train mean loss 0.003727141433069144, test mean loss [0.00377357 0.00223403 0.00413108 0.00640893 0.00411915 0.0026928
 0.00222969]
Model epoch 164: train total loss -59.7026008878949, train mean loss 0.0037619897787161045, test mean loss [0.00371647 0.00200296 0.00412996 0.00627586 0.00395632 0.00258989
 0.00225395]
Model epoch 165: train total loss -59.85963623306357, train mean loss 0.003734819997607931, test mean loss [0.00365243 0.00203535 0.00398974 0.0061632  0.00409722 0.0026462
 0.00227494]
Model epoch 166: train total loss -59.64651487336751, train mean loss 0.0035419635951640313, test mean loss [0.00353039 0.00194068 0.00431962 0.00625068 0.00399543 0.00265622
 0.00219095]
Model epoch 167: train total loss -59.348096466685455, train mean loss 0.0037215610374660367, test mean loss [0.00360754 0.00216135 0.0039235  0.00596499 0.00388059 0.00261321
 0.00212905]
Model epoch 168: train total loss -59.57096177022561, train mean loss 0.003592703816511079, test mean loss [0.00352525 0.00229105 0.00385233 0.00585951 0.00374468 0.00265796
 0.00210829]
Model epoch 169: train total loss -59.679183207343506, train mean loss 0.0034376433381524433, test mean loss [0.00367057 0.00213566 0.00366913 0.00565953 0.00372515 0.00268346
 0.00209871]
Model epoch 170: train total loss -59.91006020528682, train mean loss 0.003178147175271363, test mean loss [0.00351151 0.00197487 0.00363429 0.00547656 0.00345064 0.00251647
 0.00202224]
Model epoch 171: train total loss -59.90580278009516, train mean loss 0.003350046802880549, test mean loss [0.00336039 0.00186176 0.00360525 0.00555986 0.00349109 0.00256343
 0.00215168]
Model epoch 172: train total loss -60.003124821929525, train mean loss 0.003281130388095712, test mean loss [0.00352386 0.00176358 0.00359446 0.00544849 0.00340939 0.00242269
 0.00193512]
Model epoch 173: train total loss -60.026132896573664, train mean loss 0.0031411460729735313, test mean loss [0.00361492 0.00181633 0.0035645  0.00527456 0.00351828 0.00242183
 0.00193522]
Model epoch 174: train total loss -59.92504072791528, train mean loss 0.003286403233943214, test mean loss [0.00337288 0.00174756 0.00359843 0.00528744 0.00328439 0.00236368
 0.00201273]
Model epoch 175: train total loss -60.16703090967594, train mean loss 0.0031667475853142378, test mean loss [0.00332058 0.00165305 0.00355653 0.00503368 0.00321455 0.00227702
 0.001957  ]
Model epoch 176: train total loss -60.12528280788602, train mean loss 0.0030708633398054885, test mean loss [0.00315945 0.00160747 0.00334239 0.00520369 0.00309302 0.00223016
 0.00190393]
Model epoch 177: train total loss -60.02496094885381, train mean loss 0.003080443412633378, test mean loss [0.00320557 0.00164192 0.00326952 0.0049376  0.00308922 0.00233928
 0.00191495]
Model epoch 178: train total loss -60.03341178221013, train mean loss 0.002928405681570809, test mean loss [0.00318273 0.00157396 0.00328262 0.0049793  0.0030779  0.0022312
 0.00200195]
Model epoch 179: train total loss -60.12436866160875, train mean loss 0.0027728408053209197, test mean loss [0.00310069 0.0014881  0.00317835 0.00487853 0.00313931 0.00229969
 0.00196232]
Model epoch 180: train total loss -60.138708573291616, train mean loss 0.0030092113318987723, test mean loss [0.00309409 0.00147566 0.00316351 0.00521244 0.00299526 0.002212
 0.00182353]
Model epoch 181: train total loss -60.09390727162042, train mean loss 0.0026748928366182923, test mean loss [0.00303346 0.00152503 0.00311565 0.00470994 0.00298807 0.00222187
 0.00183275]
Model epoch 182: train total loss -60.35547212904748, train mean loss 0.0027499647716022067, test mean loss [0.00296883 0.00153564 0.00304435 0.00459021 0.00306309 0.00201507
 0.00175237]
Model epoch 183: train total loss -60.239486743609, train mean loss 0.0026856424805777154, test mean loss [0.0029642  0.00144713 0.00306126 0.0045201  0.00267311 0.0021098
 0.00171521]
Model epoch 184: train total loss -60.43703160196528, train mean loss 0.0028894703888915066, test mean loss [0.00287725 0.0013691  0.00294119 0.00432306 0.00268292 0.00207735
 0.00170847]
Model epoch 185: train total loss -60.510986800492354, train mean loss 0.0028478575852231955, test mean loss [0.00283882 0.00136613 0.00286615 0.00438993 0.00274336 0.00210394
 0.00164561]
Model epoch 186: train total loss -60.505676989141584, train mean loss 0.0026232519960510694, test mean loss [0.00305763 0.00128258 0.00289692 0.0041714  0.00269581 0.00208103
 0.00161145]
Model epoch 187: train total loss -60.4220788786487, train mean loss 0.0027644764635999667, test mean loss [0.00306872 0.0012999  0.00287975 0.00426996 0.00258871 0.00200805
 0.00167451]
Model epoch 188: train total loss -60.59301366952766, train mean loss 0.0026862443325598637, test mean loss [0.00274447 0.00129149 0.00271201 0.00415647 0.00258101 0.00196166
 0.00155642]
Model epoch 189: train total loss -60.54337106825604, train mean loss 0.002582301533159965, test mean loss [0.00281565 0.00130103 0.00265128 0.00407644 0.00255916 0.00196785
 0.00157561]
Model epoch 190: train total loss -60.71228116726511, train mean loss 0.002399896222964001, test mean loss [0.00281948 0.00121768 0.00259815 0.00393857 0.00251532 0.0019166
 0.00147972]
Model epoch 191: train total loss -60.718718239738244, train mean loss 0.0023195907511514326, test mean loss [0.0026603  0.00125896 0.00263764 0.00393162 0.0025257  0.00190384
 0.00156661]
Model epoch 192: train total loss -60.636429353376116, train mean loss 0.0024790249801015067, test mean loss [0.00263573 0.00123564 0.00263925 0.00377012 0.00248393 0.00196108
 0.00151155]
Model epoch 193: train total loss -60.67313463784734, train mean loss 0.0023813239472068276, test mean loss [0.00254038 0.00116444 0.00280082 0.00377802 0.00236913 0.00181015
 0.00145632]
Model epoch 194: train total loss -60.76491558351083, train mean loss 0.002377782022174592, test mean loss [0.00248563 0.00119177 0.00275024 0.00370068 0.00244597 0.0018018
 0.00147139]
Model epoch 195: train total loss -60.75439913823572, train mean loss 0.002418701036709376, test mean loss [0.00243417 0.00122157 0.00249959 0.00370191 0.00237213 0.00184492
 0.00148926]
Model epoch 196: train total loss -60.429144660334764, train mean loss 0.002441461183063138, test mean loss [0.00266279 0.00120845 0.00267223 0.00351934 0.00356369 0.00184527
 0.00138237]
Model epoch 197: train total loss -60.383744956600964, train mean loss 0.00244414189612277, test mean loss [0.00255486 0.0012061  0.00259893 0.0036122  0.00284863 0.00184844
 0.00147472]
Model epoch 198: train total loss -60.358123975534234, train mean loss 0.0023108502331387316, test mean loss [0.00234846 0.00116786 0.00253599 0.00352812 0.00255871 0.00179803
 0.00151485]
Model epoch 199: train total loss -60.69016912076181, train mean loss 0.0023066177527552504, test mean loss [0.00252131 0.00113929 0.0025183  0.00354903 0.00238383 0.00169686
 0.0014706 ]
Model epoch 200: train total loss -60.69796227234568, train mean loss 0.0022881753393833373, test mean loss [0.00230871 0.00114275 0.0024217  0.00340815 0.00233529 0.00170658
 0.00145172]
Model epoch 201: train total loss -60.567615643311825, train mean loss 0.002418818140634622, test mean loss [0.00228061 0.00114479 0.00236758 0.00333383 0.00230224 0.00188797
 0.00135574]
Model epoch 202: train total loss -60.77651064105449, train mean loss 0.002225889921915505, test mean loss [0.00220623 0.00108257 0.00248596 0.0033258  0.00220798 0.00173657
 0.00132898]
Model epoch 203: train total loss -60.88514548148245, train mean loss 0.0021907341463111, test mean loss [0.00220014 0.00100993 0.00242673 0.00320976 0.00219448 0.0017121
 0.00138587]
Model epoch 204: train total loss -60.85732381452256, train mean loss 0.0022502440894428713, test mean loss [0.00221174 0.00101387 0.00232616 0.00328394 0.00220372 0.0016342
 0.00137078]
Model epoch 205: train total loss -60.801907082662474, train mean loss 0.0021064365809218694, test mean loss [0.00225767 0.00105387 0.00231063 0.00323128 0.0021324  0.00156395
 0.00130443]
Model epoch 206: train total loss -60.96264072683095, train mean loss 0.002007869155115568, test mean loss [0.00213607 0.00100421 0.00235135 0.003136   0.0022577  0.00159232
 0.00128675]
Model epoch 207: train total loss -61.11210382508901, train mean loss 0.001984837234718174, test mean loss [0.00209392 0.00097477 0.00228184 0.00314894 0.00220368 0.00155505
 0.00129452]
Model epoch 208: train total loss -60.79970738520186, train mean loss 0.0021073905596648546, test mean loss [0.00205034 0.00093261 0.00232246 0.00309887 0.00210307 0.00150401
 0.00125912]
Model epoch 209: train total loss -60.777837401527776, train mean loss 0.0021099248263255657, test mean loss [0.00227327 0.00092312 0.00223017 0.00306639 0.00204777 0.00152826
 0.00120544]
Model epoch 210: train total loss -60.89804473480877, train mean loss 0.001981031588400796, test mean loss [0.00218613 0.00099571 0.00224398 0.00289761 0.00199003 0.00150998
 0.00122803]
Model epoch 211: train total loss -61.031594626724285, train mean loss 0.0019977318075957633, test mean loss [0.00218717 0.00092536 0.00220945 0.00279463 0.0020352  0.00162967
 0.00118663]
Model epoch 212: train total loss -61.082254945395356, train mean loss 0.001965820363856269, test mean loss [0.00210292 0.00086948 0.0022368  0.00292792 0.00200065 0.0015048
 0.00117408]
Model epoch 213: train total loss -60.89577879372519, train mean loss 0.0019469693237513421, test mean loss [0.00205665 0.00085609 0.0021728  0.00299404 0.00193096 0.00149203
 0.00118955]
Model epoch 214: train total loss -61.0580002817019, train mean loss 0.0019363614527509513, test mean loss [0.00192669 0.00083108 0.00207793 0.00295325 0.00199446 0.00150927
 0.00111283]
Model epoch 215: train total loss -61.10260883748715, train mean loss 0.0018859249590205047, test mean loss [0.00208431 0.00083766 0.00208251 0.00291932 0.00183575 0.00144678
 0.00112098]
Model epoch 216: train total loss -60.7056619587201, train mean loss 0.0019927383301963156, test mean loss [0.00193332 0.00092952 0.00210373 0.00283983 0.00212614 0.00148276
 0.00107947]
Model epoch 217: train total loss -60.972465526651916, train mean loss 0.0017952853161424683, test mean loss [0.00188134 0.00087528 0.00207424 0.00273052 0.00224449 0.00139945
 0.00107675]
Model epoch 218: train total loss -61.19918285347989, train mean loss 0.001830745037024245, test mean loss [0.00186641 0.00086923 0.00206914 0.00265213 0.00202604 0.00131547
 0.00105041]
Model epoch 219: train total loss -61.23979026111934, train mean loss 0.0018372249503495312, test mean loss [0.00182178 0.00078756 0.00204773 0.00258759 0.00195634 0.00140504
 0.00104835]
Model epoch 220: train total loss -61.23026378335151, train mean loss 0.0017934732794479726, test mean loss [0.00177049 0.00081608 0.00195773 0.00277227 0.00190387 0.00144422
 0.00100484]
Model epoch 221: train total loss -61.353569410628396, train mean loss 0.001697040745356863, test mean loss [0.00177905 0.00079471 0.00201186 0.00260953 0.00194599 0.00133329
 0.00102401]
Model epoch 222: train total loss -61.20984489483937, train mean loss 0.0017629856290610193, test mean loss [0.00175431 0.00078822 0.00213851 0.00261695 0.00183    0.00127668
 0.00110524]
Model epoch 223: train total loss -61.26709835351248, train mean loss 0.0017217909643595535, test mean loss [0.00177138 0.00080239 0.0019917  0.00257479 0.00185593 0.00129113
 0.00095743]
Model epoch 224: train total loss -61.445566731622655, train mean loss 0.0017858958359969698, test mean loss [0.00178306 0.00074504 0.00196581 0.00256716 0.00183959 0.0012633
 0.00099823]
Model epoch 225: train total loss -61.23609063978448, train mean loss 0.0017640443776055393, test mean loss [0.00173184 0.00084962 0.001862   0.00240584 0.00195615 0.00124035
 0.00094783]
Model epoch 226: train total loss -61.32139259023784, train mean loss 0.0017157668047271825, test mean loss [0.00171179 0.00082153 0.00181884 0.00242507 0.00183406 0.00124406
 0.00101455]
Model epoch 227: train total loss -61.06401290670568, train mean loss 0.001688673053068078, test mean loss [0.00171218 0.00078363 0.00205812 0.00242392 0.00189017 0.00123162
 0.00095633]
Model epoch 228: train total loss -61.44127183135735, train mean loss 0.0016007252735404653, test mean loss [0.00161919 0.00073509 0.00195288 0.00245639 0.0017803  0.00128046
 0.00094292]
Model epoch 229: train total loss -61.541965888916316, train mean loss 0.0016222499490322394, test mean loss [0.00165022 0.00069285 0.00186491 0.00234618 0.00166569 0.00125102
 0.00093053]
Model epoch 230: train total loss -61.52879797701248, train mean loss 0.0015808910527775433, test mean loss [0.00168306 0.00068575 0.00176635 0.00237163 0.00170492 0.00116605
 0.0009294 ]
Model epoch 231: train total loss -61.454796639388995, train mean loss 0.001490580448581707, test mean loss [0.0016435  0.0006753  0.0018012  0.00227171 0.00179915 0.00110887
 0.00085875]
Model epoch 232: train total loss -61.51269287323735, train mean loss 0.0015559612798818718, test mean loss [0.00158012 0.00070172 0.00183709 0.00232037 0.00165087 0.00115386
 0.00086034]
Model epoch 233: train total loss -61.364158814441616, train mean loss 0.0015552814274592533, test mean loss [0.00150062 0.00076269 0.00179265 0.00227927 0.00169574 0.00110224
 0.00088554]
Model epoch 234: train total loss -61.52366567553665, train mean loss 0.0014639359169697293, test mean loss [0.0015262  0.00071321 0.001823   0.0022935  0.00170798 0.00111457
 0.00084953]
Model epoch 235: train total loss -61.35703345498344, train mean loss 0.0015707768407281397, test mean loss [0.0016991  0.00069191 0.00177197 0.00212764 0.00160095 0.00104077
 0.00094381]
Model epoch 236: train total loss -61.46760133483391, train mean loss 0.0014449622509274096, test mean loss [0.00148789 0.00067932 0.00177979 0.0021783  0.00161604 0.00097526
 0.00090616]
Model epoch 237: train total loss -61.59870270202338, train mean loss 0.0015289359311740523, test mean loss [0.00147569 0.00064175 0.00173502 0.00211227 0.00162759 0.00101836
 0.00085085]
Model epoch 238: train total loss -61.54935660018102, train mean loss 0.0015476221504593188, test mean loss [0.00158192 0.00064067 0.00174977 0.00213981 0.0015324  0.00106438
 0.00083292]
Model epoch 239: train total loss -61.55934994442712, train mean loss 0.0015042156290444543, test mean loss [0.00153642 0.00066785 0.00173005 0.00208689 0.00161915 0.00101223
 0.0008055 ]
Model epoch 240: train total loss -61.62968249048163, train mean loss 0.0014293747410570705, test mean loss [0.00149484 0.00062304 0.00173217 0.00216382 0.00151023 0.0009626
 0.00085443]
Model epoch 241: train total loss -61.41510085457123, train mean loss 0.0015039004187898358, test mean loss [0.00142188 0.00062679 0.00177877 0.00201613 0.00154167 0.00099069
 0.00142885]
Model epoch 242: train total loss -61.47137084500577, train mean loss 0.0015230041352525849, test mean loss [0.00136497 0.0006189  0.00178573 0.00205421 0.00148785 0.00093673
 0.00124033]
Model epoch 243: train total loss -61.61579477521757, train mean loss 0.0014689259590856423, test mean loss [0.00138021 0.00063847 0.0016374  0.00217612 0.00152749 0.00092883
 0.00108024]
Model epoch 244: train total loss -61.67975762830551, train mean loss 0.0014548445995504332, test mean loss [0.0013589  0.00064912 0.00167457 0.00200574 0.00149696 0.00091618
 0.00091043]
Model epoch 245: train total loss -61.70860167114135, train mean loss 0.0014937486498368137, test mean loss [0.0013153  0.0006206  0.00168098 0.00200723 0.00148601 0.0009403
 0.00087036]
Model epoch 246: train total loss -61.88807914114698, train mean loss 0.0012878728909411698, test mean loss [0.00141058 0.00059742 0.00166729 0.00193923 0.00144159 0.00086675
 0.00083308]
Model epoch 247: train total loss -62.04887258151378, train mean loss 0.001301878468261547, test mean loss [0.00127695 0.00061001 0.00164862 0.00193848 0.00148438 0.00083029
 0.00083992]
Model epoch 248: train total loss -61.71081529204519, train mean loss 0.0012789205094705031, test mean loss [0.0012729  0.00060948 0.00163283 0.0019141  0.00139519 0.0007773
 0.00082186]
Model epoch 249: train total loss -61.901189144370264, train mean loss 0.0012259463908908187, test mean loss [0.001269   0.00068681 0.00160227 0.00202726 0.00133027 0.00081583
 0.0007918 ]
Model epoch 250: train total loss -61.986186836110846, train mean loss 0.001309385558651938, test mean loss [0.00121998 0.00061723 0.00153778 0.00194179 0.00140955 0.0007883
 0.00077806]
Model epoch 251: train total loss -62.151044162888354, train mean loss 0.0012306268175837532, test mean loss [0.00130645 0.00060549 0.00152344 0.00184786 0.00135087 0.00078359
 0.00075344]
Model epoch 252: train total loss -62.06750931532074, train mean loss 0.0013090865211150553, test mean loss [0.00123226 0.00058136 0.00150339 0.00187247 0.0013435  0.00074154
 0.00072864]
Model epoch 253: train total loss -61.90293565081806, train mean loss 0.0011901099987154365, test mean loss [0.00121735 0.00057521 0.00153264 0.00182699 0.00124882 0.00101148
 0.00074134]
Model epoch 254: train total loss -61.81907306152948, train mean loss 0.0014638310672122322, test mean loss [0.00116437 0.00055022 0.00154036 0.00195321 0.00122244 0.00153903
 0.00071133]
Model epoch 255: train total loss -61.84304105714333, train mean loss 0.0012945584478266812, test mean loss [0.00117435 0.00055484 0.00155223 0.00183657 0.00122954 0.00120556
 0.00072859]
Model epoch 256: train total loss -61.66321254696478, train mean loss 0.001259612908452235, test mean loss [0.00116488 0.00053664 0.00153926 0.00173599 0.00118307 0.00099536
 0.00071597]
Model epoch 257: train total loss -61.786282563041766, train mean loss 0.0012184585034811588, test mean loss [0.00116063 0.00057203 0.00147483 0.00172935 0.00124565 0.00097468
 0.00071973]
Model epoch 258: train total loss -61.91349144300988, train mean loss 0.001322217857392427, test mean loss [0.00116379 0.00055626 0.00156769 0.00170647 0.00127987 0.00083369
 0.00070173]
Model epoch 259: train total loss -62.069547639697994, train mean loss 0.0012251055870147892, test mean loss [0.00110247 0.000566   0.00148924 0.00168096 0.0012228  0.00080963
 0.00069628]
Model epoch 260: train total loss -62.29979527552645, train mean loss 0.00110380331040145, test mean loss [0.00116434 0.00052703 0.00140415 0.00160545 0.00118854 0.00072958
 0.00068764]
Model epoch 261: train total loss -62.15621497837372, train mean loss 0.0010959059608353463, test mean loss [0.001139   0.00051865 0.00138834 0.00174165 0.00116781 0.00068904
 0.00067179]
Model epoch 262: train total loss -62.07007826407491, train mean loss 0.0011593460972958323, test mean loss [0.00108615 0.00050927 0.00138365 0.00169606 0.00115959 0.00071175
 0.00067785]
Model epoch 263: train total loss -62.080841073710516, train mean loss 0.001197984565101646, test mean loss [0.00105649 0.00052523 0.00140693 0.00160869 0.00123581 0.0006947
 0.00070626]
Model epoch 264: train total loss -62.27073617517091, train mean loss 0.0012548077073850348, test mean loss [0.00102524 0.00052082 0.0013989  0.00159679 0.00119645 0.0006701
 0.00068743]
Model epoch 265: train total loss -62.30380880966712, train mean loss 0.0011476812487838408, test mean loss [0.00105941 0.00052168 0.00130804 0.00160514 0.00115189 0.00065881
 0.00066879]
Model epoch 266: train total loss -62.34160434566032, train mean loss 0.00115668810010101, test mean loss [0.00101276 0.00051949 0.00141452 0.00155412 0.00108341 0.00064645
 0.00065806]
Model epoch 267: train total loss -62.1559226404779, train mean loss 0.0010436548986195449, test mean loss [0.00100664 0.00049087 0.00140321 0.00159463 0.00109886 0.00061503
 0.00071495]
Model epoch 268: train total loss -62.128760703347666, train mean loss 0.001166501502867595, test mean loss [0.00092218 0.00049018 0.00140586 0.0015447  0.00108943 0.00063462
 0.00066724]
Model epoch 269: train total loss -62.225189743808514, train mean loss 0.001090865278730562, test mean loss [0.00096051 0.00050229 0.00133148 0.00158602 0.00104605 0.00059952
 0.00066824]
Model epoch 270: train total loss -62.48606594029288, train mean loss 0.001179092398312218, test mean loss [0.00095492 0.00054472 0.00131009 0.00156568 0.00106202 0.00063263
 0.00064693]
Model epoch 271: train total loss -62.370652705714626, train mean loss 0.0010780105172726654, test mean loss [0.0009937  0.00050819 0.00127529 0.00151235 0.00102757 0.00059542
 0.00064915]
Model epoch 272: train total loss -61.96324443663239, train mean loss 0.001062235046228069, test mean loss [0.00093958 0.00050958 0.00126496 0.00154624 0.00096444 0.00059758
 0.00064689]
Model epoch 273: train total loss -61.88382142252979, train mean loss 0.0011408405642679437, test mean loss [0.00096268 0.00049829 0.00130041 0.00147461 0.00108364 0.00063979
 0.00065061]
Model epoch 274: train total loss -62.06400838133648, train mean loss 0.0011782679555390064, test mean loss [0.00089521 0.00050159 0.00127488 0.00143012 0.00095297 0.00063747
 0.00070368]
Model epoch 275: train total loss -62.365301797420216, train mean loss 0.0010526200686015214, test mean loss [0.0008327  0.00049385 0.00124968 0.00143979 0.00101784 0.00061539
 0.0006546 ]
Model epoch 276: train total loss -61.968019599234154, train mean loss 0.001026520189364301, test mean loss [0.00091617 0.00049869 0.00122709 0.00146149 0.00097029 0.00057391
 0.00075409]
Model epoch 277: train total loss -62.048989684998254, train mean loss 0.0010808490770216244, test mean loss [0.00084053 0.0005069  0.00117417 0.00144666 0.00090284 0.00055623
 0.00087044]
Model epoch 278: train total loss -61.95087611486915, train mean loss 0.0010947187614108473, test mean loss [0.00079739 0.00048876 0.00120596 0.00145792 0.00091272 0.00054016
 0.0008731 ]
Model epoch 279: train total loss -62.16808467935834, train mean loss 0.0010493861420903076, test mean loss [0.00084135 0.00049241 0.00117611 0.001395   0.00092254 0.00052828
 0.0009378 ]
Model epoch 280: train total loss -61.816670799599805, train mean loss 0.001048767804683641, test mean loss [0.0008028  0.00047309 0.00114419 0.00142586 0.00089264 0.00115352
 0.00080955]
Model epoch 281: train total loss -61.80901835846776, train mean loss 0.0010847348023088367, test mean loss [0.00079614 0.00049672 0.0011644  0.00141435 0.00083713 0.00084787
 0.00073307]
Model epoch 282: train total loss -61.56225999643904, train mean loss 0.0011565296561457964, test mean loss [0.0008121  0.00184601 0.00113323 0.00138884 0.00079342 0.00083234
 0.0006438 ]
Model epoch 283: train total loss -61.77890828761489, train mean loss 0.0012074967422897483, test mean loss [0.0007951  0.00191631 0.00112218 0.0013838  0.00083259 0.0008045
 0.00061917]
Model epoch 284: train total loss -61.99494398500155, train mean loss 0.0011833323905273835, test mean loss [0.00074072 0.00170809 0.00114894 0.00135028 0.00090275 0.00071237
 0.00062518]
Model epoch 285: train total loss -62.12670866540561, train mean loss 0.0010982379119167508, test mean loss [0.00074743 0.00133817 0.00110306 0.00133351 0.00084437 0.00073086
 0.00061107]
Model epoch 286: train total loss -62.32894157031473, train mean loss 0.0010268978030436458, test mean loss [0.00073524 0.00115362 0.00106901 0.00132235 0.00079419 0.00062053
 0.00059604]
Model epoch 287: train total loss -61.98259670874612, train mean loss 0.0010208489738292787, test mean loss [0.00073243 0.00108456 0.00107479 0.00122767 0.00078286 0.0005677
 0.00118187]
Model epoch 288: train total loss -61.81219946424768, train mean loss 0.0013164962573049056, test mean loss [0.00071408 0.00100286 0.0010525  0.001262   0.00078539 0.00056366
 0.00261195]
Model epoch 289: train total loss -62.006278162953684, train mean loss 0.0011946087283730908, test mean loss [0.00070782 0.00092193 0.00104684 0.00123773 0.00079153 0.00057606
 0.00242186]
Model epoch 290: train total loss -62.03208427844032, train mean loss 0.0011703693511834216, test mean loss [0.00073989 0.00091705 0.00105692 0.00118794 0.00071684 0.00052593
 0.00207517]
Model epoch 291: train total loss -62.21586164333566, train mean loss 0.0011039903368101603, test mean loss [0.00067588 0.00087943 0.00098    0.00119672 0.00075525 0.00053228
 0.00164664]
Model epoch 292: train total loss -62.28478305904262, train mean loss 0.0010100525557499643, test mean loss [0.00066013 0.0008799  0.00101342 0.00123237 0.00070869 0.00053111
 0.00139835]
Model epoch 293: train total loss -62.38021712816394, train mean loss 0.0009967037480221954, test mean loss [0.00066168 0.00093199 0.00103332 0.00125159 0.00069213 0.00050524
 0.00124026]
Model epoch 294: train total loss -62.079302836685166, train mean loss 0.0009880194920173309, test mean loss [0.0009698  0.00084772 0.00101871 0.00119241 0.00068062 0.00049235
 0.0011135 ]
Model epoch 295: train total loss -62.31601928765749, train mean loss 0.0009000152883891933, test mean loss [0.00073141 0.0008709  0.00096514 0.00114458 0.00065425 0.00049072
 0.00107215]
Model epoch 296: train total loss -62.4615419928366, train mean loss 0.0010030506947650549, test mean loss [0.00073231 0.00083708 0.00100076 0.00117288 0.00066829 0.00048222
 0.00098438]
Model epoch 297: train total loss -62.51933390947279, train mean loss 0.0009367592746562663, test mean loss [0.00073932 0.00078054 0.00101729 0.00115852 0.00064266 0.0004826
 0.00097545]
Model epoch 298: train total loss -62.629829306064856, train mean loss 0.0009166896895159718, test mean loss [0.00069355 0.00077221 0.00088328 0.0011877  0.00061513 0.00046464
 0.00090445]
Model epoch 299: train total loss -62.58681871413711, train mean loss 0.0009248451248116604, test mean loss [0.00063738 0.00076691 0.0009117  0.00114869 0.0006128  0.00044779
 0.00085716]
Model epoch 300: train total loss -62.75085768108715, train mean loss 0.0009613886129633595, test mean loss [0.00065672 0.00076926 0.00090385 0.00112683 0.00058189 0.00045503
 0.00084766]
Model epoch 301: train total loss -62.75258625410148, train mean loss 0.0008376076880029349, test mean loss [0.00065195 0.00073602 0.00091121 0.00106659 0.00061269 0.00045125
 0.00080323]
Model epoch 302: train total loss -62.840512136142515, train mean loss 0.0009116521223748969, test mean loss [0.00062776 0.00073757 0.00095116 0.0010747  0.00063246 0.00044941
 0.00072699]
Model epoch 303: train total loss -62.8902443289386, train mean loss 0.000845559449638281, test mean loss [0.00068314 0.00072302 0.00090134 0.00106609 0.0005593  0.00044102
 0.00073975]
Model epoch 304: train total loss -62.70902656299414, train mean loss 0.0008496190669596724, test mean loss [0.00060322 0.00068593 0.00084839 0.00108025 0.0005547  0.00040671
 0.00066364]
Model epoch 305: train total loss -62.81160522618528, train mean loss 0.0008216894751672873, test mean loss [0.00059153 0.00071064 0.00088094 0.00103955 0.00062477 0.00041499
 0.00064188]
Model epoch 306: train total loss -62.699663229095854, train mean loss 0.0008510979940815314, test mean loss [0.0005779  0.00071818 0.00088009 0.00099788 0.00060374 0.00048371
 0.00064354]
Model epoch 307: train total loss -62.76815327927319, train mean loss 0.0007852103576780879, test mean loss [0.00060335 0.00067373 0.00087532 0.00100105 0.00060608 0.00042401
 0.0006541 ]
Model epoch 308: train total loss -62.57549317147146, train mean loss 0.0007897278588520252, test mean loss [0.00060403 0.0006723  0.00084466 0.00097404 0.00059681 0.00041539
 0.00059717]
Model epoch 309: train total loss -62.70940589748534, train mean loss 0.0008775464499121033, test mean loss [0.00056602 0.00065262 0.00080925 0.00095345 0.00061573 0.00040715
 0.00061279]
Model epoch 310: train total loss -62.80203161963914, train mean loss 0.0007982823285254566, test mean loss [0.00052598 0.00060317 0.00081616 0.00099538 0.00056346 0.00040604
 0.00058861]
Model epoch 311: train total loss -62.92296859592798, train mean loss 0.0007466954358602584, test mean loss [0.00057342 0.0005715  0.00078971 0.00095548 0.00054842 0.00039658
 0.00056754]
Model epoch 312: train total loss -62.95196810592744, train mean loss 0.0007549903220836556, test mean loss [0.00053799 0.0005672  0.00073684 0.00099866 0.00051582 0.00039265
 0.00056229]
Model epoch 313: train total loss -63.098725034839056, train mean loss 0.0008026544077057905, test mean loss [0.00052434 0.00059246 0.00077573 0.00095125 0.00048523 0.00039579
 0.00054365]
Model epoch 314: train total loss -62.176509669185464, train mean loss 0.0007804248728876461, test mean loss [0.00054199 0.00054597 0.00185302 0.00092424 0.00049177 0.00039166
 0.00056276]
Model epoch 315: train total loss -62.0272281729251, train mean loss 0.0012431417245199695, test mean loss [0.00053998 0.00057628 0.00764186 0.0009415  0.00050257 0.0004051
 0.00053773]
Model epoch 316: train total loss -61.96095708823773, train mean loss 0.0015133394259959614, test mean loss [0.00052442 0.00051027 0.00925748 0.00092635 0.00049392 0.00040131
 0.00057102]
Model epoch 317: train total loss -62.10446400162237, train mean loss 0.0017233009640106795, test mean loss [0.00051287 0.00049184 0.00878056 0.00088406 0.00047982 0.0003889
 0.00055162]
Model epoch 318: train total loss -62.18273935561822, train mean loss 0.0015774618868326536, test mean loss [0.00052511 0.00049516 0.00786209 0.00085169 0.00044792 0.00038888
 0.00053241]
Model epoch 319: train total loss -62.395968376177734, train mean loss 0.001263679453775336, test mean loss [0.00053373 0.00047805 0.00669646 0.00084006 0.00041838 0.00040423
 0.00053561]
Model epoch 320: train total loss -61.957435753896426, train mean loss 0.0014752462454088572, test mean loss [0.00050362 0.00045949 0.0060658  0.00083236 0.00064544 0.00038193
 0.00051728]
Model epoch 321: train total loss -62.252981982633166, train mean loss 0.0013050479229557014, test mean loss [0.00050113 0.00044724 0.0054986  0.00083757 0.00052231 0.00039568
 0.00051753]
Model epoch 322: train total loss -62.22969952331575, train mean loss 0.0010829238230478768, test mean loss [0.00054462 0.00045525 0.00490537 0.00083549 0.00055111 0.00038547
 0.00051112]
Model epoch 323: train total loss -62.43582611578169, train mean loss 0.0011590949721269883, test mean loss [0.00054389 0.000428   0.0043489  0.00088631 0.00052439 0.00037849
 0.00052568]
Model epoch 324: train total loss -62.449219116282464, train mean loss 0.0010322298866121014, test mean loss [0.00055696 0.00042778 0.00384079 0.00087318 0.00047493 0.00041104
 0.00052013]
Model epoch 325: train total loss -62.540417662608526, train mean loss 0.0010024348788426024, test mean loss [0.00056577 0.0004396  0.00336225 0.00085451 0.00044967 0.00041149
 0.00051554]
Model epoch 326: train total loss -62.75894257204268, train mean loss 0.0009115254818095196, test mean loss [0.00051848 0.00043164 0.00290285 0.00083815 0.00042616 0.00040021
 0.00051227]
Model epoch 327: train total loss -62.856341831828495, train mean loss 0.0009507286162084646, test mean loss [0.00047586 0.00041548 0.00245893 0.00083607 0.00042074 0.00039808
 0.00050558]
Model epoch 328: train total loss -62.86553762603939, train mean loss 0.0008844409083483947, test mean loss [0.00050725 0.00042004 0.00219176 0.00076567 0.00043825 0.00039652
 0.00050572]
Model epoch 329: train total loss -63.05498654581016, train mean loss 0.0009069000254099048, test mean loss [0.00051392 0.00041098 0.00184734 0.0007464  0.00041781 0.00040475
 0.00050635]
Model epoch 330: train total loss -63.07738169306036, train mean loss 0.0007905218802093045, test mean loss [0.00049833 0.00040476 0.00173306 0.00073259 0.00041146 0.00036555
 0.00049789]
Model epoch 331: train total loss -63.02208468973569, train mean loss 0.0007403919867389501, test mean loss [0.0004876  0.00041349 0.00153347 0.00073032 0.00045674 0.00035371
 0.00049833]
Model epoch 332: train total loss -62.98256382643885, train mean loss 0.0007574594544121046, test mean loss [0.00052283 0.00042616 0.00155042 0.00071073 0.00044019 0.00035952
 0.00049833]
Model epoch 333: train total loss -62.997587730262815, train mean loss 0.0007889431463432647, test mean loss [0.00046846 0.0004018  0.00147016 0.00071743 0.00042624 0.00038747
 0.0004911 ]
Model epoch 334: train total loss -62.726794550671436, train mean loss 0.000762926329998046, test mean loss [0.00046225 0.00038303 0.00137449 0.00073563 0.0003966  0.0006079
 0.00048964]
Model epoch 335: train total loss -62.718189967876924, train mean loss 0.0007575396708781533, test mean loss [0.00045489 0.00038846 0.0013548  0.00067216 0.00037916 0.00059122
 0.00048354]
Model epoch 336: train total loss -62.6889172753578, train mean loss 0.00070254761021791, test mean loss [0.00045722 0.00039133 0.00128051 0.00067222 0.00041464 0.00052281
 0.00049347]
Model epoch 337: train total loss -62.88224680706667, train mean loss 0.0006964572737634132, test mean loss [0.00047211 0.00039995 0.00124876 0.00067897 0.00038838 0.00047708
 0.0004766 ]
Model epoch 338: train total loss -62.986467148985064, train mean loss 0.0005904977043474772, test mean loss [0.00045344 0.00043525 0.00120848 0.00063751 0.0003912  0.00044246
 0.00047663]
Model epoch 339: train total loss -62.959741091236594, train mean loss 0.0006679502087291888, test mean loss [0.00045026 0.00040069 0.00111207 0.00068196 0.00037776 0.00044003
 0.00047958]
Model epoch 340: train total loss -63.13849208760543, train mean loss 0.000751862206521675, test mean loss [0.00045475 0.00039747 0.00105531 0.00064314 0.00036812 0.00043189
 0.00048898]
Model epoch 341: train total loss -63.31062699922679, train mean loss 0.0006106297242228281, test mean loss [0.00043681 0.00038072 0.00104903 0.00064883 0.00034904 0.00043981
 0.00047578]
Model epoch 342: train total loss -63.24973170837858, train mean loss 0.0006209068751793194, test mean loss [0.00045245 0.00040508 0.00103357 0.00063518 0.00034554 0.00042117
 0.00047336]
Model epoch 343: train total loss -63.211255206787754, train mean loss 0.0006211441441378498, test mean loss [0.00043451 0.00040561 0.00100853 0.00064108 0.0003641  0.00042845
 0.00045808]
Model epoch 344: train total loss -63.06269263673993, train mean loss 0.0006250949437355661, test mean loss [0.00043154 0.00040035 0.0009105  0.00060314 0.00034815 0.00042864
 0.00047336]
Model epoch 345: train total loss -63.12368152318923, train mean loss 0.0005840533513764429, test mean loss [0.00043538 0.0003808  0.00089735 0.00060625 0.00033286 0.0003837
 0.00046388]
Model epoch 346: train total loss -63.16557971840026, train mean loss 0.0005856665516307742, test mean loss [0.00055506 0.00038913 0.00089774 0.00061664 0.00033445 0.00038767
 0.00048555]
Model epoch 347: train total loss -63.00220193640264, train mean loss 0.0006167995464539215, test mean loss [0.00048249 0.00037679 0.00087782 0.00058709 0.00036158 0.00037742
 0.00047418]
Model epoch 348: train total loss -62.93938454902813, train mean loss 0.0006076606866182253, test mean loss [0.00042814 0.00038496 0.00079747 0.00056987 0.00034063 0.00038635
 0.00046813]
Model epoch 349: train total loss -62.60068655274046, train mean loss 0.0005871910363561488, test mean loss [0.00042533 0.0003776  0.00081271 0.00053694 0.00034059 0.00054402
 0.00059125]
Model epoch 350: train total loss -62.92566668284027, train mean loss 0.0005481227801809437, test mean loss [0.00043313 0.00038307 0.00078387 0.00054315 0.00033505 0.00043146
 0.00050995]
Model epoch 351: train total loss -62.436532760095346, train mean loss 0.0005874756728117131, test mean loss [0.00113226 0.00036909 0.00079183 0.00054138 0.00035354 0.00041424
 0.00049478]
Model epoch 352: train total loss -62.550683822538815, train mean loss 0.0006004759810076118, test mean loss [0.00104954 0.00036593 0.00075477 0.00054948 0.00037253 0.00037535
 0.00048054]
Model epoch 353: train total loss -62.77822025344806, train mean loss 0.0006977595441823854, test mean loss [0.00089282 0.00038322 0.00069273 0.00055102 0.00036196 0.00036339
 0.00048605]
Model epoch 354: train total loss -63.2020683911787, train mean loss 0.0005530686543234066, test mean loss [0.00078955 0.00038276 0.00065205 0.00052565 0.00033233 0.00035839
 0.00048102]
Model epoch 355: train total loss -62.993689075748534, train mean loss 0.0005964104124748104, test mean loss [0.00072076 0.00036814 0.0006312  0.0005145  0.00032855 0.00036502
 0.00051183]
Model epoch 356: train total loss -62.281513814985814, train mean loss 0.0007319765442861849, test mean loss [0.0006784  0.00037303 0.00056709 0.00048153 0.00033337 0.00036651
 0.00156223]
Model epoch 357: train total loss -62.089832984888595, train mean loss 0.0007606654556077733, test mean loss [0.00070879 0.00037013 0.00053465 0.0005144  0.00033214 0.00036869
 0.00169786]
Model epoch 358: train total loss -62.272708810139775, train mean loss 0.0006552350153830482, test mean loss [0.00066634 0.00036784 0.00052702 0.0005094  0.00033029 0.00035769
 0.00161486]
Model epoch 359: train total loss -62.311531522040326, train mean loss 0.0007302389102011458, test mean loss [0.00068999 0.0003625  0.00054126 0.00049317 0.00031144 0.00034567
 0.00137703]
Model epoch 360: train total loss -62.5022591446618, train mean loss 0.0006748180898119632, test mean loss [0.00070828 0.00039399 0.00052279 0.00049028 0.00032802 0.00034335
 0.00130545]
Model epoch 361: train total loss -62.727997168085814, train mean loss 0.0006026721576848794, test mean loss [0.00066141 0.00054873 0.00048163 0.00047414 0.00031138 0.00037913
 0.00112049]
Model epoch 362: train total loss -62.399031863994836, train mean loss 0.0007888907793731441, test mean loss [0.00065213 0.00044953 0.00044378 0.00046677 0.00035892 0.00122063
 0.00102878]
Model epoch 363: train total loss -62.34614545422391, train mean loss 0.000730964836314954, test mean loss [0.00061806 0.00042774 0.00048206 0.00046833 0.00033394 0.00128025
 0.00100261]
Model epoch 364: train total loss -62.71527194235872, train mean loss 0.0007151706220781977, test mean loss [0.00061614 0.00040003 0.00043333 0.00047543 0.00033285 0.00089674
 0.0009682 ]
Model epoch 365: train total loss -62.94680612015091, train mean loss 0.0006611005123852529, test mean loss [0.00063192 0.00038781 0.00041711 0.00047355 0.00031745 0.00069149
 0.00095685]
Model epoch 366: train total loss -62.25695751698042, train mean loss 0.0005928179320720336, test mean loss [0.00060964 0.00164019 0.00038854 0.00044526 0.00031806 0.00066655
 0.0009208 ]
Model epoch 367: train total loss -62.05438587305512, train mean loss 0.0011436255430932584, test mean loss [0.00063658 0.00607723 0.00037949 0.00044273 0.00032126 0.00059787
 0.00090802]
Model epoch 368: train total loss -61.871003645544526, train mean loss 0.0014790452722976612, test mean loss [0.0006327  0.00719081 0.00038331 0.00043637 0.00030488 0.00055734
 0.0008747 ]
Model epoch 369: train total loss -62.41992850619883, train mean loss 0.001148270400042492, test mean loss [0.00061916 0.00640783 0.00038378 0.00042045 0.00030691 0.00052734
 0.00088105]
Model epoch 370: train total loss -62.50238587614797, train mean loss 0.001191882416124783, test mean loss [0.00059718 0.00545041 0.00036833 0.00042661 0.00030567 0.00053152
 0.00085484]
Model epoch 371: train total loss -62.59975384907651, train mean loss 0.001106019372942907, test mean loss [0.00057794 0.00482856 0.00034556 0.00041195 0.00030127 0.00052373
 0.00082226]
Model epoch 372: train total loss -62.97690092597508, train mean loss 0.0008864039005800294, test mean loss [0.00057175 0.00415809 0.00034699 0.00040818 0.00035453 0.00051131
 0.00078771]
Model epoch 373: train total loss -62.940759786168975, train mean loss 0.0009725990051352874, test mean loss [0.00055588 0.00356728 0.00032981 0.00040202 0.00031296 0.00047767
 0.00075948]
Model epoch 374: train total loss -62.76306812610833, train mean loss 0.0008760931963747981, test mean loss [0.00058341 0.00310059 0.00032114 0.00041046 0.00031181 0.00046631
 0.00077111]
Model epoch 375: train total loss -62.962904957730494, train mean loss 0.0008102006931890901, test mean loss [0.00051896 0.0026331  0.00032685 0.00040031 0.00030342 0.0004588
 0.00072851]
Model epoch 376: train total loss -63.04674927280962, train mean loss 0.0007158694675634446, test mean loss [0.00049227 0.00226919 0.00032826 0.00038739 0.0003887  0.00046027
 0.00069286]
Model epoch 377: train total loss -63.1584627347492, train mean loss 0.0007455483840883852, test mean loss [0.0004709  0.0018767  0.00031322 0.0003992  0.00032281 0.000437
 0.00066057]
Model epoch 378: train total loss -63.22497765914903, train mean loss 0.0006764242942712924, test mean loss [0.00046806 0.00162923 0.00036274 0.00039333 0.00031367 0.00044153
 0.0006523 ]
Model epoch 379: train total loss -63.24881144904141, train mean loss 0.0006839206314580624, test mean loss [0.00044208 0.00140981 0.00032237 0.00039309 0.00030504 0.00045313
 0.0006434 ]
Model epoch 380: train total loss -63.31052457138998, train mean loss 0.0006183599656214584, test mean loss [0.00043863 0.0011746  0.00030039 0.00039675 0.00040582 0.00044201
 0.00063396]
Model epoch 381: train total loss -63.09604421050663, train mean loss 0.000669725499611214, test mean loss [0.00041054 0.00107297 0.00030873 0.00039408 0.00159757 0.00040956
 0.00064563]
Model epoch 382: train total loss -62.82015029267046, train mean loss 0.0007504310923113238, test mean loss [0.00040376 0.00104262 0.0003244  0.00037946 0.00219174 0.00040417
 0.00060307]
Model epoch 383: train total loss -62.84296060132371, train mean loss 0.000725297022960164, test mean loss [0.00038845 0.00102383 0.00032983 0.00038479 0.0018444  0.00038539
 0.00058273]
Model epoch 384: train total loss -63.08543214714472, train mean loss 0.0007059305184157131, test mean loss [0.00037747 0.00096341 0.00031904 0.00037469 0.00137217 0.00035292
 0.00059518]
Model epoch 385: train total loss -63.23806772438316, train mean loss 0.0006083799124458755, test mean loss [0.00036351 0.0009148  0.00032077 0.00039445 0.00114202 0.00032367
 0.00059909]
Model epoch 386: train total loss -63.43336304751059, train mean loss 0.0006536663669599866, test mean loss [0.00035363 0.00091566 0.00030483 0.00038335 0.00092292 0.00032233
 0.00057812]
Model epoch 387: train total loss -63.476651886800916, train mean loss 0.0005953062207875869, test mean loss [0.00035553 0.00090852 0.00029581 0.00036341 0.00078575 0.00030126
 0.00057966]
Model epoch 388: train total loss -63.55344651128745, train mean loss 0.0005961565433487419, test mean loss [0.00036153 0.00087103 0.0002815  0.00036976 0.00066855 0.0003065
 0.00056512]
Model epoch 389: train total loss -63.649313328021314, train mean loss 0.0005262742693235533, test mean loss [0.00035723 0.00084165 0.00033443 0.00036503 0.00061101 0.00031175
 0.00057893]
Model epoch 390: train total loss -63.557942885118756, train mean loss 0.0005022309684122422, test mean loss [0.00034217 0.00081805 0.00029815 0.00037971 0.00058114 0.00029175
 0.00055063]
Model epoch 391: train total loss -63.36694220297509, train mean loss 0.0005777125438175148, test mean loss [0.00034545 0.00080054 0.00027765 0.00038523 0.00056952 0.00030222
 0.00056647]
Model epoch 392: train total loss -63.52033003657364, train mean loss 0.0005012967315500056, test mean loss [0.00033706 0.00079663 0.00028944 0.00036789 0.00057116 0.00029665
 0.00053553]
Model epoch 393: train total loss -63.71541933330681, train mean loss 0.000540737904512974, test mean loss [0.00033513 0.00075493 0.00026807 0.00037129 0.00051681 0.00030807
 0.00051702]
Model epoch 394: train total loss -63.69229352158697, train mean loss 0.0005567139876679309, test mean loss [0.00032946 0.00073043 0.00029149 0.00040204 0.00051032 0.00028342
 0.00052882]
Model epoch 395: train total loss -63.748647331690876, train mean loss 0.00048361071091219493, test mean loss [0.0003358  0.00072822 0.00027481 0.00037723 0.00050879 0.00028799
 0.0005466 ]
Model epoch 396: train total loss -63.806514616858905, train mean loss 0.0004920769117604723, test mean loss [0.00034625 0.00069236 0.00026406 0.00037951 0.0004842  0.00028531
 0.00051744]
Model epoch 397: train total loss -63.77420920595078, train mean loss 0.0005278731489556646, test mean loss [0.00032927 0.00067813 0.00026331 0.00036514 0.00046829 0.00033659
 0.00048751]
Model epoch 398: train total loss -63.75528321667806, train mean loss 0.0004826179365519238, test mean loss [0.00033176 0.00066195 0.00027739 0.00036576 0.00046066 0.00029252
 0.00049063]
Model epoch 399: train total loss -63.837033995260924, train mean loss 0.0004895292222531425, test mean loss [0.00033907 0.00064791 0.00026905 0.00036984 0.00046013 0.00027931
 0.00046685]
Model epoch 400: train total loss -63.939440529628534, train mean loss 0.0004954363499011037, test mean loss [0.00033007 0.00065249 0.0002656  0.00036926 0.00044366 0.00028893
 0.00045965]
Model epoch 401: train total loss -63.61481021824137, train mean loss 0.0004787313459475205, test mean loss [0.00033149 0.00070797 0.00026177 0.00036465 0.00041854 0.00028657
 0.00047501]
Model epoch 402: train total loss -63.81330412317017, train mean loss 0.0004623396050951762, test mean loss [0.00032427 0.0006686  0.00026107 0.00038243 0.00041902 0.00028419
 0.00048269]
Model epoch 403: train total loss -63.8174376415715, train mean loss 0.00046808407811971855, test mean loss [0.00032679 0.00064269 0.00026578 0.00035465 0.00040081 0.00028134
 0.00044973]
Model epoch 404: train total loss -63.98141996473626, train mean loss 0.0004895449901257922, test mean loss [0.00032484 0.00058339 0.00026509 0.00035744 0.00040366 0.00028722
 0.00043293]
Model epoch 405: train total loss -64.1014234939484, train mean loss 0.00045148496892093837, test mean loss [0.00031358 0.00058433 0.00029229 0.00035255 0.00040213 0.00027139
 0.00040676]
Model epoch 406: train total loss -63.841059594289035, train mean loss 0.0004409276452467897, test mean loss [0.00033031 0.0005801  0.00029547 0.00035993 0.00039239 0.00030803
 0.00041944]
Model epoch 407: train total loss -63.67446850726748, train mean loss 0.0004549204608611554, test mean loss [0.00035547 0.00056343 0.0002633  0.00035193 0.00040468 0.00029332
 0.00042416]
Model epoch 408: train total loss -63.64995554952917, train mean loss 0.000445593194225473, test mean loss [0.00030757 0.00054548 0.00025792 0.00036095 0.00042208 0.00028099
 0.00040351]
Model epoch 409: train total loss -63.70211916451353, train mean loss 0.0003923685528801115, test mean loss [0.00032048 0.00053267 0.00024698 0.00034696 0.00041695 0.00026674
 0.00039995]
Model epoch 410: train total loss -63.99748983068199, train mean loss 0.0004308142016163943, test mean loss [0.00031227 0.00051619 0.00024513 0.00034465 0.00037682 0.00027222
 0.0003862 ]
Model epoch 411: train total loss -63.88269734933407, train mean loss 0.00041552570724176784, test mean loss [0.00031106 0.00052314 0.00024147 0.00045686 0.00040115 0.00026474
 0.00039488]
Model epoch 412: train total loss -63.62279357453092, train mean loss 0.00041751901900271844, test mean loss [0.00030747 0.00052916 0.00025362 0.00037788 0.00037188 0.00027045
 0.00040656]
Model epoch 413: train total loss -63.935224099722866, train mean loss 0.00039691379916047064, test mean loss [0.00030761 0.00050511 0.00026478 0.00035872 0.00037206 0.00027357
 0.00038834]
Model epoch 414: train total loss -63.89863735879603, train mean loss 0.0004275370094961173, test mean loss [0.00031418 0.00052347 0.00025101 0.00035696 0.00037521 0.00026207
 0.00037556]
Model epoch 415: train total loss -63.733180166080054, train mean loss 0.00045788266326495756, test mean loss [0.00031102 0.00048929 0.00023662 0.00037377 0.00038251 0.00026034
 0.00039013]
Model epoch 416: train total loss -63.9736134677956, train mean loss 0.00039851618301463434, test mean loss [0.00030857 0.00049267 0.00025861 0.00037088 0.00037633 0.00025265
 0.00036898]
Model epoch 417: train total loss -63.8979319935101, train mean loss 0.00036912799479699035, test mean loss [0.00030842 0.0004818  0.00024583 0.00035844 0.00032801 0.00036373
 0.00041097]
Model epoch 418: train total loss -63.684283385434206, train mean loss 0.0004412769190306476, test mean loss [0.00032439 0.00048388 0.00025119 0.00034433 0.00041017 0.00026935
 0.00038871]
Model epoch 419: train total loss -63.75071198520556, train mean loss 0.0003847877284143213, test mean loss [0.00029832 0.00049391 0.00024054 0.00034913 0.00036166 0.00027482
 0.00036929]
Model epoch 420: train total loss -64.00618406002773, train mean loss 0.0003571506854603622, test mean loss [0.00030981 0.00045817 0.00025363 0.00034121 0.00034998 0.00025319
 0.00037084]
Model epoch 421: train total loss -63.77665707938184, train mean loss 0.0003889455984463851, test mean loss [0.0002966  0.00042178 0.00024994 0.00039052 0.00031879 0.00026597
 0.00037421]
Model epoch 422: train total loss -63.98725061957639, train mean loss 0.0003952207220880014, test mean loss [0.00030295 0.00043245 0.00026076 0.00036362 0.00031485 0.00027055
 0.00035997]
Model epoch 423: train total loss -63.99123427603282, train mean loss 0.00034586622226859417, test mean loss [0.00030259 0.00041468 0.00023236 0.00034347 0.00033971 0.00027813
 0.00036744]
Model epoch 424: train total loss -63.95849499905885, train mean loss 0.0003581470191206561, test mean loss [0.00036006 0.00039963 0.00024337 0.00033858 0.00030075 0.00035176
 0.00036554]
Model epoch 425: train total loss -63.73059551097255, train mean loss 0.00037715352614972435, test mean loss [0.00033205 0.00043163 0.00024211 0.00032336 0.00028135 0.00036764
 0.00036411]
Model epoch 426: train total loss -63.704924274288494, train mean loss 0.0004235469880428406, test mean loss [0.00030599 0.0004231  0.00024249 0.00032695 0.0002743  0.00033901
 0.00036267]
Model epoch 427: train total loss -63.90007440234168, train mean loss 0.0003885354706534007, test mean loss [0.00029087 0.00041187 0.0002355  0.0003304  0.00030072 0.00035979
 0.00035154]
Model epoch 428: train total loss -64.03930443166497, train mean loss 0.00036602417507621395, test mean loss [0.00029147 0.0003873  0.0002487  0.00032181 0.00028644 0.00034209
 0.00035272]
Model epoch 429: train total loss -63.97499074100876, train mean loss 0.0003589499751707012, test mean loss [0.00031761 0.00037933 0.00023042 0.00033091 0.00028036 0.00034021
 0.00036495]
Model epoch 430: train total loss -63.70318624097732, train mean loss 0.0004325506070573687, test mean loss [0.00068707 0.00035783 0.0002316  0.00032486 0.00027218 0.00033906
 0.00034719]
Model epoch 431: train total loss -63.68424180333518, train mean loss 0.0003784065315451875, test mean loss [0.00053928 0.00033542 0.00024205 0.00031973 0.00028997 0.00033284
 0.00034381]
Model epoch 432: train total loss -63.3554514739809, train mean loss 0.0004196650790892405, test mean loss [0.00046812 0.00034643 0.00030164 0.00031269 0.0002706  0.00030117
 0.00035018]
Model epoch 433: train total loss -63.22263681192002, train mean loss 0.00039485459814798235, test mean loss [0.00042062 0.00036761 0.00027237 0.00031909 0.0002838  0.00038796
 0.00035619]
Model epoch 434: train total loss -62.36497914237392, train mean loss 0.0010306884190677166, test mean loss [0.00041387 0.00033091 0.00025901 0.00031238 0.00029547 0.00655454
 0.00035051]
Model epoch 435: train total loss -62.402694162129244, train mean loss 0.0015115086165721284, test mean loss [0.00040038 0.00032865 0.00025036 0.00031931 0.00027537 0.00967871
 0.00034766]
Model epoch 436: train total loss -62.77494786617215, train mean loss 0.001394599062372903, test mean loss [0.00037399 0.00031688 0.00023458 0.00031653 0.00027778 0.00966281
 0.00033936]
Model epoch 437: train total loss -62.89068235394007, train mean loss 0.001183911291361997, test mean loss [0.00035799 0.00030264 0.00027994 0.00032833 0.00029333 0.00885258
 0.00034609]
Model epoch 438: train total loss -61.97772592386791, train mean loss 0.001477477944227501, test mean loss [0.00040852 0.00029712 0.00111939 0.00032611 0.00030014 0.00806934
 0.00034539]
Model epoch 439: train total loss -62.658601067477264, train mean loss 0.0009750016938271694, test mean loss [0.0004045  0.00030355 0.00107112 0.00032162 0.000293   0.00717516
 0.00033962]
Model epoch 440: train total loss -62.6024043367308, train mean loss 0.0012431000819526105, test mean loss [0.00037779 0.00029322 0.0007898  0.00032045 0.0002814  0.00647789
 0.00033926]
Model epoch 441: train total loss -62.92366159867564, train mean loss 0.0012847875631355323, test mean loss [0.00034959 0.00030272 0.00065467 0.00032184 0.00027897 0.00580924
 0.00033535]
Model epoch 442: train total loss -63.31744140725624, train mean loss 0.0009697691790171376, test mean loss [0.00034796 0.00028923 0.00053478 0.00031293 0.00027858 0.00516692
 0.00033269]
Model epoch 443: train total loss -63.44051553584833, train mean loss 0.0008666600949620907, test mean loss [0.00034443 0.0002805  0.00046397 0.00031196 0.00026048 0.00456681
 0.00033214]
Model epoch 444: train total loss -63.46103883989935, train mean loss 0.0008357360536715222, test mean loss [0.0003467  0.0002806  0.0004418  0.0003367  0.00026212 0.0039637
 0.00034607]
Model epoch 445: train total loss -63.51544738735468, train mean loss 0.0007612018483241744, test mean loss [0.00035463 0.00028501 0.00042014 0.00032043 0.00026486 0.00348538
 0.00032811]
Model epoch 446: train total loss -63.785243341575395, train mean loss 0.0006944812461662893, test mean loss [0.00034112 0.0002766  0.00040677 0.00032294 0.00026415 0.00290308
 0.00033386]
Model epoch 447: train total loss -63.73995256160382, train mean loss 0.0006276265584825825, test mean loss [0.00034862 0.00026908 0.00043609 0.00031754 0.00026115 0.00242307
 0.00035086]
Model epoch 448: train total loss -63.74360379201924, train mean loss 0.0005547840864025224, test mean loss [0.00033432 0.00027407 0.00042491 0.00032057 0.00025747 0.00207691
 0.00034929]
Model epoch 449: train total loss -63.933262193139086, train mean loss 0.0005554978468260484, test mean loss [0.00032118 0.00027696 0.00042771 0.00030659 0.00025457 0.00170816
 0.00032626]
Model epoch 450: train total loss -63.90504675465208, train mean loss 0.0005263568925640543, test mean loss [0.00031853 0.00027795 0.00043156 0.00031946 0.00025599 0.00144673
 0.00033307]
Model epoch 451: train total loss -63.90773544066688, train mean loss 0.0004588702485584741, test mean loss [0.00033162 0.00028324 0.00042442 0.00033207 0.00026821 0.00121548
 0.00033004]
Model epoch 452: train total loss -63.95358203109053, train mean loss 0.0004378367207914519, test mean loss [0.00036092 0.00029276 0.00043489 0.0003095  0.00026457 0.00109599
 0.0003285 ]
Model epoch 453: train total loss -63.82214253145472, train mean loss 0.0004421353774487223, test mean loss [0.00034012 0.00026642 0.00044063 0.00030473 0.000258   0.00097369
 0.00032898]
Model epoch 454: train total loss -64.06571178155293, train mean loss 0.0004299855156298796, test mean loss [0.00032979 0.00027085 0.00042995 0.00029539 0.00026078 0.00085457
 0.0003278 ]
Model epoch 455: train total loss -64.16072365972462, train mean loss 0.00042239869511743815, test mean loss [0.00032912 0.00027267 0.00043805 0.0002931  0.00024544 0.00076949
 0.00032091]
Model epoch 456: train total loss -64.24119068470966, train mean loss 0.00045019283403561263, test mean loss [0.00032856 0.00025838 0.00041933 0.00029688 0.00024704 0.00068861
 0.00033115]
Model epoch 457: train total loss -63.8565640802132, train mean loss 0.00044917145771609983, test mean loss [0.00033554 0.00025016 0.00042504 0.00035633 0.00026931 0.00062315
 0.00032754]
Model epoch 458: train total loss -63.87899977636191, train mean loss 0.0004045289379139398, test mean loss [0.0003195  0.00028299 0.00043909 0.00031383 0.00025479 0.00054771
 0.00032071]
Model epoch 459: train total loss -64.02396668300021, train mean loss 0.0004146479204416491, test mean loss [0.0003208  0.00029008 0.00044964 0.00030687 0.00024937 0.00055466
 0.00032358]
Model epoch 460: train total loss -63.90549297625709, train mean loss 0.0003705546457476473, test mean loss [0.000302   0.00026605 0.00043816 0.00029777 0.00024616 0.00050304
 0.00032912]
Model epoch 461: train total loss -64.12594707687805, train mean loss 0.0003999496028492531, test mean loss [0.0002948  0.00027488 0.00042051 0.00028494 0.00024447 0.0004932
 0.00031348]
Model epoch 462: train total loss -64.1815140237486, train mean loss 0.0003698806190572908, test mean loss [0.00029411 0.00026182 0.00043124 0.00029872 0.00023916 0.00047177
 0.00031758]
Model epoch 463: train total loss -64.22207346829376, train mean loss 0.00039187916162238733, test mean loss [0.00028948 0.00026665 0.00048015 0.00029861 0.00024367 0.00047751
 0.00031973]
Model epoch 464: train total loss -62.87110387300351, train mean loss 0.0004026142608194805, test mean loss [0.00028574 0.00045439 0.00047899 0.00051928 0.0002494  0.00045642
 0.00034308]
Model epoch 465: train total loss -63.392240781496206, train mean loss 0.0006386513947182903, test mean loss [0.00027597 0.00143274 0.00046437 0.00115427 0.00023598 0.00044155
 0.00032318]
Model epoch 466: train total loss -63.476507197573305, train mean loss 0.0006594987016379938, test mean loss [0.00026657 0.00181096 0.00044616 0.00116227 0.00024595 0.0004145
 0.00032022]
Model epoch 467: train total loss -63.70779985126821, train mean loss 0.0005904177232845282, test mean loss [0.00026753 0.0012762  0.00045044 0.00098499 0.0002498  0.00040631
 0.00034346]
Model epoch 468: train total loss -63.71229814253491, train mean loss 0.0005497821226548104, test mean loss [0.00026106 0.00093674 0.0004567  0.00090596 0.00024625 0.00042546
 0.00030962]
Model epoch 469: train total loss -63.78361919572063, train mean loss 0.000493816785205177, test mean loss [0.00026666 0.00080974 0.00044909 0.00087382 0.00028547 0.00041069
 0.00030942]
Model epoch 470: train total loss -63.90433386603909, train mean loss 0.000516864266299606, test mean loss [0.00026906 0.00073988 0.00043581 0.00085113 0.00024717 0.0004074
 0.00031196]
Model epoch 471: train total loss -64.13025489423158, train mean loss 0.000452091304835715, test mean loss [0.00026365 0.00066419 0.00042591 0.00081382 0.00025301 0.00040959
 0.00030429]
Model epoch 472: train total loss -64.20163054259059, train mean loss 0.0004485480845629371, test mean loss [0.00026548 0.00062866 0.00043977 0.00078054 0.0002501  0.00042234
 0.00030212]
Model epoch 473: train total loss -63.97084267761535, train mean loss 0.00046874971002856846, test mean loss [0.00025893 0.00065861 0.00044433 0.00075136 0.0002447  0.00044992
 0.00030351]
Model epoch 474: train total loss -63.9274470004202, train mean loss 0.0004589704804257162, test mean loss [0.00026613 0.00058779 0.00045628 0.00071951 0.00027403 0.00042418
 0.00033387]
Model epoch 475: train total loss -63.913121086080785, train mean loss 0.0004317963769556546, test mean loss [0.00027645 0.00054555 0.00042146 0.0007633  0.00025741 0.00039532
 0.00030814]
Model epoch 476: train total loss -63.958087507357575, train mean loss 0.00047152196898880155, test mean loss [0.00026318 0.000528   0.00045623 0.00072933 0.00024907 0.00040031
 0.00031197]
Model epoch 477: train total loss -63.81421449824813, train mean loss 0.0004433009113950782, test mean loss [0.00025211 0.00057697 0.00041891 0.00069105 0.00024983 0.00036561
 0.00030451]
Model epoch 478: train total loss -64.1962633082513, train mean loss 0.00044452575876171804, test mean loss [0.00026008 0.00053523 0.0004746  0.00067376 0.00025334 0.00039023
 0.00029784]
Model epoch 479: train total loss -64.35256181762854, train mean loss 0.00044959838389349436, test mean loss [0.00024923 0.00050316 0.000469   0.00068479 0.00023867 0.00032973
 0.00030041]
Model epoch 480: train total loss -63.97763216309386, train mean loss 0.00043106087883464756, test mean loss [0.00031158 0.00048949 0.00043044 0.00065271 0.00023617 0.000332
 0.00062935]
Model epoch 481: train total loss -63.39771594964841, train mean loss 0.0004927200097124604, test mean loss [0.00026877 0.00048159 0.00044306 0.00066038 0.00027254 0.00030045
 0.00052515]
Model epoch 482: train total loss -63.67685979389335, train mean loss 0.0004508889659411354, test mean loss [0.00025394 0.00046902 0.00043654 0.0006298  0.00027248 0.00029665
 0.00050634]
Model epoch 483: train total loss -63.94249272595773, train mean loss 0.0004421055974731155, test mean loss [0.00025257 0.00044455 0.00040036 0.00062614 0.0002604  0.00028415
 0.00043975]
Model epoch 484: train total loss -64.22861932936894, train mean loss 0.00040359847006964734, test mean loss [0.00024866 0.00045479 0.00039449 0.00066014 0.00025294 0.00028344
 0.00041422]
Model epoch 485: train total loss -64.26726760223241, train mean loss 0.0004031102466793272, test mean loss [0.00026093 0.00047778 0.00038082 0.00065193 0.00024633 0.00026475
 0.00041378]
Model trained in 486 epochs with 1000 transitions.
[2025-01-23 12:39:32,505][absl][INFO] - {'eval/walltime': 74.16115951538086, 'training/sps': 1.1551225437721473, 'training/walltime': 865.7090153694153, 'training/model_train_time': 793.7677795886993, 'training/other_time': 71.10440945625305, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 10, 'training/env_buffer_size': Array(2000, dtype=int32), 'model/train_total_loss': Array(-64.2672676, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00040311, dtype=float64), 'model/test_total_loss': Array(-63.02440948, dtype=float64), 'model/test_mean_loss': Array(0.00038519, dtype=float64), 'model/train_epochs': 486, 'model/sec_per_epoch': 1.6298416421246626, 'sac/actor_loss': Array(-11.74954904, dtype=float64), 'sac/alpha': Array(0.9169369, dtype=float32), 'sac/alpha_loss': Array(9.71262236, dtype=float64), 'sac/buffer_current_size': Array(3600., dtype=float32), 'sac/critic_loss': Array(0.66815068, dtype=float64), 'eval/episode_forward_vel': Array(-210.38895589, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-0.11948643, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(51.34302292, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.82996073, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-90.4898735, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(52.53020501, dtype=float64), 'eval/episode_rew_roll': Array(52.06346879, dtype=float64), 'eval/episode_rew_side_motion': Array(65.95290412, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(69.85838194, dtype=float64), 'eval/episode_rew_yaw': Array(80.29835185, dtype=float64), 'eval/episode_rew_z_vel_change': Array(25.27735857, dtype=float64), 'eval/episode_reward': Array(307.86821411, dtype=float64), 'eval/episode_step_count': Array(499500., dtype=float64), 'eval/avg_episode_length': Array(1000., dtype=float64), 'eval/epoch_eval_time': 30.683274745941162, 'eval/sps': 32.591045391342455}
Steps / Eval:  2000.0
Reward is  307.86821411213833
Model horizon updated to 2.
Hallucination updates per training step updated to 257.
SAC buffer resized to 205600 samples.
Model epoch 0: train total loss -62.43684099813143, train mean loss 0.00042059270927046415, test mean loss [0.00034371 0.00055827 0.00043111 0.00076036 0.00028608 0.00033037
 0.00037753]
Model epoch 1: train total loss -63.34425315681292, train mean loss 0.0004169350335507327, test mean loss [0.00032102 0.00053506 0.00040138 0.00074488 0.00027938 0.00030884
 0.00034094]
Model epoch 2: train total loss -63.64543538759817, train mean loss 0.00041010535491572985, test mean loss [0.00031577 0.00053597 0.00037928 0.00073526 0.00028129 0.00030113
 0.00033765]
Model epoch 3: train total loss -63.77156289927025, train mean loss 0.0004052088242729557, test mean loss [0.00031331 0.00052004 0.00036488 0.00071394 0.00027039 0.00028995
 0.00033168]
Model epoch 4: train total loss -63.650991916619546, train mean loss 0.000416079461569968, test mean loss [0.00032158 0.00053559 0.00036273 0.00071268 0.00025965 0.00028299
 0.00031937]
Model epoch 5: train total loss -63.75927397209955, train mean loss 0.0003873842617840856, test mean loss [0.00030034 0.00049007 0.00032284 0.00065014 0.00028774 0.0002877
 0.00030902]
Model epoch 6: train total loss -64.01701251360852, train mean loss 0.0003914372671195439, test mean loss [0.00029986 0.00047958 0.00031837 0.00064395 0.00026327 0.00028134
 0.00029647]
Model epoch 7: train total loss -63.71956500239962, train mean loss 0.0003333587383599039, test mean loss [0.00044543 0.00046849 0.00030168 0.00064831 0.00025282 0.00027239
 0.0003074 ]
Model epoch 8: train total loss -62.39850136911683, train mean loss 0.00044737504847128674, test mean loss [0.00032495 0.0004611  0.00028744 0.00064737 0.00043786 0.00029449
 0.00030493]
Model epoch 9: train total loss -63.44754929017581, train mean loss 0.0003289684093938381, test mean loss [0.00029938 0.0004354  0.00028366 0.00060041 0.00032983 0.00027734
 0.00029469]
Model epoch 10: train total loss -63.66680118301137, train mean loss 0.00035809403820801384, test mean loss [0.00029513 0.00042943 0.00027872 0.00056022 0.00029905 0.00026929
 0.00028535]
Model epoch 11: train total loss -63.924611799350416, train mean loss 0.0003349537921036407, test mean loss [0.00032215 0.0004328  0.00027767 0.0005328  0.00027298 0.00026707
 0.000292  ]
Model epoch 12: train total loss -64.07381285543914, train mean loss 0.0003357728892627282, test mean loss [0.0002905  0.00041311 0.00026075 0.00052146 0.00028148 0.0002675
 0.00027722]
Model epoch 13: train total loss -64.05403153733438, train mean loss 0.0003623151362598744, test mean loss [0.00029683 0.00039703 0.00026163 0.00050505 0.00026275 0.00026391
 0.00028564]
Model epoch 14: train total loss -64.20298913965868, train mean loss 0.00029814252731904525, test mean loss [0.00028747 0.00037158 0.00026402 0.00046976 0.00025602 0.0002729
 0.00028625]
Model epoch 15: train total loss -64.18117822614558, train mean loss 0.00033518894709058775, test mean loss [0.00028572 0.00034686 0.00025874 0.00045083 0.00025751 0.00027944
 0.00027988]
Model epoch 16: train total loss -64.10138819064994, train mean loss 0.00031095329001619865, test mean loss [0.00029995 0.00031765 0.00025286 0.0004306  0.00025279 0.00026263
 0.00027213]
Model epoch 17: train total loss -63.93369937757301, train mean loss 0.00027890402268151716, test mean loss [0.00028274 0.00029701 0.00027532 0.00040725 0.00025929 0.0002575
 0.0002802 ]
Model epoch 18: train total loss -64.25499137858932, train mean loss 0.0002855791677061354, test mean loss [0.00027715 0.00028913 0.00026652 0.00036624 0.00025983 0.00026534
 0.0002758 ]
Model epoch 19: train total loss -64.21890933970718, train mean loss 0.00026708488558878205, test mean loss [0.00028107 0.00027466 0.00025638 0.00035778 0.00024987 0.00026166
 0.00027915]
Model epoch 20: train total loss -63.867313197686016, train mean loss 0.00026755838894322614, test mean loss [0.00029733 0.00026567 0.00025239 0.00033855 0.00025993 0.00026223
 0.00028277]
Model epoch 21: train total loss -64.12184609601364, train mean loss 0.0002837927968421485, test mean loss [0.00029395 0.00026343 0.00026816 0.00033779 0.00025831 0.00026334
 0.0002711 ]
Model epoch 22: train total loss -64.10452560306878, train mean loss 0.00024645869932465625, test mean loss [0.000281   0.00026036 0.00025558 0.00032794 0.00025869 0.00025947
 0.00026574]
Model epoch 23: train total loss -64.26538978124945, train mean loss 0.00024155159789283803, test mean loss [0.00028268 0.00026372 0.00025163 0.00031278 0.00025764 0.00026039
 0.00027339]
Model epoch 24: train total loss -63.978629554616816, train mean loss 0.0002812824932597496, test mean loss [0.00027919 0.00026703 0.00026397 0.00031946 0.00025272 0.00025459
 0.00026794]
Model epoch 25: train total loss -64.17159788729113, train mean loss 0.00025847784642430436, test mean loss [0.00028014 0.00027153 0.00025153 0.00030431 0.00024632 0.00026158
 0.00026155]
Model epoch 26: train total loss -64.25001192183974, train mean loss 0.0002598555972835396, test mean loss [0.0002715  0.00026509 0.00024911 0.00030357 0.00025197 0.00025199
 0.00027252]
Model epoch 27: train total loss -64.31671362048822, train mean loss 0.00022591554644491813, test mean loss [0.00027328 0.0002609  0.00024305 0.00029708 0.0002587  0.00025752
 0.00027416]
Model epoch 28: train total loss -64.2474953958819, train mean loss 0.0002614588272439983, test mean loss [0.00027973 0.0002644  0.00023813 0.00029455 0.00024781 0.00026206
 0.00026853]
Model epoch 29: train total loss -64.45646826992815, train mean loss 0.00026519720614025325, test mean loss [0.00027394 0.00026374 0.00024565 0.00029726 0.00023703 0.00025449
 0.00025845]
Model epoch 30: train total loss -64.2978776175764, train mean loss 0.00025321492460584895, test mean loss [0.00026378 0.00027995 0.00024056 0.00029263 0.00024182 0.00026309
 0.00027002]
Model epoch 31: train total loss -64.3389592608072, train mean loss 0.0002448314377574523, test mean loss [0.00026449 0.00025084 0.00023399 0.00029987 0.00024379 0.00028652
 0.00026634]
Model epoch 32: train total loss -64.22426982138796, train mean loss 0.00026694672657484017, test mean loss [0.00026664 0.00025177 0.00023301 0.00031354 0.00023739 0.00026124
 0.00025913]
Model epoch 33: train total loss -64.3419484204441, train mean loss 0.0002482654346107553, test mean loss [0.0002591  0.00025693 0.00023772 0.00029214 0.00024346 0.00025244
 0.0002746 ]
Model epoch 34: train total loss -64.35222347359189, train mean loss 0.0002484965921253362, test mean loss [0.00026657 0.00024946 0.00023953 0.00028875 0.00023871 0.00025188
 0.00025986]
Model epoch 35: train total loss -64.21923679675113, train mean loss 0.00026485035336842975, test mean loss [0.00026894 0.00024597 0.0002339  0.00028891 0.00022901 0.00026578
 0.00025632]
Model epoch 36: train total loss -64.10872914070927, train mean loss 0.00024727262819622284, test mean loss [0.00026927 0.00024382 0.00024264 0.00028811 0.00024939 0.00028699
 0.00026234]
Model epoch 37: train total loss -64.05234185910324, train mean loss 0.00024002239563576216, test mean loss [0.00025554 0.00026411 0.00023533 0.00028546 0.00029472 0.00026069
 0.00025772]
Model epoch 38: train total loss -63.89328985620013, train mean loss 0.00025319782230945933, test mean loss [0.00027779 0.00032693 0.00023346 0.00029033 0.00024892 0.00025237
 0.00025594]
Model epoch 39: train total loss -64.23032098872191, train mean loss 0.00023737895834466041, test mean loss [0.00026012 0.00029321 0.0002318  0.00028918 0.0002395  0.00024834
 0.00025691]
Model epoch 40: train total loss -62.908829627179564, train mean loss 0.00025612132500451174, test mean loss [0.00025506 0.00026874 0.00022541 0.00028246 0.00116949 0.00027394
 0.00025326]
Model epoch 41: train total loss -63.08278524848351, train mean loss 0.0012426490493766837, test mean loss [0.00025128 0.0002578  0.00022905 0.00028801 0.00656074 0.000262
 0.00028216]
Model epoch 42: train total loss -63.40277807300389, train mean loss 0.0009808788999232205, test mean loss [0.00025479 0.00025763 0.00023531 0.00028013 0.00539252 0.00025674
 0.00027687]
Model epoch 43: train total loss -63.81055212844006, train mean loss 0.0006669292893746008, test mean loss [0.00024936 0.00025295 0.00023002 0.00027973 0.00412775 0.00025006
 0.00025236]
Model epoch 44: train total loss -63.92179711419833, train mean loss 0.000679418909137133, test mean loss [0.00024975 0.00024734 0.00022548 0.00027457 0.00304238 0.0002527
 0.00027213]
Model epoch 45: train total loss -63.740253251549, train mean loss 0.000559014493764049, test mean loss [0.00024622 0.0002495  0.00032562 0.00028027 0.0023782  0.00025216
 0.00026192]
Model epoch 46: train total loss -64.09588408381703, train mean loss 0.0004325248219209793, test mean loss [0.0002533  0.00024271 0.0003186  0.00028356 0.00197822 0.00023877
 0.00025116]
Model epoch 47: train total loss -64.34503384739251, train mean loss 0.0004201717914387243, test mean loss [0.00025218 0.00024025 0.00025229 0.0002736  0.00162333 0.00023949
 0.00024862]
Model epoch 48: train total loss -64.05107711219578, train mean loss 0.00047393898816545655, test mean loss [0.00024795 0.00025604 0.00022918 0.00027389 0.00138719 0.00027111
 0.00024915]
Model epoch 49: train total loss -63.607553467260054, train mean loss 0.0003960026260788979, test mean loss [0.00025258 0.00024533 0.00052297 0.00027223 0.00122866 0.00024248
 0.0002524 ]
Model epoch 50: train total loss -63.7412089039311, train mean loss 0.00045057139125463853, test mean loss [0.00025805 0.0002414  0.00074464 0.00027451 0.00110372 0.00024201
 0.00025262]
Model epoch 51: train total loss -64.00056054050916, train mean loss 0.00043049518771110776, test mean loss [0.00025119 0.0002502  0.00064033 0.00027294 0.00104789 0.00023824
 0.00024812]
Model epoch 52: train total loss -64.100763472102, train mean loss 0.00037851522000947695, test mean loss [0.00024876 0.00024194 0.0006581  0.00026545 0.00099898 0.00025375
 0.00025533]
Model epoch 53: train total loss -63.74247922648794, train mean loss 0.0004281576347479272, test mean loss [0.00024705 0.00024094 0.00060338 0.00028934 0.00097439 0.00024747
 0.0002524 ]
Model epoch 54: train total loss -63.84855459281753, train mean loss 0.0003867321207063262, test mean loss [0.000245   0.00023871 0.00053753 0.00030894 0.00097917 0.00023256
 0.00023607]
Model epoch 55: train total loss -64.1630262004889, train mean loss 0.0003574012012868657, test mean loss [0.00023885 0.00023387 0.000528   0.00028736 0.00105311 0.00023473
 0.00024309]
Model epoch 56: train total loss -64.18623853323615, train mean loss 0.00041984716289993545, test mean loss [0.0002414  0.00023306 0.00050027 0.00027177 0.00096329 0.00024708
 0.00024651]
Model epoch 57: train total loss -64.2968500252847, train mean loss 0.00037850454616391015, test mean loss [0.00023787 0.00023284 0.00048461 0.00028515 0.00096794 0.00024243
 0.00024187]
Model epoch 58: train total loss -64.49752690016292, train mean loss 0.00037249478249162994, test mean loss [0.00023725 0.00023479 0.00046358 0.00027605 0.0009919  0.00023889
 0.00023837]
Model epoch 59: train total loss -64.44857950069527, train mean loss 0.00035720583277898865, test mean loss [0.0002361  0.00022768 0.00044926 0.00027163 0.00096339 0.0002366
 0.00024548]
Model epoch 60: train total loss -64.32075836548258, train mean loss 0.0003518522894623897, test mean loss [0.00024032 0.00023912 0.00040578 0.00027474 0.00092519 0.00026673
 0.00023946]
Model epoch 61: train total loss -64.37631173545594, train mean loss 0.0003752597881169933, test mean loss [0.00024428 0.00023319 0.00039973 0.00026686 0.00090143 0.00024163
 0.00024509]
Model epoch 62: train total loss -64.44124179800696, train mean loss 0.00033745149265490115, test mean loss [0.0002327  0.00023068 0.00039412 0.00026978 0.00089047 0.00024333
 0.00024234]
Model epoch 63: train total loss -64.48428703578398, train mean loss 0.0003258827715918261, test mean loss [0.00023376 0.00023536 0.00036523 0.0002567  0.00089781 0.00024489
 0.00023908]
Model epoch 64: train total loss -64.14323295442605, train mean loss 0.0003520579548174265, test mean loss [0.00023716 0.00023779 0.00033227 0.00026183 0.00091376 0.00024843
 0.00024911]
Model epoch 65: train total loss -64.4820542020408, train mean loss 0.0003110501205043394, test mean loss [0.0002366  0.00023226 0.00031691 0.00026412 0.00089085 0.00023237
 0.00024357]
Model epoch 66: train total loss -64.55649495979867, train mean loss 0.0003173778949758389, test mean loss [0.00025005 0.00022312 0.00029021 0.00026225 0.00086605 0.00023606
 0.00023562]
Model epoch 67: train total loss -64.60914597467404, train mean loss 0.0003335563065997926, test mean loss [0.00023643 0.00022433 0.00028769 0.00026116 0.00084371 0.00023017
 0.00023888]
Model epoch 68: train total loss -64.5586502515998, train mean loss 0.000307890463140351, test mean loss [0.0002386  0.0002212  0.00026819 0.00026479 0.00082768 0.00023297
 0.00025444]
Model epoch 69: train total loss -64.24845423820824, train mean loss 0.0002973617076920144, test mean loss [0.00028735 0.00022745 0.00025621 0.00025654 0.00083387 0.00022533
 0.00023526]
Model epoch 70: train total loss -64.40105004498692, train mean loss 0.000292273349091014, test mean loss [0.00025122 0.00023123 0.00025971 0.00025377 0.0008302  0.00022968
 0.00023228]
Model epoch 71: train total loss -64.56876993307813, train mean loss 0.0003025135544854503, test mean loss [0.00023129 0.00022155 0.00025024 0.00025066 0.00080549 0.00023793
 0.00023136]
Model epoch 72: train total loss -64.647379417849, train mean loss 0.00030670984900067825, test mean loss [0.00023233 0.00022236 0.00024761 0.00025909 0.00084484 0.0002405
 0.00023772]
Model epoch 73: train total loss -64.50251978925515, train mean loss 0.00027646006036230643, test mean loss [0.0002458  0.00022711 0.00023892 0.0002594  0.0007938  0.00023864
 0.00023138]
Model epoch 74: train total loss -64.69709677258476, train mean loss 0.0002565306257824167, test mean loss [0.00023025 0.00021872 0.0002345  0.00025635 0.00076049 0.00022289
 0.00022639]
Model epoch 75: train total loss -64.59325627190427, train mean loss 0.00029746341676976717, test mean loss [0.0002327  0.00022367 0.00023568 0.0002499  0.00076886 0.00024158
 0.00022426]
Model epoch 76: train total loss -64.4994873028714, train mean loss 0.0002948799483295062, test mean loss [0.00022405 0.0002157  0.00022665 0.00024913 0.00075702 0.00023943
 0.00022569]
Model epoch 77: train total loss -64.70632082061924, train mean loss 0.00024524405037321, test mean loss [0.00024519 0.0002129  0.00022788 0.00025035 0.00072754 0.00022753
 0.00023199]
Model epoch 78: train total loss -64.53586358888793, train mean loss 0.000286722984796597, test mean loss [0.0002396  0.00021413 0.00022807 0.00024878 0.00073952 0.00022879
 0.00023042]
Model epoch 79: train total loss -64.63967204403436, train mean loss 0.00027488790741750504, test mean loss [0.00023502 0.00022226 0.000228   0.00024881 0.00071801 0.00023277
 0.00023397]
Model epoch 80: train total loss -64.63464981479112, train mean loss 0.00030719890044335693, test mean loss [0.00022611 0.00022077 0.00022283 0.00024419 0.00070637 0.00023509
 0.00022758]
Model epoch 81: train total loss -64.7593571411498, train mean loss 0.0002631643794432471, test mean loss [0.00022615 0.00021646 0.00022154 0.00025334 0.00070702 0.00022193
 0.00022301]
Model epoch 82: train total loss -64.42982168450926, train mean loss 0.00028998897324697284, test mean loss [0.00024052 0.00028488 0.00023193 0.00024327 0.00071382 0.00022151
 0.00022121]
Model epoch 83: train total loss -64.33741163589502, train mean loss 0.0002916522729572908, test mean loss [0.0002293  0.00027403 0.00021709 0.00024851 0.0007054  0.00023639
 0.00022884]
Model epoch 84: train total loss -64.38629306768735, train mean loss 0.00029854734157333973, test mean loss [0.00021896 0.00025451 0.00021876 0.0002439  0.00070883 0.00022643
 0.00024763]
Model epoch 85: train total loss -64.39369608569496, train mean loss 0.00025069370119388905, test mean loss [0.0002298  0.00023965 0.00021717 0.00024555 0.00069507 0.00021963
 0.00024125]
Model epoch 86: train total loss -64.32713398142303, train mean loss 0.00025759091573264757, test mean loss [0.00021786 0.00023861 0.0002099  0.00025225 0.00070455 0.00022229
 0.00022634]
Model epoch 87: train total loss -64.57552818226142, train mean loss 0.0002804503383269886, test mean loss [0.00022412 0.00024587 0.00021346 0.00024772 0.00067155 0.00022151
 0.00022858]
Model epoch 88: train total loss -64.55305433526107, train mean loss 0.00028105020812069464, test mean loss [0.00022629 0.00022359 0.00021232 0.00023903 0.00068015 0.00022977
 0.00022148]
Model epoch 89: train total loss -64.69103745100513, train mean loss 0.0002507450788250708, test mean loss [0.00022047 0.000221   0.00021013 0.00023771 0.00064633 0.00021844
 0.00022682]
Model epoch 90: train total loss -64.76415314683142, train mean loss 0.00026474836240361876, test mean loss [0.00022281 0.00021632 0.00020785 0.00023624 0.00065853 0.00021292
 0.0002256 ]
Model epoch 91: train total loss -64.36188689227829, train mean loss 0.0002923054520828849, test mean loss [0.00022116 0.00022129 0.00026054 0.00023681 0.00065764 0.00024246
 0.00022667]
Model epoch 92: train total loss -64.48773234639278, train mean loss 0.00025592132193500864, test mean loss [0.00021855 0.00021574 0.00023542 0.00024096 0.0006261  0.00022072
 0.0002304 ]
Model epoch 93: train total loss -64.51968627942057, train mean loss 0.0002781685854516502, test mean loss [0.00021773 0.00020954 0.00022012 0.00023776 0.0006291  0.00022051
 0.00022092]
Model epoch 94: train total loss -64.81772836559982, train mean loss 0.0002646114773683682, test mean loss [0.00022011 0.00021714 0.00022164 0.00023641 0.0006127  0.00021243
 0.00022348]
Model epoch 95: train total loss -64.85117601908655, train mean loss 0.0002469368050098187, test mean loss [0.00021811 0.000213   0.00021904 0.00023959 0.0006342  0.00022301
 0.00023015]
Model epoch 96: train total loss -64.89150519004272, train mean loss 0.00024117296661477967, test mean loss [0.0002173  0.00020887 0.0002107  0.00024358 0.00060974 0.00021605
 0.0002199 ]
Model epoch 97: train total loss -64.86238619700981, train mean loss 0.00024049473761160532, test mean loss [0.00024542 0.00021316 0.0002016  0.0002361  0.00059986 0.00021379
 0.00022784]
Model epoch 98: train total loss -64.77684181166316, train mean loss 0.00025815970695523724, test mean loss [0.00022483 0.00021622 0.00020012 0.00023856 0.00059077 0.00020909
 0.00021533]
Model epoch 99: train total loss -64.8449412433437, train mean loss 0.00023925187992779204, test mean loss [0.00022113 0.00020778 0.00021421 0.00023772 0.00058182 0.00022268
 0.00021396]
Model epoch 100: train total loss -64.92053744786797, train mean loss 0.0002370368577898568, test mean loss [0.0002101  0.00021061 0.0002134  0.000236   0.00058794 0.00022203
 0.00021896]
Model epoch 101: train total loss -64.80204306538421, train mean loss 0.00023971121319095413, test mean loss [0.00021912 0.00021345 0.00021064 0.00023494 0.00058127 0.00021378
 0.00023391]
Model epoch 102: train total loss -64.80039566031951, train mean loss 0.00024519299044220257, test mean loss [0.00021564 0.00020644 0.00020514 0.00025128 0.00052048 0.00021787
 0.00021546]
Model epoch 103: train total loss -64.7362152706499, train mean loss 0.0002599549595533679, test mean loss [0.00021956 0.000209   0.0002023  0.00024072 0.00052923 0.00026136
 0.00021302]
Model epoch 104: train total loss -64.87600957589936, train mean loss 0.00023005320078005954, test mean loss [0.00021042 0.00020495 0.00020412 0.00023168 0.00051136 0.00022658
 0.00021235]
Model epoch 105: train total loss -64.73235037369056, train mean loss 0.00022766363398314145, test mean loss [0.00021651 0.00021875 0.00021255 0.00023372 0.0004897  0.00021187
 0.00021424]
Model epoch 106: train total loss -64.89698762940148, train mean loss 0.0002352457216296889, test mean loss [0.00021506 0.00021072 0.00020415 0.0002334  0.00045923 0.00021447
 0.00021519]
Model epoch 107: train total loss -64.98805211052353, train mean loss 0.0002374130665351645, test mean loss [0.000211   0.00021379 0.00020918 0.00022921 0.00045521 0.00021352
 0.00021661]
Model epoch 108: train total loss -64.96892834373399, train mean loss 0.00023161055231427424, test mean loss [0.00021368 0.0002078  0.00021578 0.00022608 0.00043191 0.00021318
 0.00021107]
Model epoch 109: train total loss -65.14882192712636, train mean loss 0.0002179348586449714, test mean loss [0.00021648 0.00021098 0.00020159 0.00022519 0.00041318 0.00020867
 0.00021296]
Model epoch 110: train total loss -64.6896865016433, train mean loss 0.00023750392924548692, test mean loss [0.00022817 0.00020095 0.00019937 0.00022678 0.00039834 0.00022004
 0.00021621]
Model epoch 111: train total loss -64.81906652433541, train mean loss 0.00020884079073525197, test mean loss [0.00022799 0.00020295 0.00020489 0.00023004 0.00038425 0.00021745
 0.00021512]
Model epoch 112: train total loss -64.9288484902848, train mean loss 0.00021208647602922852, test mean loss [0.00021414 0.00021382 0.00019695 0.00022874 0.00037753 0.00021157
 0.00022157]
Model epoch 113: train total loss -64.9684513712706, train mean loss 0.00021551179250289522, test mean loss [0.00021127 0.00021307 0.00020733 0.00023618 0.00034356 0.00020908
 0.00023091]
Model epoch 114: train total loss -64.89100776896687, train mean loss 0.00020072435528536184, test mean loss [0.00022233 0.00020131 0.00021096 0.00023066 0.00033628 0.00020378
 0.00021301]
Model epoch 115: train total loss -65.03920313979391, train mean loss 0.00019918162919358465, test mean loss [0.00021832 0.00019922 0.00019837 0.00023072 0.00031621 0.00020363
 0.0002114 ]
Model epoch 116: train total loss -64.75284274416826, train mean loss 0.00019643232619245225, test mean loss [0.00022326 0.00022534 0.00019767 0.00022705 0.00028529 0.00021402
 0.00021639]
Model epoch 117: train total loss -64.852037587416, train mean loss 0.00020389177251292788, test mean loss [0.00020923 0.00021134 0.00019602 0.00023614 0.00027841 0.00021388
 0.00022017]
Model epoch 118: train total loss -65.02914177722681, train mean loss 0.00020135312804355268, test mean loss [0.00021531 0.00019442 0.00019228 0.00022395 0.00027465 0.00020667
 0.00021334]
Model epoch 119: train total loss -65.0799657424702, train mean loss 0.0001848950538398239, test mean loss [0.00021091 0.00020979 0.0001957  0.0002219  0.00026159 0.00020849
 0.00021374]
Model epoch 120: train total loss -64.83946052357287, train mean loss 0.00018957947189310898, test mean loss [0.00020747 0.00020613 0.00020753 0.000234   0.00026235 0.00020599
 0.00021633]
Model epoch 121: train total loss -64.96840627789922, train mean loss 0.00018754719501813433, test mean loss [0.00021094 0.0002039  0.00019808 0.00023147 0.00024413 0.00020951
 0.0002044 ]
Model epoch 122: train total loss -64.98860482619307, train mean loss 0.0001945108404817396, test mean loss [0.00021005 0.00019857 0.00020366 0.00022108 0.00023365 0.00020312
 0.00020914]
Model epoch 123: train total loss -65.07342094138997, train mean loss 0.0001944813830794166, test mean loss [0.00020731 0.00019608 0.00020354 0.0002301  0.00021902 0.00020532
 0.00020635]
Model epoch 124: train total loss -65.07653027349512, train mean loss 0.0001868406911858781, test mean loss [0.00020615 0.00019683 0.00019744 0.00022349 0.00021347 0.00020192
 0.000215  ]
Model epoch 125: train total loss -65.05387335365745, train mean loss 0.00017089523037873164, test mean loss [0.00020806 0.00019823 0.00019952 0.00022362 0.00021194 0.00020776
 0.00020626]
Model epoch 126: train total loss -65.14007805275057, train mean loss 0.0001790236994902593, test mean loss [0.00020498 0.00019657 0.00019506 0.00022    0.00020562 0.00021385
 0.00020418]
Model epoch 127: train total loss -65.20560385542308, train mean loss 0.00018170533608192607, test mean loss [0.00020038 0.00020235 0.00019145 0.00021595 0.00020147 0.00020464
 0.00021362]
Model epoch 128: train total loss -64.97203730005114, train mean loss 0.0001778199017377434, test mean loss [0.00021388 0.00019151 0.00019502 0.0002291  0.00019476 0.00020172
 0.00021497]
Model epoch 129: train total loss -65.14601821499076, train mean loss 0.00017074443169393173, test mean loss [0.00019873 0.00020274 0.00019676 0.00022667 0.0001887  0.00020027
 0.00020094]
Model epoch 130: train total loss -65.1537122860403, train mean loss 0.0001769940927722882, test mean loss [0.00020532 0.00019487 0.00019199 0.00022008 0.00019287 0.00019765
 0.0002044 ]
Model epoch 131: train total loss -65.16889251466186, train mean loss 0.00018602042746156849, test mean loss [0.00020393 0.00019719 0.00019023 0.00021839 0.00020006 0.00020009
 0.00020681]
Model epoch 132: train total loss -65.03253116299457, train mean loss 0.0001781519993682549, test mean loss [0.00019926 0.00019246 0.00020344 0.000226   0.0001997  0.00022089
 0.00020305]
Model epoch 133: train total loss -65.16232367968155, train mean loss 0.00019143228081471185, test mean loss [0.0002056  0.00019264 0.00019778 0.00022023 0.00019615 0.00020377
 0.00022929]
Model epoch 134: train total loss -65.3113599942678, train mean loss 0.0001670384320022032, test mean loss [0.00021197 0.00018974 0.00019104 0.00021521 0.00019908 0.00019609
 0.00020316]
Model epoch 135: train total loss -65.21221200070599, train mean loss 0.00016563236959191816, test mean loss [0.00020151 0.00019628 0.00019719 0.00021807 0.00021765 0.00019863
 0.00020398]
Model epoch 136: train total loss -64.88574355325838, train mean loss 0.00018174722113828838, test mean loss [0.00019856 0.00019079 0.00019871 0.00021914 0.00019313 0.00019656
 0.00022173]
Model epoch 137: train total loss -65.09306257628226, train mean loss 0.00018710705029836635, test mean loss [0.00020401 0.00018919 0.00019883 0.00021355 0.00020571 0.00019518
 0.00021172]
Model epoch 138: train total loss -65.36530017898087, train mean loss 0.0001739850268063671, test mean loss [0.00020853 0.00018781 0.00019424 0.00021135 0.00019651 0.00019165
 0.00020392]
Model epoch 139: train total loss -65.17517083593275, train mean loss 0.00017625834842569294, test mean loss [0.0002025  0.00018363 0.00019297 0.00020862 0.00020416 0.00019486
 0.00020639]
Model epoch 140: train total loss -65.21314665182456, train mean loss 0.00017889458294127194, test mean loss [0.00020357 0.00019279 0.0002071  0.00020639 0.00019031 0.00019894
 0.00020261]
Model epoch 141: train total loss -65.26242709553331, train mean loss 0.00016828790797391007, test mean loss [0.00020907 0.00019922 0.00019936 0.00021527 0.0001907  0.00019886
 0.0001971 ]
Model epoch 142: train total loss -64.96493119696251, train mean loss 0.0001751126858350252, test mean loss [0.00019767 0.00018975 0.00019692 0.00020866 0.00020343 0.00019742
 0.00021704]
Model epoch 143: train total loss -64.94930997096326, train mean loss 0.00017817245620416512, test mean loss [0.00019843 0.00020197 0.00019129 0.00023108 0.0001879  0.00019905
 0.00020831]
Model epoch 144: train total loss -64.87598741676128, train mean loss 0.00017857135926757777, test mean loss [0.00019677 0.00019154 0.000192   0.00020862 0.00018961 0.00019392
 0.00020361]
Model epoch 145: train total loss -65.08106204081353, train mean loss 0.00017542116335476826, test mean loss [0.00019683 0.00018716 0.00019737 0.00021404 0.0001918  0.00019818
 0.00020576]
Model epoch 146: train total loss -64.71150611860108, train mean loss 0.00017287507179045234, test mean loss [0.0001976  0.00018865 0.00019132 0.00021799 0.00019751 0.00019338
 0.00032471]
Model epoch 147: train total loss -65.10262416804268, train mean loss 0.00017589558288126216, test mean loss [0.00020047 0.00018372 0.00019047 0.00021227 0.00018991 0.00019124
 0.00023746]
Model epoch 148: train total loss -65.00424946121186, train mean loss 0.00017420080539868178, test mean loss [0.00019482 0.0001994  0.00019714 0.00020613 0.00021704 0.00019866
 0.00021788]
Model epoch 149: train total loss -64.96515189646553, train mean loss 0.00017342170103141507, test mean loss [0.00020618 0.00019033 0.00020187 0.00020965 0.00019211 0.00019679
 0.0002083 ]
Model epoch 150: train total loss -65.14241696663221, train mean loss 0.00016483735745208752, test mean loss [0.0002006  0.00018757 0.00019778 0.00020364 0.0001875  0.00019598
 0.00020661]
Model epoch 151: train total loss -65.25201670849954, train mean loss 0.00016799863657604178, test mean loss [0.00019582 0.00018941 0.00018879 0.0002053  0.00018028 0.00019664
 0.00022337]
Model epoch 152: train total loss -63.826358686269614, train mean loss 0.00018620579556440016, test mean loss [0.0002787  0.00018666 0.00019918 0.00020872 0.00026569 0.00019725
 0.00025784]
Model epoch 153: train total loss -64.34842433558663, train mean loss 0.00023718063885776135, test mean loss [0.00026193 0.00018651 0.00019666 0.00020103 0.00061216 0.00018878
 0.00023315]
Model epoch 154: train total loss -64.80326619165011, train mean loss 0.00020258054096416322, test mean loss [0.00021907 0.00018503 0.00018878 0.00020945 0.00044735 0.0001878
 0.00020863]
Model epoch 155: train total loss -65.0394554583584, train mean loss 0.00020250267384879062, test mean loss [0.00021754 0.00018487 0.00018758 0.00020492 0.0003709  0.0001897
 0.00020374]
Model epoch 156: train total loss -65.2155891984636, train mean loss 0.00019004867960309413, test mean loss [0.00024234 0.00018464 0.00018558 0.00021398 0.00034284 0.00018972
 0.00019751]
Model epoch 157: train total loss -64.9522520975766, train mean loss 0.0001940541825219697, test mean loss [0.00022165 0.00018652 0.00018441 0.00020504 0.00033073 0.00018968
 0.00020788]
Model epoch 158: train total loss -64.67326527987865, train mean loss 0.0001917308591018481, test mean loss [0.00021629 0.0001839  0.00019491 0.0002072  0.00037515 0.00018528
 0.00020642]
Model epoch 159: train total loss -64.86262707758056, train mean loss 0.00019816630998726112, test mean loss [0.0002151  0.00018163 0.00019326 0.00021121 0.00034904 0.00018879
 0.00019654]
Model epoch 160: train total loss -65.00863974033697, train mean loss 0.00017982521295017715, test mean loss [0.00019992 0.00019285 0.00018831 0.00020619 0.00033873 0.00018768
 0.00019692]
Model epoch 161: train total loss -65.13562195976823, train mean loss 0.00018431587049671405, test mean loss [0.0002099  0.00018834 0.00018947 0.0001996  0.0003358  0.00018566
 0.00019746]
Model epoch 162: train total loss -65.13665846947532, train mean loss 0.00019923329915532475, test mean loss [0.00020471 0.00018466 0.0001794  0.00021067 0.00032212 0.00019577
 0.00019733]
Model epoch 163: train total loss -65.29450587668497, train mean loss 0.00017601896635320694, test mean loss [0.00020234 0.00018558 0.00018894 0.00020711 0.0003236  0.00018485
 0.0002021 ]
Model epoch 164: train total loss -65.28762396063402, train mean loss 0.00017940823361036474, test mean loss [0.00020395 0.00018506 0.00018355 0.00021182 0.0003033  0.00019821
 0.00019112]
Model epoch 165: train total loss -65.19571321878247, train mean loss 0.00017132965162724125, test mean loss [0.00020037 0.0001862  0.00018688 0.00020191 0.00026928 0.00019504
 0.00019277]
Model epoch 166: train total loss -65.3146630580475, train mean loss 0.0001706630680071691, test mean loss [0.00019709 0.0001827  0.00019588 0.00020136 0.00025229 0.00019043
 0.00019657]
Model epoch 167: train total loss -65.32995728604365, train mean loss 0.00015721890070605462, test mean loss [0.00019046 0.00017923 0.0001883  0.0002093  0.00024143 0.00018853
 0.00019181]
Model epoch 168: train total loss -65.19150323129155, train mean loss 0.0001684643435946873, test mean loss [0.00019329 0.0001827  0.0001778  0.00020192 0.0002249  0.00018018
 0.00019407]
Model epoch 169: train total loss -64.98631769899123, train mean loss 0.0001710269913905442, test mean loss [0.00020617 0.00019379 0.00019327 0.00020088 0.00020941 0.00019249
 0.00018956]
Model epoch 170: train total loss -65.1524149602207, train mean loss 0.0001713203064836455, test mean loss [0.00019072 0.00018896 0.0001863  0.00019623 0.0002015  0.00019189
 0.0002003 ]
Model epoch 171: train total loss -65.22047591934135, train mean loss 0.00016552495847449165, test mean loss [0.00018341 0.00018226 0.00018327 0.00021113 0.00019451 0.00018339
 0.00019396]
Model epoch 172: train total loss -65.37067749396404, train mean loss 0.00015894962204972054, test mean loss [0.00018792 0.00017785 0.00018365 0.00020282 0.00018555 0.00018199
 0.0002029 ]
Model epoch 173: train total loss -65.55105461044133, train mean loss 0.0001589039629340498, test mean loss [0.00019363 0.0001796  0.00018681 0.00019918 0.00018145 0.00017684
 0.00018975]
Model epoch 174: train total loss -64.18723965014873, train mean loss 0.0001901506377216868, test mean loss [0.00018963 0.00017944 0.00018055 0.00020159 0.00019464 0.00035942
 0.0001915 ]
Model epoch 175: train total loss -64.94878128235236, train mean loss 0.00017483626107523323, test mean loss [0.00020987 0.00017736 0.00018136 0.00019788 0.00018276 0.0003047
 0.00019194]
Model epoch 176: train total loss -65.14151980636159, train mean loss 0.0001630402328992275, test mean loss [0.00019871 0.00017405 0.00018184 0.00019638 0.00018222 0.00024198
 0.00019776]
Model epoch 177: train total loss -65.19233176895499, train mean loss 0.00016325476961337167, test mean loss [0.00019613 0.00018115 0.00017973 0.00020008 0.00018578 0.00022227
 0.00019516]
Model epoch 178: train total loss -65.25432564067515, train mean loss 0.00016462409987385532, test mean loss [0.00020024 0.00017938 0.00018706 0.00019825 0.00018697 0.00021042
 0.00018704]
Model epoch 179: train total loss -65.4251965037874, train mean loss 0.00015632565148887632, test mean loss [0.00018773 0.00017901 0.00017737 0.00019847 0.00019341 0.00020915
 0.00019163]
Model epoch 180: train total loss -65.32504039525625, train mean loss 0.000152931061592111, test mean loss [0.00018419 0.00018886 0.00019428 0.00019923 0.00017857 0.00020272
 0.00019102]
Model epoch 181: train total loss -65.38214146554449, train mean loss 0.00015732436569701217, test mean loss [0.00018756 0.0001804  0.00018125 0.00019939 0.00017738 0.00020055
 0.00020536]
Model epoch 182: train total loss -65.32002222199802, train mean loss 0.00015753553907743576, test mean loss [0.00019758 0.00017255 0.00018108 0.0001959  0.00018591 0.00020365
 0.00019612]
Model epoch 183: train total loss -65.19183010530966, train mean loss 0.00017022815116103795, test mean loss [0.00018862 0.00017861 0.00020067 0.00019317 0.00018037 0.00019718
 0.00019079]
Model epoch 184: train total loss -65.27090521002849, train mean loss 0.00016586546536930568, test mean loss [0.00018622 0.00017953 0.0001828  0.00019303 0.0001884  0.00019476
 0.00018862]
Model epoch 185: train total loss -65.29911571441004, train mean loss 0.00016304976914623703, test mean loss [0.00018673 0.00017808 0.00017618 0.00019521 0.00017717 0.00020438
 0.0001858 ]
Model epoch 186: train total loss -65.44787499328406, train mean loss 0.00016071952399263656, test mean loss [0.00018819 0.00017994 0.00017763 0.00019379 0.0001766  0.00019719
 0.00018381]
Model epoch 187: train total loss -65.39341260861211, train mean loss 0.00015270655734401944, test mean loss [0.00018764 0.00016995 0.00017781 0.00019233 0.00018335 0.00019879
 0.00018181]
Model epoch 188: train total loss -65.41290057837793, train mean loss 0.00015748073152459398, test mean loss [0.00018878 0.00017585 0.00018362 0.00019531 0.00018432 0.00018847
 0.00018669]
Model epoch 189: train total loss -65.46805146022116, train mean loss 0.00015253602529743382, test mean loss [0.00018667 0.00017096 0.00017097 0.00019183 0.0001851  0.00017711
 0.00018326]
Model epoch 190: train total loss -65.4275476881895, train mean loss 0.00015722025658822583, test mean loss [0.00018484 0.00017264 0.0001776  0.00019319 0.00017783 0.00017276
 0.00018135]
Model epoch 191: train total loss -65.61685353662384, train mean loss 0.000148595718852347, test mean loss [0.00019031 0.00017109 0.00019265 0.00019395 0.00017991 0.00017267
 0.00018541]
Model epoch 192: train total loss -65.52836431576326, train mean loss 0.00014796355797249466, test mean loss [0.00018492 0.00017508 0.00018531 0.00018638 0.00018131 0.00017646
 0.00018192]
Model epoch 193: train total loss -65.55309214981138, train mean loss 0.00014674964356859715, test mean loss [0.0001827  0.0001694  0.00017224 0.00019027 0.00018134 0.00017649
 0.00019546]
Model epoch 194: train total loss -65.23118658471135, train mean loss 0.00014896708274856596, test mean loss [0.00019175 0.00017206 0.00017187 0.00021965 0.00017949 0.00017661
 0.00019149]
Model epoch 195: train total loss -65.34713020539292, train mean loss 0.00014999952910234074, test mean loss [0.0001829  0.00017955 0.00018551 0.00020462 0.00017968 0.00017429
 0.00018691]
Model epoch 196: train total loss -65.30738506161427, train mean loss 0.00015634461756978223, test mean loss [0.00019143 0.00018531 0.00018101 0.00019837 0.00018196 0.00017458
 0.00018589]
Model epoch 197: train total loss -65.57440327376342, train mean loss 0.00015264059503341962, test mean loss [0.00018447 0.00017266 0.00017149 0.00020354 0.00017819 0.00017446
 0.00018837]
Model epoch 198: train total loss -65.32886277809902, train mean loss 0.00015957838783427146, test mean loss [0.00018906 0.00017414 0.00017244 0.00020157 0.00020635 0.00017475
 0.00018556]
Model trained in 199 epochs with 2000 transitions.
[2025-01-23 12:55:44,756][absl][INFO] - {'eval/walltime': 104.58449816703796, 'training/sps': 1.0619390149926067, 'training/walltime': 1807.3826763629913, 'training/model_train_time': 579.8036544322968, 'training/other_time': 361.02978324890137, 'training/model_horizon': 2, 'training/hallucination_updates_per_training_step': 257, 'training/env_buffer_size': Array(3000, dtype=int32), 'model/train_total_loss': Array(-65.32886278, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00015958, dtype=float64), 'model/test_total_loss': Array(-64.74139546, dtype=float64), 'model/test_mean_loss': Array(0.00018627, dtype=float64), 'model/train_epochs': 199, 'model/sec_per_epoch': 2.9031787913049287, 'sac/actor_loss': Array(-13.03514047, dtype=float64), 'sac/alpha': Array(0.23569728, dtype=float32), 'sac/alpha_loss': Array(1.98487785, dtype=float64), 'sac/buffer_current_size': Array(108129.18, dtype=float32), 'sac/critic_loss': Array(0.1114758, dtype=float64), 'eval/episode_forward_vel': Array(-160.59929701, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-1.04113619, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(52.22902751, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(1.20969625, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-69.07496646, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(52.95690678, dtype=float64), 'eval/episode_rew_roll': Array(52.41988102, dtype=float64), 'eval/episode_rew_side_motion': Array(49.94875112, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(81.74303801, dtype=float64), 'eval/episode_rew_yaw': Array(25.47861887, dtype=float64), 'eval/episode_rew_z_vel_change': Array(26.84203832, dtype=float64), 'eval/episode_reward': Array(272.93290621, dtype=float64), 'eval/episode_step_count': Array(499500., dtype=float64), 'eval/avg_episode_length': Array(1000., dtype=float64), 'eval/epoch_eval_time': 30.423338651657104, 'eval/sps': 32.86950230708923}
Steps / Eval:  3000.0
Reward is  272.93290620531536
Model horizon updated to 4.
Hallucination updates per training step updated to 505.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -28.849715718728508, train mean loss 0.030517825774435035, test mean loss [0.02034887 0.030825   0.02676007 0.02903018 0.03170897 0.0331136
 0.02999412]
Model epoch 1: train total loss -35.49823120654174, train mean loss 0.027352355112955366, test mean loss [0.01834459 0.02743029 0.02335047 0.02567275 0.02901812 0.02939102
 0.02867695]
Model epoch 2: train total loss -39.629478952995974, train mean loss 0.024591067194919772, test mean loss [0.01633228 0.02465651 0.02112445 0.02182749 0.02691655 0.02739296
 0.02552393]
Model epoch 3: train total loss -43.27919130446655, train mean loss 0.022910968602030013, test mean loss [0.0144187  0.02306742 0.01919897 0.01745133 0.02507646 0.02538686
 0.02259578]
Model epoch 4: train total loss -45.78811239943592, train mean loss 0.019785829354966793, test mean loss [0.01308391 0.02012752 0.01674231 0.0160207  0.0228011  0.02208699
 0.02060792]
Model epoch 5: train total loss -48.06749873956449, train mean loss 0.01770642014331662, test mean loss [0.01146875 0.0165336  0.01486206 0.01511518 0.0203822  0.01940889
 0.01788084]
Model epoch 6: train total loss -50.285417764116524, train mean loss 0.014639169939048674, test mean loss [0.01024396 0.01454661 0.01327095 0.01449039 0.017894   0.01705577
 0.01575591]
Model epoch 7: train total loss -51.850002598310745, train mean loss 0.013622849690353588, test mean loss [0.00896719 0.01352091 0.01199757 0.01404214 0.01545018 0.01513189
 0.014323  ]
Model epoch 8: train total loss -53.20347372136922, train mean loss 0.012317064592731967, test mean loss [0.00766719 0.01198822 0.01102581 0.01333958 0.01371513 0.01397606
 0.01294085]
Model epoch 9: train total loss -54.48182029472489, train mean loss 0.01133231013386984, test mean loss [0.00649096 0.01083355 0.00991821 0.01280126 0.01264974 0.0129903
 0.01148856]
Model epoch 10: train total loss -55.29628019609086, train mean loss 0.010027766071383466, test mean loss [0.005536   0.00964658 0.00907361 0.01191479 0.0118769  0.01181423
 0.01019457]
Model epoch 11: train total loss -55.986119496435606, train mean loss 0.009301820036230458, test mean loss [0.00489961 0.00848505 0.00814358 0.01114189 0.01098022 0.01096193
 0.00921096]
Model epoch 12: train total loss -56.69333084575192, train mean loss 0.008562785322381314, test mean loss [0.00430674 0.00748165 0.00739169 0.01030227 0.01029588 0.01004328
 0.00812895]
Model epoch 13: train total loss -57.17042045163552, train mean loss 0.007627402909611339, test mean loss [0.0036979  0.00670598 0.00670078 0.0095327  0.00971438 0.00937458
 0.00711131]
Model epoch 14: train total loss -57.61171333520844, train mean loss 0.007132107176170704, test mean loss [0.00318201 0.00601022 0.00607734 0.0088924  0.0089199  0.00861943
 0.00638023]
Model epoch 15: train total loss -57.91486071740302, train mean loss 0.006534937434567864, test mean loss [0.00272307 0.00542654 0.00546587 0.00834938 0.00834208 0.00814132
 0.00573232]
Model epoch 16: train total loss -58.376539420080334, train mean loss 0.005699282517097268, test mean loss [0.00239723 0.004825   0.00485024 0.00764289 0.00782443 0.00734858
 0.00496485]
Model epoch 17: train total loss -58.43532768399951, train mean loss 0.005264147442244635, test mean loss [0.00208554 0.00433521 0.00422508 0.00726567 0.00720627 0.00705438
 0.00441831]
Model epoch 18: train total loss -58.58946805234692, train mean loss 0.005044962983356095, test mean loss [0.00190539 0.00393854 0.00380345 0.00682026 0.00679376 0.00657967
 0.00380928]
Model epoch 19: train total loss -59.123211703822186, train mean loss 0.0044860944686221085, test mean loss [0.00173118 0.00354863 0.00342274 0.00635796 0.00641835 0.00597248
 0.00335967]
Model epoch 20: train total loss -59.313982052360714, train mean loss 0.004142707042997198, test mean loss [0.00158998 0.00305799 0.00311521 0.00607339 0.00599381 0.0055685
 0.00290042]
Model epoch 21: train total loss -59.63360895241209, train mean loss 0.0038255312419994106, test mean loss [0.00149452 0.00268584 0.0027846  0.00554992 0.00560575 0.00499157
 0.00266586]
Model epoch 22: train total loss -59.77970504367792, train mean loss 0.003492229157599526, test mean loss [0.00140072 0.00227768 0.00254647 0.00532732 0.00518897 0.00459867
 0.00237735]
Model epoch 23: train total loss -60.0760514647924, train mean loss 0.0028298401381089723, test mean loss [0.00133443 0.0020445  0.00230476 0.00493848 0.00483651 0.00409617
 0.00214677]
Model epoch 24: train total loss -60.17714511768984, train mean loss 0.0029709005885560267, test mean loss [0.00127447 0.00179422 0.00203132 0.00458938 0.00455016 0.00369979
 0.00195069]
Model epoch 25: train total loss -60.371922612727175, train mean loss 0.002577900254808875, test mean loss [0.00120994 0.00163845 0.0018679  0.00415506 0.00426604 0.00332909
 0.00176434]
Model epoch 26: train total loss -60.547410466466154, train mean loss 0.0022549023348932247, test mean loss [0.00116358 0.00152968 0.0017018  0.00394072 0.00387951 0.00292075
 0.00154788]
Model epoch 27: train total loss -60.70220460039031, train mean loss 0.0020186376301413278, test mean loss [0.00113248 0.00142421 0.00158064 0.00351633 0.00357369 0.00247281
 0.0014126 ]
Model epoch 28: train total loss -60.89904990724103, train mean loss 0.002003397254188077, test mean loss [0.00111036 0.00131208 0.00146509 0.00328769 0.00337192 0.00214296
 0.00130731]
Model epoch 29: train total loss -61.00704189688263, train mean loss 0.0018662863655284634, test mean loss [0.00108129 0.00127685 0.00130459 0.00313588 0.00316985 0.00200659
 0.00122055]
Model epoch 30: train total loss -61.02026480834635, train mean loss 0.0016636493102981965, test mean loss [0.00104104 0.00122866 0.00125317 0.00287721 0.00294776 0.00173307
 0.00117024]
Model epoch 31: train total loss -61.306249866339556, train mean loss 0.0014466087443369352, test mean loss [0.00102816 0.00116117 0.00118559 0.00254576 0.00271417 0.00157777
 0.00108866]
Model epoch 32: train total loss -61.35917203218599, train mean loss 0.00142411240000129, test mean loss [0.00098659 0.0011045  0.00113439 0.00238649 0.00248741 0.00143203
 0.00105714]
Model epoch 33: train total loss -61.535419858061125, train mean loss 0.0012135961471490579, test mean loss [0.00097844 0.00109227 0.00109335 0.00214968 0.00230777 0.00132211
 0.00103007]
Model epoch 34: train total loss -61.63751708706953, train mean loss 0.0011445653280856673, test mean loss [0.00094621 0.00104165 0.00108128 0.00197655 0.00210438 0.00120054
 0.00098813]
Model epoch 35: train total loss -61.74678281387703, train mean loss 0.001183480545772418, test mean loss [0.00094372 0.00103743 0.0010221  0.00177721 0.00198155 0.00119081
 0.00095789]
Model epoch 36: train total loss -61.788866635221176, train mean loss 0.0010415646613516313, test mean loss [0.00090703 0.00097668 0.00098881 0.00163995 0.00177196 0.00114576
 0.00095038]
Model epoch 37: train total loss -61.854222228073176, train mean loss 0.001049283455920161, test mean loss [0.00089082 0.00098435 0.0009267  0.00144694 0.00162575 0.0010916
 0.00090605]
Model epoch 38: train total loss -61.85899112027011, train mean loss 0.0009400137802400794, test mean loss [0.00088125 0.00091971 0.00090324 0.00135921 0.00152148 0.00106617
 0.00090161]
Model epoch 39: train total loss -62.13236686731081, train mean loss 0.0008248247096352378, test mean loss [0.00085116 0.00090427 0.00086572 0.00122653 0.00134926 0.001041
 0.00087719]
Model epoch 40: train total loss -62.03595732625212, train mean loss 0.0008354238032014885, test mean loss [0.00083466 0.00088683 0.00083239 0.00111699 0.00131765 0.00102086
 0.00086139]
Model epoch 41: train total loss -62.09191451366059, train mean loss 0.0007750354753857502, test mean loss [0.00083279 0.0008519  0.00080754 0.00105478 0.00125767 0.00099472
 0.00084965]
Model epoch 42: train total loss -62.2920714531146, train mean loss 0.0007239137776549405, test mean loss [0.00081136 0.00084847 0.00076339 0.00099859 0.00115314 0.00098368
 0.00083072]
Model epoch 43: train total loss -62.340133419444676, train mean loss 0.0007828070190421091, test mean loss [0.00078495 0.00081483 0.00074479 0.00093975 0.00108281 0.00094055
 0.00082283]
Model epoch 44: train total loss -62.50037301118929, train mean loss 0.0007047650380296016, test mean loss [0.00076581 0.00083013 0.00073035 0.00089968 0.00095171 0.00093352
 0.00081649]
Model epoch 45: train total loss -62.34542448647359, train mean loss 0.0006702404167165493, test mean loss [0.00077137 0.00078423 0.00071008 0.00089229 0.00090758 0.00088577
 0.00078439]
Model epoch 46: train total loss -62.580547617342724, train mean loss 0.0006589677168591694, test mean loss [0.00077142 0.00075218 0.00068814 0.00084667 0.00084806 0.00089136
 0.00077212]
Model epoch 47: train total loss -62.51907637436959, train mean loss 0.0006456671835355167, test mean loss [0.00073817 0.00073259 0.00066533 0.00082735 0.00080761 0.00087868
 0.00075281]
Model epoch 48: train total loss -62.57730316225107, train mean loss 0.0006645412039782088, test mean loss [0.00072064 0.00074112 0.00064876 0.00080199 0.00079769 0.00085729
 0.00074777]
Model epoch 49: train total loss -62.68223974884324, train mean loss 0.0006186984609398583, test mean loss [0.00071188 0.00071411 0.00063803 0.00078338 0.00074206 0.00082741
 0.0007506 ]
Model epoch 50: train total loss -62.73221544963129, train mean loss 0.0005796812068581434, test mean loss [0.00070036 0.00069297 0.00062857 0.00075503 0.00072439 0.00084475
 0.0007274 ]
Model epoch 51: train total loss -62.80217070907874, train mean loss 0.000539466237554016, test mean loss [0.00070552 0.00066633 0.0006068  0.00073024 0.00073147 0.00084062
 0.00071405]
Model epoch 52: train total loss -62.723021961731064, train mean loss 0.0005688411824575748, test mean loss [0.00068619 0.00066387 0.00059319 0.0007454  0.00070367 0.00079374
 0.00072774]
Model epoch 53: train total loss -63.04529908537705, train mean loss 0.0005705510336014554, test mean loss [0.00066752 0.00065295 0.00059332 0.00071944 0.00067789 0.00079362
 0.0007169 ]
Model epoch 54: train total loss -62.72854165683684, train mean loss 0.0005986117818022237, test mean loss [0.00066819 0.00063234 0.00059015 0.00071031 0.00067648 0.00077948
 0.00069987]
Model epoch 55: train total loss -62.93090488652884, train mean loss 0.0005667704595321357, test mean loss [0.00066063 0.00061614 0.00057555 0.00071226 0.00066471 0.00074341
 0.00069222]
Model epoch 56: train total loss -63.064539594624804, train mean loss 0.0005055441975514044, test mean loss [0.00063865 0.00061874 0.00057009 0.0006738  0.00066223 0.00073412
 0.00067458]
Model epoch 57: train total loss -63.13057474983837, train mean loss 0.00047492828404674674, test mean loss [0.00062748 0.00061477 0.00055369 0.00065162 0.00064124 0.00072699
 0.00067382]
Model epoch 58: train total loss -63.03004568553853, train mean loss 0.000569884005720229, test mean loss [0.00063219 0.0005956  0.00056409 0.00064889 0.00063368 0.00071511
 0.00067514]
Model epoch 59: train total loss -63.15487578833717, train mean loss 0.0005195728329042478, test mean loss [0.00062818 0.00058168 0.00054878 0.00064761 0.00062882 0.00070748
 0.00064988]
Model epoch 60: train total loss -63.21314280997121, train mean loss 0.00046498470288587894, test mean loss [0.00061021 0.0005887  0.00054756 0.00064145 0.00061803 0.0006954
 0.00063667]
Model epoch 61: train total loss -63.174536417563914, train mean loss 0.0004903087017002911, test mean loss [0.00059076 0.00057854 0.00053216 0.00063397 0.00061071 0.00068033
 0.00062616]
Model epoch 62: train total loss -63.28123147774759, train mean loss 0.00045352849526553624, test mean loss [0.00058692 0.00057209 0.00051993 0.00063447 0.00060507 0.00066688
 0.00062553]
Model epoch 63: train total loss -63.16115017196847, train mean loss 0.0004666180418388666, test mean loss [0.00058494 0.00054708 0.00051962 0.00061432 0.00058206 0.00066158
 0.00061916]
Model epoch 64: train total loss -63.11052109572977, train mean loss 0.000460865761869297, test mean loss [0.0005781  0.00055872 0.00051185 0.00059368 0.00057909 0.00066664
 0.00062494]
Model epoch 65: train total loss -63.282524811192864, train mean loss 0.00042936143122246216, test mean loss [0.00056536 0.00053883 0.00049639 0.00058136 0.00058486 0.00067663
 0.00060114]
Model epoch 66: train total loss -63.474172401518025, train mean loss 0.00041220277701082934, test mean loss [0.00055893 0.0005328  0.00049338 0.00059245 0.00057336 0.00063638
 0.00060023]
Model epoch 67: train total loss -63.3071373528479, train mean loss 0.0005158786673555176, test mean loss [0.00056611 0.00051083 0.00049626 0.0005713  0.0005609  0.00063633
 0.00059313]
Model epoch 68: train total loss -63.39367004160322, train mean loss 0.0004631454229529664, test mean loss [0.00055636 0.0004988  0.00049137 0.00056163 0.00055045 0.00062039
 0.00058268]
Model epoch 69: train total loss -63.42730968816885, train mean loss 0.00043145903535639124, test mean loss [0.0005453  0.00049501 0.00047681 0.00055774 0.00054165 0.00063261
 0.00058239]
Model epoch 70: train total loss -63.57352706869842, train mean loss 0.00043363628498498553, test mean loss [0.000541   0.00048407 0.00047706 0.00055121 0.00054493 0.00060365
 0.00057402]
Model epoch 71: train total loss -63.32886555930349, train mean loss 0.00046656784193028177, test mean loss [0.00053905 0.0004771  0.0004776  0.00054847 0.00053619 0.00059969
 0.00057546]
Model epoch 72: train total loss -63.46007172507537, train mean loss 0.0004241924101858022, test mean loss [0.00052876 0.000465   0.0004742  0.00054071 0.00053852 0.00060779
 0.00056716]
Model epoch 73: train total loss -63.60631147111187, train mean loss 0.00038199159229988317, test mean loss [0.00051663 0.00048111 0.00046281 0.00053696 0.00054165 0.00058616
 0.00057236]
Model epoch 74: train total loss -63.52803401739857, train mean loss 0.0004635672457929396, test mean loss [0.00051525 0.00047699 0.00046775 0.00053031 0.00051703 0.0005812
 0.00055521]
Model epoch 75: train total loss -63.666373909488, train mean loss 0.000342796003279569, test mean loss [0.00050749 0.00047007 0.00045636 0.00051103 0.00051594 0.00057871
 0.00054979]
Model epoch 76: train total loss -63.57243421717222, train mean loss 0.0004499223894032269, test mean loss [0.00049925 0.00044964 0.00044502 0.00053547 0.00050386 0.00058281
 0.00054416]
Model epoch 77: train total loss -63.54413988504679, train mean loss 0.0003912385123704196, test mean loss [0.00049358 0.00045174 0.00045467 0.00051437 0.00050916 0.00055807
 0.00055114]
Model epoch 78: train total loss -63.64106189330819, train mean loss 0.0003721084940851271, test mean loss [0.00048882 0.00044525 0.00043592 0.00051194 0.00050621 0.00054453
 0.00052578]
Model epoch 79: train total loss -63.67736294940924, train mean loss 0.0003631664413449592, test mean loss [0.00048166 0.00045158 0.00043835 0.00050212 0.0005005  0.00053784
 0.00052996]
Model epoch 80: train total loss -63.60384261558002, train mean loss 0.00042146103962065033, test mean loss [0.00048954 0.00044216 0.00042729 0.00049518 0.00049402 0.00054544
 0.000559  ]
Model epoch 81: train total loss -63.5287042238026, train mean loss 0.0003617045984965634, test mean loss [0.00048    0.00042741 0.00042446 0.00049389 0.00049314 0.00054028
 0.00051999]
Model epoch 82: train total loss -63.78057095201906, train mean loss 0.0004257775506519493, test mean loss [0.00047285 0.000421   0.00042598 0.00049479 0.00048311 0.00052983
 0.00051181]
Model epoch 83: train total loss -63.61112929221722, train mean loss 0.00041722295358563545, test mean loss [0.00046801 0.00041192 0.00043129 0.00048474 0.0004766  0.00056222
 0.0004991 ]
Model epoch 84: train total loss -63.75338376907001, train mean loss 0.0003556646028469634, test mean loss [0.00047942 0.00042512 0.00042095 0.0004831  0.00047299 0.00054909
 0.00049424]
Model epoch 85: train total loss -63.89184240717629, train mean loss 0.0003486775815641285, test mean loss [0.00046024 0.00040219 0.00041503 0.0004686  0.00047685 0.00052527
 0.00049057]
Model epoch 86: train total loss -63.953252621865, train mean loss 0.0003387979393438167, test mean loss [0.00045442 0.00040359 0.00041634 0.00046158 0.00047019 0.00052041
 0.00048765]
Model epoch 87: train total loss -63.944296098823635, train mean loss 0.0003960596625665948, test mean loss [0.00045553 0.00039767 0.0004189  0.00047047 0.00047742 0.00050158
 0.00048357]
Model epoch 88: train total loss -63.834359354983945, train mean loss 0.0003355630551889934, test mean loss [0.00045671 0.00039323 0.00041229 0.00045635 0.0004717  0.00049746
 0.00048412]
Model epoch 89: train total loss -63.96441108319562, train mean loss 0.000354162885343598, test mean loss [0.00044726 0.00038513 0.00040605 0.00045084 0.00046076 0.00049062
 0.00046999]
Model epoch 90: train total loss -64.07917559915151, train mean loss 0.00039261318366302326, test mean loss [0.00044729 0.00038375 0.00040433 0.00044765 0.00046148 0.00048446
 0.00046064]
Model epoch 91: train total loss -63.69701016519626, train mean loss 0.00032880874826607376, test mean loss [0.00044785 0.00038175 0.00040088 0.00044997 0.00045431 0.00048174
 0.00045009]
Model epoch 92: train total loss -64.0892133169586, train mean loss 0.0003245069367438016, test mean loss [0.00044138 0.00038004 0.00039255 0.0004415  0.00045362 0.00047435
 0.00044957]
Model epoch 93: train total loss -63.966026454107215, train mean loss 0.0003580357523325045, test mean loss [0.00044395 0.00036776 0.00039269 0.00043939 0.00045506 0.00047827
 0.00044822]
Model epoch 94: train total loss -63.94546461025693, train mean loss 0.0003484396857267674, test mean loss [0.00043825 0.00037682 0.00038793 0.00044591 0.00043408 0.00047192
 0.0004443 ]
Model epoch 95: train total loss -64.19831810654179, train mean loss 0.00029694306596421736, test mean loss [0.00042685 0.00037594 0.00038954 0.0004341  0.00043514 0.00045953
 0.0004494 ]
Model epoch 96: train total loss -64.18348886804883, train mean loss 0.0003380452431703931, test mean loss [0.00042659 0.00036149 0.00039046 0.00043051 0.00043383 0.00046178
 0.00044043]
Model epoch 97: train total loss -64.17647478902106, train mean loss 0.00033906592104495373, test mean loss [0.00041996 0.00036122 0.00038179 0.00043851 0.00042218 0.00045284
 0.00044728]
Model epoch 98: train total loss -64.16710432339676, train mean loss 0.00026596670134997817, test mean loss [0.00041728 0.0003534  0.00038548 0.00044832 0.00042303 0.00045777
 0.0004306 ]
Model epoch 99: train total loss -64.1584497078388, train mean loss 0.00032379602953913416, test mean loss [0.00042065 0.00035428 0.000369   0.00042061 0.0004165  0.00045019
 0.00042341]
Model epoch 100: train total loss -64.03154177047273, train mean loss 0.0003501829579052522, test mean loss [0.00042392 0.00035144 0.00038111 0.00041719 0.00041812 0.00044913
 0.00041756]
Model epoch 101: train total loss -64.12448199506669, train mean loss 0.00027057378609717333, test mean loss [0.00041317 0.00034644 0.00037468 0.000416   0.0004145  0.00044842
 0.00041656]
Model epoch 102: train total loss -64.11267330176531, train mean loss 0.0003322379976064657, test mean loss [0.00042602 0.00034457 0.00037331 0.00041787 0.00041751 0.00045105
 0.00042173]
Model epoch 103: train total loss -64.29634692079513, train mean loss 0.0002914736826896403, test mean loss [0.00040954 0.00034172 0.00036749 0.00042042 0.00040516 0.0004401
 0.00041827]
Model epoch 104: train total loss -63.69466022392226, train mean loss 0.00032880889293301945, test mean loss [0.00041646 0.0003359  0.00041899 0.00049014 0.00040241 0.0004341
 0.0004071 ]
Model epoch 105: train total loss -63.96921456724221, train mean loss 0.00033252143638639486, test mean loss [0.00040517 0.00033871 0.00037529 0.00043744 0.00040515 0.00043069
 0.00040443]
Model epoch 106: train total loss -64.30600494110104, train mean loss 0.0003012440149497508, test mean loss [0.00041247 0.00033791 0.00037088 0.00041698 0.0004002  0.00041896
 0.00039698]
Model epoch 107: train total loss -64.10118365927838, train mean loss 0.00032244446835898226, test mean loss [0.00040013 0.00032021 0.00036672 0.00040113 0.00040113 0.00041487
 0.00039867]
Model epoch 108: train total loss -64.20061086961184, train mean loss 0.00030364677096994584, test mean loss [0.00039471 0.00032303 0.00037452 0.00039371 0.00040871 0.00041461
 0.00039453]
Model epoch 109: train total loss -64.2258083344214, train mean loss 0.0003013956936978549, test mean loss [0.00039792 0.00032268 0.00035801 0.00039574 0.00038881 0.00041513
 0.00038759]
Model epoch 110: train total loss -64.20484080865361, train mean loss 0.00030094836276573015, test mean loss [0.0004067  0.00031102 0.00035207 0.00039154 0.00039219 0.00041089
 0.0003954 ]
Model epoch 111: train total loss -64.38692562410264, train mean loss 0.0002560245608498, test mean loss [0.00039442 0.00031851 0.00034624 0.00040057 0.00039207 0.00041831
 0.00038323]
Model epoch 112: train total loss -64.08803009923635, train mean loss 0.00029923537271712855, test mean loss [0.00040922 0.00031086 0.00035366 0.00039357 0.00037929 0.00040764
 0.00038206]
Model epoch 113: train total loss -64.42518063052326, train mean loss 0.00029937567293916435, test mean loss [0.00040121 0.00031122 0.00033789 0.00038118 0.00039022 0.00041303
 0.000373  ]
Model epoch 114: train total loss -64.23107701738613, train mean loss 0.0003094838632415659, test mean loss [0.00039525 0.00031217 0.00034405 0.00039061 0.00038132 0.00041273
 0.00038002]
Model epoch 115: train total loss -64.35641956172343, train mean loss 0.00027703190357383973, test mean loss [0.00038471 0.00031502 0.00034089 0.00039203 0.00038076 0.00041108
 0.00037384]
Model epoch 116: train total loss -64.396190537939, train mean loss 0.00026901557635727733, test mean loss [0.0003835  0.00030845 0.00033479 0.00038254 0.0003739  0.0003914
 0.00037176]
Model epoch 117: train total loss -64.12063259408282, train mean loss 0.00029053549520102187, test mean loss [0.00039618 0.00030081 0.00032943 0.00039683 0.00037657 0.00041475
 0.00036634]
Model epoch 118: train total loss -64.392438781141, train mean loss 0.00030472650955582376, test mean loss [0.00038581 0.00029646 0.00032894 0.00038022 0.00036806 0.00039162
 0.0003688 ]
Model epoch 119: train total loss -64.4026175456085, train mean loss 0.00029493478129963014, test mean loss [0.00037941 0.00030403 0.00032565 0.00038262 0.00036827 0.00039862
 0.0003642 ]
Model epoch 120: train total loss -64.58943288921823, train mean loss 0.0002786315526371638, test mean loss [0.00038581 0.0003037  0.00033702 0.00037682 0.00035849 0.00038766
 0.00036401]
Model epoch 121: train total loss -64.33552698497121, train mean loss 0.0002936258863750652, test mean loss [0.00038364 0.00029395 0.00033474 0.00037566 0.00035741 0.00040275
 0.00036229]
Model epoch 122: train total loss -64.2148020192238, train mean loss 0.00030229356730871517, test mean loss [0.00037156 0.00028639 0.00033982 0.00038276 0.00037576 0.00039434
 0.00035008]
Model epoch 123: train total loss -64.60939322793556, train mean loss 0.0002369156610075776, test mean loss [0.0003672  0.00028441 0.00032408 0.00037222 0.00036091 0.00038653
 0.00034941]
Model epoch 124: train total loss -64.48737259305867, train mean loss 0.0002800183487448182, test mean loss [0.00037431 0.00028304 0.00032514 0.00036142 0.00036047 0.00037964
 0.00034841]
Model epoch 125: train total loss -64.61970605728571, train mean loss 0.00024629428598174803, test mean loss [0.00037952 0.00028768 0.00032225 0.00036134 0.00034918 0.00038125
 0.00034124]
Model epoch 126: train total loss -64.26385680629218, train mean loss 0.00027561644899855845, test mean loss [0.00037371 0.00028265 0.000323   0.00036785 0.00034455 0.00038363
 0.00033569]
Model epoch 127: train total loss -64.37296779861354, train mean loss 0.0002501181608865809, test mean loss [0.00037363 0.00028276 0.00031307 0.00036863 0.00033869 0.00036945
 0.00036448]
Model epoch 128: train total loss -64.44640677822048, train mean loss 0.00028422296104009976, test mean loss [0.00036395 0.00027011 0.00031668 0.00037066 0.0003415  0.00037297
 0.00034169]
Model epoch 129: train total loss -64.55474773367271, train mean loss 0.0002458401286882623, test mean loss [0.00036354 0.00027762 0.00031811 0.00035545 0.00033264 0.00037015
 0.0003271 ]
Model epoch 130: train total loss -64.60304848053816, train mean loss 0.0002328634535801108, test mean loss [0.00035838 0.00028113 0.00031757 0.0003609  0.00033835 0.00036654
 0.00033786]
Model epoch 131: train total loss -64.59117349071026, train mean loss 0.00024910583291427, test mean loss [0.00035898 0.0002694  0.00031729 0.00035598 0.00033139 0.00036966
 0.00032577]
Model epoch 132: train total loss -64.60881207296607, train mean loss 0.00023763392041121952, test mean loss [0.00036206 0.00027238 0.00031455 0.00035169 0.00032716 0.00036293
 0.00038527]
Model epoch 133: train total loss -64.33738119682134, train mean loss 0.000257034356109679, test mean loss [0.00036133 0.00027528 0.00032946 0.00034698 0.00034256 0.00037415
 0.00033952]
Model epoch 134: train total loss -64.59005486466327, train mean loss 0.00024360862963661344, test mean loss [0.00034966 0.00027138 0.00031109 0.00034851 0.00032958 0.00036734
 0.00032781]
Model epoch 135: train total loss -64.56636930170967, train mean loss 0.0002634933792326168, test mean loss [0.00034781 0.00027395 0.00030763 0.00034685 0.00033525 0.00036274
 0.00032784]
Model epoch 136: train total loss -64.57649734045239, train mean loss 0.00022737246327281021, test mean loss [0.00035164 0.00027209 0.00031104 0.00034375 0.00032421 0.00036365
 0.00032688]
Model epoch 137: train total loss -64.63988044826203, train mean loss 0.00023850622016459108, test mean loss [0.00034529 0.00026009 0.00030796 0.0003523  0.00033345 0.00035176
 0.00032298]
Model epoch 138: train total loss -64.5776645711449, train mean loss 0.00023326478435877228, test mean loss [0.00035801 0.00025872 0.00030605 0.00034811 0.00032    0.00035458
 0.00031786]
Model epoch 139: train total loss -64.7371842382843, train mean loss 0.00024043930916444267, test mean loss [0.00034505 0.00025948 0.00030477 0.00034181 0.000315   0.00035592
 0.00031211]
Model epoch 140: train total loss -64.74292695306889, train mean loss 0.0002145239284594657, test mean loss [0.0003438  0.00026021 0.00029969 0.00033778 0.00032776 0.00035215
 0.00031865]
Model epoch 141: train total loss -64.76254995723173, train mean loss 0.00022999546548912097, test mean loss [0.00034402 0.00025255 0.00030434 0.00034404 0.00032231 0.0003435
 0.00031328]
Model epoch 142: train total loss -64.82555811953159, train mean loss 0.00022322333058674988, test mean loss [0.00034414 0.00025962 0.00030002 0.00033589 0.0003082  0.00034034
 0.00031126]
Model epoch 143: train total loss -64.93436426253983, train mean loss 0.0002540028006951945, test mean loss [0.00033406 0.00024406 0.00030272 0.00033692 0.00031627 0.0003385
 0.00031308]
Model epoch 144: train total loss -64.66137511108181, train mean loss 0.00025916780363837165, test mean loss [0.00033697 0.00024547 0.00029428 0.00034818 0.00031135 0.00034347
 0.00031259]
Model epoch 145: train total loss -64.79767717069265, train mean loss 0.0002345476961470853, test mean loss [0.00033728 0.00024562 0.00029696 0.00034148 0.00031645 0.00033113
 0.00030543]
Model epoch 146: train total loss -64.72372589360745, train mean loss 0.0002321996134227457, test mean loss [0.00033045 0.00023642 0.00029476 0.00034035 0.00031003 0.00034069
 0.00030992]
Model epoch 147: train total loss -64.70356546285741, train mean loss 0.00019897815792869526, test mean loss [0.00033951 0.00023433 0.00029308 0.00033044 0.00031619 0.00034829
 0.00030411]
Model epoch 148: train total loss -64.64780926169239, train mean loss 0.00023037730220667565, test mean loss [0.00033626 0.00023539 0.00028913 0.00032909 0.00030372 0.00033256
 0.00029461]
Model epoch 149: train total loss -64.8046687207655, train mean loss 0.000244561666002329, test mean loss [0.00032834 0.00024096 0.00028818 0.00033088 0.00030512 0.00033221
 0.00030231]
Model epoch 150: train total loss -64.69136572390633, train mean loss 0.00020479494907055164, test mean loss [0.00033135 0.00024752 0.000305   0.0003355  0.00030019 0.00032677
 0.00029437]
Model epoch 151: train total loss -64.75101561229907, train mean loss 0.00023346165075923043, test mean loss [0.00032672 0.00024925 0.00029156 0.000325   0.0003089  0.00032229
 0.00029498]
Model epoch 152: train total loss -64.7323979293685, train mean loss 0.00024669813435647777, test mean loss [0.00032289 0.00023987 0.00029081 0.00032705 0.00029931 0.00032225
 0.00028511]
Model epoch 153: train total loss -64.87511884772232, train mean loss 0.0001968931184737442, test mean loss [0.00032958 0.00023547 0.0002895  0.0003265  0.00029609 0.00031882
 0.0002854 ]
Model epoch 154: train total loss -64.84839507711851, train mean loss 0.00021277193230200028, test mean loss [0.00033042 0.00023406 0.00028398 0.00032641 0.00029639 0.00032446
 0.00028182]
Model epoch 155: train total loss -64.85738813377145, train mean loss 0.00019872113784363403, test mean loss [0.0003277  0.00022851 0.0002833  0.00032241 0.00030005 0.00031989
 0.00028822]
Model epoch 156: train total loss -64.61171206151822, train mean loss 0.00023724374832976859, test mean loss [0.00031939 0.00024061 0.00028649 0.00032392 0.00029428 0.00032315
 0.00029528]
Model epoch 157: train total loss -64.68993430307088, train mean loss 0.00020384541309082904, test mean loss [0.00031549 0.00022786 0.00028171 0.00032019 0.00029753 0.00031758
 0.00027866]
Model epoch 158: train total loss -64.75100027796958, train mean loss 0.00022812461855429506, test mean loss [0.00032094 0.00023016 0.00028759 0.00032782 0.00029458 0.00032222
 0.00027604]
Model epoch 159: train total loss -64.75547960687028, train mean loss 0.00020749922280998372, test mean loss [0.00032413 0.00022782 0.00028657 0.00032151 0.00029925 0.00031558
 0.000281  ]
Model epoch 160: train total loss -64.9849592232913, train mean loss 0.0002243358096326355, test mean loss [0.00031418 0.0002256  0.00027867 0.00031532 0.00029406 0.00031491
 0.00028437]
Model epoch 161: train total loss -64.66668645197628, train mean loss 0.00024086455201721317, test mean loss [0.00031552 0.000245   0.00027973 0.00031951 0.00028771 0.00029821
 0.00028501]
Model epoch 162: train total loss -64.77846159376547, train mean loss 0.0002119793865917717, test mean loss [0.00031657 0.0002307  0.00028162 0.00031682 0.00028709 0.00030739
 0.00027522]
Model epoch 163: train total loss -64.98161198278868, train mean loss 0.0002198389460133252, test mean loss [0.00030432 0.00022174 0.0002798  0.00031486 0.00028224 0.00030602
 0.00027022]
Model epoch 164: train total loss -64.87134148583587, train mean loss 0.00024094297517540788, test mean loss [0.00030806 0.00022027 0.00027877 0.00031233 0.00027711 0.00031681
 0.00026614]
Model epoch 165: train total loss -64.90625965110716, train mean loss 0.00022620046538487435, test mean loss [0.00031077 0.00022326 0.00027159 0.00030728 0.00027406 0.00030052
 0.00027137]
Model epoch 166: train total loss -64.94623143396855, train mean loss 0.00020695979364394632, test mean loss [0.00032729 0.00022999 0.00028175 0.00030436 0.00028248 0.00030285
 0.00026536]
Model epoch 167: train total loss -64.89423056438818, train mean loss 0.00018956937192176368, test mean loss [0.00031208 0.00022275 0.00026743 0.0003086  0.00028428 0.00030098
 0.00026941]
Model epoch 168: train total loss -65.03364252924128, train mean loss 0.00019408974964482266, test mean loss [0.00032053 0.0002157  0.00026685 0.00030114 0.00027358 0.00030799
 0.00026263]
Model epoch 169: train total loss -65.04979256168173, train mean loss 0.00020624208448134475, test mean loss [0.00030255 0.00021363 0.00027149 0.00031132 0.00026874 0.0002984
 0.00026096]
Model epoch 170: train total loss -64.93863493637451, train mean loss 0.00022491918964227483, test mean loss [0.00029503 0.00021486 0.00028865 0.00029897 0.00027061 0.00030186
 0.00026432]
Model epoch 171: train total loss -64.7655413481707, train mean loss 0.0002133914456356359, test mean loss [0.00030465 0.0002228  0.0002728  0.00029314 0.0002681  0.00029734
 0.00026562]
Model epoch 172: train total loss -65.03967258171836, train mean loss 0.000218816303408256, test mean loss [0.00029867 0.00022724 0.00025941 0.00029587 0.00026495 0.00029405
 0.0002606 ]
Model epoch 173: train total loss -64.98714105624555, train mean loss 0.00022353659145697493, test mean loss [0.0002954  0.00021679 0.00026776 0.00029956 0.00027255 0.00029808
 0.00025578]
Model epoch 174: train total loss -65.03971170249089, train mean loss 0.0001856009019070387, test mean loss [0.00030615 0.00020759 0.00026752 0.00029686 0.00026915 0.00028812
 0.00025831]
Model epoch 175: train total loss -64.88034766093013, train mean loss 0.00019400490378852008, test mean loss [0.00030161 0.00021135 0.00025883 0.00029325 0.00027494 0.00029203
 0.0002574 ]
Model epoch 176: train total loss -65.02944372746926, train mean loss 0.00022072504546128717, test mean loss [0.00030367 0.00020999 0.00026168 0.00029469 0.00026704 0.00029285
 0.00026143]
Model epoch 177: train total loss -65.06995662019158, train mean loss 0.00018069784995310189, test mean loss [0.00029747 0.00020645 0.00025885 0.00029746 0.00026179 0.00029911
 0.00025597]
Model epoch 178: train total loss -65.0840633501062, train mean loss 0.00018056480327976242, test mean loss [0.0002946  0.00021136 0.00026728 0.00029798 0.0002745  0.00028883
 0.00025208]
Model epoch 179: train total loss -65.01016941801899, train mean loss 0.00017341839106645572, test mean loss [0.00029427 0.00020879 0.0002615  0.0003018  0.00026827 0.00029212
 0.0002553 ]
Model epoch 180: train total loss -64.89096309410033, train mean loss 0.00023660725148032165, test mean loss [0.00029528 0.00021037 0.00025964 0.00029153 0.00025803 0.00028581
 0.00024974]
Model epoch 181: train total loss -65.1448901328955, train mean loss 0.00021957204470991358, test mean loss [0.00028699 0.00020745 0.00025811 0.00028653 0.00026255 0.00027466
 0.00025265]
Model epoch 182: train total loss -64.91064628563231, train mean loss 0.000184564552115382, test mean loss [0.00029157 0.00020375 0.00026467 0.00029466 0.00025995 0.00027808
 0.00024493]
Model epoch 183: train total loss -65.11669155684204, train mean loss 0.00018230889050281618, test mean loss [0.00028483 0.00020678 0.00025408 0.00028277 0.00025708 0.00028405
 0.00024475]
Model epoch 184: train total loss -64.96921159725503, train mean loss 0.0002304494765520386, test mean loss [0.00029228 0.00022071 0.00025675 0.00028771 0.00025925 0.00027273
 0.00024566]
Model epoch 185: train total loss -65.00842038141806, train mean loss 0.00019491243123775952, test mean loss [0.00028492 0.00021005 0.00025124 0.00028298 0.00025671 0.00027166
 0.00025169]
Model epoch 186: train total loss -65.05308553197867, train mean loss 0.00017315710751383183, test mean loss [0.00028747 0.00020663 0.00025835 0.00028134 0.00025508 0.00027905
 0.00023667]
Model epoch 187: train total loss -64.9952385707633, train mean loss 0.00020107649756557816, test mean loss [0.00030566 0.0002003  0.00026302 0.00028858 0.00025935 0.00027938
 0.00024417]
Model epoch 188: train total loss -65.17172054953514, train mean loss 0.00016919532543452448, test mean loss [0.00029087 0.00020301 0.00025771 0.00028297 0.00025352 0.00027819
 0.00024001]
Model epoch 189: train total loss -65.11632187721081, train mean loss 0.00020262796240907112, test mean loss [0.00029307 0.00020508 0.00024867 0.00028478 0.00025199 0.00027304
 0.00023811]
Model epoch 190: train total loss -65.09359622036982, train mean loss 0.00019498593236846683, test mean loss [0.00027917 0.00019803 0.00025105 0.00028144 0.00025086 0.00027178
 0.00023992]
Model epoch 191: train total loss -65.11965230390805, train mean loss 0.00018552720212964687, test mean loss [0.0002862  0.00020478 0.00024643 0.00028882 0.00025661 0.00026602
 0.00024422]
Model epoch 192: train total loss -65.07066226138942, train mean loss 0.00018979452448641694, test mean loss [0.00027766 0.00019981 0.00024749 0.00030927 0.00024475 0.0002702
 0.00024493]
Model epoch 193: train total loss -64.97917145920724, train mean loss 0.00020572711773536982, test mean loss [0.00028241 0.00019617 0.00024874 0.00031938 0.00024449 0.00027101
 0.00023888]
Model epoch 194: train total loss -65.23658294869715, train mean loss 0.00018017650278861398, test mean loss [0.00027774 0.00019287 0.00024776 0.00028262 0.00024915 0.00026608
 0.00023573]
Model epoch 195: train total loss -65.01894368675474, train mean loss 0.000198126299723148, test mean loss [0.00027589 0.00019663 0.00024677 0.00029679 0.00024608 0.00026718
 0.00022995]
Model epoch 196: train total loss -65.04445058623905, train mean loss 0.00017133913847772991, test mean loss [0.00029285 0.00019495 0.00024741 0.00027965 0.00024606 0.00026976
 0.00023287]
Model epoch 197: train total loss -65.05404957461809, train mean loss 0.0001857292549485113, test mean loss [0.00027587 0.00019294 0.00025031 0.00032978 0.0002485  0.00026426
 0.0002292 ]
Model epoch 198: train total loss -65.22476591239251, train mean loss 0.00017879111591470278, test mean loss [0.00027996 0.00019846 0.00024653 0.00027948 0.00024522 0.00026001
 0.00022929]
Model epoch 199: train total loss -65.12852688957592, train mean loss 0.00016345485298498413, test mean loss [0.0002789  0.00019553 0.00025013 0.00028941 0.00023951 0.00026214
 0.00022832]
Model epoch 200: train total loss -65.21367951748289, train mean loss 0.00016585859192223777, test mean loss [0.00027226 0.00019478 0.00024116 0.00027622 0.00024453 0.00026246
 0.00022863]
Model epoch 201: train total loss -65.18336121533643, train mean loss 0.00018693749129314766, test mean loss [0.00026337 0.0001924  0.00024066 0.00027542 0.00023997 0.00025736
 0.00022384]
Model epoch 202: train total loss -65.09933340280243, train mean loss 0.00017125774840983204, test mean loss [0.00026829 0.0001885  0.000238   0.00027443 0.00025133 0.00025385
 0.00022926]
Model epoch 203: train total loss -65.22852030768776, train mean loss 0.00017619089653369565, test mean loss [0.00026428 0.00019052 0.00023968 0.00027529 0.00023669 0.00025663
 0.00022225]
Model epoch 204: train total loss -64.98887476926377, train mean loss 0.00018773999590338013, test mean loss [0.00026694 0.00019078 0.00024598 0.00028803 0.00023654 0.00026437
 0.00023604]
Model epoch 205: train total loss -65.17330689590182, train mean loss 0.00017624956932832668, test mean loss [0.00027119 0.0001941  0.00023776 0.00027284 0.00024227 0.00025217
 0.00022127]
Model epoch 206: train total loss -65.21706584440066, train mean loss 0.00020548034883876554, test mean loss [0.00027017 0.00018886 0.0002355  0.00026456 0.00023388 0.00025482
 0.00022573]
Model epoch 207: train total loss -65.31677987958847, train mean loss 0.00018466683342387128, test mean loss [0.00026651 0.00018966 0.0002338  0.00026309 0.00023447 0.00025061
 0.00021983]
Model epoch 208: train total loss -65.25746098555202, train mean loss 0.0001797027153872334, test mean loss [0.00027231 0.0001906  0.000229   0.00025946 0.00022981 0.00024809
 0.00022332]
Model epoch 209: train total loss -65.41981872863052, train mean loss 0.0001688413553167726, test mean loss [0.00025899 0.00019441 0.00022864 0.00026711 0.00023299 0.00024862
 0.00021907]
Model epoch 210: train total loss -65.04984267300973, train mean loss 0.0001827896548574031, test mean loss [0.00026077 0.00019135 0.00024484 0.00025834 0.0002352  0.00025579
 0.00021732]
Model epoch 211: train total loss -65.14813318622149, train mean loss 0.00017339851642499672, test mean loss [0.0002583  0.00018776 0.00023377 0.0002622  0.00023298 0.00024965
 0.00022222]
Model epoch 212: train total loss -65.27579326580175, train mean loss 0.00016670450092477198, test mean loss [0.00027363 0.00018311 0.00024054 0.00026004 0.00023488 0.00024666
 0.00021405]
Model epoch 213: train total loss -65.39322952549979, train mean loss 0.0001859779350228485, test mean loss [0.00026166 0.00017703 0.00023394 0.00025678 0.00022881 0.00025697
 0.00021875]
Model epoch 214: train total loss -65.34303723345343, train mean loss 0.00018245015231692493, test mean loss [0.00026099 0.00018716 0.00022618 0.0002588  0.00022849 0.00024716
 0.00021247]
Model epoch 215: train total loss -65.3934206718033, train mean loss 0.0001794248266361464, test mean loss [0.00025729 0.00018238 0.00023233 0.00026235 0.00022321 0.00024255
 0.00020877]
Model epoch 216: train total loss -65.442236132485, train mean loss 0.0001573384767224389, test mean loss [0.00026444 0.00019209 0.0002391  0.0002591  0.00022189 0.00025799
 0.00020991]
Model epoch 217: train total loss -65.47983573678357, train mean loss 0.00015204868423249388, test mean loss [0.00025717 0.00018903 0.00022958 0.00025439 0.00023173 0.00024415
 0.00021241]
Model epoch 218: train total loss -65.38447887128811, train mean loss 0.00016863572992848204, test mean loss [0.00024987 0.00017993 0.00022643 0.00026047 0.00022678 0.00024079
 0.00021647]
Model epoch 219: train total loss -65.25506984447968, train mean loss 0.0001718122092154767, test mean loss [0.00025076 0.00017879 0.00022552 0.00025385 0.00022649 0.0002427
 0.00021507]
Model epoch 220: train total loss -65.25496182116022, train mean loss 0.00016858237444053895, test mean loss [0.00026084 0.00017661 0.00022441 0.00026377 0.00023158 0.00024356
 0.00020481]
Model epoch 221: train total loss -65.29104387891446, train mean loss 0.00017207703515497236, test mean loss [0.00026131 0.00017832 0.00023153 0.00024853 0.00022504 0.00023749
 0.00021202]
Model epoch 222: train total loss -65.34892945361645, train mean loss 0.00017143144006217408, test mean loss [0.00025184 0.00017983 0.00022284 0.00025065 0.00022474 0.00024717
 0.00021278]
Model epoch 223: train total loss -65.26225140169562, train mean loss 0.00017498128139369106, test mean loss [0.00025145 0.00017632 0.00022844 0.00024976 0.0002229  0.00023629
 0.00020976]
Model epoch 224: train total loss -65.35735918328149, train mean loss 0.0001702572205734436, test mean loss [0.0002492  0.00018254 0.00022266 0.00025403 0.00022152 0.000255
 0.00019892]
Model epoch 225: train total loss -65.31850826052401, train mean loss 0.0001704633995141279, test mean loss [0.00025279 0.00018304 0.00022597 0.00024958 0.00021876 0.00024529
 0.00020952]
Model epoch 226: train total loss -65.20970006119782, train mean loss 0.00015371527046145587, test mean loss [0.00025529 0.00017577 0.00022965 0.00024624 0.00023612 0.00023844
 0.00020646]
Model epoch 227: train total loss -65.27043731548842, train mean loss 0.00015333995871123958, test mean loss [0.00024825 0.00017582 0.00022006 0.000247   0.00022292 0.00023945
 0.00019373]
Model epoch 228: train total loss -65.34312364662055, train mean loss 0.0001607258616032681, test mean loss [0.0002425  0.0001816  0.0002282  0.00024613 0.00021563 0.0002367
 0.00020071]
Model epoch 229: train total loss -65.43692839236999, train mean loss 0.00015405084517527897, test mean loss [0.00023884 0.00017839 0.00021785 0.00024646 0.00022343 0.00024026
 0.00019806]
Model epoch 230: train total loss -65.42415956013922, train mean loss 0.00015974176632828967, test mean loss [0.00025272 0.00018185 0.00021853 0.00024603 0.00021788 0.00023228
 0.00019976]
Model epoch 231: train total loss -65.38648107926753, train mean loss 0.00016687046619393283, test mean loss [0.00024557 0.00018928 0.00022923 0.00025688 0.00021937 0.00023006
 0.00020367]
Model epoch 232: train total loss -65.40541183845752, train mean loss 0.0001676122744884232, test mean loss [0.00024236 0.00017326 0.00021772 0.00024303 0.00021693 0.00023367
 0.00020818]
Model epoch 233: train total loss -65.13526494511828, train mean loss 0.00016700054604873771, test mean loss [0.00025482 0.00016845 0.00021802 0.00024903 0.00021667 0.00024541
 0.00020957]
Model epoch 234: train total loss -65.30481279013338, train mean loss 0.000150519805445234, test mean loss [0.00024422 0.00018306 0.00021526 0.00024896 0.00021385 0.00023107
 0.00019787]
Model epoch 235: train total loss -65.46397959930704, train mean loss 0.0001503868745415985, test mean loss [0.00024096 0.00017499 0.00021667 0.0002469  0.0002133  0.00023204
 0.00019385]
Model epoch 236: train total loss -65.20436582029771, train mean loss 0.00014729560592252838, test mean loss [0.00023416 0.000173   0.00021787 0.00023776 0.00021455 0.0002483
 0.00020482]
Model epoch 237: train total loss -65.38694178009719, train mean loss 0.0001592886833114902, test mean loss [0.00024091 0.00017428 0.0002071  0.00023755 0.00021271 0.00022624
 0.00020277]
Model epoch 238: train total loss -65.48838742052777, train mean loss 0.00017179558573127122, test mean loss [0.00024233 0.00017349 0.00021052 0.00024217 0.00021415 0.00023259
 0.00019225]
Model epoch 239: train total loss -65.31453683953897, train mean loss 0.00016238818984016945, test mean loss [0.00023541 0.00017077 0.0002119  0.00024657 0.00020746 0.00023879
 0.00020042]
Model epoch 240: train total loss -65.3115942435658, train mean loss 0.0001669659694859896, test mean loss [0.00023644 0.00017579 0.00021957 0.00023328 0.000207   0.0002428
 0.00019487]
Model epoch 241: train total loss -65.26336230745312, train mean loss 0.00013691302755205334, test mean loss [0.00023741 0.00016664 0.00021358 0.00023585 0.00021283 0.0002373
 0.00020031]
Model epoch 242: train total loss -65.36814793387238, train mean loss 0.00015691472251671009, test mean loss [0.00024562 0.00017715 0.00020901 0.00023434 0.0002078  0.00021956
 0.00019778]
Model epoch 243: train total loss -65.37136394213381, train mean loss 0.0001674900870891425, test mean loss [0.0002358  0.00018466 0.0002056  0.00024104 0.0002103  0.00022503
 0.000192  ]
Model epoch 244: train total loss -65.39918294538295, train mean loss 0.00016189258682361302, test mean loss [0.00024168 0.00017032 0.00020989 0.0002354  0.00021035 0.00022993
 0.00019066]
Model epoch 245: train total loss -65.52670536020935, train mean loss 0.00015433761003767003, test mean loss [0.00023679 0.00017259 0.00020166 0.00023674 0.00020523 0.00022354
 0.000187  ]
Model epoch 246: train total loss -65.63726098343248, train mean loss 0.00016765562163109546, test mean loss [0.00023142 0.00018357 0.00020012 0.00022693 0.00020796 0.00022713
 0.00019163]
Model epoch 247: train total loss -65.43204432741287, train mean loss 0.0001560271804854627, test mean loss [0.00023545 0.00016943 0.00020371 0.00023639 0.00020785 0.0002412
 0.00019622]
Model epoch 248: train total loss -65.37296518607224, train mean loss 0.00015202513993717464, test mean loss [0.00023414 0.00017458 0.00021174 0.00022854 0.0002158  0.00022101
 0.0001932 ]
Model epoch 249: train total loss -65.41382297081944, train mean loss 0.00016820690243921942, test mean loss [0.00022942 0.00017446 0.00020243 0.00022714 0.00020974 0.00021365
 0.00019371]
Model epoch 250: train total loss -65.50119474052657, train mean loss 0.00015538924698027526, test mean loss [0.00022347 0.00017412 0.00020436 0.00023157 0.00021112 0.00021941
 0.0001954 ]
Model epoch 251: train total loss -65.67392699829908, train mean loss 0.00013627998379805938, test mean loss [0.00022799 0.00016943 0.00020699 0.00022533 0.00020002 0.00021743
 0.00018541]
Model epoch 252: train total loss -65.66797071647457, train mean loss 0.00016074868051092292, test mean loss [0.00022416 0.00017115 0.00020007 0.00023131 0.00020786 0.00021664
 0.00017886]
Model epoch 253: train total loss -65.4360157580435, train mean loss 0.00015386642931918522, test mean loss [0.00022708 0.00016392 0.00020799 0.00022761 0.00019509 0.00021611
 0.00019528]
Model epoch 254: train total loss -65.38945022726729, train mean loss 0.00016218887385776806, test mean loss [0.00022453 0.00016811 0.00020157 0.0002282  0.00019792 0.00021163
 0.00019071]
Model epoch 255: train total loss -65.49013462011537, train mean loss 0.00015011605683821835, test mean loss [0.00022834 0.00016601 0.00020503 0.00023282 0.00020098 0.00021258
 0.00018676]
Model epoch 256: train total loss -65.40194382428658, train mean loss 0.0001555985511033628, test mean loss [0.00022211 0.00016821 0.00019848 0.00022224 0.00019508 0.00021299
 0.0001826 ]
Model epoch 257: train total loss -65.68815212202037, train mean loss 0.00014678803496655148, test mean loss [0.00021903 0.00016559 0.00020361 0.00022823 0.00019724 0.00020778
 0.00019042]
Model epoch 258: train total loss -65.60730685752706, train mean loss 0.00014530197512902318, test mean loss [0.00021762 0.00015982 0.00019643 0.00023556 0.00020894 0.00021258
 0.00018426]
Model epoch 259: train total loss -65.56687352885132, train mean loss 0.00013953733714330168, test mean loss [0.00022021 0.00016346 0.00019891 0.00022143 0.00020152 0.00021578
 0.00017735]
Model epoch 260: train total loss -65.65367716346873, train mean loss 0.00014247853866825017, test mean loss [0.00021852 0.00016368 0.00019786 0.00021998 0.00020155 0.0002101
 0.00018399]
Model epoch 261: train total loss -65.5542271660134, train mean loss 0.0001508730963594208, test mean loss [0.00022495 0.00015972 0.00019866 0.00022356 0.00020731 0.00020426
 0.00018593]
Model epoch 262: train total loss -65.49875507293686, train mean loss 0.00016292537349372948, test mean loss [0.00022809 0.00015919 0.00020116 0.00023351 0.00019469 0.0002127
 0.00018022]
Model epoch 263: train total loss -65.63020621729379, train mean loss 0.0001457999316801194, test mean loss [0.00021661 0.00016241 0.00020123 0.00022182 0.00020035 0.00021679
 0.0001777 ]
Model epoch 264: train total loss -65.54831141409878, train mean loss 0.00015249891386142546, test mean loss [0.00022866 0.00016218 0.00019659 0.00021941 0.0002004  0.00021018
 0.00017182]
Model epoch 265: train total loss -65.61149672786811, train mean loss 0.00014191777052124113, test mean loss [0.00022141 0.00016145 0.00019317 0.00022781 0.00019465 0.00020697
 0.00017227]
Model epoch 266: train total loss -65.68561460137704, train mean loss 0.00014641701416230884, test mean loss [0.00021912 0.00016263 0.0001941  0.00022185 0.00020034 0.00020489
 0.00017958]
Model epoch 267: train total loss -65.47662319110012, train mean loss 0.00016696052605290988, test mean loss [0.00021967 0.00016479 0.00019723 0.00022325 0.00020286 0.00020578
 0.00018118]
Model epoch 268: train total loss -65.31706446495437, train mean loss 0.0001572446855836431, test mean loss [0.00022319 0.00015594 0.00020493 0.00021624 0.00020426 0.00020747
 0.0001762 ]
Model epoch 269: train total loss -65.50937737765136, train mean loss 0.0001404319689651336, test mean loss [0.00021261 0.00015253 0.00020024 0.00022291 0.00020121 0.00021076
 0.00017392]
Model epoch 270: train total loss -65.49134402366496, train mean loss 0.00015865617305010996, test mean loss [0.00022313 0.00016578 0.00020046 0.00021473 0.00019098 0.00019874
 0.00017322]
Model epoch 271: train total loss -65.46527165029096, train mean loss 0.00016413790039526675, test mean loss [0.0002259  0.00016421 0.00019707 0.00022694 0.00018699 0.00020342
 0.00018805]
Model epoch 272: train total loss -65.74412552903067, train mean loss 0.0001489160280057143, test mean loss [0.00021322 0.00015266 0.00019277 0.00021861 0.00018586 0.00021182
 0.00017254]
Model epoch 273: train total loss -65.71378913937338, train mean loss 0.0001512602526160631, test mean loss [0.0002076  0.00015788 0.00019355 0.00021428 0.00019336 0.00019913
 0.00017257]
Model epoch 274: train total loss -65.78626286634547, train mean loss 0.00014162566800378484, test mean loss [0.00021226 0.0001554  0.0001922  0.00021184 0.00018996 0.00020785
 0.00018156]
Model epoch 275: train total loss -65.6852631178942, train mean loss 0.00013985673323029828, test mean loss [0.00020799 0.00015904 0.00020076 0.00022157 0.0001889  0.00020065
 0.00017304]
Model epoch 276: train total loss -65.70900424279162, train mean loss 0.0001468510156814837, test mean loss [0.00021401 0.00016492 0.00019182 0.0002194  0.00019293 0.00020189
 0.00017173]
Model epoch 277: train total loss -65.63768418921481, train mean loss 0.00013956831947778655, test mean loss [0.00021627 0.00015803 0.00019067 0.00022631 0.00019371 0.00019855
 0.00017693]
Model epoch 278: train total loss -65.58213735721573, train mean loss 0.00014825688086639945, test mean loss [0.00020654 0.00016329 0.00019001 0.00020871 0.00019552 0.00020114
 0.00017051]
Model epoch 279: train total loss -65.64707963371677, train mean loss 0.00014256673189401168, test mean loss [0.0002062  0.00016704 0.00018561 0.00020769 0.00019244 0.00019832
 0.00016205]
Model epoch 280: train total loss -65.66060050750977, train mean loss 0.00012715830515388615, test mean loss [0.0002012  0.00016654 0.00019209 0.00021461 0.00019021 0.00019868
 0.00016554]
Model epoch 281: train total loss -65.89246052204155, train mean loss 0.00014085854270185616, test mean loss [0.00021324 0.00016255 0.0001902  0.00021285 0.00018889 0.00019501
 0.00016529]
Model epoch 282: train total loss -65.65407365273337, train mean loss 0.00015351392631338668, test mean loss [0.00020577 0.00015232 0.00018718 0.00021805 0.00018902 0.00020476
 0.00017291]
Model epoch 283: train total loss -65.64865478307732, train mean loss 0.00014276121425057113, test mean loss [0.00020232 0.00015766 0.000191   0.00020714 0.00019803 0.00020148
 0.00017112]
Model epoch 284: train total loss -65.64994491338042, train mean loss 0.00014541547263664326, test mean loss [0.00020831 0.00015394 0.00018829 0.00023431 0.00019687 0.00019916
 0.00016494]
Model epoch 285: train total loss -65.56645277714908, train mean loss 0.0001356202253144619, test mean loss [0.00021779 0.00015364 0.00018528 0.0002107  0.00019034 0.00020111
 0.00017401]
Model epoch 286: train total loss -65.58315938152067, train mean loss 0.0001500291237082187, test mean loss [0.00022344 0.00015454 0.0001914  0.00020448 0.00018881 0.00019639
 0.00016865]
Model epoch 287: train total loss -65.57342285862762, train mean loss 0.00015111537274752242, test mean loss [0.00020234 0.00015829 0.00018579 0.00022137 0.00018658 0.00019503
 0.00017721]
Model epoch 288: train total loss -65.62205351765272, train mean loss 0.00014794137436617604, test mean loss [0.00020851 0.0001583  0.00019426 0.00020871 0.00018486 0.0001925
 0.00016901]
Model epoch 289: train total loss -65.54456236848324, train mean loss 0.0001413485758646957, test mean loss [0.00020719 0.00015598 0.00018535 0.00020227 0.00018417 0.00020034
 0.00017202]
Model epoch 290: train total loss -65.65291638936756, train mean loss 0.00013987226196415597, test mean loss [0.00020135 0.00015299 0.00017895 0.00021016 0.00018263 0.00020512
 0.00016376]
Model epoch 291: train total loss -65.70324828437634, train mean loss 0.00013652922888042487, test mean loss [0.00020273 0.00015055 0.00019966 0.0002016  0.00018723 0.00019336
 0.00016541]
Model epoch 292: train total loss -65.1323062489302, train mean loss 0.00015618773239375533, test mean loss [0.00019953 0.00014731 0.00018576 0.00020792 0.000185   0.0002212
 0.00016771]
Model epoch 293: train total loss -65.56132833429591, train mean loss 0.0001388921633091167, test mean loss [0.0001979  0.00015094 0.00018699 0.00020943 0.00018461 0.000226
 0.00018361]
Model epoch 294: train total loss -65.50382561747757, train mean loss 0.00014289905880166136, test mean loss [0.00019826 0.00014836 0.00017946 0.00020697 0.00018714 0.00019595
 0.00016454]
Model epoch 295: train total loss -65.42834291629494, train mean loss 0.00014021623898910102, test mean loss [0.00020086 0.00014502 0.00018161 0.00019741 0.00017762 0.00019365
 0.00017476]
Model epoch 296: train total loss -65.79530490704087, train mean loss 0.000140324757102549, test mean loss [0.00020094 0.00014698 0.00018441 0.00020037 0.00018081 0.00018805
 0.00017213]
Model epoch 297: train total loss -65.80689961030178, train mean loss 0.00013345674157738143, test mean loss [0.00020189 0.00015345 0.00017866 0.000203   0.00018542 0.000194
 0.00016801]
Model epoch 298: train total loss -65.55797963965645, train mean loss 0.00013280072780684737, test mean loss [0.00019169 0.00015089 0.00018154 0.00019544 0.00018671 0.00019305
 0.00017312]
Model epoch 299: train total loss -65.71288946330615, train mean loss 0.00012388930652486166, test mean loss [0.00019625 0.00014797 0.00018044 0.00020067 0.00018073 0.00019309
 0.00016638]
Model epoch 300: train total loss -65.79463387637217, train mean loss 0.00012922569728750265, test mean loss [0.00019518 0.00015978 0.00018211 0.00019878 0.00017743 0.00018802
 0.00016694]
Model epoch 301: train total loss -65.71050280431241, train mean loss 0.0001422025605543447, test mean loss [0.00019758 0.00016211 0.00018617 0.00020298 0.00017859 0.0001972
 0.00016335]
Model epoch 302: train total loss -65.67387914541459, train mean loss 0.00014927277928806465, test mean loss [0.00020373 0.00015611 0.00017765 0.00020358 0.00017588 0.00018277
 0.00016621]
Model epoch 303: train total loss -65.92389911350439, train mean loss 0.0001268709508315097, test mean loss [0.000206   0.00014462 0.00018415 0.00019747 0.00017622 0.00018394
 0.00016705]
Model epoch 304: train total loss -65.82358197828584, train mean loss 0.00013091278040754011, test mean loss [0.0001985  0.00014871 0.00018446 0.00019927 0.00017722 0.00018888
 0.00015911]
Model epoch 305: train total loss -65.90523730360007, train mean loss 0.0001181144531606459, test mean loss [0.00020061 0.00015118 0.00017728 0.00019861 0.00018038 0.00018468
 0.00016215]
Model epoch 306: train total loss -65.86229643391322, train mean loss 0.00012960811596080473, test mean loss [0.00019186 0.00014628 0.0001729  0.00019429 0.00017075 0.00018044
 0.00017404]
Model epoch 307: train total loss -65.82419659411151, train mean loss 0.00014358973184044202, test mean loss [0.00019185 0.00014658 0.00017694 0.00019588 0.00017294 0.00017883
 0.00016244]
Model epoch 308: train total loss -65.55716426961656, train mean loss 0.00013498252979793034, test mean loss [0.00019512 0.00014271 0.00018119 0.00019652 0.00017378 0.00020317
 0.00016441]
Model epoch 309: train total loss -65.76678363453294, train mean loss 0.00012522661706005785, test mean loss [0.0001945  0.00014614 0.0001835  0.00019064 0.00017186 0.00019281
 0.00016329]
Model epoch 310: train total loss -65.83992091344223, train mean loss 0.00013626631825455678, test mean loss [0.00019337 0.00014275 0.00017654 0.00020275 0.00016929 0.00018716
 0.00015539]
Model epoch 311: train total loss -65.32482651274931, train mean loss 0.00015180010416913632, test mean loss [0.00020578 0.00015776 0.00017841 0.00020471 0.00018037 0.00023833
 0.0001564 ]
Model epoch 312: train total loss -65.63938649649936, train mean loss 0.0001344738541875256, test mean loss [0.00019674 0.00014384 0.00017421 0.00020087 0.00017426 0.000208
 0.00016143]
Model epoch 313: train total loss -65.53367312441246, train mean loss 0.00013202997289327772, test mean loss [0.00021483 0.00014462 0.00017683 0.00019641 0.00017149 0.00019649
 0.00016988]
Model epoch 314: train total loss -65.7355786981654, train mean loss 0.00013848055475624023, test mean loss [0.0002086  0.00014638 0.00017342 0.00019429 0.00017363 0.00018542
 0.00015829]
Model epoch 315: train total loss -65.58402648084352, train mean loss 0.00012818716417673808, test mean loss [0.00019649 0.00014635 0.00017567 0.00019804 0.00017427 0.00018547
 0.00016278]
Model epoch 316: train total loss -65.72790408218486, train mean loss 0.00012492760859304832, test mean loss [0.00019674 0.0001459  0.00017854 0.00019514 0.00017377 0.00017688
 0.00016021]
Model epoch 317: train total loss -65.68643681864312, train mean loss 0.00013969382591339896, test mean loss [0.00019968 0.00014583 0.00017357 0.00019332 0.0001749  0.00018388
 0.00016143]
Model epoch 318: train total loss -65.88708043627253, train mean loss 0.0001245152072506398, test mean loss [0.00018291 0.00014661 0.00017568 0.0002029  0.0001755  0.00018974
 0.0001509 ]
Model epoch 319: train total loss -65.67653347400683, train mean loss 0.00012931077672552365, test mean loss [0.00020949 0.00014425 0.00017399 0.00019711 0.00017171 0.00017731
 0.00016196]
Model epoch 320: train total loss -65.8022555600579, train mean loss 0.0001264875424704328, test mean loss [0.00018737 0.00014834 0.00017542 0.00018424 0.0001669  0.00017865
 0.00016022]
Model epoch 321: train total loss -65.75073661568672, train mean loss 0.00013111863594740368, test mean loss [0.00019002 0.00014593 0.00017466 0.00018959 0.00017228 0.0001758
 0.0001561 ]
Model epoch 322: train total loss -65.83218265137735, train mean loss 0.0001315492892227459, test mean loss [0.0001889  0.00014525 0.00017454 0.00019482 0.00016662 0.00017691
 0.00015854]
Model epoch 323: train total loss -65.89481311353485, train mean loss 0.0001324390615334687, test mean loss [0.00019333 0.00014361 0.00017817 0.00019209 0.00017041 0.00017518
 0.00015777]
Model epoch 324: train total loss -65.83760547238415, train mean loss 0.00012309728262453976, test mean loss [0.00019207 0.00014308 0.00018277 0.00018997 0.00017016 0.00017724
 0.00016036]
Model epoch 325: train total loss -65.83211997429962, train mean loss 0.00012603643553171242, test mean loss [0.00018376 0.00014213 0.00017931 0.00019173 0.00016769 0.00018051
 0.00016817]
Model epoch 326: train total loss -65.92744381741457, train mean loss 0.00012894081617908877, test mean loss [0.00018448 0.00014781 0.00017727 0.00018888 0.00016648 0.00017538
 0.00015845]
Model trained in 327 epochs with 3000 transitions.
[2025-01-23 13:31:54,080][absl][INFO] - {'eval/walltime': 135.0803451538086, 'training/sps': 0.46758004878968357, 'training/walltime': 3946.0539104938507, 'training/model_train_time': 1415.093513250351, 'training/other_time': 722.7344200611115, 'training/model_horizon': 4, 'training/hallucination_updates_per_training_step': 505, 'training/env_buffer_size': Array(4000, dtype=int32), 'model/train_total_loss': Array(-65.92744382, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00012894, dtype=float64), 'model/test_total_loss': Array(-65.28536181, dtype=float64), 'model/test_mean_loss': Array(0.00017125, dtype=float64), 'model/train_epochs': 327, 'model/sec_per_epoch': 4.321188173527382, 'sac/actor_loss': Array(-11.93850655, dtype=float64), 'sac/alpha': Array(0.03792017, dtype=float32), 'sac/alpha_loss': Array(0.00090423, dtype=float64), 'sac/buffer_current_size': Array(377045.56, dtype=float32), 'sac/critic_loss': Array(0.01654607, dtype=float64), 'eval/episode_forward_vel': Array(-2.58590818, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-7.25834007, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(6.33464039, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.00070434, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-1.11221857, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(6.05088132, dtype=float64), 'eval/episode_rew_roll': Array(4.95070762, dtype=float64), 'eval/episode_rew_side_motion': Array(3.51642542, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(4.43767404, dtype=float64), 'eval/episode_rew_yaw': Array(10.64760033, dtype=float64), 'eval/episode_rew_z_vel_change': Array(3.29390823, dtype=float64), 'eval/episode_reward': Array(29.86671838, dtype=float64), 'eval/episode_step_count': Array(9180., dtype=float64), 'eval/avg_episode_length': Array(136., dtype=float64), 'eval/epoch_eval_time': 30.49584698677063, 'eval/sps': 32.79135025939135}
Steps / Eval:  4000.0
Reward is  29.8667183789277
Model horizon updated to 6.
Hallucination updates per training step updated to 752.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -32.85507188577179, train mean loss 0.021782803021225924, test mean loss [0.02031836 0.02853249 0.01704871 0.01638305 0.01844657 0.03438353
 0.02192815]
Model epoch 1: train total loss -38.35086159130989, train mean loss 0.017722417325961484, test mean loss [0.01734551 0.01776885 0.01455632 0.01459302 0.01464914 0.02202546
 0.01682759]
Model epoch 2: train total loss -42.776795675004, train mean loss 0.013221483632744974, test mean loss [0.01541404 0.01154397 0.0126377  0.01373208 0.01246229 0.0155333
 0.01392824]
Model epoch 3: train total loss -45.84072837310925, train mean loss 0.011594030976282865, test mean loss [0.01420542 0.01023749 0.01064455 0.01270561 0.01086269 0.01309375
 0.01296305]
Model epoch 4: train total loss -48.781851347368246, train mean loss 0.00995951543620977, test mean loss [0.01244718 0.00837215 0.0089759  0.01042842 0.00971717 0.01191174
 0.01223205]
Model epoch 5: train total loss -50.8375170325182, train mean loss 0.008976644192549683, test mean loss [0.01094248 0.00802844 0.00767685 0.00827466 0.00905738 0.01073076
 0.01094803]
Model epoch 6: train total loss -52.86473384097932, train mean loss 0.008005175784906131, test mean loss [0.00953536 0.0072779  0.00652579 0.00657722 0.00819928 0.00990485
 0.01011591]
Model epoch 7: train total loss -54.44091036124868, train mean loss 0.007097292553212165, test mean loss [0.00798304 0.00643604 0.00566134 0.00512267 0.00709145 0.00877835
 0.00867157]
Model epoch 8: train total loss -55.975793344208284, train mean loss 0.005479219522973345, test mean loss [0.00650109 0.00555173 0.00476193 0.00413328 0.00592895 0.00747211
 0.00770018]
Model epoch 9: train total loss -56.882396835217904, train mean loss 0.004865931648108588, test mean loss [0.00535539 0.00466707 0.00389734 0.00334513 0.00495105 0.00606152
 0.00685352]
Model epoch 10: train total loss -57.94260504518801, train mean loss 0.0040546690369333335, test mean loss [0.00434327 0.00382579 0.00319124 0.00273887 0.00412514 0.00521671
 0.00565428]
Model epoch 11: train total loss -58.572600940139075, train mean loss 0.003159892443819235, test mean loss [0.00357115 0.00318938 0.00256158 0.0022826  0.00352442 0.00440358
 0.00442307]
Model epoch 12: train total loss -59.01682116966661, train mean loss 0.0025664840361686275, test mean loss [0.00304897 0.00263336 0.00203478 0.00194458 0.00293278 0.00364805
 0.0033217 ]
Model epoch 13: train total loss -59.394718109392414, train mean loss 0.0021657444095267613, test mean loss [0.00264357 0.00227695 0.00172374 0.00167158 0.00258337 0.00305061
 0.00254401]
Model epoch 14: train total loss -59.8952201658584, train mean loss 0.0018032549497494553, test mean loss [0.00232247 0.00200644 0.00152721 0.00151972 0.0023193  0.00251947
 0.00203158]
Model epoch 15: train total loss -60.11263296861431, train mean loss 0.0016890106341633927, test mean loss [0.00213622 0.00182037 0.00138202 0.00134431 0.00208519 0.00211857
 0.00170158]
Model epoch 16: train total loss -60.66149898785393, train mean loss 0.0013398471766496289, test mean loss [0.00183848 0.00170192 0.00129212 0.00126105 0.00191122 0.00185595
 0.00147543]
Model epoch 17: train total loss -60.610482588835836, train mean loss 0.0014000527802223671, test mean loss [0.00165169 0.00161232 0.00118114 0.0011237  0.00172525 0.00161624
 0.00130472]
Model epoch 18: train total loss -60.78961211887203, train mean loss 0.0011579308015247484, test mean loss [0.00156886 0.00156207 0.00111053 0.00107287 0.00152786 0.00140756
 0.00119328]
Model epoch 19: train total loss -61.224210599299994, train mean loss 0.0010653516778066962, test mean loss [0.00140037 0.00146429 0.00105674 0.00100523 0.00145343 0.00128184
 0.00113188]
Model epoch 20: train total loss -61.47269062742073, train mean loss 0.0009359583260663347, test mean loss [0.00123686 0.00141815 0.00099707 0.00096168 0.00127696 0.00112803
 0.00110451]
Model epoch 21: train total loss -61.35816487090711, train mean loss 0.0009750911489735522, test mean loss [0.00112326 0.00130778 0.0009715  0.00089804 0.00123158 0.00102448
 0.00103471]
Model epoch 22: train total loss -61.62540554021512, train mean loss 0.0009431618934939259, test mean loss [0.00109749 0.0012851  0.00090675 0.00087223 0.0011156  0.00096274
 0.00096199]
Model epoch 23: train total loss -61.870844863441405, train mean loss 0.0008355244229761263, test mean loss [0.00101332 0.00120961 0.00086505 0.00082175 0.00099935 0.00088736
 0.0009551 ]
Model epoch 24: train total loss -61.88029553913833, train mean loss 0.0007989149579089633, test mean loss [0.00096454 0.00116645 0.00083394 0.00077842 0.00095257 0.00083557
 0.00085479]
Model epoch 25: train total loss -62.19066129393877, train mean loss 0.0007078755648307386, test mean loss [0.00092326 0.00112923 0.00078273 0.00074909 0.00091624 0.00082707
 0.00086027]
Model epoch 26: train total loss -62.15287898208848, train mean loss 0.0008125743032112517, test mean loss [0.00084507 0.00106542 0.00074872 0.00073073 0.00087669 0.00078354
 0.00079318]
Model epoch 27: train total loss -62.24591149284285, train mean loss 0.0007069858223374542, test mean loss [0.0008124  0.00106506 0.00072941 0.00068986 0.00083185 0.00076362
 0.00077396]
Model epoch 28: train total loss -62.15490435917931, train mean loss 0.0007206897165080342, test mean loss [0.00079249 0.00102601 0.0007024  0.00068415 0.00076284 0.00071613
 0.0007383 ]
Model epoch 29: train total loss -62.401963801502475, train mean loss 0.0006600279364895987, test mean loss [0.00075161 0.00097353 0.00068612 0.00065349 0.00073976 0.00069751
 0.00071818]
Model epoch 30: train total loss -62.44034991121869, train mean loss 0.0006730451985132224, test mean loss [0.00071011 0.00096574 0.00065346 0.0006476  0.00069927 0.00068114
 0.00069179]
Model epoch 31: train total loss -62.725755502160084, train mean loss 0.0005339970005830583, test mean loss [0.00068167 0.00092926 0.00065679 0.00062668 0.00067657 0.00065627
 0.00066506]
Model epoch 32: train total loss -62.405432447246454, train mean loss 0.0006633611204035841, test mean loss [0.00066185 0.00088637 0.00062708 0.00060754 0.00064709 0.00064036
 0.00064449]
Model epoch 33: train total loss -62.69178841962188, train mean loss 0.000554411429354499, test mean loss [0.00065336 0.00086582 0.00062892 0.00059606 0.00061708 0.00062293
 0.00062822]
Model epoch 34: train total loss -62.77058406811418, train mean loss 0.0006003534764011617, test mean loss [0.00065926 0.00084378 0.0005925  0.00057615 0.00061564 0.00059227
 0.00060053]
Model epoch 35: train total loss -62.86930655195118, train mean loss 0.0005276904616074461, test mean loss [0.00060729 0.00084174 0.00057851 0.00056428 0.00059951 0.00058537
 0.00059266]
Model epoch 36: train total loss -62.92364379490579, train mean loss 0.0005696584501047459, test mean loss [0.00058694 0.00078207 0.00056447 0.00054752 0.00057841 0.00057023
 0.0005813 ]
Model epoch 37: train total loss -63.020740027475675, train mean loss 0.0005245407353576747, test mean loss [0.00057713 0.00076665 0.00055417 0.0005348  0.00057096 0.0005636
 0.00054425]
Model epoch 38: train total loss -63.01381020924023, train mean loss 0.0005207811286809193, test mean loss [0.00057381 0.00076125 0.000532   0.00052651 0.00055869 0.00054488
 0.00054637]
Model epoch 39: train total loss -63.108371402566334, train mean loss 0.0005016028568290246, test mean loss [0.0005527  0.00073982 0.00052915 0.00051242 0.0005395  0.00053332
 0.00053712]
Model epoch 40: train total loss -63.29196742880123, train mean loss 0.0004657309039060871, test mean loss [0.00055793 0.00073124 0.00053536 0.00049982 0.00052397 0.00052371
 0.00051412]
Model epoch 41: train total loss -63.01106882060724, train mean loss 0.0004723662333024237, test mean loss [0.00053262 0.00071989 0.00051597 0.0004959  0.00052301 0.00051324
 0.0004991 ]
Model epoch 42: train total loss -63.14718915835312, train mean loss 0.0005090265595328855, test mean loss [0.00052791 0.00070243 0.00050222 0.00047791 0.00050388 0.00053224
 0.0005071 ]
Model epoch 43: train total loss -63.221006956702965, train mean loss 0.00048106871360853985, test mean loss [0.00050724 0.00068096 0.00048719 0.00047222 0.00049113 0.00048816
 0.00048188]
Model epoch 44: train total loss -63.47566473343283, train mean loss 0.00043850219938381584, test mean loss [0.00050617 0.00068645 0.00048272 0.00048519 0.00049279 0.00048779
 0.00047871]
Model epoch 45: train total loss -63.459294814522764, train mean loss 0.0004813201166244586, test mean loss [0.00049308 0.00065856 0.00046899 0.00045412 0.00048923 0.00047888
 0.00047806]
Model epoch 46: train total loss -63.407452019581186, train mean loss 0.0004260372331970584, test mean loss [0.00047985 0.00064665 0.00045676 0.00045638 0.00046552 0.00046645
 0.0004538 ]
Model epoch 47: train total loss -63.48611011585626, train mean loss 0.00033551483670700796, test mean loss [0.00046814 0.00063628 0.00044615 0.00044875 0.00047343 0.00046341
 0.00045779]
Model epoch 48: train total loss -63.64126932860392, train mean loss 0.000349298204004752, test mean loss [0.00046546 0.00063593 0.00045041 0.00045142 0.00045918 0.00044436
 0.00044258]
Model epoch 49: train total loss -63.6278458499061, train mean loss 0.00037789678649052447, test mean loss [0.0004474  0.00061295 0.00043889 0.0004201  0.00045836 0.00044069
 0.00042634]
Model epoch 50: train total loss -63.53600773841421, train mean loss 0.0004262822417148006, test mean loss [0.00044276 0.0006233  0.00043831 0.00042646 0.00044657 0.00043326
 0.00042446]
Model epoch 51: train total loss -63.74705101583924, train mean loss 0.0003337447818187788, test mean loss [0.00045037 0.00059371 0.0004382  0.0004156  0.00043711 0.00042345
 0.00042562]
Model epoch 52: train total loss -63.72838954175729, train mean loss 0.00036970081022095265, test mean loss [0.00043354 0.00058719 0.00042011 0.00040759 0.00043105 0.00041298
 0.00042113]
Model epoch 53: train total loss -63.68309806870462, train mean loss 0.00039248150106600664, test mean loss [0.00043797 0.00057753 0.00042437 0.00039978 0.00041237 0.00041223
 0.00039847]
Model epoch 54: train total loss -63.7035976039456, train mean loss 0.0003940541903861214, test mean loss [0.00041823 0.00057511 0.00042032 0.00040867 0.00042617 0.00040755
 0.00041516]
Model epoch 55: train total loss -63.67641227822245, train mean loss 0.0003789910822505317, test mean loss [0.00043548 0.00054633 0.00041275 0.00038568 0.00040211 0.00040392
 0.00039493]
Model epoch 56: train total loss -63.731213258021356, train mean loss 0.00037119412208903136, test mean loss [0.00041696 0.00055987 0.00040965 0.00038475 0.00040825 0.00039348
 0.0004109 ]
Model epoch 57: train total loss -63.821467766473894, train mean loss 0.00029472897912938197, test mean loss [0.00040273 0.00053136 0.00040169 0.0003753  0.00041028 0.00040132
 0.00038991]
Model epoch 58: train total loss -63.875664854908116, train mean loss 0.00032619723020504103, test mean loss [0.00040054 0.00052932 0.00039524 0.00037233 0.00040799 0.00038499
 0.00038929]
Model epoch 59: train total loss -63.826378917965755, train mean loss 0.00036485746275314104, test mean loss [0.00037983 0.00053846 0.00039004 0.00037341 0.00038664 0.00037706
 0.00038895]
Model epoch 60: train total loss -64.09642224088891, train mean loss 0.000305905454399699, test mean loss [0.00037563 0.00051094 0.00038977 0.00036722 0.00037957 0.0003767
 0.0003703 ]
Model epoch 61: train total loss -63.85265219689216, train mean loss 0.0003412094424350815, test mean loss [0.00038345 0.00051773 0.00038648 0.00036143 0.00038801 0.0003732
 0.00037529]
Model epoch 62: train total loss -64.17209325560144, train mean loss 0.00030448328953156797, test mean loss [0.00036301 0.00049519 0.00038135 0.00034712 0.00038044 0.00036161
 0.00036425]
Model epoch 63: train total loss -64.04222158265263, train mean loss 0.000317528983678234, test mean loss [0.0003645  0.00048826 0.00038091 0.00034936 0.00037184 0.00035424
 0.00035036]
Model epoch 64: train total loss -64.06538208117807, train mean loss 0.00029751113509122323, test mean loss [0.00036116 0.00048169 0.00037503 0.00034189 0.00036538 0.00035305
 0.00034535]
Model epoch 65: train total loss -64.12356964664781, train mean loss 0.00033331644759522434, test mean loss [0.00036548 0.00048788 0.00037997 0.00033978 0.00036011 0.00035354
 0.00033983]
Model epoch 66: train total loss -64.19946860257316, train mean loss 0.00027469316440321316, test mean loss [0.00036049 0.00047135 0.00036256 0.00034751 0.0003615  0.00034764
 0.00034104]
Model epoch 67: train total loss -64.00852367851033, train mean loss 0.00030736002197120416, test mean loss [0.00033871 0.00046155 0.00035718 0.00033891 0.00035902 0.00033484
 0.00033485]
Model epoch 68: train total loss -64.32363633850085, train mean loss 0.00024571917192988166, test mean loss [0.00032954 0.00044539 0.00036947 0.00032661 0.00036731 0.00035016
 0.00034689]
Model epoch 69: train total loss -64.19329507733525, train mean loss 0.00027763744770090376, test mean loss [0.00033459 0.00043855 0.00035927 0.00033147 0.00035366 0.0003267
 0.0003291 ]
Model epoch 70: train total loss -64.15339079087012, train mean loss 0.0003239815296234655, test mean loss [0.0003453  0.0004419  0.00035459 0.00032629 0.00034848 0.00035656
 0.00032989]
Model epoch 71: train total loss -64.21330854116282, train mean loss 0.00028182111856620104, test mean loss [0.00035612 0.00044443 0.00034994 0.00032513 0.00035435 0.0003195
 0.00033032]
Model epoch 72: train total loss -64.23134344467903, train mean loss 0.00028136445674356667, test mean loss [0.00034057 0.00043998 0.00034462 0.00031812 0.00034128 0.00032917
 0.00032298]
Model epoch 73: train total loss -64.2421653987524, train mean loss 0.0003270709809550587, test mean loss [0.00031396 0.00042099 0.00033579 0.00032372 0.00034341 0.0003255
 0.00032424]
Model epoch 74: train total loss -64.11914227399272, train mean loss 0.00030749610906117376, test mean loss [0.00032375 0.00042453 0.00033215 0.000315   0.00033925 0.00031864
 0.00031928]
Model epoch 75: train total loss -64.369878545728, train mean loss 0.00022146790611475009, test mean loss [0.00032576 0.00041809 0.00034255 0.00030423 0.00035758 0.00031571
 0.00031097]
Model epoch 76: train total loss -64.0985718295785, train mean loss 0.0002558884657671044, test mean loss [0.00031213 0.0004299  0.00033692 0.00029976 0.00031596 0.00031002
 0.00030786]
Model epoch 77: train total loss -64.34220693969864, train mean loss 0.00027253388215609084, test mean loss [0.00030965 0.00040304 0.00033682 0.00031426 0.00032331 0.00030742
 0.00030201]
Model epoch 78: train total loss -64.27122073010698, train mean loss 0.00028273685774485866, test mean loss [0.00030757 0.00040544 0.00033396 0.0002977  0.000322   0.00031001
 0.00029433]
Model epoch 79: train total loss -64.50644655031812, train mean loss 0.00022818256814374836, test mean loss [0.00030498 0.00039918 0.00033625 0.00030157 0.00032082 0.00029188
 0.00029991]
Model epoch 80: train total loss -64.40194742801432, train mean loss 0.00022566720038196239, test mean loss [0.00029867 0.00039448 0.00032634 0.00028297 0.00031093 0.00029342
 0.00029153]
Model epoch 81: train total loss -64.35722348370174, train mean loss 0.0002451703544659077, test mean loss [0.00030172 0.00039265 0.0003265  0.00029848 0.00029914 0.00029269
 0.00029829]
Model epoch 82: train total loss -64.40412382342618, train mean loss 0.00025965954382128767, test mean loss [0.0002923  0.00038797 0.0003221  0.00028688 0.0003096  0.00028578
 0.00028348]
Model epoch 83: train total loss -64.46713281538916, train mean loss 0.00025334695430515725, test mean loss [0.00028911 0.00037661 0.00032974 0.00028245 0.0003031  0.00029033
 0.00029551]
Model epoch 84: train total loss -64.45933769438516, train mean loss 0.00025501662361111864, test mean loss [0.00028929 0.00037959 0.0003139  0.00028812 0.00032339 0.00029113
 0.00027952]
Model epoch 85: train total loss -64.45455276898173, train mean loss 0.00027960956706076835, test mean loss [0.00029077 0.00038442 0.00031276 0.00027966 0.00031049 0.00028209
 0.00028466]
Model epoch 86: train total loss -64.62846346007801, train mean loss 0.0002014269659720749, test mean loss [0.0002893  0.0003827  0.00031514 0.00027853 0.00030178 0.00028833
 0.0002791 ]
Model epoch 87: train total loss -64.67133484650778, train mean loss 0.0002553793130724812, test mean loss [0.0002784  0.00037261 0.00030689 0.00027979 0.00029148 0.00028712
 0.00027   ]
Model epoch 88: train total loss -64.26802971762524, train mean loss 0.0002980352314548576, test mean loss [0.00028272 0.00037404 0.00031316 0.00028048 0.00029389 0.00027525
 0.00027067]
Model epoch 89: train total loss -64.65226161401493, train mean loss 0.0001994639510124461, test mean loss [0.00027235 0.00038458 0.00030978 0.00027892 0.00029994 0.00027781
 0.0002659 ]
Model epoch 90: train total loss -64.54909302698641, train mean loss 0.0002151462983619352, test mean loss [0.00027015 0.00035722 0.00031257 0.000274   0.00029309 0.00028236
 0.00026579]
Model epoch 91: train total loss -64.62851006745477, train mean loss 0.00022181717821622316, test mean loss [0.00027187 0.00036381 0.00029777 0.0002711  0.00029246 0.00027317
 0.00028917]
Model epoch 92: train total loss -64.56110498877827, train mean loss 0.00021548531291074616, test mean loss [0.00027176 0.00034791 0.00029656 0.00027152 0.00027993 0.00027845
 0.00025657]
Model epoch 93: train total loss -64.5486102347441, train mean loss 0.00023111913021864618, test mean loss [0.00026842 0.00035525 0.00029287 0.00026879 0.00027847 0.00026325
 0.00026589]
Model epoch 94: train total loss -64.73029583138145, train mean loss 0.00019941510766950017, test mean loss [0.0002604  0.00034023 0.00029225 0.00026    0.0002761  0.00028305
 0.00025047]
Model epoch 95: train total loss -64.62924368964292, train mean loss 0.00021386546338556024, test mean loss [0.00026415 0.00033318 0.0002836  0.0002591  0.0002736  0.00026248
 0.00025705]
Model epoch 96: train total loss -64.85560120592031, train mean loss 0.00019540047898672778, test mean loss [0.00025782 0.00032897 0.00028314 0.00026953 0.00028257 0.00025706
 0.00025473]
Model epoch 97: train total loss -64.62803558706153, train mean loss 0.0002252933143360879, test mean loss [0.00026701 0.0003272  0.00028496 0.00025882 0.00027561 0.00025761
 0.00025354]
Model epoch 98: train total loss -64.66536422162218, train mean loss 0.00021485359412085834, test mean loss [0.0002595  0.0003269  0.00028614 0.00026008 0.00027249 0.00025539
 0.00025342]
Model epoch 99: train total loss -64.59979998653031, train mean loss 0.00018642458214602372, test mean loss [0.00025373 0.00034915 0.00029195 0.00025673 0.00026178 0.00025548
 0.00025732]
Model epoch 100: train total loss -64.63149597106715, train mean loss 0.00020809134891011763, test mean loss [0.00025254 0.00031655 0.00027855 0.0002639  0.0002582  0.00026176
 0.0002455 ]
Model epoch 101: train total loss -64.78336805512457, train mean loss 0.00017782323966910828, test mean loss [0.00025191 0.00032116 0.00028119 0.00024894 0.00026564 0.00025042
 0.00024523]
Model epoch 102: train total loss -64.67600290266948, train mean loss 0.00024277219361526473, test mean loss [0.00025192 0.00033208 0.00028661 0.00024883 0.00026116 0.00024819
 0.00024725]
Model epoch 103: train total loss -64.71049466489212, train mean loss 0.0001947555079786403, test mean loss [0.00024355 0.00030754 0.00027264 0.00024745 0.00025378 0.00024943
 0.00023786]
Model epoch 104: train total loss -64.74564606410362, train mean loss 0.00019493910383719274, test mean loss [0.00024611 0.00031168 0.00027877 0.00025336 0.00025756 0.00025073
 0.00024165]
Model epoch 105: train total loss -64.84855611150434, train mean loss 0.0002169973690515715, test mean loss [0.00024064 0.00030095 0.00027553 0.0002488  0.0002473  0.00024723
 0.00023578]
Model epoch 106: train total loss -64.75540800723492, train mean loss 0.0002304317587756592, test mean loss [0.00024297 0.00030889 0.00027275 0.00024188 0.00025122 0.00024821
 0.00024865]
Model epoch 107: train total loss -64.66620118133838, train mean loss 0.00020543737005877317, test mean loss [0.00023895 0.00030761 0.00027221 0.00024628 0.00025752 0.0002434
 0.0002328 ]
Model epoch 108: train total loss -64.66914162262239, train mean loss 0.00021797272854374064, test mean loss [0.00024495 0.00029646 0.00027749 0.00024423 0.0002581  0.00024009
 0.00023834]
Model epoch 109: train total loss -64.90371023204574, train mean loss 0.0002075451982628907, test mean loss [0.00023781 0.00028892 0.00027537 0.00023643 0.00024494 0.00023176
 0.00023044]
Model epoch 110: train total loss -64.76419984580393, train mean loss 0.00022482405595293845, test mean loss [0.00023666 0.00029701 0.00027712 0.00023309 0.000258   0.00024132
 0.00023322]
Model epoch 111: train total loss -64.82762944990364, train mean loss 0.00018734857190345365, test mean loss [0.00022987 0.00029387 0.00026521 0.00022845 0.00025659 0.00023781
 0.00023339]
Model epoch 112: train total loss -64.98989310527375, train mean loss 0.0001802532756997151, test mean loss [0.0002297  0.00028061 0.00026294 0.00022708 0.00025573 0.00023777
 0.00023102]
Model epoch 113: train total loss -65.02398601415013, train mean loss 0.00020869033870931354, test mean loss [0.00023625 0.00027828 0.00026008 0.00023582 0.00024227 0.00023777
 0.00022702]
Model epoch 114: train total loss -64.76011473382887, train mean loss 0.00019473889103491674, test mean loss [0.00023599 0.00028103 0.00026137 0.00023789 0.00023596 0.00022563
 0.00023387]
Model epoch 115: train total loss -64.78735930411182, train mean loss 0.0001900045401609039, test mean loss [0.00023651 0.00028824 0.00026411 0.00022445 0.00024077 0.0002354
 0.00023131]
Model epoch 116: train total loss -64.93796050051925, train mean loss 0.00021458864877880665, test mean loss [0.00024349 0.00027911 0.00026483 0.00023018 0.00023461 0.00026004
 0.0002312 ]
Model epoch 117: train total loss -64.97239740259768, train mean loss 0.00018883499249238385, test mean loss [0.00022362 0.00026969 0.00026504 0.0002348  0.00023482 0.00025185
 0.00022835]
Model epoch 118: train total loss -64.96726281104723, train mean loss 0.00018084221477759297, test mean loss [0.00021444 0.00027144 0.0002492  0.00022775 0.00023766 0.00022957
 0.0002229 ]
Model epoch 119: train total loss -64.93349240602004, train mean loss 0.00017710557780405798, test mean loss [0.00022411 0.00026536 0.00025703 0.0002267  0.00023352 0.0002237
 0.00022064]
Model epoch 120: train total loss -64.92006895143408, train mean loss 0.00017349292980790526, test mean loss [0.00022038 0.00026659 0.00025245 0.00022973 0.00022836 0.0002222
 0.00021361]
Model epoch 121: train total loss -64.845094353797, train mean loss 0.00020029310483410872, test mean loss [0.00022106 0.00026947 0.00025068 0.00022843 0.00022817 0.00022766
 0.00021162]
Model epoch 122: train total loss -65.01857982020285, train mean loss 0.00015807708999007687, test mean loss [0.00021296 0.00026208 0.0002513  0.00022371 0.00023059 0.00021657
 0.00021157]
Model epoch 123: train total loss -65.00696796195571, train mean loss 0.00017229325084638434, test mean loss [0.00021264 0.00026734 0.00025075 0.00022197 0.00022866 0.00022818
 0.00021362]
Model epoch 124: train total loss -64.95473947612187, train mean loss 0.00017215490330820335, test mean loss [0.00021937 0.00025941 0.00024535 0.00022025 0.00022454 0.00022958
 0.00021315]
Model epoch 125: train total loss -64.84665566548092, train mean loss 0.0001776270523612797, test mean loss [0.00021316 0.00026461 0.00025806 0.00022509 0.00022109 0.00022681
 0.00020874]
Model epoch 126: train total loss -64.92993519559782, train mean loss 0.00017927753904089098, test mean loss [0.00022425 0.00026506 0.00024391 0.00021465 0.00022479 0.00021858
 0.00021105]
Model epoch 127: train total loss -64.82446198588859, train mean loss 0.00017972047563957197, test mean loss [0.00021819 0.00025248 0.00025325 0.0002191  0.00021699 0.00021838
 0.00020874]
Model epoch 128: train total loss -64.85532579919204, train mean loss 0.000186064591755418, test mean loss [0.00020784 0.00025307 0.00024176 0.00021339 0.00021804 0.00022122
 0.00021426]
Model epoch 129: train total loss -65.20842833776824, train mean loss 0.00017371983553814566, test mean loss [0.00021233 0.00024859 0.00024415 0.00021044 0.00021634 0.00021079
 0.00020747]
Model epoch 130: train total loss -65.09413859160604, train mean loss 0.00018514636890425425, test mean loss [0.00020273 0.00023928 0.00024172 0.00021553 0.00021975 0.00021197
 0.00021001]
Model epoch 131: train total loss -65.13572322444033, train mean loss 0.00016527974838047264, test mean loss [0.00020273 0.00024863 0.00024175 0.00021377 0.0002183  0.00021031
 0.00021257]
Model epoch 132: train total loss -64.90457713733045, train mean loss 0.00018040138889429194, test mean loss [0.00021033 0.00024902 0.00023997 0.00020898 0.00021051 0.00021733
 0.00019917]
Model epoch 133: train total loss -65.03463788481211, train mean loss 0.00017253785791822125, test mean loss [0.00020353 0.00024561 0.00023929 0.00021466 0.0002142  0.00023432
 0.00020176]
Model epoch 134: train total loss -65.05712611939971, train mean loss 0.00016800073555888614, test mean loss [0.00019928 0.00024353 0.00024175 0.00020685 0.00021781 0.00022686
 0.00019542]
Model epoch 135: train total loss -65.05984419100118, train mean loss 0.00017949230356070151, test mean loss [0.00021193 0.00024618 0.00024166 0.00020825 0.00022204 0.00021758
 0.00019557]
Model epoch 136: train total loss -65.16491776689256, train mean loss 0.0001655017953277115, test mean loss [0.00019961 0.0002461  0.00023888 0.00021358 0.0002183  0.00020745
 0.00019924]
Model epoch 137: train total loss -64.9469033073572, train mean loss 0.000167037153349464, test mean loss [0.00019877 0.0002268  0.000239   0.00021449 0.00020667 0.0002071
 0.00019457]
Model epoch 138: train total loss -65.1955000693031, train mean loss 0.000167372240816496, test mean loss [0.00019364 0.00024542 0.00022917 0.00020842 0.00020603 0.0002102
 0.00019198]
Model epoch 139: train total loss -65.13726262442552, train mean loss 0.00017857832229615538, test mean loss [0.00019682 0.00022814 0.00023374 0.00020335 0.00020931 0.0002095
 0.00019722]
Model epoch 140: train total loss -65.1844460945613, train mean loss 0.00017147818608143582, test mean loss [0.00019423 0.00023685 0.0002411  0.00020871 0.00021319 0.00020702
 0.00019394]
Model epoch 141: train total loss -65.31403578193456, train mean loss 0.00016656145636209324, test mean loss [0.00019421 0.00023241 0.00022749 0.00020964 0.0002149  0.00020552
 0.00019386]
Model epoch 142: train total loss -65.27570031175853, train mean loss 0.00017112832309236888, test mean loss [0.0002001  0.00023053 0.00023085 0.00020159 0.00020484 0.00020836
 0.00018986]
Model epoch 143: train total loss -65.1390181573904, train mean loss 0.00015476035469338, test mean loss [0.00019386 0.00023169 0.0002317  0.00021317 0.00020784 0.00021401
 0.00018235]
Model epoch 144: train total loss -65.2590719858449, train mean loss 0.00016793774656908222, test mean loss [0.00019441 0.00022755 0.00022646 0.00019612 0.0002106  0.00019947
 0.00018743]
Model epoch 145: train total loss -65.13868438863703, train mean loss 0.00016886023094456228, test mean loss [0.00019061 0.00023724 0.00022552 0.00020217 0.00020683 0.00019351
 0.00019162]
Model epoch 146: train total loss -65.19679700125957, train mean loss 0.0001662054686541255, test mean loss [0.0001872  0.00021815 0.00022575 0.00020732 0.00019997 0.00020356
 0.00018278]
Model epoch 147: train total loss -65.2079176298359, train mean loss 0.00017253879622393153, test mean loss [0.00018656 0.00021935 0.00022228 0.00019781 0.00019987 0.00020404
 0.00018708]
Model epoch 148: train total loss -65.26583211235622, train mean loss 0.00016876408804602459, test mean loss [0.00018386 0.00021513 0.0002202  0.00019918 0.00020191 0.00020467
 0.00018499]
Model epoch 149: train total loss -65.291566165699, train mean loss 0.0001455482015140353, test mean loss [0.00018791 0.00021282 0.0002222  0.00019965 0.00019465 0.00019963
 0.00018574]
Model epoch 150: train total loss -65.21219127682835, train mean loss 0.00017591753863753054, test mean loss [0.00018827 0.00022084 0.00023829 0.00019584 0.00019435 0.00019283
 0.00018299]
Model epoch 151: train total loss -65.16705395884398, train mean loss 0.00014892167917898242, test mean loss [0.0001917  0.00021935 0.00023249 0.00019938 0.00020036 0.00019357
 0.00018746]
Model epoch 152: train total loss -65.16231115425184, train mean loss 0.00015635874005675272, test mean loss [0.00018767 0.00021741 0.00021532 0.00021749 0.00020804 0.00020719
 0.00017597]
Model epoch 153: train total loss -65.33155284669462, train mean loss 0.00015199776099529146, test mean loss [0.00018983 0.00021232 0.00021478 0.00021415 0.00019916 0.00020782
 0.00018363]
Model epoch 154: train total loss -65.33643910924141, train mean loss 0.00014812182158701603, test mean loss [0.00018653 0.00021181 0.00021509 0.0001927  0.0001978  0.00020104
 0.0001782 ]
Model epoch 155: train total loss -65.2634695293936, train mean loss 0.00014843163751017201, test mean loss [0.00018499 0.00021082 0.00022491 0.00019058 0.00019115 0.00019136
 0.00017428]
Model epoch 156: train total loss -65.45955358601196, train mean loss 0.0001673310012829685, test mean loss [0.0001828  0.00020706 0.00021563 0.00018895 0.00018867 0.00019775
 0.00016815]
Model epoch 157: train total loss -65.29367898181363, train mean loss 0.00014949447175069804, test mean loss [0.00018164 0.00021562 0.00021463 0.00019181 0.00018377 0.00019325
 0.0001759 ]
Model epoch 158: train total loss -65.21761542920277, train mean loss 0.0001520345608798001, test mean loss [0.00018456 0.00020527 0.00021403 0.00018999 0.00018349 0.00018912
 0.00017692]
Model epoch 159: train total loss -65.31559675739611, train mean loss 0.00015367484764717312, test mean loss [0.000184   0.00020568 0.00021027 0.00018872 0.00018512 0.000194
 0.00016882]
Model epoch 160: train total loss -65.31258060514195, train mean loss 0.00014504138460271393, test mean loss [0.00018095 0.0001987  0.00021352 0.0001864  0.00018657 0.00019309
 0.00017303]
Model epoch 161: train total loss -65.39154486636531, train mean loss 0.00014014249603687412, test mean loss [0.00017916 0.00020464 0.00020839 0.00018936 0.00019027 0.0001889
 0.00017022]
Model epoch 162: train total loss -65.24909511201987, train mean loss 0.00015438296171260888, test mean loss [0.00017814 0.00020969 0.00021624 0.00018726 0.00018298 0.00020709
 0.00017152]
Model epoch 163: train total loss -65.18653694447015, train mean loss 0.00015531857754383984, test mean loss [0.00019088 0.00019998 0.00021448 0.00019043 0.00018152 0.00019748
 0.00017349]
Model epoch 164: train total loss -65.0518486712663, train mean loss 0.0001566363557138485, test mean loss [0.00017441 0.0002035  0.00020808 0.00018077 0.000196   0.00019721
 0.00017674]
Model epoch 165: train total loss -65.28627318805155, train mean loss 0.00016620169270303148, test mean loss [0.00018057 0.00020066 0.00020736 0.00018344 0.00018481 0.00019566
 0.00016988]
Model epoch 166: train total loss -65.29837812180621, train mean loss 0.00016164958070132354, test mean loss [0.00017232 0.00020363 0.00020594 0.00018245 0.0002015  0.00018647
 0.00016988]
Model epoch 167: train total loss -65.30652994349703, train mean loss 0.00013842380290674834, test mean loss [0.00017518 0.00019982 0.00020239 0.00018576 0.00018987 0.00018177
 0.00018151]
Model epoch 168: train total loss -65.38012900438541, train mean loss 0.00015168867513533054, test mean loss [0.00017397 0.00019734 0.00020522 0.00017891 0.00018101 0.00017676
 0.00017758]
Model epoch 169: train total loss -65.27511408980745, train mean loss 0.00015056729862880134, test mean loss [0.00017422 0.00018965 0.00020541 0.0001903  0.00017907 0.00018248
 0.00017967]
Model epoch 170: train total loss -65.46630468868976, train mean loss 0.0001574961799386935, test mean loss [0.00017298 0.00019042 0.00020302 0.00017793 0.00018295 0.00018255
 0.00017018]
Model epoch 171: train total loss -65.35799104270575, train mean loss 0.00015117447377668402, test mean loss [0.0001722  0.00019993 0.00020474 0.00018164 0.00018537 0.0001802
 0.00017062]
Model epoch 172: train total loss -65.39180825381736, train mean loss 0.00014919526088817003, test mean loss [0.00017689 0.00019563 0.00020379 0.00018119 0.00017284 0.00018652
 0.00016668]
Model epoch 173: train total loss -65.38341499225463, train mean loss 0.00015448991024643384, test mean loss [0.00017067 0.00018536 0.00020445 0.00018531 0.00017962 0.00018464
 0.00016762]
Model epoch 174: train total loss -65.33017576821585, train mean loss 0.00012944781335539663, test mean loss [0.00017311 0.00018746 0.00019848 0.00017907 0.00017828 0.00020793
 0.00016911]
Model epoch 175: train total loss -65.43715700513205, train mean loss 0.00014879704080187237, test mean loss [0.00018025 0.00018956 0.00019549 0.0001755  0.0001754  0.0001773
 0.00016341]
Model epoch 176: train total loss -65.1665014398562, train mean loss 0.0001428580956084371, test mean loss [0.00017287 0.0001904  0.00020637 0.00018136 0.00018391 0.00017664
 0.00016424]
Model epoch 177: train total loss -65.42341149610077, train mean loss 0.00013041958679218526, test mean loss [0.00017111 0.00017963 0.0001988  0.00017918 0.00017693 0.00019093
 0.00016458]
Model epoch 178: train total loss -65.34916781870244, train mean loss 0.00013117989086155294, test mean loss [0.0001671  0.00018899 0.00019576 0.00017932 0.00017748 0.00018213
 0.0001758 ]
Model epoch 179: train total loss -65.3988198178429, train mean loss 0.00013491352196982258, test mean loss [0.00016976 0.00019477 0.00019832 0.0001735  0.00017816 0.00017869
 0.00016575]
Model epoch 180: train total loss -65.44559039592637, train mean loss 0.00014208191547310638, test mean loss [0.00016509 0.00018918 0.00020568 0.00017772 0.00017937 0.00017817
 0.00016554]
Model epoch 181: train total loss -65.49192452029875, train mean loss 0.00015237187489973138, test mean loss [0.00016648 0.00018866 0.00019325 0.00017991 0.00017146 0.00017997
 0.00015623]
Model epoch 182: train total loss -65.37419447350817, train mean loss 0.00014380816701629916, test mean loss [0.00017266 0.00017971 0.00019628 0.00017435 0.00017392 0.00018096
 0.00017492]
Model epoch 183: train total loss -65.29155230810144, train mean loss 0.0001521751054280741, test mean loss [0.000168   0.00017668 0.00019145 0.00019881 0.00018395 0.00018319
 0.00016655]
Model epoch 184: train total loss -65.4542854910061, train mean loss 0.000143894021153844, test mean loss [0.00017278 0.00018716 0.00018897 0.0001758  0.00017397 0.00017477
 0.00016625]
Model epoch 185: train total loss -65.32938180976744, train mean loss 0.00014103331759878423, test mean loss [0.00016878 0.00018035 0.00019567 0.00017378 0.00017415 0.00016936
 0.00016061]
Model epoch 186: train total loss -65.45816010746138, train mean loss 0.00014066743957914796, test mean loss [0.00016923 0.00017511 0.00018494 0.00017441 0.00017809 0.00017649
 0.00016336]
Model epoch 187: train total loss -65.50560705880876, train mean loss 0.00015003601120568423, test mean loss [0.00016407 0.00018481 0.00018563 0.00017015 0.00016647 0.00017526
 0.00015684]
Model epoch 188: train total loss -65.37780564922585, train mean loss 0.00014997419958515812, test mean loss [0.0001593  0.0001749  0.0001907  0.00018042 0.00016988 0.00017779
 0.0001612 ]
Model epoch 189: train total loss -65.53192204501302, train mean loss 0.0001372933571044764, test mean loss [0.00016196 0.00017348 0.00019457 0.00017337 0.0001801  0.00016871
 0.000163  ]
Model epoch 190: train total loss -65.60826103051845, train mean loss 0.00014029088644668838, test mean loss [0.00015961 0.00017875 0.00019454 0.00016861 0.0001731  0.00016902
 0.0001617 ]
Model epoch 191: train total loss -65.51839899621889, train mean loss 0.00012981631995004185, test mean loss [0.00016286 0.00017031 0.00018495 0.00017122 0.00018209 0.00017798
 0.00016384]
Model epoch 192: train total loss -65.42904909325766, train mean loss 0.00013884516137124613, test mean loss [0.00016096 0.00016855 0.00018542 0.00017442 0.00017146 0.00017069
 0.00016403]
Model epoch 193: train total loss -65.36277094815905, train mean loss 0.00015649672494566163, test mean loss [0.00016314 0.00017364 0.00018867 0.00017733 0.00016898 0.00017626
 0.00016208]
Model epoch 194: train total loss -65.61941664671852, train mean loss 0.00013214943586587348, test mean loss [0.00015761 0.00016782 0.00018298 0.00017424 0.00016632 0.00017226
 0.00015709]
Model epoch 195: train total loss -65.59031308465114, train mean loss 0.00012857104465530055, test mean loss [0.00016281 0.00017547 0.00018905 0.00017272 0.00018024 0.00017224
 0.00014655]
Model epoch 196: train total loss -65.53337437848806, train mean loss 0.00015005698291221232, test mean loss [0.000153   0.00017907 0.00018487 0.00017025 0.00016681 0.00017205
 0.00014962]
Model epoch 197: train total loss -65.44854036399884, train mean loss 0.0001461750979778456, test mean loss [0.00015866 0.00017213 0.00018148 0.00016349 0.00016638 0.00017093
 0.00015958]
Model epoch 198: train total loss -65.56387877478595, train mean loss 0.00013490669487140896, test mean loss [0.00015921 0.00016849 0.00018166 0.00017153 0.00016891 0.00017519
 0.00015399]
Model epoch 199: train total loss -65.5216633793877, train mean loss 0.0001352946960913534, test mean loss [0.00015513 0.00017074 0.0001839  0.00016891 0.00016588 0.00017097
 0.0001502 ]
Model epoch 200: train total loss -65.5333137458072, train mean loss 0.00013381336651594266, test mean loss [0.00016687 0.00016682 0.00017904 0.00016737 0.0001684  0.00017207
 0.00015002]
Model epoch 201: train total loss -65.57135436397029, train mean loss 0.00014353073536624826, test mean loss [0.00015979 0.00017118 0.00018037 0.00017048 0.00016208 0.0001715
 0.00015117]
Model epoch 202: train total loss -65.61369533374939, train mean loss 0.00013967071943073425, test mean loss [0.00015808 0.00016082 0.00018233 0.00016801 0.0001748  0.00016563
 0.00015311]
Model epoch 203: train total loss -65.49636619348576, train mean loss 0.00013635108762740386, test mean loss [0.00015684 0.00016171 0.00018149 0.00016593 0.00016762 0.00017391
 0.00016112]
Model epoch 204: train total loss -65.62865133552162, train mean loss 0.0001343064240915746, test mean loss [0.00015875 0.00016241 0.00017959 0.00016068 0.00017556 0.00016618
 0.00015566]
Model epoch 205: train total loss -65.58818315502761, train mean loss 0.00013798858327138586, test mean loss [0.00015795 0.00017868 0.00018244 0.00017161 0.00016429 0.00017398
 0.00015056]
Model epoch 206: train total loss -65.58078667903852, train mean loss 0.000141397251412029, test mean loss [0.00015456 0.00017656 0.00018065 0.000171   0.0001576  0.00016647
 0.0001527 ]
Model epoch 207: train total loss -65.6392083597512, train mean loss 0.00014177958272079918, test mean loss [0.00015169 0.00016868 0.00017924 0.00017082 0.0001604  0.00016837
 0.00015239]
Model epoch 208: train total loss -65.33913780255048, train mean loss 0.00014430863112416335, test mean loss [0.00015657 0.00017497 0.00018144 0.00016376 0.0001594  0.00016397
 0.00015692]
Model epoch 209: train total loss -65.44003078874326, train mean loss 0.00012621794666186625, test mean loss [0.0001567  0.00015988 0.00017868 0.00018172 0.00015685 0.00018329
 0.00015135]
Model epoch 210: train total loss -65.4159325043474, train mean loss 0.0001435231221280079, test mean loss [0.0001523  0.00017269 0.00017939 0.00017227 0.00016201 0.00019036
 0.00015451]
Model epoch 211: train total loss -65.56634308844083, train mean loss 0.00013764220977217708, test mean loss [0.0001585  0.00016012 0.00017438 0.00017313 0.00016867 0.00016259
 0.0001701 ]
Model epoch 212: train total loss -65.50456557364937, train mean loss 0.00014045378518691087, test mean loss [0.00015267 0.0001628  0.00018191 0.00016623 0.00016668 0.00015996
 0.00014888]
Model epoch 213: train total loss -65.42946221809625, train mean loss 0.00012569871049258918, test mean loss [0.00015646 0.00015981 0.00017806 0.00016048 0.00016036 0.00017118
 0.00015561]
Model epoch 214: train total loss -65.58512243979003, train mean loss 0.00013310816953229117, test mean loss [0.00015862 0.00016765 0.00017558 0.00015904 0.00016515 0.00017212
 0.00014804]
Model epoch 215: train total loss -65.56444317339061, train mean loss 0.00013240734969594497, test mean loss [0.00015076 0.00015297 0.00017777 0.00015963 0.00016832 0.00016471
 0.00014873]
Model epoch 216: train total loss -65.64971835782302, train mean loss 0.000142547900128181, test mean loss [0.00015113 0.00015128 0.00017173 0.00016063 0.00016384 0.00016248
 0.00014457]
Model epoch 217: train total loss -65.67626393368617, train mean loss 0.00012982291046321806, test mean loss [0.00015774 0.0001535  0.00017275 0.00016515 0.00015823 0.00016545
 0.00014842]
Model epoch 218: train total loss -65.68083925100382, train mean loss 0.00012757409156297756, test mean loss [0.00014665 0.00015235 0.00016794 0.00016232 0.00015793 0.00016693
 0.00014537]
Model epoch 219: train total loss -65.64680915952752, train mean loss 0.00013223780054836046, test mean loss [0.00014776 0.00015628 0.00016825 0.00016157 0.00016278 0.00016563
 0.00014451]
Model epoch 220: train total loss -65.79780429896132, train mean loss 0.00013509465755795342, test mean loss [0.00014583 0.00015378 0.00017213 0.00015635 0.00016393 0.00015503
 0.0001449 ]
Model epoch 221: train total loss -65.42245580412266, train mean loss 0.00012943047854512815, test mean loss [0.00015449 0.0001536  0.00017329 0.00016035 0.00015819 0.00015997
 0.00014624]
Model epoch 222: train total loss -65.43583522984176, train mean loss 0.00013221227003197176, test mean loss [0.00014964 0.00015979 0.00017207 0.00016383 0.00016591 0.00016459
 0.00014516]
Model epoch 223: train total loss -65.66262564284077, train mean loss 0.0001282289402074428, test mean loss [0.00015038 0.00016077 0.00016802 0.00016237 0.00015524 0.00016583
 0.00014425]
Model epoch 224: train total loss -65.70098492117896, train mean loss 0.00012359980175830003, test mean loss [0.00014299 0.00016054 0.00016586 0.0001576  0.00016387 0.00015837
 0.00014639]
Model epoch 225: train total loss -65.76330551905608, train mean loss 0.00012486739935409273, test mean loss [0.00014572 0.00015078 0.00017326 0.00015665 0.00015673 0.00015358
 0.00014917]
Model epoch 226: train total loss -65.63795729385993, train mean loss 0.00012188418686102153, test mean loss [0.0001493  0.00015102 0.00016473 0.00015585 0.00016508 0.00016664
 0.00014555]
Model epoch 227: train total loss -65.56266614549192, train mean loss 0.00013037438070764306, test mean loss [0.00014686 0.00015749 0.00017151 0.00015603 0.0001603  0.00015625
 0.0001426 ]
Model epoch 228: train total loss -65.40308453110258, train mean loss 0.00013419639504826586, test mean loss [0.00014148 0.00015532 0.0001645  0.00016475 0.00015288 0.00015855
 0.00015068]
Model epoch 229: train total loss -65.79866962475766, train mean loss 0.00012891239864972856, test mean loss [0.00014929 0.00015903 0.00016652 0.00016222 0.00015187 0.00015171
 0.0001459 ]
Model epoch 230: train total loss -65.82571537004323, train mean loss 0.000124943815086017, test mean loss [0.00015056 0.00014576 0.00016017 0.00015502 0.00014928 0.00015702
 0.0001464 ]
Model epoch 231: train total loss -65.47406406378094, train mean loss 0.00013758897316425479, test mean loss [0.0001494  0.00014834 0.0001653  0.00016474 0.00015635 0.00017755
 0.00014552]
Model epoch 232: train total loss -65.74942639054068, train mean loss 0.0001262661485394168, test mean loss [0.00014613 0.00014739 0.00016357 0.00015636 0.00014968 0.00015476
 0.00014016]
Model epoch 233: train total loss -65.74054405016875, train mean loss 0.0001320416004193209, test mean loss [0.00014525 0.00014958 0.00016437 0.0001619  0.00015054 0.00015056
 0.00014308]
Model epoch 234: train total loss -65.71015016749362, train mean loss 0.00012640320242002326, test mean loss [0.0001419  0.00014756 0.00017712 0.00015688 0.00014524 0.0001651
 0.00015014]
Model epoch 235: train total loss -65.69399735712022, train mean loss 0.00012822024279783163, test mean loss [0.00014503 0.00014692 0.00018095 0.00015802 0.0001539  0.00015636
 0.00015346]
Model epoch 236: train total loss -65.62736632463263, train mean loss 0.00012689618370940103, test mean loss [0.00014385 0.00014296 0.00016973 0.0001587  0.00014703 0.00016085
 0.00014116]
Model epoch 237: train total loss -65.73894453732966, train mean loss 0.00012858745613577812, test mean loss [0.00014875 0.0001508  0.0001683  0.00015676 0.00015604 0.00015622
 0.00014538]
Model epoch 238: train total loss -65.64721692744007, train mean loss 0.00012896852699154592, test mean loss [0.00014727 0.00014666 0.00016459 0.0001512  0.00015408 0.00015837
 0.00013808]
Model epoch 239: train total loss -65.62341290606274, train mean loss 0.00013339051878479295, test mean loss [0.00014184 0.00014748 0.00017256 0.00015208 0.000157   0.00015653
 0.00014171]
Model epoch 240: train total loss -65.79455319295633, train mean loss 0.0001190951142142044, test mean loss [0.0001383  0.00014385 0.00016221 0.00015392 0.00015019 0.00015985
 0.00014164]
Model epoch 241: train total loss -65.8307615596644, train mean loss 0.0001241085939090176, test mean loss [0.0001457  0.00014046 0.00016044 0.00015083 0.00014919 0.00015926
 0.00013625]
Model epoch 242: train total loss -65.73274105774706, train mean loss 0.00013414039377856665, test mean loss [0.00014561 0.00014827 0.00016051 0.00015406 0.00014606 0.00016079
 0.00014144]
Model epoch 243: train total loss -65.74617746350488, train mean loss 0.00012832081097755444, test mean loss [0.00013914 0.00014088 0.00016201 0.00015232 0.00014842 0.00015632
 0.000139  ]
Model epoch 244: train total loss -65.61894206178319, train mean loss 0.00013227036057404117, test mean loss [0.00014647 0.0001482  0.0001648  0.00015343 0.00015048 0.00015891
 0.00013581]
Model epoch 245: train total loss -65.87874655558718, train mean loss 0.00011326678700348377, test mean loss [0.00014239 0.00014332 0.00016122 0.00015781 0.00015598 0.00015099
 0.00014223]
Model epoch 246: train total loss -65.83700082797608, train mean loss 0.00011673877146260667, test mean loss [0.00014376 0.00014274 0.00016822 0.00015034 0.00015387 0.00015676
 0.00013615]
Model epoch 247: train total loss -65.78696323014815, train mean loss 0.0001270890586741439, test mean loss [0.00014076 0.00014622 0.00016153 0.00015496 0.00014721 0.00014968
 0.00013957]
Model epoch 248: train total loss -65.88210822287634, train mean loss 0.00012226261216299953, test mean loss [0.00013569 0.00014019 0.00016422 0.00014946 0.00014884 0.00015152
 0.00013742]
Model epoch 249: train total loss -65.83003856830716, train mean loss 0.00012763750867237408, test mean loss [0.00014404 0.00015609 0.00015909 0.00015485 0.00015141 0.00014882
 0.00014383]
Model epoch 250: train total loss -65.72347544392261, train mean loss 0.00012722355469495255, test mean loss [0.00014588 0.00014314 0.00015952 0.00015394 0.00015134 0.00015484
 0.00014191]
Model epoch 251: train total loss -65.73920861840409, train mean loss 0.00013595482651585465, test mean loss [0.00014307 0.00013797 0.00016164 0.00015199 0.00014628 0.00015603
 0.00013794]
Model epoch 252: train total loss -65.66333246176329, train mean loss 0.00013898851853070952, test mean loss [0.00014471 0.00015781 0.00015923 0.00015358 0.00015759 0.00015301
 0.00014103]
Model epoch 253: train total loss -65.74771070398192, train mean loss 0.00011598191918067008, test mean loss [0.00013742 0.00014622 0.00015928 0.00014961 0.00014881 0.00015492
 0.00013895]
Model epoch 254: train total loss -65.70636821967406, train mean loss 0.0001289786059064263, test mean loss [0.0001474  0.00013592 0.00015588 0.0001524  0.00014574 0.00014947
 0.00013592]
Model epoch 255: train total loss -65.64101743642063, train mean loss 0.00012818589373478264, test mean loss [0.00014319 0.00014647 0.00016291 0.00015089 0.0001471  0.000159
 0.00013751]
Model epoch 256: train total loss -65.67719843660458, train mean loss 0.0001229521819090035, test mean loss [0.00013849 0.00013799 0.00015882 0.0001495  0.00014774 0.0001528
 0.00013175]
Model epoch 257: train total loss -65.8278725782715, train mean loss 0.00011922450892407366, test mean loss [0.00014125 0.00015097 0.00016403 0.00014672 0.00014548 0.00014058
 0.00013456]
Model epoch 258: train total loss -65.81199618428253, train mean loss 0.00012535962046546356, test mean loss [0.00013709 0.00013696 0.00016913 0.00015283 0.00014596 0.00015161
 0.00013495]
Model epoch 259: train total loss -65.81788661206221, train mean loss 0.0001224195550874617, test mean loss [0.00013869 0.00014532 0.00016171 0.00014351 0.00015088 0.0001438
 0.0001399 ]
Model epoch 260: train total loss -65.91475548563045, train mean loss 0.00012343851397767782, test mean loss [0.0001349  0.00013834 0.00015069 0.00015414 0.00014256 0.00014478
 0.0001442 ]
Model epoch 261: train total loss -65.82231177466063, train mean loss 0.00012154632194897321, test mean loss [0.00013355 0.00014511 0.00016139 0.00014934 0.00013935 0.00014323
 0.00013983]
Model epoch 262: train total loss -66.09318138654753, train mean loss 0.00011479064581662192, test mean loss [0.00013807 0.00014295 0.00015174 0.00014747 0.00014793 0.00014269
 0.0001299 ]
Model epoch 263: train total loss -65.9347313217632, train mean loss 0.00012538744604749386, test mean loss [0.00014312 0.00013764 0.00015351 0.0001449  0.00014449 0.00014317
 0.00013499]
Model epoch 264: train total loss -65.85102162864717, train mean loss 0.0001230854389038463, test mean loss [0.00014015 0.00014285 0.00015806 0.00014786 0.00014726 0.00014565
 0.00013618]
Model epoch 265: train total loss -65.87605990201867, train mean loss 0.00011235576329220024, test mean loss [0.00013636 0.00013754 0.00016435 0.0001471  0.00013946 0.00015009
 0.00013428]
Model epoch 266: train total loss -65.84371892907542, train mean loss 0.00012743001615008866, test mean loss [0.00014095 0.00014164 0.00015749 0.00014866 0.00013723 0.00015348
 0.00013106]
Model epoch 267: train total loss -66.08849091984641, train mean loss 0.00012123161297972532, test mean loss [0.00013401 0.00013493 0.00015287 0.00014977 0.00014541 0.0001412
 0.0001286 ]
Model epoch 268: train total loss -65.78591726318764, train mean loss 0.00012120227490852377, test mean loss [0.00013562 0.00013892 0.00015447 0.00014647 0.00014727 0.00014783
 0.00013513]
Model epoch 269: train total loss -65.94453481188263, train mean loss 0.00011690322823021149, test mean loss [0.00012938 0.00013604 0.00015795 0.00014705 0.00014196 0.0001451
 0.00013705]
Model epoch 270: train total loss -65.88984189587856, train mean loss 0.00011343920333985393, test mean loss [0.00013588 0.00014854 0.00015901 0.00014702 0.00015838 0.00014122
 0.00013465]
Model epoch 271: train total loss -65.74304417351763, train mean loss 0.00012242953640657518, test mean loss [0.00013508 0.00014368 0.00015317 0.00014058 0.00014248 0.00014374
 0.00013627]
Model epoch 272: train total loss -65.75798451838877, train mean loss 0.00011872292483362394, test mean loss [0.00012762 0.00014494 0.00015337 0.00015329 0.0001457  0.00014525
 0.0001266 ]
Model epoch 273: train total loss -65.92431149536927, train mean loss 0.00011217038342329343, test mean loss [0.00013622 0.0001349  0.00015158 0.00014803 0.00014426 0.00015468
 0.00012875]
Model epoch 274: train total loss -65.89387477093328, train mean loss 0.00011215058888611401, test mean loss [0.00013328 0.00013622 0.00014873 0.00014445 0.0001417  0.00014709
 0.00014055]
Model epoch 275: train total loss -65.91110390333037, train mean loss 0.000123779632061822, test mean loss [0.00013529 0.00013922 0.00014766 0.00014545 0.00013664 0.00014891
 0.00013396]
Model epoch 276: train total loss -65.9168093303125, train mean loss 0.0001189272053247861, test mean loss [0.00013171 0.00013682 0.00014895 0.00014127 0.00013865 0.00014613
 0.0001398 ]
Model epoch 277: train total loss -65.8936715594898, train mean loss 0.0001162842738404807, test mean loss [0.00013174 0.00012987 0.0001531  0.0001418  0.00015127 0.00014219
 0.00013388]
Model epoch 278: train total loss -65.81325985918532, train mean loss 0.00010753678208123356, test mean loss [0.00013153 0.00014118 0.00014775 0.00013997 0.00014684 0.00014923
 0.00013616]
Model epoch 279: train total loss -65.76659993315326, train mean loss 0.00011989222813983479, test mean loss [0.00013101 0.00013421 0.00015928 0.00013845 0.00015064 0.00014208
 0.00013016]
Model epoch 280: train total loss -65.96592761488047, train mean loss 0.00011441738022282227, test mean loss [0.00013737 0.00013716 0.00015906 0.00014367 0.00014518 0.00013863
 0.00013272]
Model epoch 281: train total loss -65.89938459687346, train mean loss 0.00011787129367173965, test mean loss [0.00012868 0.00013742 0.00015339 0.00014068 0.0001428  0.00014603
 0.00013385]
Model epoch 282: train total loss -65.80858261029522, train mean loss 0.00011794307027256971, test mean loss [0.00013278 0.0001408  0.00014817 0.00014091 0.00014117 0.00014647
 0.00013375]
Model epoch 283: train total loss -65.79008602045971, train mean loss 0.00010946395106622162, test mean loss [0.00013198 0.00012844 0.0001507  0.00014969 0.00014552 0.00014099
 0.00013107]
Model epoch 284: train total loss -65.72344772869796, train mean loss 0.00012371212525447934, test mean loss [0.00013565 0.00013767 0.00015073 0.00014036 0.0001655  0.00014017
 0.00015036]
Model epoch 285: train total loss -65.91693422857199, train mean loss 0.00012472017158425037, test mean loss [0.00013822 0.00013891 0.00015257 0.00014044 0.00013716 0.00014403
 0.00013322]
Model epoch 286: train total loss -65.73537532582858, train mean loss 0.00012951395220088375, test mean loss [0.0001293  0.00014921 0.00015583 0.00014134 0.00014481 0.00014154
 0.0001275 ]
Model epoch 287: train total loss -66.00372358354633, train mean loss 0.00011381262734598683, test mean loss [0.0001323  0.00013169 0.00014819 0.00014318 0.00013961 0.00013926
 0.00013157]
Model epoch 288: train total loss -65.8670362029938, train mean loss 0.00011272125073037051, test mean loss [0.00012898 0.00013314 0.00015309 0.00013799 0.00014119 0.00013546
 0.00013027]
Model epoch 289: train total loss -65.98012480960317, train mean loss 0.00011299464582027906, test mean loss [0.00013811 0.0001341  0.0001532  0.00013478 0.00014358 0.00014487
 0.0001352 ]
Model epoch 290: train total loss -65.9216908040266, train mean loss 0.00010885927343219554, test mean loss [0.00013241 0.0001394  0.00014859 0.00013695 0.00013852 0.00013708
 0.00013088]
Model epoch 291: train total loss -66.06659000990408, train mean loss 0.00011839494207922601, test mean loss [0.00012974 0.00013254 0.00015508 0.00014021 0.00013849 0.00013386
 0.00013281]
Model epoch 292: train total loss -65.9324944093379, train mean loss 0.0001181829593103807, test mean loss [0.00013566 0.00013604 0.00014624 0.00013924 0.00013627 0.00014025
 0.000123  ]
Model epoch 293: train total loss -65.96999869664373, train mean loss 0.0001188714078014839, test mean loss [0.00012626 0.00012985 0.00014251 0.00014416 0.00013404 0.00014161
 0.00013459]
Model epoch 294: train total loss -65.87620562495201, train mean loss 0.00012140715804607681, test mean loss [0.00012794 0.00013768 0.00015027 0.00013714 0.0001447  0.00013368
 0.00012747]
Model epoch 295: train total loss -66.13124068825104, train mean loss 0.00011094450901484685, test mean loss [0.00013213 0.00013185 0.00014737 0.00014619 0.00013568 0.00013738
 0.00012783]
Model epoch 296: train total loss -66.13242880355496, train mean loss 0.00010795781498663216, test mean loss [0.00012756 0.00013039 0.00015199 0.00013528 0.00013783 0.00013989
 0.00013003]
Model epoch 297: train total loss -65.97065097152944, train mean loss 0.0001221189053711376, test mean loss [0.00012638 0.00013358 0.00014791 0.00013283 0.00013857 0.00014037
 0.00013438]
Model epoch 298: train total loss -65.93888480137693, train mean loss 0.00011388663002616518, test mean loss [0.00012859 0.00013068 0.00015025 0.00013865 0.00013822 0.00013935
 0.00012939]
Model epoch 299: train total loss -65.85757144256029, train mean loss 0.0001136395751179223, test mean loss [0.00013047 0.00013741 0.00015373 0.00014361 0.00013817 0.00015108
 0.00012582]
Model epoch 300: train total loss -65.70606417105226, train mean loss 0.00011249255337936477, test mean loss [0.0001333  0.00014278 0.00014942 0.00014957 0.00013742 0.00014234
 0.00012774]
Model epoch 301: train total loss -65.75808294260588, train mean loss 0.0001176535193487894, test mean loss [0.00013048 0.00013366 0.00015369 0.00014384 0.00014081 0.0001383
 0.00013152]
Model epoch 302: train total loss -65.95704565977044, train mean loss 0.00011509969379939821, test mean loss [0.00013137 0.00013287 0.00014654 0.00013717 0.00013735 0.00013966
 0.00013306]
Model epoch 303: train total loss -65.9619686366435, train mean loss 0.00011082854567264099, test mean loss [0.00012706 0.00012869 0.00014951 0.0001354  0.00014009 0.00014248
 0.0001297 ]
Model trained in 304 epochs with 4000 transitions.
[2025-01-23 14:20:41,558][absl][INFO] - {'eval/walltime': 165.7156686782837, 'training/sps': 0.34521256491273167, 'training/walltime': 6842.819850206375, 'training/model_train_time': 1744.9005010128021, 'training/other_time': 1151.0259792804718, 'training/model_horizon': 6, 'training/hallucination_updates_per_training_step': 752, 'training/env_buffer_size': Array(5000, dtype=int32), 'model/train_total_loss': Array(-65.96196864, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00011083, dtype=float64), 'model/test_total_loss': Array(-65.39630131, dtype=float64), 'model/test_mean_loss': Array(0.00013613, dtype=float64), 'model/train_epochs': 304, 'model/sec_per_epoch': 5.733392763294671, 'sac/actor_loss': Array(-17.7619132, dtype=float64), 'sac/alpha': Array(0.02825089, dtype=float32), 'sac/alpha_loss': Array(2.25097102e-05, dtype=float64), 'sac/buffer_current_size': Array(400000., dtype=float32), 'sac/critic_loss': Array(0.01613998, dtype=float64), 'eval/episode_forward_vel': Array(-35.609012, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-4.86653552, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(5.50953098, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.02518936, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-15.31570409, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(4.9965047, dtype=float64), 'eval/episode_rew_roll': Array(5.44134983, dtype=float64), 'eval/episode_rew_side_motion': Array(5.70269886, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(7.38206064, dtype=float64), 'eval/episode_rew_yaw': Array(10.64707403, dtype=float64), 'eval/episode_rew_z_vel_change': Array(3.0947652, dtype=float64), 'eval/episode_reward': Array(21.53202946, dtype=float64), 'eval/episode_step_count': Array(6216., dtype=float64), 'eval/avg_episode_length': Array(112., dtype=float64), 'eval/epoch_eval_time': 30.635323524475098, 'eval/sps': 32.64205776058093}
Steps / Eval:  5000.0
Reward is  21.53202946092269
Model horizon updated to 8.
Hallucination updates per training step updated to 1000.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -28.734546198334062, train mean loss 0.08209010561060137, test mean loss [0.06494646 0.04356712 0.07246039 0.07825761 0.14705102 0.07888513
 0.19865567]
Model epoch 1: train total loss -35.78760432138996, train mean loss 0.0355806742262735, test mean loss [0.02406946 0.03624901 0.03844977 0.0369096  0.03355064 0.04459839
 0.0332498 ]
Model epoch 2: train total loss -41.26908209925746, train mean loss 0.027694521397647172, test mean loss [0.02193136 0.03306702 0.02674319 0.03023615 0.02996537 0.02997545
 0.02902099]
Model epoch 3: train total loss -45.40554367366057, train mean loss 0.02366388006254269, test mean loss [0.02005015 0.03317049 0.02042595 0.02519448 0.02509538 0.02481813
 0.02604684]
Model epoch 4: train total loss -48.71690742186781, train mean loss 0.02046195320334335, test mean loss [0.01789584 0.02873751 0.01617085 0.02206604 0.01962603 0.0211027
 0.02104038]
Model epoch 5: train total loss -51.13641083657805, train mean loss 0.016447623967128996, test mean loss [0.01531773 0.02358143 0.01218976 0.01818596 0.01538422 0.01803414
 0.01776816]
Model epoch 6: train total loss -52.91695472051904, train mean loss 0.013156467153087412, test mean loss [0.01298309 0.02017129 0.00961763 0.01502081 0.01248574 0.01535834
 0.01504489]
Model epoch 7: train total loss -54.35573533461119, train mean loss 0.011118975792952413, test mean loss [0.01099963 0.01751698 0.00772036 0.01259612 0.01026371 0.01245793
 0.01270582]
Model epoch 8: train total loss -54.94711603482436, train mean loss 0.009796570364442973, test mean loss [0.00933531 0.01516144 0.0063985  0.01067488 0.00874394 0.01039997
 0.01063881]
Model epoch 9: train total loss -55.92952590531615, train mean loss 0.0077844438058314565, test mean loss [0.00785034 0.01344854 0.00533024 0.00898116 0.00744753 0.00830253
 0.0089977 ]
Model epoch 10: train total loss -56.49996179261971, train mean loss 0.006253449056428615, test mean loss [0.00657331 0.01200641 0.00447964 0.00757043 0.0063058  0.0069557
 0.00784196]
Model epoch 11: train total loss -57.18172579601149, train mean loss 0.005641158745576013, test mean loss [0.00548539 0.0105365  0.00391409 0.00644274 0.0054792  0.00580592
 0.00654375]
Model epoch 12: train total loss -57.56683909208884, train mean loss 0.005042896984011721, test mean loss [0.00463978 0.00912573 0.0034485  0.00573305 0.004785   0.00497678
 0.00545379]
Model epoch 13: train total loss -57.993784626837964, train mean loss 0.004185817014618309, test mean loss [0.00411103 0.00789969 0.00298849 0.00512046 0.00426866 0.00423097
 0.00461699]
Model epoch 14: train total loss -58.55937196834589, train mean loss 0.004223193841031422, test mean loss [0.00368949 0.00709855 0.00271503 0.00448972 0.00383273 0.00368548
 0.004165  ]
Model epoch 15: train total loss -58.95079035080194, train mean loss 0.0031964413489381704, test mean loss [0.00333971 0.00609636 0.00241898 0.00407603 0.00351543 0.00329292
 0.00371236]
Model epoch 16: train total loss -59.185886170280895, train mean loss 0.0031385465645920913, test mean loss [0.00303159 0.00557903 0.00225581 0.00361562 0.0032087  0.00300328
 0.00340096]
Model epoch 17: train total loss -59.41449082342513, train mean loss 0.0029209496240904602, test mean loss [0.00278003 0.00485958 0.00205936 0.00336883 0.00306457 0.00274899
 0.00306663]
Model epoch 18: train total loss -59.44062290599492, train mean loss 0.0025876696379054484, test mean loss [0.00260083 0.00437658 0.00185894 0.00316073 0.00275599 0.00254187
 0.00287211]
Model epoch 19: train total loss -59.63005560765334, train mean loss 0.0025784978235110535, test mean loss [0.0024195  0.00403419 0.0017507  0.00294936 0.00259523 0.002323
 0.00269862]
Model epoch 20: train total loss -60.27032377237047, train mean loss 0.002426902444303216, test mean loss [0.00230082 0.0035255  0.00164762 0.00275375 0.00243938 0.00220597
 0.00250894]
Model epoch 21: train total loss -60.43333753797675, train mean loss 0.0022571048211944295, test mean loss [0.00226627 0.0033086  0.0015519  0.00263051 0.00233957 0.00210556
 0.00236617]
Model epoch 22: train total loss -60.52595801589152, train mean loss 0.001909756000736054, test mean loss [0.00210586 0.00309259 0.00143876 0.00249357 0.00218581 0.00193631
 0.00229705]
Model epoch 23: train total loss -60.93319241034196, train mean loss 0.001915243943595748, test mean loss [0.00194275 0.00300537 0.00138494 0.00238062 0.00203829 0.00184015
 0.00216886]
Model epoch 24: train total loss -60.7690149799676, train mean loss 0.0017193169015405772, test mean loss [0.00184246 0.00281719 0.00131832 0.00222904 0.00193673 0.00171738
 0.00202021]
Model epoch 25: train total loss -60.776349665558925, train mean loss 0.001797632969758311, test mean loss [0.00172249 0.00263189 0.00129274 0.00209296 0.0018599  0.00165471
 0.00193918]
Model epoch 26: train total loss -60.96736055660981, train mean loss 0.0016848400163225275, test mean loss [0.0016925  0.00250113 0.0012174  0.00201116 0.00178405 0.0015373
 0.00186811]
Model epoch 27: train total loss -61.311292180060974, train mean loss 0.0015451771920289832, test mean loss [0.00156753 0.00241797 0.00118995 0.00195829 0.00167129 0.00146707
 0.00172613]
Model epoch 28: train total loss -61.277653164610044, train mean loss 0.0014621657006362691, test mean loss [0.00147913 0.00229824 0.00108171 0.00191152 0.00160605 0.00141002
 0.00169176]
Model epoch 29: train total loss -61.44175376076128, train mean loss 0.0013681816760267955, test mean loss [0.00140617 0.00219562 0.001049   0.0017572  0.00155974 0.0013184
 0.00155714]
Model epoch 30: train total loss -61.63379441785748, train mean loss 0.0013265415595947788, test mean loss [0.00142185 0.00208665 0.00101351 0.00174205 0.00147989 0.0012797
 0.00146847]
Model epoch 31: train total loss -61.91382522506723, train mean loss 0.001180641622681765, test mean loss [0.00133872 0.00204813 0.00100364 0.00161472 0.0014901  0.00126523
 0.00139558]
Model epoch 32: train total loss -61.718316818914055, train mean loss 0.001160967780334071, test mean loss [0.00125485 0.00196913 0.00096819 0.00160424 0.00134804 0.00120901
 0.00137701]
Model epoch 33: train total loss -61.96543387188279, train mean loss 0.0012710483466371247, test mean loss [0.00122516 0.00192265 0.0009345  0.00152104 0.00129868 0.00114965
 0.00131045]
Model epoch 34: train total loss -61.75571736624338, train mean loss 0.0011451810946901606, test mean loss [0.00121475 0.00186946 0.00089121 0.00147972 0.00134375 0.00108266
 0.00129759]
Model epoch 35: train total loss -62.14007960374275, train mean loss 0.0011516408500366387, test mean loss [0.00116147 0.00177475 0.0008622  0.00142988 0.00124015 0.0010343
 0.00119354]
Model epoch 36: train total loss -62.12289869369977, train mean loss 0.0009751227894420947, test mean loss [0.00113199 0.00173013 0.00082716 0.00136426 0.0011227  0.00098788
 0.00112561]
Model epoch 37: train total loss -62.26103620916705, train mean loss 0.0009361712601239445, test mean loss [0.00107937 0.00169421 0.00084983 0.0013406  0.00117336 0.00100082
 0.00110456]
Model epoch 38: train total loss -62.173738321438215, train mean loss 0.001112752879538108, test mean loss [0.00106722 0.001637   0.00080611 0.0012845  0.00111027 0.00093127
 0.00106358]
Model epoch 39: train total loss -62.2755661314032, train mean loss 0.0008955216089794921, test mean loss [0.00101723 0.00158247 0.00077648 0.00127383 0.00103789 0.00093298
 0.00100247]
Model epoch 40: train total loss -62.48308472692919, train mean loss 0.0010230696591915674, test mean loss [0.00098027 0.00154989 0.00078766 0.00122994 0.00100594 0.00089858
 0.0009932 ]
Model epoch 41: train total loss -62.65729001661283, train mean loss 0.0008831207984504408, test mean loss [0.00096012 0.00152239 0.00073199 0.00118435 0.00099658 0.00086732
 0.00095491]
Model epoch 42: train total loss -62.74300992464186, train mean loss 0.0006965321938109855, test mean loss [0.00095527 0.0015084  0.00073078 0.00117711 0.00096073 0.0008197
 0.0009443 ]
Model epoch 43: train total loss -62.866802206315775, train mean loss 0.0007939140421642487, test mean loss [0.00089641 0.00145951 0.00069978 0.00113518 0.00090199 0.00079455
 0.00089526]
Model epoch 44: train total loss -62.72266559066589, train mean loss 0.0008142627143279329, test mean loss [0.00089969 0.00144465 0.00067644 0.00111631 0.0008862  0.00081717
 0.00084494]
Model epoch 45: train total loss -62.71156188662348, train mean loss 0.0008409272850261699, test mean loss [0.00087659 0.00136448 0.00068971 0.00433247 0.00087381 0.00077431
 0.00081632]
Model epoch 46: train total loss -62.60240318661453, train mean loss 0.0013249266711067252, test mean loss [0.00084318 0.00137473 0.00067278 0.00316537 0.00082039 0.00073016
 0.00077957]
Model epoch 47: train total loss -62.73335834079996, train mean loss 0.0009686881323188691, test mean loss [0.00080263 0.00134472 0.00064487 0.00178689 0.00084389 0.00073029
 0.00076963]
Model epoch 48: train total loss -62.767389662664264, train mean loss 0.0008084946540907814, test mean loss [0.00079535 0.00133313 0.00062885 0.00144765 0.0008075  0.00071563
 0.00074557]
Model epoch 49: train total loss -62.70562652146616, train mean loss 0.0007088593772291243, test mean loss [0.00078364 0.00128376 0.00067124 0.00123261 0.00078556 0.00068528
 0.00071367]
Model epoch 50: train total loss -63.09519269987654, train mean loss 0.0006522775592312024, test mean loss [0.00076209 0.00129156 0.00063176 0.00111625 0.00074128 0.00066158
 0.00069804]
Model epoch 51: train total loss -63.108361872956166, train mean loss 0.0006205053677165392, test mean loss [0.00073723 0.00124956 0.00060154 0.0010623  0.00074465 0.00066796
 0.00069989]
Model epoch 52: train total loss -63.21338220442606, train mean loss 0.0006915411049154968, test mean loss [0.000739   0.00120552 0.00056804 0.0009766  0.00073061 0.00067989
 0.00066374]
Model epoch 53: train total loss -62.91818635563662, train mean loss 0.0006487452184626291, test mean loss [0.00072925 0.00119156 0.00055285 0.00093913 0.00071365 0.00067138
 0.00064097]
Model epoch 54: train total loss -63.43297873135712, train mean loss 0.0006516874875435986, test mean loss [0.00072012 0.00113578 0.00054704 0.00091403 0.00068439 0.0006379
 0.00062185]
Model epoch 55: train total loss -63.13918147775996, train mean loss 0.0005895894342528184, test mean loss [0.00068467 0.0011272  0.00055481 0.00088914 0.00070384 0.00060601
 0.00060823]
Model epoch 56: train total loss -63.09670116070145, train mean loss 0.0006281986131139813, test mean loss [0.00068054 0.00108408 0.00053329 0.00084282 0.00067671 0.00061259
 0.00058292]
Model epoch 57: train total loss -63.301645717080014, train mean loss 0.0006141315039585741, test mean loss [0.00067972 0.00107469 0.00050638 0.00081946 0.00064397 0.00058969
 0.00058959]
Model epoch 58: train total loss -63.37856694475805, train mean loss 0.0005984237757143429, test mean loss [0.00066278 0.0010637  0.00049906 0.00083762 0.00064961 0.00057921
 0.00054545]
Model epoch 59: train total loss -63.424690989919235, train mean loss 0.0005541842032866516, test mean loss [0.00065792 0.00102339 0.00051475 0.00081231 0.00063902 0.00056699
 0.00054407]
Model epoch 60: train total loss -63.55073964356023, train mean loss 0.0005607217963684987, test mean loss [0.00064774 0.00101782 0.00048687 0.00077387 0.00061721 0.00054347
 0.0005259 ]
Model epoch 61: train total loss -63.363873684984426, train mean loss 0.0004938269711841617, test mean loss [0.00063625 0.00099268 0.00048893 0.00075911 0.00059005 0.00056425
 0.00051041]
Model epoch 62: train total loss -63.25313805017441, train mean loss 0.0005762168890331258, test mean loss [0.00063695 0.00097452 0.00048612 0.00075081 0.00059999 0.00053876
 0.00053399]
Model epoch 63: train total loss -63.35735204213517, train mean loss 0.0004792803819490504, test mean loss [0.0006089  0.00097482 0.0004754  0.00071183 0.0005741  0.00053499
 0.00049152]
Model epoch 64: train total loss -63.499976876574344, train mean loss 0.0005011885880627032, test mean loss [0.00061829 0.00098298 0.00048417 0.00070432 0.00057825 0.00053862
 0.00048038]
Model epoch 65: train total loss -63.429197392444955, train mean loss 0.0005064340284818963, test mean loss [0.00059074 0.00094186 0.0004878  0.0007106  0.00058469 0.00051482
 0.00047481]
Model epoch 66: train total loss -63.6396091016972, train mean loss 0.0004911068104393405, test mean loss [0.00061419 0.00089125 0.00044569 0.00069714 0.0005511  0.00049638
 0.00045231]
Model epoch 67: train total loss -63.58051022846307, train mean loss 0.00038873632795987333, test mean loss [0.00058413 0.00088816 0.00045242 0.00066845 0.00057039 0.00049117
 0.00046883]
Model epoch 68: train total loss -63.46422224028209, train mean loss 0.0005331561068355863, test mean loss [0.00059312 0.00100773 0.00042741 0.00066456 0.00055821 0.00050256
 0.00045922]
Model epoch 69: train total loss -63.56058700383576, train mean loss 0.0005187515786520216, test mean loss [0.00056853 0.00084651 0.00042669 0.00064195 0.00053075 0.00051025
 0.00045588]
Model epoch 70: train total loss -63.79270352446602, train mean loss 0.0005346816353303813, test mean loss [0.00072217 0.00082913 0.00045177 0.00064986 0.00058018 0.00046676
 0.00042679]
Model epoch 71: train total loss -63.63263041440833, train mean loss 0.00040765484848262105, test mean loss [0.00055852 0.00080316 0.00041921 0.00065872 0.00052116 0.00047489
 0.00042524]
Model epoch 72: train total loss -63.42759532017384, train mean loss 0.0004505475972332925, test mean loss [0.00053854 0.00078304 0.00042127 0.00062287 0.00052751 0.00045135
 0.00043964]
Model epoch 73: train total loss -63.7578090660071, train mean loss 0.00039822421237161484, test mean loss [0.00052206 0.00081977 0.00040602 0.00062431 0.00050622 0.00045795
 0.00040919]
Model epoch 74: train total loss -63.68779099012944, train mean loss 0.0004403196875400861, test mean loss [0.00051342 0.00077269 0.00040395 0.00060288 0.00050404 0.00045576
 0.00042013]
Model epoch 75: train total loss -63.82722900592436, train mean loss 0.00039516669963762823, test mean loss [0.00051874 0.0007602  0.00040564 0.00057953 0.00057524 0.00044055
 0.00040547]
Model epoch 76: train total loss -63.714662827317696, train mean loss 0.0004448955694554263, test mean loss [0.00051625 0.00071324 0.00040602 0.00062701 0.0004797  0.00043586
 0.00038936]
Model epoch 77: train total loss -63.79405199733223, train mean loss 0.0003687812373091321, test mean loss [0.00052227 0.00068777 0.00039795 0.00058215 0.00047639 0.00041514
 0.00039608]
Model epoch 78: train total loss -63.84374890828246, train mean loss 0.0003941899546960586, test mean loss [0.00049628 0.00069672 0.00040368 0.0005575  0.00047105 0.00042105
 0.00039056]
Model epoch 79: train total loss -63.972965392370575, train mean loss 0.00042646123591066356, test mean loss [0.0004918  0.00068114 0.00039255 0.00055367 0.00048573 0.00040953
 0.0003845 ]
Model epoch 80: train total loss -64.1922835638591, train mean loss 0.0003936194774009858, test mean loss [0.00048354 0.00066584 0.00037417 0.00054785 0.00046463 0.00040994
 0.00036594]
Model epoch 81: train total loss -63.97252513358117, train mean loss 0.00039264101172817626, test mean loss [0.00048402 0.00063376 0.00038787 0.00055739 0.00045161 0.00039072
 0.00036468]
Model epoch 82: train total loss -64.10068352367487, train mean loss 0.00039058693240053287, test mean loss [0.00051592 0.00062007 0.00037352 0.0005395  0.00042999 0.0004012
 0.00041931]
Model epoch 83: train total loss -64.05690725699773, train mean loss 0.0004050621589061034, test mean loss [0.00047633 0.0006223  0.00038599 0.00052306 0.00043251 0.00039144
 0.00034125]
Model epoch 84: train total loss -64.09284854609625, train mean loss 0.0003229435611462768, test mean loss [0.00046695 0.00060806 0.00038799 0.00053224 0.00044214 0.00038724
 0.00036836]
Model epoch 85: train total loss -64.12685162019685, train mean loss 0.00035866208338402694, test mean loss [0.00045051 0.00058201 0.00037193 0.00051965 0.0004321  0.00041992
 0.00034421]
Model epoch 86: train total loss -64.2234385977141, train mean loss 0.00036378968316870915, test mean loss [0.00045089 0.00057014 0.00037188 0.00050937 0.00042326 0.0003867
 0.00035237]
Model epoch 87: train total loss -63.96609541474679, train mean loss 0.0003586924575762884, test mean loss [0.00046306 0.00056813 0.00038158 0.00052077 0.00039915 0.00037984
 0.00033713]
Model epoch 88: train total loss -64.1866228751683, train mean loss 0.00034939917428452574, test mean loss [0.0004332  0.00055669 0.00036954 0.00049329 0.00039647 0.0003826
 0.00032651]
Model epoch 89: train total loss -64.18376906450067, train mean loss 0.0003593997948833331, test mean loss [0.00042219 0.00055078 0.00035433 0.00050433 0.00044403 0.00039768
 0.00034108]
Model epoch 90: train total loss -64.17382083883278, train mean loss 0.0003514770866302804, test mean loss [0.00044657 0.00054327 0.0003602  0.00048103 0.00038669 0.00036131
 0.00034252]
Model epoch 91: train total loss -64.18884246909691, train mean loss 0.0003387010142664948, test mean loss [0.00044784 0.00051325 0.0003451  0.00048644 0.00038988 0.00037528
 0.00032903]
Model epoch 92: train total loss -64.21203399902122, train mean loss 0.000329797930850897, test mean loss [0.00042712 0.00053016 0.00034401 0.00047018 0.00037741 0.0003715
 0.00032089]
Model epoch 93: train total loss -64.32918005948922, train mean loss 0.00032244390663855216, test mean loss [0.00041125 0.00049993 0.00032855 0.00045905 0.00035982 0.00035793
 0.00031285]
Model epoch 94: train total loss -63.88800934415693, train mean loss 0.000341599094463352, test mean loss [0.00038946 0.00049554 0.00034855 0.0004649  0.00036961 0.00036526
 0.00032075]
Model epoch 95: train total loss -64.1341164593772, train mean loss 0.00030778524283141246, test mean loss [0.00042572 0.00049889 0.00033173 0.00046537 0.00037287 0.00034971
 0.00030533]
Model epoch 96: train total loss -64.29501414590814, train mean loss 0.0002791203061004227, test mean loss [0.00039764 0.00052762 0.00034552 0.00044803 0.00036541 0.00034961
 0.00031736]
Model epoch 97: train total loss -64.1541312540215, train mean loss 0.0002523536715860551, test mean loss [0.00040308 0.00047086 0.0003325  0.00043976 0.00034505 0.00033363
 0.00032969]
Model epoch 98: train total loss -64.08509402233538, train mean loss 0.00033398422972996406, test mean loss [0.00039516 0.00048527 0.00031876 0.00046117 0.00033958 0.00034998
 0.00029035]
Model epoch 99: train total loss -64.05284920596021, train mean loss 0.0003047022960626202, test mean loss [0.00039144 0.00046542 0.00032286 0.00044169 0.00034373 0.0003613
 0.00030064]
Model epoch 100: train total loss -64.38352366655707, train mean loss 0.0003184803573634603, test mean loss [0.00037811 0.00047281 0.00032696 0.00042717 0.00034344 0.00033265
 0.00030218]
Model epoch 101: train total loss -64.40193612921003, train mean loss 0.00030570228238227477, test mean loss [0.00039219 0.000461   0.00032685 0.00044236 0.00033787 0.00034509
 0.00029821]
Model epoch 102: train total loss -64.22141649529293, train mean loss 0.00029821188310304365, test mean loss [0.00038887 0.00043959 0.00032102 0.00042377 0.00032444 0.00032241
 0.00028293]
Model epoch 103: train total loss -64.1179339935291, train mean loss 0.0002998384320749652, test mean loss [0.00037098 0.00043827 0.00031085 0.00041915 0.00043497 0.00031425
 0.00030222]
Model epoch 104: train total loss -64.41454102694573, train mean loss 0.00025788931473003015, test mean loss [0.00038292 0.00045788 0.0003177  0.00041531 0.00034115 0.00033073
 0.00028649]
Model epoch 105: train total loss -64.23016981929761, train mean loss 0.00030063446954039277, test mean loss [0.00036051 0.00046352 0.00032765 0.00041076 0.00033539 0.00032476
 0.00029301]
Model epoch 106: train total loss -64.29438380154456, train mean loss 0.0003074575656515293, test mean loss [0.0003497  0.00045215 0.00031481 0.00039579 0.00032142 0.0003434
 0.00027864]
Model epoch 107: train total loss -64.35892611075666, train mean loss 0.00030408149882995737, test mean loss [0.0003631  0.00042085 0.00031166 0.00041091 0.00032812 0.00031374
 0.00028564]
Model epoch 108: train total loss -64.56092194581828, train mean loss 0.00029116152069341895, test mean loss [0.00034923 0.00041323 0.00031125 0.00040594 0.00032476 0.00030825
 0.00028083]
Model epoch 109: train total loss -64.32228259447062, train mean loss 0.0002713100752941249, test mean loss [0.00033488 0.00041926 0.00030992 0.0003951  0.00031712 0.00031899
 0.00028376]
Model epoch 110: train total loss -64.35561445573327, train mean loss 0.0002892797599730609, test mean loss [0.00035289 0.00043491 0.00030557 0.00038579 0.00030539 0.00031835
 0.000265  ]
Model epoch 111: train total loss -64.20922880253285, train mean loss 0.0002855902564386265, test mean loss [0.00033635 0.00042692 0.00030205 0.0004225  0.00030885 0.00030144
 0.00026455]
Model epoch 112: train total loss -64.66060483858992, train mean loss 0.00026997555475392616, test mean loss [0.00034557 0.00040988 0.00031379 0.00037839 0.00032024 0.00029403
 0.00028503]
Model epoch 113: train total loss -64.46188464141393, train mean loss 0.0002722208501291417, test mean loss [0.00034359 0.00040777 0.00029593 0.00038759 0.00029334 0.00029724
 0.00027218]
Model epoch 114: train total loss -64.54988722175686, train mean loss 0.00023379369487708712, test mean loss [0.00033954 0.00038449 0.00031461 0.00038453 0.00031263 0.00030224
 0.00027727]
Model epoch 115: train total loss -64.19940172816654, train mean loss 0.00028592210951673176, test mean loss [0.0003369  0.00039222 0.00029782 0.00038041 0.00029916 0.00030946
 0.00025364]
Model epoch 116: train total loss -64.47670303468121, train mean loss 0.00024829590946790853, test mean loss [0.00033899 0.00039321 0.00028859 0.00038129 0.00029725 0.00029966
 0.00025315]
Model epoch 117: train total loss -64.62774582791901, train mean loss 0.0002523230468695236, test mean loss [0.00032057 0.00039087 0.00029459 0.00036336 0.00028776 0.00029029
 0.00025837]
Model epoch 118: train total loss -64.4261229375739, train mean loss 0.00027624484073252503, test mean loss [0.00032344 0.00037132 0.00029089 0.00034364 0.0003118  0.00028526
 0.00025621]
Model epoch 119: train total loss -64.46540892299126, train mean loss 0.0002470739887459479, test mean loss [0.00032129 0.000382   0.00029352 0.00041159 0.00029008 0.00030314
 0.00027422]
Model epoch 120: train total loss -64.61245583405525, train mean loss 0.00027548240350722754, test mean loss [0.00031381 0.00037346 0.00029862 0.00036823 0.00029424 0.00028748
 0.00024971]
Model epoch 121: train total loss -64.5918776277138, train mean loss 0.00027226515047081506, test mean loss [0.0003142  0.00042246 0.00027991 0.00034701 0.00028443 0.0002771
 0.00025664]
Model epoch 122: train total loss -64.39448897644647, train mean loss 0.000279170372708519, test mean loss [0.00032641 0.00038959 0.00029803 0.00034345 0.00029171 0.00026724
 0.00025405]
Model epoch 123: train total loss -64.62983435237406, train mean loss 0.000260050929562963, test mean loss [0.00032173 0.00036977 0.0003128  0.00035106 0.00027266 0.00027273
 0.00024714]
Model epoch 124: train total loss -64.62403563468007, train mean loss 0.00022840399661816147, test mean loss [0.00032424 0.00035163 0.00029034 0.00033898 0.00028942 0.00027696
 0.00024394]
Model epoch 125: train total loss -64.53747296449731, train mean loss 0.0002359012473932798, test mean loss [0.00030524 0.00036638 0.0002856  0.00034364 0.00028818 0.00027447
 0.00026066]
Model epoch 126: train total loss -64.68977686853913, train mean loss 0.00024047490007781644, test mean loss [0.00030294 0.00036698 0.00027875 0.00033678 0.00029337 0.00028837
 0.00023932]
Model epoch 127: train total loss -64.56468597625408, train mean loss 0.0002502554398274058, test mean loss [0.00029129 0.00035216 0.00027441 0.000362   0.00027498 0.00026264
 0.00025502]
Model epoch 128: train total loss -64.6702464356473, train mean loss 0.000234387778373227, test mean loss [0.00029584 0.00034116 0.00031932 0.00033292 0.00027436 0.00025877
 0.00023599]
Model epoch 129: train total loss -64.72298519955066, train mean loss 0.00024671799308835366, test mean loss [0.00030308 0.00034738 0.00028237 0.00033969 0.00029848 0.00026402
 0.00025609]
Model epoch 130: train total loss -64.78744275283645, train mean loss 0.0002226844278219967, test mean loss [0.00029639 0.00033507 0.0002845  0.00032039 0.0002788  0.00025826
 0.00024869]
Model epoch 131: train total loss -64.57568690693336, train mean loss 0.00024575130440079195, test mean loss [0.00029681 0.00034222 0.00028548 0.0003096  0.00026611 0.0002499
 0.00022713]
Model epoch 132: train total loss -64.40238390423796, train mean loss 0.0002353898621925145, test mean loss [0.00028353 0.00033141 0.00029546 0.00032847 0.00028949 0.00025754
 0.00025494]
Model epoch 133: train total loss -64.48875069044747, train mean loss 0.00024194571297151164, test mean loss [0.00028816 0.00032676 0.00027018 0.00031565 0.00027784 0.00026175
 0.00023974]
Model epoch 134: train total loss -64.70692996128544, train mean loss 0.0002184560598295664, test mean loss [0.00027985 0.00031724 0.0002645  0.00032096 0.00027594 0.00027101
 0.00023332]
Model epoch 135: train total loss -65.0331814994034, train mean loss 0.00020436985639605683, test mean loss [0.00027886 0.00032499 0.00028033 0.00031669 0.00027553 0.0002662
 0.00023306]
Model epoch 136: train total loss -64.52344895455356, train mean loss 0.0002486540660175053, test mean loss [0.00029713 0.00031782 0.00026372 0.00030932 0.00027006 0.00028533
 0.0002245 ]
Model epoch 137: train total loss -64.53762640360898, train mean loss 0.00023717754298744164, test mean loss [0.00027442 0.00034139 0.00026576 0.00033725 0.00028777 0.0002548
 0.0002277 ]
Model epoch 138: train total loss -64.7504859776149, train mean loss 0.00022719017993784162, test mean loss [0.00026663 0.00032758 0.00025346 0.00032019 0.00026937 0.00025682
 0.00022173]
Model epoch 139: train total loss -64.80075409887223, train mean loss 0.00023415815882817705, test mean loss [0.0002719  0.00031967 0.00028385 0.00030257 0.00026668 0.0002454
 0.00023881]
Model epoch 140: train total loss -64.90475707348882, train mean loss 0.00020917925861382394, test mean loss [0.0002776  0.00031211 0.00026509 0.0002881  0.00026524 0.00026135
 0.0002194 ]
Model epoch 141: train total loss -64.60832409804637, train mean loss 0.00021234921281181585, test mean loss [0.00027027 0.00031284 0.00029313 0.00028221 0.00026221 0.00024447
 0.00022385]
Model epoch 142: train total loss -64.65828167032993, train mean loss 0.00023500623636122248, test mean loss [0.00027251 0.0003057  0.00030725 0.00030604 0.00025765 0.00025381
 0.0002344 ]
Model epoch 143: train total loss -64.99397804823752, train mean loss 0.00022486548628729836, test mean loss [0.00027175 0.00030917 0.00026441 0.00030469 0.00026088 0.00023628
 0.00022433]
Model epoch 144: train total loss -64.73700634810729, train mean loss 0.0002412213452663785, test mean loss [0.00026208 0.00030944 0.00027038 0.00029535 0.00025342 0.00024964
 0.00022677]
Model epoch 145: train total loss -64.55551259779762, train mean loss 0.00023858214379086196, test mean loss [0.00025831 0.00029226 0.00028835 0.00029501 0.00026011 0.00024307
 0.00023375]
Model epoch 146: train total loss -64.99227222595499, train mean loss 0.00023420168633665558, test mean loss [0.00025776 0.00028619 0.00026023 0.00030084 0.0002622  0.00024442
 0.00022714]
Model epoch 147: train total loss -64.78849601485767, train mean loss 0.0002204148092064662, test mean loss [0.00027098 0.00028937 0.00025867 0.00028666 0.00026855 0.00026467
 0.00022079]
Model epoch 148: train total loss -64.88354184247284, train mean loss 0.00021374107518961797, test mean loss [0.00025367 0.00029387 0.00027677 0.0002802  0.00026711 0.00023978
 0.00021925]
Model epoch 149: train total loss -64.90704336593022, train mean loss 0.0002087692306381906, test mean loss [0.00025395 0.00029206 0.00024757 0.0002909  0.00028856 0.00024529
 0.00021616]
Model epoch 150: train total loss -64.80416775013158, train mean loss 0.0002230213154515102, test mean loss [0.00027217 0.00028814 0.00027063 0.00028572 0.00025635 0.00024684
 0.00022409]
Model epoch 151: train total loss -64.75942124027254, train mean loss 0.00023591913442920037, test mean loss [0.00025993 0.00030031 0.00024477 0.00028179 0.00025818 0.00030383
 0.00022651]
Model epoch 152: train total loss -64.9260936133687, train mean loss 0.00021118671183320298, test mean loss [0.00026428 0.00027762 0.00024814 0.0002824  0.00027292 0.00025229
 0.00021908]
Model epoch 153: train total loss -64.82678299665149, train mean loss 0.00021531698147470154, test mean loss [0.00025018 0.00028502 0.0002555  0.00029184 0.00025368 0.00022903
 0.00023955]
Model epoch 154: train total loss -64.77275107349102, train mean loss 0.00022397522604374523, test mean loss [0.00026282 0.00028446 0.00024055 0.00029423 0.00027607 0.00023141
 0.00021134]
Model epoch 155: train total loss -65.13538250793971, train mean loss 0.00020903340000525138, test mean loss [0.0002596  0.0002751  0.00024233 0.000274   0.00024806 0.00023511
 0.00021181]
Model epoch 156: train total loss -64.83792136067296, train mean loss 0.00020054179495667223, test mean loss [0.00027413 0.00027866 0.00024082 0.00027122 0.00025277 0.00022888
 0.00022051]
Model epoch 157: train total loss -64.87115516003587, train mean loss 0.0002141389182402627, test mean loss [0.00026565 0.00027948 0.00022833 0.00027026 0.0002487  0.00024164
 0.00027596]
Model epoch 158: train total loss -65.02102390478751, train mean loss 0.00020271702423754499, test mean loss [0.00024938 0.00025601 0.00024326 0.00030148 0.00026348 0.00023845
 0.00021671]
Model epoch 159: train total loss -64.77892879717999, train mean loss 0.00021572623949092613, test mean loss [0.00025312 0.00027618 0.00025947 0.00026661 0.00025699 0.00022759
 0.00021809]
Model epoch 160: train total loss -64.60768479160086, train mean loss 0.0002146769793506394, test mean loss [0.00027742 0.00029384 0.00024129 0.00027698 0.00025119 0.00025058
 0.00020917]
Model epoch 161: train total loss -65.0262261128485, train mean loss 0.0001994669210100812, test mean loss [0.00023204 0.00033846 0.00024183 0.0002616  0.00024402 0.00023591
 0.00022737]
Model epoch 162: train total loss -64.77485914856184, train mean loss 0.00021862476165569994, test mean loss [0.00025451 0.00031944 0.00024048 0.0003285  0.00025753 0.00022698
 0.00022603]
Model epoch 163: train total loss -64.90190838114377, train mean loss 0.00018019007364677178, test mean loss [0.00023931 0.0002815  0.0002422  0.00028698 0.00023793 0.00022067
 0.00021753]
Model epoch 164: train total loss -64.79910003553677, train mean loss 0.00019617703022231964, test mean loss [0.0002393  0.00028543 0.00022905 0.0002601  0.00024115 0.00023289
 0.00022181]
Model epoch 165: train total loss -64.79872677242713, train mean loss 0.0002039634088399241, test mean loss [0.00024002 0.00026748 0.00023678 0.000268   0.00024097 0.00023506
 0.00021561]
Model epoch 166: train total loss -64.79134708860636, train mean loss 0.00020433021140560962, test mean loss [0.00025117 0.00026212 0.00024284 0.00024887 0.00025041 0.00022523
 0.00020948]
Model epoch 167: train total loss -64.76873130619896, train mean loss 0.0002130428083692394, test mean loss [0.00023616 0.00026484 0.00022377 0.00026717 0.00024065 0.00022904
 0.00020727]
Model epoch 168: train total loss -65.14837310680078, train mean loss 0.00019179213717130674, test mean loss [0.00023846 0.00026455 0.00021912 0.00026093 0.00023295 0.00023428
 0.00020418]
Model epoch 169: train total loss -65.00419880861597, train mean loss 0.0001896231492110898, test mean loss [0.00023127 0.00024927 0.00023012 0.00024302 0.00024552 0.00022825
 0.00020624]
Model epoch 170: train total loss -65.1697773334246, train mean loss 0.00018852937624871916, test mean loss [0.00024404 0.00025497 0.00021757 0.00027487 0.00023647 0.00023395
 0.00020271]
Model epoch 171: train total loss -64.8766542295472, train mean loss 0.00019414160128032972, test mean loss [0.000227   0.00025722 0.00023443 0.00025508 0.00023595 0.00023995
 0.00021708]
Model epoch 172: train total loss -65.098381383822, train mean loss 0.00019328283354122294, test mean loss [0.00022855 0.00024169 0.00022404 0.00024512 0.00024908 0.00022145
 0.00022538]
Model epoch 173: train total loss -64.95676286128335, train mean loss 0.00020594212249099822, test mean loss [0.00024347 0.00024894 0.00022131 0.00024267 0.00023817 0.00022994
 0.00020702]
Model epoch 174: train total loss -65.0060319745558, train mean loss 0.000181355029770442, test mean loss [0.00024382 0.00024858 0.00022568 0.00023668 0.00028416 0.00022526
 0.00020549]
Model epoch 175: train total loss -65.0127008802692, train mean loss 0.00018887564208009495, test mean loss [0.00024526 0.00025065 0.00022552 0.00024778 0.00024775 0.0002182
 0.00022168]
Model epoch 176: train total loss -64.97482934879187, train mean loss 0.00019148962123207816, test mean loss [0.00022953 0.00024161 0.00021095 0.00022999 0.00024141 0.00022161
 0.00020513]
Model epoch 177: train total loss -65.08600820384297, train mean loss 0.0001874635937984119, test mean loss [0.00022325 0.00022992 0.00021772 0.00023628 0.00024596 0.00021971
 0.00021721]
Model epoch 178: train total loss -64.82913019374746, train mean loss 0.00018987458470222547, test mean loss [0.00023943 0.0002357  0.00021852 0.00022888 0.00023661 0.00022339
 0.00019895]
Model epoch 179: train total loss -64.94594205130947, train mean loss 0.00017426990469894134, test mean loss [0.00023278 0.00023846 0.00022189 0.00023902 0.00024295 0.00021973
 0.00021599]
Model epoch 180: train total loss -64.68952196355782, train mean loss 0.00019053084572911218, test mean loss [0.00026546 0.00023382 0.0002116  0.00024339 0.00023745 0.00021968
 0.00020159]
Model epoch 181: train total loss -64.94551967723731, train mean loss 0.00017461151758906514, test mean loss [0.00022607 0.00024334 0.00022925 0.00022486 0.0002283  0.00021042
 0.0002053 ]
Model epoch 182: train total loss -64.96305727245257, train mean loss 0.0001786005918002711, test mean loss [0.00022243 0.0002273  0.00022219 0.00023004 0.00023616 0.00022823
 0.00020934]
Model epoch 183: train total loss -65.04833782359623, train mean loss 0.00020582572299897157, test mean loss [0.00024334 0.00024416 0.00020837 0.00022774 0.00023444 0.00022874
 0.0002147 ]
Model epoch 184: train total loss -64.96765162899264, train mean loss 0.00017790516991621845, test mean loss [0.0002317  0.00023875 0.0002003  0.00023382 0.00024874 0.00022414
 0.00019785]
Model epoch 185: train total loss -65.13632116215071, train mean loss 0.00017133270107405466, test mean loss [0.00022037 0.00022487 0.00026104 0.00022502 0.00021607 0.000224
 0.00020358]
Model epoch 186: train total loss -65.06771975143849, train mean loss 0.00018791387660825837, test mean loss [0.00022039 0.00021924 0.00021577 0.00023467 0.00023043 0.00022609
 0.0002002 ]
Model epoch 187: train total loss -65.02947838714279, train mean loss 0.00017742171856427913, test mean loss [0.00022959 0.00023449 0.00020568 0.0002279  0.00022159 0.00025198
 0.00020649]
Model epoch 188: train total loss -65.04753777843993, train mean loss 0.0001801052766884198, test mean loss [0.00022062 0.00022699 0.00019499 0.0002318  0.00022248 0.00021896
 0.00020077]
Model epoch 189: train total loss -64.98579208998665, train mean loss 0.0001897833895950902, test mean loss [0.00024088 0.00021987 0.00019334 0.00022486 0.00021973 0.00021729
 0.00020989]
Model epoch 190: train total loss -64.9997717076008, train mean loss 0.00017915249381756344, test mean loss [0.00022694 0.00023013 0.0002023  0.00027115 0.00021879 0.00022081
 0.00020016]
Model epoch 191: train total loss -64.94966834177583, train mean loss 0.0001835517787497317, test mean loss [0.0002227  0.00022004 0.00020282 0.00022614 0.00022254 0.00023272
 0.0002164 ]
Model epoch 192: train total loss -65.0577648917116, train mean loss 0.00018692399746138668, test mean loss [0.00022493 0.00022546 0.00018786 0.00022892 0.00022937 0.00022565
 0.00019645]
Model epoch 193: train total loss -65.08961270266371, train mean loss 0.00018277839566346697, test mean loss [0.00022866 0.00020433 0.00020188 0.00023125 0.00022755 0.00021444
 0.000208  ]
Model epoch 194: train total loss -64.9774227011474, train mean loss 0.0001898670566145096, test mean loss [0.00022252 0.00021657 0.00019149 0.00022443 0.00022023 0.00021318
 0.00021344]
Model epoch 195: train total loss -64.9402345465646, train mean loss 0.0001789051921025207, test mean loss [0.00020678 0.00022479 0.00020043 0.0002293  0.00024281 0.00020176
 0.00024076]
Model epoch 196: train total loss -64.99438225527612, train mean loss 0.0001804730427402609, test mean loss [0.00021169 0.00021592 0.00020986 0.00022293 0.00023224 0.00020647
 0.00019572]
Model epoch 197: train total loss -65.08261841393985, train mean loss 0.00019424867592068227, test mean loss [0.00021275 0.00022299 0.00019565 0.00022584 0.00022081 0.00027232
 0.00019922]
Model epoch 198: train total loss -65.14811006884209, train mean loss 0.0001773428194385194, test mean loss [0.00022009 0.00020595 0.00021415 0.0002348  0.00025888 0.00023018
 0.00019815]
Model epoch 199: train total loss -64.9574134097484, train mean loss 0.00019054987938597255, test mean loss [0.00021496 0.00021033 0.00019388 0.00022529 0.00024435 0.00020835
 0.00018647]
Model epoch 200: train total loss -65.0059214558453, train mean loss 0.00017588925853596573, test mean loss [0.00021128 0.00020546 0.00019637 0.00022906 0.00023029 0.0002051
 0.00020094]
Model epoch 201: train total loss -65.33876858813403, train mean loss 0.00017553699596787386, test mean loss [0.00021757 0.00021594 0.00019293 0.00022528 0.00022519 0.00021681
 0.00019959]
Model epoch 202: train total loss -65.0766260275545, train mean loss 0.00017944933235046703, test mean loss [0.00021774 0.00019788 0.00020593 0.00022399 0.00022707 0.0002062
 0.00020811]
Model epoch 203: train total loss -65.16949411593548, train mean loss 0.00018079674634818963, test mean loss [0.00021689 0.00019981 0.00019339 0.00022625 0.00022447 0.00021303
 0.00020516]
Model epoch 204: train total loss -65.17032803211177, train mean loss 0.00018716888090644271, test mean loss [0.00022059 0.00020984 0.00018968 0.0002342  0.00021443 0.00023283
 0.00020485]
Model epoch 205: train total loss -65.10054722399637, train mean loss 0.00017409765184731813, test mean loss [0.0002053  0.00021337 0.00019161 0.0002311  0.00022663 0.00020353
 0.00019407]
Model epoch 206: train total loss -65.30580012138311, train mean loss 0.0001645134871514951, test mean loss [0.00022155 0.00019367 0.00020686 0.00022549 0.00021677 0.00020691
 0.00020031]
Model epoch 207: train total loss -64.96989410828085, train mean loss 0.00018398895414140602, test mean loss [0.00022318 0.00020515 0.00020305 0.0002157  0.00022159 0.00020914
 0.00020204]
Model epoch 208: train total loss -65.22606670069855, train mean loss 0.00021136066372765705, test mean loss [0.0002203  0.00019539 0.00019953 0.00024378 0.00021979 0.00021698
 0.00029935]
Model epoch 209: train total loss -65.21017011599709, train mean loss 0.00019047500590497628, test mean loss [0.00021717 0.00020131 0.00021748 0.00022124 0.00022129 0.00019442
 0.00020336]
Model epoch 210: train total loss -65.27969632017339, train mean loss 0.00017126062031399457, test mean loss [0.00020733 0.00019619 0.00018885 0.00021698 0.00020797 0.00020958
 0.00020297]
Model epoch 211: train total loss -65.20364141798619, train mean loss 0.00019080872284211068, test mean loss [0.00022085 0.00019042 0.00020467 0.00022999 0.00022029 0.00020589
 0.00018818]
Model epoch 212: train total loss -65.05555578973924, train mean loss 0.00017051609060628493, test mean loss [0.00021838 0.00020723 0.00018767 0.00023594 0.00020938 0.00020438
 0.00019644]
Model epoch 213: train total loss -65.1816569894084, train mean loss 0.00017575752918631192, test mean loss [0.00020939 0.0001982  0.00019738 0.00021505 0.00024838 0.00021631
 0.00019955]
Model epoch 214: train total loss -65.19790420420081, train mean loss 0.00016948896701300724, test mean loss [0.00021288 0.00020243 0.00019485 0.00021033 0.00022364 0.00018628
 0.00019846]
Model epoch 215: train total loss -65.0759756875424, train mean loss 0.00017783576440189136, test mean loss [0.00021314 0.00020547 0.00018876 0.00021125 0.00023112 0.0002053
 0.00018394]
Model epoch 216: train total loss -65.08892003599406, train mean loss 0.0001798336156638031, test mean loss [0.00021596 0.0001945  0.00019105 0.00020586 0.00020316 0.00021048
 0.00019349]
Model epoch 217: train total loss -65.33985055894104, train mean loss 0.0001871874965162356, test mean loss [0.00020538 0.00019705 0.00018349 0.00021664 0.00023102 0.0002055
 0.00020192]
Model epoch 218: train total loss -64.97756517061926, train mean loss 0.0001658276274859152, test mean loss [0.00020467 0.00019553 0.00018037 0.00022455 0.00020493 0.00020772
 0.00019557]
Model epoch 219: train total loss -65.20635366802345, train mean loss 0.00018920062778234961, test mean loss [0.00021842 0.00019162 0.0001883  0.00019621 0.00026411 0.000211
 0.00018811]
Model epoch 220: train total loss -65.25985702995693, train mean loss 0.00016561232606805503, test mean loss [0.00020694 0.0002008  0.00018626 0.00022255 0.00020372 0.00020598
 0.00019445]
Model epoch 221: train total loss -65.27970348683601, train mean loss 0.00018657462912158085, test mean loss [0.00021832 0.00019342 0.0001845  0.00021552 0.00022961 0.00020622
 0.00022744]
Model epoch 222: train total loss -65.55919709970128, train mean loss 0.00016992434842506718, test mean loss [0.00020876 0.0001869  0.00019183 0.00021009 0.00021704 0.00019848
 0.00021114]
Model epoch 223: train total loss -65.31911588074996, train mean loss 0.00019530481781935234, test mean loss [0.00023871 0.00019386 0.00024915 0.00021085 0.00021764 0.00019163
 0.00019356]
Model epoch 224: train total loss -65.24363345091916, train mean loss 0.000163980815046176, test mean loss [0.00020815 0.00019686 0.00020239 0.00020932 0.00021656 0.00019343
 0.00018876]
Model epoch 225: train total loss -65.27558791250347, train mean loss 0.00016950325930485202, test mean loss [0.00020304 0.0001854  0.00019534 0.00020286 0.00020453 0.00019435
 0.00018976]
Model epoch 226: train total loss -65.11358355626695, train mean loss 0.00018133137013856782, test mean loss [0.00020801 0.00018461 0.00019834 0.00020555 0.00021162 0.00019411
 0.00018496]
Model epoch 227: train total loss -65.09210882202528, train mean loss 0.0001625319313843003, test mean loss [0.00022491 0.00018249 0.00018944 0.00021059 0.00021091 0.00019638
 0.0001867 ]
Model epoch 228: train total loss -65.27809242065923, train mean loss 0.0001676017961465659, test mean loss [0.00020362 0.00020207 0.00018871 0.00020672 0.00020849 0.00019155
 0.00018766]
Model epoch 229: train total loss -65.54452726251849, train mean loss 0.00016908121562194574, test mean loss [0.00019327 0.00019121 0.00018997 0.00020624 0.0002046  0.00019224
 0.00019593]
Model epoch 230: train total loss -65.48338398247337, train mean loss 0.00016858308670114586, test mean loss [0.00022171 0.00019455 0.00018769 0.00020335 0.00022552 0.00020689
 0.00018702]
Model epoch 231: train total loss -65.21445863049108, train mean loss 0.00017365236981627173, test mean loss [0.00020401 0.00019293 0.00018459 0.00020499 0.00021612 0.00021429
 0.00018178]
Model epoch 232: train total loss -65.24950669678535, train mean loss 0.00018203531894341136, test mean loss [0.00020343 0.00018872 0.00018797 0.00020385 0.00020642 0.00020048
 0.00020464]
Model epoch 233: train total loss -65.31280530823669, train mean loss 0.00017341404767271773, test mean loss [0.00020187 0.0001943  0.00018181 0.00020095 0.00021448 0.00019125
 0.00019158]
Model epoch 234: train total loss -65.19064379078257, train mean loss 0.00017055638634957702, test mean loss [0.0002126  0.00019506 0.00018032 0.00020226 0.00021159 0.0002125
 0.00018475]
Model epoch 235: train total loss -65.43782967354714, train mean loss 0.00016977315320556807, test mean loss [0.00021042 0.0001771  0.00018299 0.00019764 0.00020557 0.00020855
 0.00018817]
Model epoch 236: train total loss -65.11173243513643, train mean loss 0.00016862301585192626, test mean loss [0.00020266 0.00020392 0.00018733 0.00021891 0.00020151 0.00019104
 0.00018114]
Model epoch 237: train total loss -65.32195552489607, train mean loss 0.0001700402195727747, test mean loss [0.00020707 0.00018693 0.00026711 0.00022375 0.00020362 0.00020716
 0.00019583]
Model epoch 238: train total loss -65.2434681481914, train mean loss 0.00016761050617407442, test mean loss [0.00020243 0.00018855 0.00020087 0.00020426 0.00020235 0.0001919
 0.0001838 ]
Model epoch 239: train total loss -65.38740745425615, train mean loss 0.00016768347511377532, test mean loss [0.00020311 0.00020192 0.00018071 0.00019489 0.00020473 0.0001955
 0.00018949]
Model epoch 240: train total loss -65.34132920992805, train mean loss 0.0001555569134387467, test mean loss [0.0002049  0.00018864 0.00018106 0.00019991 0.00020169 0.00019085
 0.00018474]
Model epoch 241: train total loss -65.3025414083122, train mean loss 0.00016321926311818047, test mean loss [0.00019622 0.00018776 0.00017382 0.00020574 0.00019722 0.00019703
 0.00018646]
Model epoch 242: train total loss -65.6190653848084, train mean loss 0.00017401874132494293, test mean loss [0.00021632 0.00018282 0.00023055 0.00021061 0.00020603 0.00020421
 0.00018241]
Model epoch 243: train total loss -65.4076642314325, train mean loss 0.00016020886363124468, test mean loss [0.00020476 0.00018931 0.00021181 0.00022463 0.00019842 0.00019339
 0.00018132]
Model epoch 244: train total loss -65.19971134435772, train mean loss 0.00023097448859548826, test mean loss [0.00019684 0.00019114 0.00017938 0.00021287 0.00019393 0.00020832
 0.00042723]
Model epoch 245: train total loss -65.38573233525359, train mean loss 0.00017360496470640455, test mean loss [0.00020597 0.00018799 0.0001844  0.00022511 0.00020699 0.00021508
 0.00020487]
Model epoch 246: train total loss -65.20552016415762, train mean loss 0.00017054358420046518, test mean loss [0.00020226 0.00022955 0.00018042 0.00021444 0.00020702 0.0001864
 0.0001951 ]
Model epoch 247: train total loss -65.44804207627975, train mean loss 0.00016337086403104935, test mean loss [0.00019091 0.00019498 0.0001905  0.0002024  0.00021183 0.00019557
 0.00018382]
Model epoch 248: train total loss -65.29966275354842, train mean loss 0.00015209831446497457, test mean loss [0.00019871 0.00020201 0.00018734 0.00020854 0.00020047 0.00018934
 0.00018671]
Model epoch 249: train total loss -65.20596854597875, train mean loss 0.00017586992634868382, test mean loss [0.00019403 0.00018115 0.00017934 0.0002039  0.00023686 0.00018735
 0.00018559]
Model epoch 250: train total loss -65.33209162290721, train mean loss 0.0001673229016967394, test mean loss [0.00020505 0.00018134 0.00018683 0.00019711 0.00019079 0.00018153
 0.00018771]
Model epoch 251: train total loss -65.34830807963547, train mean loss 0.00015664422083826247, test mean loss [0.0002186  0.00017382 0.00017599 0.00019504 0.00020177 0.00017798
 0.00019452]
Model epoch 252: train total loss -65.28777999918417, train mean loss 0.0001604593981354611, test mean loss [0.00019455 0.00017547 0.0001866  0.00020045 0.00019376 0.00019208
 0.0001823 ]
Model epoch 253: train total loss -65.5399446526394, train mean loss 0.00017472909490611537, test mean loss [0.00020221 0.00017991 0.00016863 0.00019744 0.00021478 0.00018418
 0.00018448]
Model epoch 254: train total loss -65.26295878536197, train mean loss 0.00016835898764011484, test mean loss [0.00019625 0.00018737 0.00018789 0.0002083  0.00020266 0.00019105
 0.00018461]
Model epoch 255: train total loss -65.3512778381161, train mean loss 0.00017116623015333134, test mean loss [0.00020726 0.00018531 0.00017613 0.00019705 0.00020026 0.00019281
 0.00019652]
Model epoch 256: train total loss -65.22361777107254, train mean loss 0.00016961286547753337, test mean loss [0.00022932 0.00018596 0.00017757 0.00024234 0.00020275 0.00019522
 0.00018323]
Model epoch 257: train total loss -65.45620865606362, train mean loss 0.00016527799010471612, test mean loss [0.00019653 0.00017204 0.0001719  0.000212   0.00022824 0.00020185
 0.00017846]
Model epoch 258: train total loss -65.51631946670248, train mean loss 0.00015096926403972429, test mean loss [0.00019341 0.00018553 0.00017108 0.00019958 0.00020568 0.00019395
 0.00019008]
Model epoch 259: train total loss -65.4148485671628, train mean loss 0.00019833298543910354, test mean loss [0.0002021  0.00018467 0.00017786 0.00019717 0.00057606 0.0001846
 0.00018384]
Model epoch 260: train total loss -65.09807741556097, train mean loss 0.00017373607709979152, test mean loss [0.00020234 0.00017289 0.0001823  0.00019682 0.00038266 0.00019686
 0.00018024]
Model epoch 261: train total loss -65.32632620388658, train mean loss 0.00017900753354912653, test mean loss [0.00020299 0.00017725 0.00018174 0.000208   0.00031542 0.00019549
 0.00017617]
Model epoch 262: train total loss -65.39578663766109, train mean loss 0.00018637370197374954, test mean loss [0.00019928 0.00018237 0.00019455 0.0001949  0.000245   0.00018378
 0.00019137]
Model epoch 263: train total loss -65.21209480083306, train mean loss 0.0001677023220254448, test mean loss [0.00018957 0.00017942 0.00017865 0.00020251 0.00021032 0.00020297
 0.00018834]
Model epoch 264: train total loss -65.41736973446022, train mean loss 0.0001643070980141019, test mean loss [0.00019408 0.00027774 0.00018177 0.00019659 0.00020571 0.00021362
 0.00018524]
Model epoch 265: train total loss -65.30480125870962, train mean loss 0.00016398338765861715, test mean loss [0.00019542 0.0001875  0.00017154 0.00019672 0.00020845 0.00018566
 0.00018318]
Model epoch 266: train total loss -65.44988494916181, train mean loss 0.00016707151142065002, test mean loss [0.00019921 0.00018478 0.00017579 0.00020583 0.00020397 0.00018158
 0.00017944]
Model epoch 267: train total loss -65.42225413513356, train mean loss 0.00016136360650158385, test mean loss [0.00019062 0.00019301 0.00018311 0.00019965 0.00020504 0.00018484
 0.00017733]
Model trained in 268 epochs with 5000 transitions.
[2025-01-23 15:19:45,833][absl][INFO] - {'eval/walltime': 196.2100830078125, 'training/sps': 0.28459550659135724, 'training/walltime': 10356.578770637512, 'training/model_train_time': 1918.9913702011108, 'training/other_time': 1593.9334161281586, 'training/model_horizon': 8, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(6000, dtype=int32), 'model/train_total_loss': Array(-65.42225414, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00016136, dtype=float64), 'model/test_total_loss': Array(-64.94927011, dtype=float64), 'model/test_mean_loss': Array(0.00019051, dtype=float64), 'model/train_epochs': 268, 'model/sec_per_epoch': 7.151427530530674, 'sac/actor_loss': Array(-23.66799115, dtype=float64), 'sac/alpha': Array(0.02460377, dtype=float32), 'sac/alpha_loss': Array(1.54890833e-06, dtype=float64), 'sac/buffer_current_size': Array(400000.03, dtype=float32), 'sac/critic_loss': Array(0.03099895, dtype=float64), 'eval/episode_forward_vel': Array(1.89614961, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-3.59410802, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(5.25897061, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.00880996, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(0.81554822, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(5.65484194, dtype=float64), 'eval/episode_rew_roll': Array(4.88866887, dtype=float64), 'eval/episode_rew_side_motion': Array(2.83436306, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(6.7631853, dtype=float64), 'eval/episode_rew_yaw': Array(9.56424272, dtype=float64), 'eval/episode_rew_z_vel_change': Array(3.10205014, dtype=float64), 'eval/episode_reward': Array(34.37599867, dtype=float64), 'eval/episode_step_count': Array(5995., dtype=float64), 'eval/avg_episode_length': Array(110., dtype=float64), 'eval/epoch_eval_time': 30.49441432952881, 'eval/sps': 32.79289082891699}
Steps / Eval:  6000.0
Reward is  34.37599866747323
Model horizon updated to 10.
Hallucination updates per training step updated to 1000.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -33.68102296910561, train mean loss 0.08059751895924017, test mean loss [0.09583407 0.04136926 0.03487332 0.07685747 0.09291538 0.14143945
 0.06821449]
Model epoch 1: train total loss -40.7987904306674, train mean loss 0.03202805663959574, test mean loss [0.0412834  0.02800183 0.02120368 0.03049144 0.03612279 0.04541393
 0.03077303]
Model epoch 2: train total loss -45.4505577277459, train mean loss 0.019827348514533685, test mean loss [0.02515476 0.02226725 0.01497159 0.02480777 0.02040543 0.02140949
 0.02032544]
Model epoch 3: train total loss -49.246403064232226, train mean loss 0.01587395361212306, test mean loss [0.01846755 0.01751211 0.01129158 0.01975938 0.01674138 0.01409911
 0.01480328]
Model epoch 4: train total loss -52.10716469399394, train mean loss 0.011855992654039263, test mean loss [0.0145818  0.01347033 0.009166   0.01627667 0.01471465 0.01038839
 0.01211892]
Model epoch 5: train total loss -53.450722461753436, train mean loss 0.010517827341118113, test mean loss [0.01129151 0.01037367 0.00723861 0.01344836 0.01265472 0.0082065
 0.01048803]
Model epoch 6: train total loss -55.6028705259114, train mean loss 0.008597160655644193, test mean loss [0.00888989 0.008197   0.00572968 0.01095567 0.01065518 0.00669706
 0.00901609]
Model epoch 7: train total loss -56.87808081975266, train mean loss 0.006558667886232851, test mean loss [0.0070802  0.00655629 0.00449973 0.00899627 0.00870011 0.00552386
 0.0081034 ]
Model epoch 8: train total loss -57.743809472259294, train mean loss 0.0053193333084521005, test mean loss [0.00580179 0.00535902 0.00377318 0.00732827 0.00708368 0.00449425
 0.00709307]
Model epoch 9: train total loss -58.35570167873117, train mean loss 0.005107228520853677, test mean loss [0.00490176 0.00445562 0.00323452 0.00630124 0.00582622 0.00374654
 0.00644393]
Model epoch 10: train total loss -59.00703672790852, train mean loss 0.0037532414607109863, test mean loss [0.0042251  0.00377626 0.0027778  0.00562411 0.00456436 0.0032405
 0.00571239]
Model epoch 11: train total loss -59.5123240665753, train mean loss 0.003431101807288877, test mean loss [0.00370114 0.00320316 0.00238345 0.00511113 0.00359159 0.00285142
 0.00530004]
Model epoch 12: train total loss -60.1575043936645, train mean loss 0.0026374820454734345, test mean loss [0.00329153 0.00289502 0.00215273 0.00464002 0.00304587 0.00255696
 0.00479747]
Model epoch 13: train total loss -60.41295715369992, train mean loss 0.002637705921934006, test mean loss [0.00290524 0.00254229 0.00188377 0.00431991 0.00238081 0.00231476
 0.00450949]
Model epoch 14: train total loss -60.76075550300224, train mean loss 0.0023815233437939017, test mean loss [0.00265125 0.0023251  0.0016932  0.004012   0.00203996 0.00211289
 0.00429231]
Model epoch 15: train total loss -61.125629174362736, train mean loss 0.0017582116548060037, test mean loss [0.00244706 0.00209894 0.00153818 0.00369686 0.00182796 0.00193648
 0.00430424]
Model epoch 16: train total loss -61.604200722154594, train mean loss 0.0016933683034640872, test mean loss [0.00231589 0.00201596 0.00142319 0.00343473 0.0015983  0.0019166
 0.0039955 ]
Model epoch 17: train total loss -61.807536650788215, train mean loss 0.0015009580375327386, test mean loss [0.00215505 0.00187537 0.00130058 0.00321486 0.00145398 0.00169836
 0.00384929]
Model epoch 18: train total loss -61.401138457614834, train mean loss 0.001576096938596512, test mean loss [0.00203381 0.00175847 0.00122187 0.00294872 0.00133044 0.00156053
 0.00370492]
Model epoch 19: train total loss -61.96494864516359, train mean loss 0.0012447841839972925, test mean loss [0.00196841 0.00167762 0.00117181 0.00278871 0.00124689 0.00151839
 0.00356472]
Model epoch 20: train total loss -61.91986503245801, train mean loss 0.001417322242237565, test mean loss [0.00185182 0.00156009 0.00111719 0.00258702 0.00119406 0.00146223
 0.00346556]
Model epoch 21: train total loss -62.282263175277805, train mean loss 0.0010252734585424184, test mean loss [0.00177866 0.00155044 0.0010574  0.00242413 0.00112398 0.00131828
 0.00339389]
Model epoch 22: train total loss -61.976254305831695, train mean loss 0.0013216079447816898, test mean loss [0.00167693 0.00145194 0.00100525 0.0022325  0.00114425 0.00124006
 0.00329619]
Model epoch 23: train total loss -62.280641109102845, train mean loss 0.001429431991003361, test mean loss [0.0016254  0.00140838 0.00104934 0.00211454 0.00099944 0.00119525
 0.00321831]
Model epoch 24: train total loss -62.60211652575516, train mean loss 0.0011417047151157926, test mean loss [0.00155401 0.00133008 0.0009535  0.00198716 0.00093436 0.00116267
 0.00307098]
Model epoch 25: train total loss -62.58414703973405, train mean loss 0.0009470454538416726, test mean loss [0.0014654  0.00131534 0.00090482 0.00190924 0.00091487 0.00109136
 0.00297236]
Model epoch 26: train total loss -62.5214466232152, train mean loss 0.0012768367140625213, test mean loss [0.00140002 0.00128716 0.00088891 0.00182924 0.00086768 0.00104998
 0.00288782]
Model epoch 27: train total loss -62.66544675844241, train mean loss 0.0011428440185939298, test mean loss [0.00136032 0.00117225 0.00086228 0.00176651 0.00084016 0.00106145
 0.00281466]
Model epoch 28: train total loss -62.77794149642937, train mean loss 0.0009699199087631674, test mean loss [0.00129353 0.00114875 0.00082886 0.00169757 0.00082925 0.00098874
 0.00276768]
Model epoch 29: train total loss -63.021104617996116, train mean loss 0.0008410732264015786, test mean loss [0.00126819 0.00109644 0.00078659 0.00163343 0.00078879 0.0009606
 0.00267401]
Model epoch 30: train total loss -63.05127478096265, train mean loss 0.000818471920656547, test mean loss [0.00123596 0.00106714 0.00078689 0.00158187 0.00077474 0.00093081
 0.00253261]
Model epoch 31: train total loss -62.915628463875215, train mean loss 0.0009244639880305954, test mean loss [0.0012     0.00109328 0.00075912 0.00155136 0.00074053 0.00089052
 0.00247303]
Model epoch 32: train total loss -62.77592944546617, train mean loss 0.0009703077639046596, test mean loss [0.00119648 0.00103488 0.00073954 0.00150212 0.00075453 0.00092307
 0.00239514]
Model epoch 33: train total loss -63.42521613454473, train mean loss 0.0007416076229825767, test mean loss [0.00115667 0.00099205 0.00073605 0.00148075 0.00070665 0.00085658
 0.00230357]
Model epoch 34: train total loss -63.27946486041623, train mean loss 0.0008469255213996258, test mean loss [0.00113619 0.00100509 0.00070694 0.00144317 0.00070488 0.00085919
 0.00221961]
Model epoch 35: train total loss -63.402560170657985, train mean loss 0.0006768856351854398, test mean loss [0.00110551 0.00091973 0.00071338 0.00141462 0.00069639 0.00084461
 0.00220679]
Model epoch 36: train total loss -63.3483589359474, train mean loss 0.0007983862350744373, test mean loss [0.00106008 0.00092225 0.00068391 0.00138159 0.00068043 0.00084212
 0.00211334]
Model epoch 37: train total loss -62.98508427927524, train mean loss 0.0007271781508670566, test mean loss [0.00105323 0.00090988 0.00077568 0.00134407 0.00066572 0.00081698
 0.0021745 ]
Model epoch 38: train total loss -63.34788462847411, train mean loss 0.0005578770950828413, test mean loss [0.00104063 0.00087528 0.00067234 0.00129857 0.0006576  0.00082878
 0.00199914]
Model epoch 39: train total loss -63.412397963538176, train mean loss 0.0006157974234281394, test mean loss [0.00101255 0.00087006 0.00064417 0.00127203 0.00064011 0.00080545
 0.00195093]
Model epoch 40: train total loss -63.40826050503141, train mean loss 0.0007124495520586556, test mean loss [0.00098756 0.00086506 0.00062859 0.00123222 0.00062939 0.00081935
 0.00192413]
Model epoch 41: train total loss -63.27317420111293, train mean loss 0.0005058914665066212, test mean loss [0.00097621 0.00083284 0.00063171 0.0012118  0.0006574  0.00078576
 0.00184846]
Model epoch 42: train total loss -63.51363254184809, train mean loss 0.0006036991064203966, test mean loss [0.00102094 0.00084805 0.00061015 0.00119251 0.00061624 0.00077697
 0.00179816]
Model epoch 43: train total loss -63.71987238760962, train mean loss 0.0005910084652106716, test mean loss [0.00095383 0.00081261 0.00061583 0.00116529 0.00058957 0.00076298
 0.00175799]
Model epoch 44: train total loss -63.51883018077304, train mean loss 0.0004966988434916096, test mean loss [0.0009147  0.00080067 0.00060686 0.00115277 0.00059682 0.0008114
 0.00171015]
Model epoch 45: train total loss -63.83343828325622, train mean loss 0.000647239449363334, test mean loss [0.00091245 0.00078367 0.00059118 0.001142   0.00060889 0.00075307
 0.00163485]
Model epoch 46: train total loss -63.79190937401578, train mean loss 0.0007582231176575957, test mean loss [0.0008873  0.00078277 0.00063484 0.00112764 0.00058428 0.00075673
 0.00162313]
Model epoch 47: train total loss -64.01137773417071, train mean loss 0.0005867684872169493, test mean loss [0.00088148 0.00077721 0.00058136 0.00107245 0.00058305 0.00073876
 0.00153658]
Model epoch 48: train total loss -63.58315146553592, train mean loss 0.0005619611334251815, test mean loss [0.000892   0.0007406  0.00057492 0.00107375 0.00059454 0.00074558
 0.0014748 ]
Model epoch 49: train total loss -63.61364194136449, train mean loss 0.0006461346133416791, test mean loss [0.00086484 0.00073785 0.00056809 0.00107604 0.00056609 0.00071839
 0.00144902]
Model epoch 50: train total loss -64.103901955978, train mean loss 0.0006517801189038058, test mean loss [0.00086913 0.0007178  0.00056156 0.00104466 0.00055484 0.00070771
 0.00144214]
Model epoch 51: train total loss -63.815319147419544, train mean loss 0.00047434794948177057, test mean loss [0.00085639 0.00076972 0.00054298 0.00103453 0.00054492 0.00071994
 0.00139984]
Model epoch 52: train total loss -63.72076246797154, train mean loss 0.0006936476437047471, test mean loss [0.00082065 0.00069972 0.0005518  0.00103962 0.00055349 0.00070699
 0.00131175]
Model epoch 53: train total loss -63.74174347035372, train mean loss 0.000465100527767171, test mean loss [0.00080029 0.00070201 0.00053998 0.00100069 0.00055691 0.00067981
 0.00129211]
Model epoch 54: train total loss -64.01461964993824, train mean loss 0.000516589369145709, test mean loss [0.00080134 0.00069524 0.00052273 0.00101861 0.00053002 0.00070088
 0.0012528 ]
Model epoch 55: train total loss -63.78663424863995, train mean loss 0.0005093995201245807, test mean loss [0.0007973  0.00068707 0.00054112 0.00099678 0.00054766 0.00068045
 0.0012147 ]
Model epoch 56: train total loss -64.04760080236267, train mean loss 0.0004925508011648247, test mean loss [0.00077921 0.00067301 0.00052426 0.00099525 0.00052727 0.00068082
 0.00122838]
Model epoch 57: train total loss -64.21480101691387, train mean loss 0.00030963505203294495, test mean loss [0.0007874  0.00067433 0.00053702 0.00098949 0.00053517 0.00067628
 0.00117312]
Model epoch 58: train total loss -63.87680410679129, train mean loss 0.0005192489126056968, test mean loss [0.00077562 0.00065389 0.00050654 0.00097351 0.0005102  0.00070135
 0.00118662]
Model epoch 59: train total loss -64.20712567881284, train mean loss 0.0004108283543280704, test mean loss [0.00076331 0.0006555  0.00050649 0.00096216 0.00053326 0.00065478
 0.00115554]
Model epoch 60: train total loss -64.07379359969222, train mean loss 0.0004347814262958658, test mean loss [0.00076322 0.00064084 0.00050148 0.0009656  0.00054937 0.00067609
 0.00115073]
Model epoch 61: train total loss -63.80430757249664, train mean loss 0.0005237605171779548, test mean loss [0.0007618  0.0006852  0.00049993 0.00096307 0.0005082  0.00065193
 0.00112407]
Model epoch 62: train total loss -63.99597391006545, train mean loss 0.0005930519173894176, test mean loss [0.0007365  0.00064531 0.00046791 0.00093234 0.00049584 0.00064029
 0.00109698]
Model epoch 63: train total loss -64.1418344865298, train mean loss 0.00036318414859717527, test mean loss [0.00073762 0.00063735 0.00048041 0.00092977 0.00051091 0.00067184
 0.00110003]
Model epoch 64: train total loss -64.06884775195407, train mean loss 0.0004441917187503686, test mean loss [0.00075368 0.00062008 0.00046473 0.00093566 0.00051292 0.00067073
 0.00106085]
Model epoch 65: train total loss -63.878948772482026, train mean loss 0.0005963307267674037, test mean loss [0.00070609 0.00062619 0.00046136 0.00090878 0.00049967 0.0006404
 0.00104154]
Model epoch 66: train total loss -64.18998213045958, train mean loss 0.0003428826313673722, test mean loss [0.00070809 0.00062828 0.00046543 0.0010432  0.00048111 0.00063118
 0.00119265]
Model epoch 67: train total loss -64.06449974716634, train mean loss 0.00046623093909548886, test mean loss [0.00069408 0.00062464 0.00045156 0.00097882 0.00048176 0.00063362
 0.00110102]
Model epoch 68: train total loss -64.10322069353987, train mean loss 0.00034085632891877997, test mean loss [0.00068466 0.0006096  0.00045591 0.00092287 0.00046884 0.00062565
 0.00104976]
Model epoch 69: train total loss -63.92768359457475, train mean loss 0.00038508462409023305, test mean loss [0.00069707 0.00060558 0.00045463 0.00089365 0.0004679  0.00063736
 0.00100708]
Model epoch 70: train total loss -64.35980235604593, train mean loss 0.0003805897050516328, test mean loss [0.00068475 0.00060363 0.00044169 0.00088696 0.00048893 0.00063251
 0.00099411]
Model epoch 71: train total loss -64.15624924497294, train mean loss 0.0003598220629572873, test mean loss [0.0006954  0.00058258 0.00044356 0.00090004 0.00048108 0.00061006
 0.00098609]
Model epoch 72: train total loss -64.09417570544126, train mean loss 0.0003420664570349421, test mean loss [0.00066835 0.00060025 0.00043466 0.0009093  0.00046687 0.00060097
 0.00097009]
Model epoch 73: train total loss -64.38298054644844, train mean loss 0.00044909810959080544, test mean loss [0.00067121 0.00061144 0.00044142 0.00086694 0.00046255 0.00060458
 0.00096464]
Model epoch 74: train total loss -64.23621181059838, train mean loss 0.0006268972190657268, test mean loss [0.00064737 0.00058207 0.00042249 0.0008926  0.00045689 0.00060889
 0.00093555]
Model epoch 75: train total loss -64.36932734378458, train mean loss 0.0004285430610587313, test mean loss [0.00064757 0.00058394 0.00041246 0.00087069 0.00046982 0.00059921
 0.00093701]
Model epoch 76: train total loss -64.39410459366839, train mean loss 0.00046104154280063325, test mean loss [0.00067234 0.00057941 0.00042324 0.00084956 0.00045989 0.00061855
 0.000904  ]
Model epoch 77: train total loss -64.16238684825366, train mean loss 0.000352406511869433, test mean loss [0.00063957 0.00057259 0.00041087 0.00089067 0.00045897 0.00059585
 0.00089496]
Model epoch 78: train total loss -64.41618805075034, train mean loss 0.0003763368038379534, test mean loss [0.00063532 0.0005647  0.00040045 0.00086175 0.00044381 0.00058211
 0.00090867]
Model epoch 79: train total loss -64.36775446952274, train mean loss 0.00034833300852357116, test mean loss [0.00062397 0.00057256 0.00039897 0.00087353 0.00043902 0.0005735
 0.00090365]
Model epoch 80: train total loss -64.37082084716675, train mean loss 0.0003489126344743993, test mean loss [0.00060843 0.00056945 0.00040176 0.00085602 0.00043206 0.00058588
 0.00089381]
Model epoch 81: train total loss -64.34330144867506, train mean loss 0.0003026824186033814, test mean loss [0.00063205 0.00056164 0.00039737 0.00084322 0.00043401 0.00059068
 0.00089055]
Model epoch 82: train total loss -64.38477093202744, train mean loss 0.00039543250113058937, test mean loss [0.00059737 0.0005409  0.00039393 0.00083777 0.00043171 0.00057088
 0.0008839 ]
Model epoch 83: train total loss -64.30656326988867, train mean loss 0.000368679534898973, test mean loss [0.00060053 0.00054481 0.00040901 0.00085063 0.00042797 0.00057528
 0.00085913]
Model epoch 84: train total loss -64.35509916760293, train mean loss 0.0003052854159689543, test mean loss [0.0006038  0.00054815 0.00039071 0.00084798 0.00044176 0.00058052
 0.00084903]
Model epoch 85: train total loss -64.62893734500993, train mean loss 0.0003195452543340085, test mean loss [0.00059385 0.00054816 0.000379   0.00081017 0.00042532 0.00055757
 0.0008623 ]
Model epoch 86: train total loss -64.38089858358217, train mean loss 0.0005076683416565999, test mean loss [0.00059463 0.00054517 0.00039341 0.00082223 0.00041782 0.00057591
 0.00085716]
Model epoch 87: train total loss -64.24788649369057, train mean loss 0.00044170458568658556, test mean loss [0.00057351 0.00054042 0.00038469 0.00081327 0.0004157  0.00055311
 0.00085796]
Model epoch 88: train total loss -64.25603482320545, train mean loss 0.0004213895157284803, test mean loss [0.00056601 0.00055097 0.00037172 0.00083561 0.00041587 0.00056917
 0.00081227]
Model epoch 89: train total loss -64.46766058224574, train mean loss 0.0003541628608655708, test mean loss [0.00056262 0.00053153 0.00037193 0.00081961 0.00042195 0.00054657
 0.00082809]
Model epoch 90: train total loss -64.3907570892798, train mean loss 0.0004430300158385247, test mean loss [0.00054676 0.00052364 0.00036344 0.00082207 0.00041901 0.00054676
 0.00083151]
Model epoch 91: train total loss -64.66301180350666, train mean loss 0.00030706216904268077, test mean loss [0.00055065 0.00053039 0.00036812 0.00082737 0.0004133  0.00054528
 0.00081531]
Model epoch 92: train total loss -64.59616957041935, train mean loss 0.00028956722772462536, test mean loss [0.00054263 0.00052085 0.00036265 0.00080494 0.00040833 0.0005639
 0.00079788]
Model epoch 93: train total loss -64.0699797609513, train mean loss 0.00040184806625709205, test mean loss [0.00056521 0.00050309 0.00035984 0.00078209 0.00040746 0.00054201
 0.00081172]
Model epoch 94: train total loss -64.37619083276113, train mean loss 0.0003580684758712222, test mean loss [0.00054785 0.00050209 0.00035959 0.00079471 0.0004046  0.00053396
 0.00079307]
Model epoch 95: train total loss -64.79442758542359, train mean loss 0.00026244551661509867, test mean loss [0.00053161 0.00050851 0.00036062 0.00077909 0.00040019 0.00053627
 0.00078448]
Model epoch 96: train total loss -64.4366341196361, train mean loss 0.00038823674156349315, test mean loss [0.00053557 0.00051292 0.00036943 0.00080141 0.00040482 0.00053093
 0.00077652]
Model epoch 97: train total loss -64.35559584405834, train mean loss 0.00031139400592386843, test mean loss [0.00053115 0.00052241 0.00035388 0.00078056 0.00040153 0.00061097
 0.00077313]
Model epoch 98: train total loss -64.56615106027206, train mean loss 0.00026075887026941197, test mean loss [0.00051705 0.00053063 0.00034271 0.00076377 0.00039563 0.00052734
 0.00076369]
Model epoch 99: train total loss -64.52796932600816, train mean loss 0.0005047469508545734, test mean loss [0.0005171  0.00051917 0.00033255 0.00077568 0.00039076 0.00052476
 0.00077911]
Model epoch 100: train total loss -64.4570343899209, train mean loss 0.0003679429887368982, test mean loss [0.00050696 0.00050165 0.00035103 0.00079636 0.00039296 0.00052856
 0.00075583]
Model epoch 101: train total loss -64.52693712718539, train mean loss 0.00033278354864625843, test mean loss [0.00050646 0.00050953 0.00034331 0.00077378 0.00038856 0.00051342
 0.00073303]
Model epoch 102: train total loss -64.54467006173748, train mean loss 0.00027534117326651183, test mean loss [0.00049046 0.00048795 0.00033403 0.00076477 0.00038158 0.00053949
 0.00073189]
Model epoch 103: train total loss -64.67236596066512, train mean loss 0.00031660492199796, test mean loss [0.00049836 0.00048606 0.00032517 0.00075508 0.0003848  0.00050757
 0.00075687]
Model epoch 104: train total loss -64.16564578353592, train mean loss 0.0002953104402638518, test mean loss [0.00051253 0.00048062 0.00032952 0.00075792 0.00040983 0.00050436
 0.00072644]
Model epoch 105: train total loss -64.62271095531166, train mean loss 0.00029577965720216007, test mean loss [0.00048279 0.00048809 0.00034448 0.00074525 0.00038021 0.000499
 0.000724  ]
Model epoch 106: train total loss -64.76327048922153, train mean loss 0.00026354500169276297, test mean loss [0.00049605 0.00048682 0.00031613 0.0007666  0.0003704  0.00050736
 0.00073583]
Model epoch 107: train total loss -64.65074153414294, train mean loss 0.0002789040766632053, test mean loss [0.00047593 0.00047796 0.00033153 0.00075215 0.00039251 0.00052141
 0.00070503]
Model epoch 108: train total loss -64.40735079740459, train mean loss 0.00034282395763227634, test mean loss [0.00049011 0.00049074 0.00032426 0.00074951 0.00038238 0.00050112
 0.0007726 ]
Model epoch 109: train total loss -64.65611582561407, train mean loss 0.00022776670350173906, test mean loss [0.0004812  0.00048516 0.00033825 0.00072862 0.00038464 0.00050168
 0.00069183]
Model epoch 110: train total loss -64.64500591004149, train mean loss 0.00026809375996130575, test mean loss [0.00045752 0.00047845 0.00031263 0.00073252 0.00037271 0.00049533
 0.0006782 ]
Model epoch 111: train total loss -64.7605087957162, train mean loss 0.0003036547483523078, test mean loss [0.00046274 0.00048481 0.00032702 0.00072274 0.00037264 0.0004952
 0.00069717]
Model epoch 112: train total loss -64.68822016109301, train mean loss 0.0003655500966290994, test mean loss [0.00046632 0.00046917 0.00035458 0.00073594 0.00037577 0.00051314
 0.00068476]
Model epoch 113: train total loss -64.85014083060608, train mean loss 0.00026328221802124374, test mean loss [0.00045979 0.00046308 0.00032136 0.00071909 0.00038213 0.00049814
 0.0006846 ]
Model epoch 114: train total loss -64.56632841523319, train mean loss 0.00040372901916179967, test mean loss [0.00046122 0.00048046 0.00031337 0.00071656 0.00035576 0.00049606
 0.00066777]
Model epoch 115: train total loss -64.50442226835733, train mean loss 0.0002677140412124431, test mean loss [0.00044766 0.00046652 0.00031139 0.00072871 0.00036558 0.00063982
 0.00067639]
Model epoch 116: train total loss -64.77512903212235, train mean loss 0.0003593974415879534, test mean loss [0.00045311 0.00046101 0.00030314 0.00070418 0.00037191 0.0005397
 0.00067604]
Model epoch 117: train total loss -64.9654659192726, train mean loss 0.00024922422691719503, test mean loss [0.00046371 0.00044559 0.00030728 0.00072683 0.00036223 0.00048907
 0.00069064]
Model epoch 118: train total loss -64.7313832609202, train mean loss 0.0002983740641696364, test mean loss [0.00042684 0.00046205 0.00031405 0.00070672 0.00038159 0.00052417
 0.0006806 ]
Model epoch 119: train total loss -64.84833026982128, train mean loss 0.0002815816920464481, test mean loss [0.00044477 0.00045201 0.000304   0.00069456 0.00035674 0.00046838
 0.00067213]
Model epoch 120: train total loss -64.76626547638594, train mean loss 0.0002458382863486361, test mean loss [0.00041673 0.00047551 0.00030591 0.00071712 0.00035081 0.00046793
 0.00065938]
Model epoch 121: train total loss -64.74098808466158, train mean loss 0.00030344646090668627, test mean loss [0.00041407 0.00044358 0.00029351 0.00071562 0.00035671 0.00048336
 0.00065006]
Model epoch 122: train total loss -64.70320843231433, train mean loss 0.00028142546141382286, test mean loss [0.00043892 0.00045244 0.00029779 0.00069793 0.0003392  0.00046434
 0.00065722]
Model epoch 123: train total loss -64.68491614546137, train mean loss 0.00030041296748423174, test mean loss [0.00041784 0.00044962 0.00029297 0.00068987 0.00033826 0.00045915
 0.00066556]
Model epoch 124: train total loss -64.65939814153477, train mean loss 0.00026833778504392267, test mean loss [0.00040661 0.0004453  0.00032185 0.00070059 0.00034333 0.00046712
 0.00066613]
Model epoch 125: train total loss -64.7114408109974, train mean loss 0.0003896096662373733, test mean loss [0.00041388 0.00044018 0.00029948 0.00068617 0.00033678 0.00046507
 0.00064015]
Model epoch 126: train total loss -64.84247842465388, train mean loss 0.00031022175376653824, test mean loss [0.00040188 0.00044994 0.00029747 0.00068199 0.00035498 0.00047712
 0.00063094]
Model epoch 127: train total loss -64.61928304860213, train mean loss 0.000325215669670265, test mean loss [0.00039437 0.00044119 0.00028801 0.00068211 0.00032997 0.00047159
 0.00064017]
Model epoch 128: train total loss -64.43176239413758, train mean loss 0.0002241073663291762, test mean loss [0.00042037 0.00045167 0.00028418 0.0006777  0.00034322 0.0004551
 0.00063364]
Model epoch 129: train total loss -64.69576611873298, train mean loss 0.00024594009072316525, test mean loss [0.00038485 0.00043995 0.00028068 0.00069251 0.00032407 0.00045044
 0.00063372]
Model epoch 130: train total loss -64.78551409109218, train mean loss 0.0003680354772404654, test mean loss [0.00040594 0.00045301 0.00027979 0.00066235 0.00034471 0.00045531
 0.0006214 ]
Model epoch 131: train total loss -64.82289926748419, train mean loss 0.0002521311901753238, test mean loss [0.00038348 0.00043663 0.00029219 0.0006624  0.00034097 0.00045171
 0.00060229]
Model epoch 132: train total loss -64.27421843141377, train mean loss 0.0003277340528270695, test mean loss [0.00039576 0.00044059 0.00028795 0.00067006 0.00032975 0.00045653
 0.00063793]
Model epoch 133: train total loss -64.8026805443499, train mean loss 0.0002741500122581559, test mean loss [0.0003896  0.00044101 0.00030167 0.00066667 0.00032155 0.00044979
 0.00060787]
Model epoch 134: train total loss -64.9799838475366, train mean loss 0.0003027259470094157, test mean loss [0.00037184 0.00042969 0.00028232 0.00065224 0.00033103 0.00044463
 0.0006015 ]
Model epoch 135: train total loss -65.00242385398683, train mean loss 0.00019306083305166926, test mean loss [0.00038444 0.00042698 0.00027152 0.00066864 0.00032815 0.00044681
 0.00062404]
Model epoch 136: train total loss -64.7382902575845, train mean loss 0.0002479493655637392, test mean loss [0.00036794 0.00041821 0.00026474 0.0006497  0.00033278 0.00043978
 0.00059874]
Model epoch 137: train total loss -64.84742881762105, train mean loss 0.00032766138420204407, test mean loss [0.00036132 0.00044431 0.0002959  0.00062671 0.00032496 0.00044092
 0.00061518]
Model epoch 138: train total loss -64.567242850721, train mean loss 0.00034901628056775616, test mean loss [0.0003541  0.00043779 0.00028214 0.00065099 0.00034329 0.00044943
 0.00059578]
Model epoch 139: train total loss -64.87007065287662, train mean loss 0.00026397275540737414, test mean loss [0.00036492 0.00042565 0.00028313 0.00064964 0.00031128 0.00043174
 0.0005854 ]
Model epoch 140: train total loss -64.90530364495059, train mean loss 0.00023793830027566228, test mean loss [0.00035973 0.00041345 0.00028009 0.00063024 0.00031882 0.00043395
 0.00059689]
Model epoch 141: train total loss -64.87965501023113, train mean loss 0.00026234660829482006, test mean loss [0.00035809 0.00042523 0.0002708  0.00064252 0.00032041 0.0004201
 0.00060212]
Model epoch 142: train total loss -64.75080905241346, train mean loss 0.0003055274537904897, test mean loss [0.00034872 0.0004143  0.00026425 0.00062823 0.00032171 0.00042353
 0.00061178]
Model epoch 143: train total loss -64.61794259525205, train mean loss 0.00026834505565127533, test mean loss [0.00034887 0.00042899 0.00028253 0.00062725 0.00032016 0.00041663
 0.00060329]
Model epoch 144: train total loss -65.0075589996995, train mean loss 0.000268200519439513, test mean loss [0.00033095 0.00040644 0.00026093 0.00063237 0.00031571 0.00041703
 0.00057358]
Model epoch 145: train total loss -64.79503572136964, train mean loss 0.0002783844885148187, test mean loss [0.00035313 0.00042515 0.00029855 0.00064798 0.00031231 0.0004199
 0.0005924 ]
Model epoch 146: train total loss -64.9788016507742, train mean loss 0.0002732176510223361, test mean loss [0.00033738 0.00040703 0.00026692 0.00062449 0.00031489 0.00042577
 0.00056661]
Model epoch 147: train total loss -64.8325107712158, train mean loss 0.00029160517518879024, test mean loss [0.00034518 0.00041484 0.00026534 0.00061097 0.00030736 0.00040958
 0.00056083]
Model epoch 148: train total loss -64.86152624369967, train mean loss 0.00025336363376128113, test mean loss [0.00034157 0.00039883 0.00025754 0.00061179 0.00031931 0.0004148
 0.00057425]
Model epoch 149: train total loss -65.13109633419985, train mean loss 0.00017163286557667293, test mean loss [0.0003408  0.00040266 0.00025788 0.00061569 0.0003045  0.00042181
 0.00056514]
Model epoch 150: train total loss -64.99069712407986, train mean loss 0.00021569920409061607, test mean loss [0.00033919 0.00040213 0.00025602 0.00060564 0.00037351 0.00040487
 0.00057723]
Model epoch 151: train total loss -64.74795858554869, train mean loss 0.00019189157263881088, test mean loss [0.00034189 0.0004073  0.00025428 0.00061445 0.00031657 0.000436
 0.00056665]
Model epoch 152: train total loss -64.70362288497402, train mean loss 0.00020847780699198522, test mean loss [0.0003146  0.00040452 0.00025904 0.00061413 0.00030579 0.00041938
 0.00054808]
Model epoch 153: train total loss -64.7430716304198, train mean loss 0.000269161878548413, test mean loss [0.00032424 0.00040325 0.00026357 0.00060661 0.00030485 0.00041892
 0.00055776]
Model epoch 154: train total loss -64.70296201665889, train mean loss 0.00024047969509083828, test mean loss [0.00031333 0.00040024 0.00025312 0.00072479 0.00031541 0.00041359
 0.00055724]
Model epoch 155: train total loss -65.14558221341959, train mean loss 0.00021444691013675104, test mean loss [0.00031739 0.0003932  0.00026598 0.00060058 0.00031138 0.00040154
 0.00057958]
Model epoch 156: train total loss -64.79928566329649, train mean loss 0.00019244836797042007, test mean loss [0.0003158  0.00040447 0.00025616 0.00060856 0.000313   0.00040862
 0.00055914]
Model epoch 157: train total loss -64.7885859190645, train mean loss 0.0002418654757519079, test mean loss [0.00030521 0.00041056 0.00025074 0.00060643 0.0003025  0.00039843
 0.00055806]
Model epoch 158: train total loss -65.15724547329333, train mean loss 0.00022042099825279486, test mean loss [0.00029986 0.0003936  0.00024443 0.00059254 0.00029934 0.00039714
 0.0005557 ]
Model epoch 159: train total loss -65.09123261536085, train mean loss 0.0002101673092389574, test mean loss [0.00030951 0.00039456 0.00024431 0.00060252 0.00029396 0.00038965
 0.00055171]
Model epoch 160: train total loss -64.99748049862798, train mean loss 0.00032991013730567675, test mean loss [0.00030405 0.00040005 0.00024174 0.00058175 0.00028307 0.00042441
 0.00052871]
Model epoch 161: train total loss -65.02013193786348, train mean loss 0.0002208546030336798, test mean loss [0.00030373 0.00039978 0.00024819 0.00059144 0.00028077 0.00040361
 0.00053952]
Model epoch 162: train total loss -64.93781713084375, train mean loss 0.00017468235408430724, test mean loss [0.00030367 0.00039799 0.00024825 0.00058066 0.00028761 0.00038765
 0.00054068]
Model epoch 163: train total loss -64.80151298493348, train mean loss 0.00018936128602509616, test mean loss [0.00030698 0.00037889 0.00024919 0.00061552 0.00029493 0.00038364
 0.00054177]
Model epoch 164: train total loss -64.74408679775966, train mean loss 0.00018157233950899269, test mean loss [0.00032268 0.00040444 0.00025098 0.00058802 0.00030353 0.00039044
 0.00055945]
Model epoch 165: train total loss -64.7814656874619, train mean loss 0.0002745692017181627, test mean loss [0.00031969 0.00038935 0.00029446 0.00057069 0.000292   0.00039511
 0.00053813]
Model epoch 166: train total loss -65.03714006505822, train mean loss 0.0003072676835314427, test mean loss [0.00029447 0.00037108 0.00025516 0.00058135 0.00029723 0.00038329
 0.00053429]
Model epoch 167: train total loss -64.99263116082373, train mean loss 0.0002290663057363652, test mean loss [0.00029426 0.0003763  0.00023955 0.00058274 0.00028069 0.00037821
 0.00052978]
Model epoch 168: train total loss -64.93727037034395, train mean loss 0.0002768064990018902, test mean loss [0.00029116 0.00037469 0.0002392  0.0005675  0.00028226 0.00038867
 0.00052666]
Model epoch 169: train total loss -65.25687482735317, train mean loss 0.00027200135925123186, test mean loss [0.00028155 0.00036516 0.00024495 0.00057136 0.00028389 0.00039397
 0.00053832]
Model epoch 170: train total loss -65.01893493537769, train mean loss 0.00018050158583459013, test mean loss [0.00029006 0.0003689  0.00023978 0.00057784 0.0002904  0.00037691
 0.00053477]
Model epoch 171: train total loss -65.0019164111877, train mean loss 0.00019157829770045145, test mean loss [0.00028641 0.00036566 0.00023561 0.0005544  0.00029438 0.00038458
 0.0005291 ]
Model epoch 172: train total loss -65.1400850243511, train mean loss 0.00022307826552748504, test mean loss [0.00027598 0.00037443 0.00024422 0.00055102 0.00029063 0.00039078
 0.00052049]
Model epoch 173: train total loss -64.98611306735164, train mean loss 0.00018486187764759038, test mean loss [0.00027849 0.00037193 0.00023319 0.0005569  0.00027859 0.00039144
 0.00052861]
Model epoch 174: train total loss -65.1770107739052, train mean loss 0.0002858898291863517, test mean loss [0.00029434 0.00037924 0.00023847 0.0005604  0.00027692 0.00037219
 0.00052937]
Model epoch 175: train total loss -65.0008445620985, train mean loss 0.00021406329649324563, test mean loss [0.00027737 0.00037916 0.00026932 0.00054984 0.00027476 0.00037866
 0.00051946]
Model epoch 176: train total loss -64.90203715847277, train mean loss 0.00030785694143371073, test mean loss [0.00027121 0.00035981 0.0002473  0.0005529  0.00027262 0.00037356
 0.00052893]
Model epoch 177: train total loss -65.02217434692609, train mean loss 0.0002340808250202614, test mean loss [0.00029892 0.00036527 0.00023973 0.00054511 0.00027694 0.00036659
 0.00052312]
Model epoch 178: train total loss -64.96643184024627, train mean loss 0.0002273224462432719, test mean loss [0.0002757  0.00035552 0.00022864 0.00053604 0.0002924  0.00036299
 0.0005172 ]
Model epoch 179: train total loss -64.99929247360934, train mean loss 0.0003637415822786508, test mean loss [0.00027246 0.00036738 0.00022609 0.00060637 0.00026971 0.00036694
 0.00052362]
Model epoch 180: train total loss -64.96920753669373, train mean loss 0.00019921623162514539, test mean loss [0.00025942 0.00035253 0.00022516 0.00053825 0.00026996 0.00038687
 0.00050366]
Model epoch 181: train total loss -65.06091463928244, train mean loss 0.0001927957009964644, test mean loss [0.00027542 0.00036468 0.00022601 0.00053041 0.00026955 0.00036724
 0.00050669]
Model epoch 182: train total loss -65.13997468206689, train mean loss 0.00023724434081052957, test mean loss [0.00026835 0.00036354 0.00022407 0.00052701 0.00027024 0.00035664
 0.00051018]
Model epoch 183: train total loss -65.09563929621035, train mean loss 0.00020576364366646212, test mean loss [0.00026315 0.00035785 0.00023271 0.00053722 0.00026804 0.00035154
 0.00050667]
Model epoch 184: train total loss -65.13850506319677, train mean loss 0.00021358494652381712, test mean loss [0.00025654 0.00035318 0.00022677 0.00055741 0.00027785 0.00037437
 0.0004895 ]
Model epoch 185: train total loss -65.13559650098638, train mean loss 0.00020919149995548831, test mean loss [0.00026362 0.00035668 0.00022665 0.00052044 0.00026342 0.00037886
 0.00049568]
Model epoch 186: train total loss -64.9338374058707, train mean loss 0.0002803432092373293, test mean loss [0.00026731 0.0003601  0.00021795 0.00054528 0.00026585 0.00036395
 0.00051852]
Model epoch 187: train total loss -64.95483974000902, train mean loss 0.0002697448695873123, test mean loss [0.00025392 0.00036538 0.00022932 0.00052873 0.0002824  0.00034591
 0.00048417]
Model epoch 188: train total loss -65.11134562462935, train mean loss 0.0002701532522164531, test mean loss [0.00025659 0.00035645 0.00024546 0.00050486 0.00028923 0.00036216
 0.00048865]
Model epoch 189: train total loss -65.04731596268671, train mean loss 0.00024335760812112375, test mean loss [0.00026115 0.00034591 0.00022006 0.00051489 0.00026453 0.00035303
 0.00051303]
Model epoch 190: train total loss -65.1053088798501, train mean loss 0.0002258972572684474, test mean loss [0.00028901 0.00036331 0.0002163  0.00052602 0.00026492 0.00037457
 0.00049848]
Model epoch 191: train total loss -64.70731297891548, train mean loss 0.00023556698081706834, test mean loss [0.00025734 0.00037116 0.00025422 0.00052272 0.00026096 0.00035245
 0.00047711]
Model epoch 192: train total loss -65.1888877070795, train mean loss 0.00020294567255954417, test mean loss [0.00025024 0.00034948 0.00022602 0.00051167 0.00026768 0.00037977
 0.00048965]
Model epoch 193: train total loss -64.96055971346803, train mean loss 0.0002878303115171868, test mean loss [0.00024799 0.00035353 0.00022296 0.00050602 0.00027488 0.00035646
 0.00049414]
Model epoch 194: train total loss -65.09303657023182, train mean loss 0.00030004628277915886, test mean loss [0.00025733 0.00035118 0.00022518 0.00049307 0.00026864 0.00033991
 0.00048403]
Model epoch 195: train total loss -65.06958855152651, train mean loss 0.00019139984895387633, test mean loss [0.0002461  0.00034735 0.00021604 0.00049371 0.00027178 0.00035059
 0.00049379]
Model epoch 196: train total loss -65.32980037440133, train mean loss 0.00017151077948818696, test mean loss [0.0002626  0.00035231 0.00021173 0.0005039  0.00028455 0.00034588
 0.00049446]
Model epoch 197: train total loss -65.17979265351595, train mean loss 0.00020888627400733866, test mean loss [0.00025268 0.00034439 0.00021334 0.00049886 0.00026712 0.00033693
 0.00046916]
Model epoch 198: train total loss -64.9421725296847, train mean loss 0.00021386769257018479, test mean loss [0.00024504 0.00036271 0.00025358 0.00048235 0.00027426 0.00034148
 0.00047295]
Model epoch 199: train total loss -64.80441506154035, train mean loss 0.0001902841714415168, test mean loss [0.00025376 0.00034103 0.00022196 0.00051806 0.00025888 0.00036288
 0.00046784]
Model epoch 200: train total loss -64.87998012949248, train mean loss 0.0002081013286666957, test mean loss [0.00026006 0.00034269 0.00022451 0.00048886 0.00026414 0.00031796
 0.00046834]
Model epoch 201: train total loss -65.00625996509176, train mean loss 0.00021237834220182516, test mean loss [0.00025531 0.00034521 0.00020776 0.00049644 0.00026132 0.00032449
 0.00046617]
Model epoch 202: train total loss -65.03685044249202, train mean loss 0.00019093240251591306, test mean loss [0.00025941 0.00034391 0.00021413 0.00048883 0.00025899 0.00032472
 0.00047955]
Model epoch 203: train total loss -65.21467304658894, train mean loss 0.00016989943431233931, test mean loss [0.00023891 0.00032858 0.00021468 0.00049822 0.00026329 0.00031485
 0.00045523]
Model epoch 204: train total loss -64.99084169603745, train mean loss 0.00016220489211326764, test mean loss [0.00024828 0.00035554 0.00021624 0.00047902 0.00025525 0.00034298
 0.00047468]
Model epoch 205: train total loss -65.1546987830597, train mean loss 0.00020652523519182472, test mean loss [0.00024397 0.00033504 0.00021157 0.00048166 0.00026557 0.00033615
 0.00045561]
Model epoch 206: train total loss -65.1239166747109, train mean loss 0.0002643349275007759, test mean loss [0.00025434 0.00032354 0.00021372 0.00047265 0.00027268 0.00031976
 0.00047183]
Model epoch 207: train total loss -65.04858244492065, train mean loss 0.0002755098315637323, test mean loss [0.00024169 0.00032269 0.00023366 0.00046754 0.00025945 0.00032794
 0.00045844]
Model epoch 208: train total loss -65.15169026766777, train mean loss 0.00019474967197046395, test mean loss [0.00023938 0.00032696 0.00021201 0.00047268 0.00025762 0.00032617
 0.00046673]
Model epoch 209: train total loss -65.2492502976304, train mean loss 0.00028410076587378753, test mean loss [0.00022779 0.00031474 0.00020793 0.00046971 0.00025431 0.00034049
 0.0004605 ]
Model epoch 210: train total loss -65.01344017312073, train mean loss 0.0003493380184464561, test mean loss [0.00023852 0.00031427 0.00021917 0.00048957 0.00027032 0.00032283
 0.00046195]
Model epoch 211: train total loss -64.96332366927928, train mean loss 0.0002138554579199454, test mean loss [0.00025511 0.00031702 0.00022123 0.00045142 0.00025835 0.0003233
 0.00045373]
Model epoch 212: train total loss -65.01935080801489, train mean loss 0.00018849836500585727, test mean loss [0.00025177 0.00032354 0.00020878 0.00047227 0.0002592  0.00031097
 0.00045337]
Model epoch 213: train total loss -65.26525229665765, train mean loss 0.00015312704537718785, test mean loss [0.00023404 0.00031323 0.00021146 0.0004594  0.00025769 0.0003215
 0.00045093]
Model epoch 214: train total loss -65.0908730982358, train mean loss 0.0001795502087066559, test mean loss [0.00023327 0.00032406 0.00021094 0.00044986 0.00027086 0.00031509
 0.00044335]
Model epoch 215: train total loss -65.11238804489005, train mean loss 0.00019709464952216056, test mean loss [0.00024825 0.00033997 0.00019693 0.00046841 0.00026008 0.00031187
 0.00044596]
Model epoch 216: train total loss -64.97022620182459, train mean loss 0.00024099799613880608, test mean loss [0.00023674 0.00030771 0.00020267 0.00045821 0.00025822 0.00030925
 0.00044779]
Model epoch 217: train total loss -65.05109785302386, train mean loss 0.0002387330705903752, test mean loss [0.00023935 0.00031568 0.0002035  0.00047587 0.00024761 0.00031387
 0.00044767]
Model epoch 218: train total loss -65.13134809546477, train mean loss 0.00023682901076391898, test mean loss [0.0002383  0.00032449 0.00020374 0.00045415 0.00026271 0.0003126
 0.00045935]
Model epoch 219: train total loss -65.17572552071567, train mean loss 0.00022497466990711203, test mean loss [0.00024603 0.00033603 0.00021136 0.0004643  0.00024999 0.00031011
 0.00043472]
Model epoch 220: train total loss -65.04250759906226, train mean loss 0.0002294749614783175, test mean loss [0.00022623 0.00032154 0.0002134  0.00044113 0.00024809 0.00031231
 0.00045162]
Model epoch 221: train total loss -65.28238403230617, train mean loss 0.00016025139947852449, test mean loss [0.00023226 0.00030582 0.00019455 0.00046519 0.00024969 0.00029714
 0.00043375]
Model epoch 222: train total loss -65.33463584958932, train mean loss 0.0001733560020344158, test mean loss [0.00022407 0.00030811 0.00020396 0.00044788 0.00024844 0.00031108
 0.00042963]
Model epoch 223: train total loss -65.23898613225491, train mean loss 0.00022959726751871373, test mean loss [0.00023386 0.00031158 0.00019793 0.00044413 0.00025286 0.00030806
 0.00042333]
Model epoch 224: train total loss -64.9563335092909, train mean loss 0.00019592425301020788, test mean loss [0.00023665 0.00029993 0.00019764 0.00043963 0.00025817 0.00030221
 0.00042941]
Model epoch 225: train total loss -65.04704585940135, train mean loss 0.00019673204978909548, test mean loss [0.00023563 0.00029507 0.00020152 0.00046462 0.00024947 0.00031183
 0.00045353]
Model epoch 226: train total loss -64.97284915704977, train mean loss 0.00017467736984223305, test mean loss [0.00022317 0.00029252 0.00021127 0.0004486  0.00024489 0.00030751
 0.0004413 ]
Model epoch 227: train total loss -65.15160559067658, train mean loss 0.00018513668451094136, test mean loss [0.00023369 0.00029794 0.00020628 0.00044911 0.00024471 0.00030461
 0.00043857]
Model epoch 228: train total loss -65.25879816551887, train mean loss 0.00023049229087672988, test mean loss [0.00023974 0.00030679 0.00020786 0.00050964 0.00024288 0.00029971
 0.0004306 ]
Model epoch 229: train total loss -65.04040261675775, train mean loss 0.00022477127403613986, test mean loss [0.00022771 0.0002989  0.00020174 0.00044649 0.00024607 0.00029878
 0.00042236]
Model epoch 230: train total loss -65.20625668059367, train mean loss 0.00015510621461098793, test mean loss [0.00025411 0.00030071 0.00019886 0.00045883 0.00026691 0.00028841
 0.00042223]
Model epoch 231: train total loss -65.08608620272646, train mean loss 0.0002492547508379296, test mean loss [0.0002268  0.00029212 0.00020045 0.00043958 0.00024278 0.00030379
 0.00042056]
Model epoch 232: train total loss -64.96476499958662, train mean loss 0.00019264093337233428, test mean loss [0.00022317 0.00030272 0.00019724 0.00044704 0.00025138 0.000302
 0.00042588]
Model epoch 233: train total loss -65.1182695578027, train mean loss 0.0002135510619340013, test mean loss [0.00022383 0.00029752 0.00019982 0.00044368 0.00024529 0.00029031
 0.00042404]
Model epoch 234: train total loss -65.11569704730373, train mean loss 0.0002074633324627264, test mean loss [0.0002133  0.00028725 0.00020299 0.00048863 0.00025254 0.00029493
 0.00041681]
Model epoch 235: train total loss -65.33554300043733, train mean loss 0.00018600644932149189, test mean loss [0.00022742 0.00029751 0.00020736 0.00044239 0.00024357 0.00029661
 0.00044891]
Model epoch 236: train total loss -65.15251422746213, train mean loss 0.00015316400941678017, test mean loss [0.0004083  0.00029432 0.00020556 0.00044566 0.00024137 0.00028827
 0.00043546]
Model epoch 237: train total loss -65.13199302779553, train mean loss 0.00019787209165669396, test mean loss [0.00024421 0.00029771 0.00019883 0.00043371 0.00023938 0.00028802
 0.00042919]
Model epoch 238: train total loss -65.21141477258205, train mean loss 0.0002383395793010212, test mean loss [0.00023086 0.00029432 0.00021315 0.00043932 0.00023891 0.00029409
 0.00040812]
Model epoch 239: train total loss -65.3163072829696, train mean loss 0.00016835146583449106, test mean loss [0.00022582 0.00028648 0.00019996 0.00042427 0.00023611 0.00028786
 0.00041097]
Model epoch 240: train total loss -65.12068603633567, train mean loss 0.00014912884021589404, test mean loss [0.00022071 0.00028933 0.00019451 0.00043121 0.00023821 0.00028149
 0.00041277]
Model epoch 241: train total loss -65.25842639938072, train mean loss 0.00017986955501770485, test mean loss [0.00023832 0.00028609 0.00020584 0.00043235 0.00023621 0.00028163
 0.00046109]
Model epoch 242: train total loss -65.08669504586152, train mean loss 0.00016678966106162938, test mean loss [0.00021493 0.00028481 0.00024758 0.00042228 0.00023666 0.00029476
 0.00041518]
Model epoch 243: train total loss -65.39503601779447, train mean loss 0.00019211390654473096, test mean loss [0.00020865 0.00029468 0.00020691 0.00042452 0.00023518 0.00028189
 0.00041484]
Model epoch 244: train total loss -65.06378284596397, train mean loss 0.00018909322688178713, test mean loss [0.00021718 0.00029228 0.00019367 0.00044543 0.00023229 0.00028202
 0.0004106 ]
Model epoch 245: train total loss -65.25686797794909, train mean loss 0.00015975670698893584, test mean loss [0.00021444 0.00028719 0.00019788 0.00041929 0.00023646 0.00028241
 0.00040987]
Model epoch 246: train total loss -65.30258401043992, train mean loss 0.00018648257272302785, test mean loss [0.00021611 0.00028143 0.00019826 0.00042554 0.00024377 0.00027699
 0.00042231]
Model epoch 247: train total loss -65.3821721499175, train mean loss 0.00016963339757703331, test mean loss [0.0002147  0.00028397 0.00019512 0.00041949 0.00023403 0.00027313
 0.00042643]
Model epoch 248: train total loss -65.17925018317442, train mean loss 0.0001647049868617791, test mean loss [0.00023663 0.00029767 0.00019353 0.00042884 0.00023617 0.00027346
 0.00042345]
Model epoch 249: train total loss -65.39090774242425, train mean loss 0.00014912694870026895, test mean loss [0.00022212 0.00026995 0.00019927 0.0003998  0.00023416 0.00027902
 0.00039679]
Model epoch 250: train total loss -65.06947936577215, train mean loss 0.00018343877791104148, test mean loss [0.00021418 0.00026671 0.00019582 0.00039656 0.00023884 0.00026987
 0.00039699]
Model epoch 251: train total loss -65.22214542170533, train mean loss 0.00019457580298160533, test mean loss [0.00020077 0.00027749 0.00018555 0.00045548 0.00022757 0.00027583
 0.00040546]
Model epoch 252: train total loss -65.34402372138031, train mean loss 0.000272587056570182, test mean loss [0.00020964 0.00026875 0.00019247 0.00041844 0.00022571 0.00028762
 0.00039338]
Model epoch 253: train total loss -65.30724067937291, train mean loss 0.00018566259430202262, test mean loss [0.00021518 0.00027184 0.00020109 0.00040441 0.0002206  0.00027959
 0.00040352]
Model epoch 254: train total loss -65.25928798374137, train mean loss 0.00016580232840914013, test mean loss [0.00021177 0.0002783  0.00018697 0.0004149  0.00022389 0.00027839
 0.00039849]
Model epoch 255: train total loss -65.11823058170505, train mean loss 0.0002341992051855258, test mean loss [0.00021489 0.00027235 0.00019171 0.00039391 0.00023047 0.00027482
 0.00039587]
Model epoch 256: train total loss -65.33257669617228, train mean loss 0.0001824137245292012, test mean loss [0.00020824 0.00027335 0.00019138 0.00041818 0.00022841 0.00027478
 0.00039642]
Model epoch 257: train total loss -65.239311409843, train mean loss 0.00015270538222701024, test mean loss [0.0002023  0.0002614  0.0001912  0.00041476 0.0002233  0.00027407
 0.00041029]
Model epoch 258: train total loss -65.32270425689009, train mean loss 0.0001642862031425772, test mean loss [0.00020909 0.00027019 0.00019587 0.0004106  0.00022521 0.00029165
 0.00039347]
Model epoch 259: train total loss -65.27720112070354, train mean loss 0.00018726739868499433, test mean loss [0.00020728 0.00026436 0.00019581 0.00041022 0.00022337 0.00027048
 0.00039467]
Model epoch 260: train total loss -65.18461946362906, train mean loss 0.00019277220189922763, test mean loss [0.0002283  0.00025447 0.00018696 0.00041252 0.00022316 0.00027736
 0.00039328]
Model epoch 261: train total loss -65.22705191762564, train mean loss 0.00018363000290729236, test mean loss [0.00020202 0.00025716 0.00018838 0.00038477 0.00022596 0.0002745
 0.00039401]
Model epoch 262: train total loss -65.34669296087765, train mean loss 0.00016349023419848954, test mean loss [0.00021847 0.00027567 0.00018212 0.00039195 0.00023224 0.00026831
 0.00038006]
Model epoch 263: train total loss -65.60070172265998, train mean loss 0.0001714879579433205, test mean loss [0.00020788 0.00025246 0.00019117 0.00039552 0.00023226 0.00027092
 0.00038644]
Model epoch 264: train total loss -65.05336213520901, train mean loss 0.00019629235030913062, test mean loss [0.00020825 0.00025483 0.00018695 0.00038985 0.00023319 0.00026566
 0.00038602]
Model epoch 265: train total loss -65.110282905598, train mean loss 0.00023075934273027168, test mean loss [0.00021201 0.00025351 0.00018876 0.00038925 0.00023478 0.00026977
 0.00036933]
Model epoch 266: train total loss -65.03024407154365, train mean loss 0.00014776227424967263, test mean loss [0.00021775 0.00024338 0.00019012 0.00038263 0.00022612 0.00027281
 0.00040115]
Model epoch 267: train total loss -65.56911205388097, train mean loss 0.00016957095473454375, test mean loss [0.00019868 0.00024663 0.00018506 0.00039565 0.00021636 0.0002652
 0.00037339]
Model epoch 268: train total loss -65.6382634081884, train mean loss 0.00018771575343971516, test mean loss [0.00021382 0.0002401  0.00018766 0.00038539 0.00021845 0.00027122
 0.00038071]
Model epoch 269: train total loss -65.21496577145714, train mean loss 0.00020718034731709282, test mean loss [0.00020077 0.00023703 0.00018833 0.00039281 0.00022665 0.00027043
 0.00037336]
Model epoch 270: train total loss -65.29849833568701, train mean loss 0.00017257785529547532, test mean loss [0.00019933 0.00025159 0.00018422 0.00040158 0.00021757 0.00026451
 0.00037154]
Model epoch 271: train total loss -65.54854601335587, train mean loss 0.00019928591202174084, test mean loss [0.00019787 0.00026335 0.0001807  0.00038759 0.00021969 0.00027387
 0.00037639]
Model epoch 272: train total loss -65.13760039093533, train mean loss 0.00018198685789520838, test mean loss [0.00020092 0.00024347 0.00017923 0.00039163 0.00021812 0.00027368
 0.00037035]
Model epoch 273: train total loss -65.34050631578306, train mean loss 0.0002274570065051488, test mean loss [0.00020085 0.00025136 0.00018854 0.00039286 0.00022164 0.00026848
 0.00036557]
Model epoch 274: train total loss -65.3024092748104, train mean loss 0.00018711167063333535, test mean loss [0.00021716 0.00024282 0.00019815 0.00040208 0.00021747 0.00025404
 0.00041236]
Model epoch 275: train total loss -65.43800971133271, train mean loss 0.0001663919843484625, test mean loss [0.00020435 0.00024467 0.00018266 0.00039001 0.00024192 0.00025333
 0.00037338]
Model epoch 276: train total loss -65.15230915738232, train mean loss 0.00016733014271058758, test mean loss [0.00020419 0.00023425 0.00020518 0.00039228 0.00022351 0.00025297
 0.00036775]
Model epoch 277: train total loss -65.12221023878698, train mean loss 0.00016402722085789214, test mean loss [0.00021229 0.0002379  0.00019    0.00038642 0.00021811 0.0002448
 0.00036074]
Model epoch 278: train total loss -65.21248504409839, train mean loss 0.00017710079318544348, test mean loss [0.00019958 0.00024592 0.00018485 0.00038555 0.00021503 0.00026117
 0.0004252 ]
Model epoch 279: train total loss -65.4103932692843, train mean loss 0.00017478572335877295, test mean loss [0.00019294 0.00023328 0.00018096 0.00040123 0.00023097 0.00025633
 0.00035959]
Model epoch 280: train total loss -65.41665106223786, train mean loss 0.00015900409937832948, test mean loss [0.00019275 0.00023214 0.00020901 0.00038028 0.00022397 0.00026498
 0.00036791]
Model epoch 281: train total loss -65.37900754075248, train mean loss 0.00017241366698688709, test mean loss [0.00019663 0.00023518 0.00019952 0.00037115 0.00021774 0.00027112
 0.00036616]
Model epoch 282: train total loss -65.06086717349466, train mean loss 0.00016584680855044351, test mean loss [0.00020384 0.00022564 0.00019833 0.00036831 0.00021207 0.00026146
 0.00035729]
Model epoch 283: train total loss -65.43054491850455, train mean loss 0.0001627493709494699, test mean loss [0.00019553 0.00023781 0.00018249 0.00036653 0.00021922 0.00026056
 0.00036217]
Model epoch 284: train total loss -65.37074943707789, train mean loss 0.00017649584999704666, test mean loss [0.00018748 0.00023893 0.00018979 0.00037576 0.00021658 0.00026559
 0.00035668]
Model epoch 285: train total loss -65.14154237751292, train mean loss 0.00015993735418908984, test mean loss [0.00019512 0.00023471 0.00023283 0.00036358 0.0002196  0.0002548
 0.00035754]
Model epoch 286: train total loss -65.35762772814675, train mean loss 0.00017190750255602688, test mean loss [0.00019369 0.00023092 0.00019601 0.00035919 0.00025009 0.00025963
 0.00034814]
Model epoch 287: train total loss -65.28017434908328, train mean loss 0.00016823125233378215, test mean loss [0.00020182 0.00022069 0.00018514 0.00036991 0.00022121 0.00025189
 0.00036011]
Model epoch 288: train total loss -65.34909171510326, train mean loss 0.00015094210780990168, test mean loss [0.00019635 0.00021908 0.00018128 0.00037671 0.0002096  0.00024392
 0.00036786]
Model epoch 289: train total loss -65.56913025898777, train mean loss 0.0001576552826905423, test mean loss [0.00019185 0.00022371 0.00017884 0.00037003 0.00020809 0.00024373
 0.00035443]
Model epoch 290: train total loss -65.3614314531801, train mean loss 0.00018284740536423605, test mean loss [0.00019089 0.00022168 0.00018249 0.00037089 0.00021865 0.00024229
 0.00034196]
Model epoch 291: train total loss -65.18964282568322, train mean loss 0.0002326309788515531, test mean loss [0.00019717 0.00023221 0.00017438 0.00036556 0.00020254 0.00024129
 0.00034259]
Model epoch 292: train total loss -65.61817683437695, train mean loss 0.00014824944149333157, test mean loss [0.00018584 0.00021357 0.00017989 0.0003778  0.00021509 0.00024752
 0.00035444]
Model epoch 293: train total loss -65.32611987669945, train mean loss 0.00016102106321374776, test mean loss [0.00018715 0.00021866 0.00017652 0.00034667 0.00020929 0.00024514
 0.00034094]
Model epoch 294: train total loss -65.31474183250131, train mean loss 0.00016052245999539886, test mean loss [0.00019618 0.00021573 0.00017328 0.00035762 0.00020785 0.00024195
 0.000342  ]
Model epoch 295: train total loss -65.50875050880065, train mean loss 0.0001772188040852069, test mean loss [0.00019925 0.00022918 0.00018039 0.00036933 0.00020565 0.00027245
 0.00034007]
Model epoch 296: train total loss -65.42972176089164, train mean loss 0.00014356903096598292, test mean loss [0.00019052 0.00021939 0.00018138 0.0003514  0.00020477 0.00024649
 0.00033801]
Model epoch 297: train total loss -65.2771646340782, train mean loss 0.00017291529390056474, test mean loss [0.00018584 0.00022113 0.00017375 0.00035188 0.00020753 0.00024349
 0.00035157]
Model epoch 298: train total loss -65.53676329081917, train mean loss 0.00016356360297558104, test mean loss [0.00019833 0.00021377 0.00018011 0.00036083 0.00021126 0.00023848
 0.00032688]
Model epoch 299: train total loss -65.38652890820131, train mean loss 0.00015719953753153652, test mean loss [0.00018284 0.00021096 0.00017571 0.00035786 0.00020313 0.00023369
 0.00034416]
Model epoch 300: train total loss -65.09595847134612, train mean loss 0.00016999349698436453, test mean loss [0.00022239 0.0002199  0.00017484 0.00035563 0.00020994 0.00022991
 0.00032358]
Model epoch 301: train total loss -65.37001829333063, train mean loss 0.00015525696486652386, test mean loss [0.00019905 0.00020462 0.00017035 0.00035209 0.00020527 0.00024306
 0.0003373 ]
Model epoch 302: train total loss -65.36806524393748, train mean loss 0.00015528949568517026, test mean loss [0.00020389 0.00020712 0.00017361 0.00034985 0.00020692 0.00023114
 0.00032815]
Model epoch 303: train total loss -65.41709442337553, train mean loss 0.0001505782809041426, test mean loss [0.00019884 0.00021424 0.00017728 0.00034107 0.00020304 0.00024257
 0.00033567]
Model epoch 304: train total loss -65.37830939210498, train mean loss 0.00016268198756540033, test mean loss [0.0002004  0.00021679 0.0001827  0.00035634 0.0002008  0.00023862
 0.00033102]
Model epoch 305: train total loss -65.3006652120435, train mean loss 0.00014963274207507318, test mean loss [0.0001922  0.00020891 0.00017101 0.00035668 0.00020573 0.00023654
 0.00033432]
Model epoch 306: train total loss -65.45010582171676, train mean loss 0.00015085698099964439, test mean loss [0.00019283 0.00022186 0.00017498 0.00035613 0.00020358 0.00026485
 0.0003395 ]
Model epoch 307: train total loss -65.49082131869639, train mean loss 0.00015829958056786395, test mean loss [0.00018623 0.00021611 0.00017988 0.00034708 0.00020594 0.00023031
 0.00032649]
Model epoch 308: train total loss -65.43670589987444, train mean loss 0.00017851206835952353, test mean loss [0.00021543 0.00019706 0.00017327 0.00035766 0.00021465 0.00023348
 0.00033683]
Model epoch 309: train total loss -65.4174185141002, train mean loss 0.0001537215250510338, test mean loss [0.00019811 0.00020847 0.0001842  0.00034354 0.00021469 0.00023484
 0.00033428]
Model epoch 310: train total loss -65.25255546851807, train mean loss 0.00019851238040889118, test mean loss [0.00019123 0.00020603 0.00017957 0.00034347 0.00021449 0.0002238
 0.00032503]
Model epoch 311: train total loss -65.30999945530459, train mean loss 0.0001573261694550149, test mean loss [0.00019307 0.00021198 0.00016849 0.00035414 0.00020653 0.00022225
 0.00033641]
Model epoch 312: train total loss -65.41441972438662, train mean loss 0.00015137441014210576, test mean loss [0.00018146 0.00020919 0.00017878 0.0003385  0.00020359 0.00023239
 0.00032036]
Model epoch 313: train total loss -65.40376669695807, train mean loss 0.00016887951897563027, test mean loss [0.0001885  0.00019965 0.00017996 0.00033684 0.00020486 0.00024063
 0.00033123]
Model epoch 314: train total loss -65.6266362488389, train mean loss 0.00016498510768355056, test mean loss [0.00018144 0.0002071  0.0001739  0.00033482 0.00020686 0.00023174
 0.00031711]
Model epoch 315: train total loss -65.41522298788286, train mean loss 0.000154451917838613, test mean loss [0.00018916 0.00019762 0.00017779 0.00033767 0.00019634 0.00023178
 0.00031497]
Model epoch 316: train total loss -65.495572427067, train mean loss 0.0001594235393221291, test mean loss [0.00019076 0.00020619 0.00017781 0.00033765 0.00019897 0.00024216
 0.00031869]
Model epoch 317: train total loss -65.69022177596301, train mean loss 0.0001502047118314666, test mean loss [0.0001866  0.00020363 0.00017513 0.00032479 0.00020171 0.00022715
 0.0003306 ]
Model epoch 318: train total loss -65.27527964430861, train mean loss 0.00016321113154543497, test mean loss [0.00018612 0.00020454 0.00017925 0.00033438 0.00019449 0.00023258
 0.00032481]
Model epoch 319: train total loss -65.31959116403756, train mean loss 0.0001744796787261225, test mean loss [0.0002098  0.00019453 0.00017786 0.00034039 0.00020182 0.00022956
 0.00032058]
Model epoch 320: train total loss -65.53832772689765, train mean loss 0.0001605804555996938, test mean loss [0.00018419 0.00019446 0.0001721  0.00033102 0.00019914 0.00022614
 0.0003118 ]
Model epoch 321: train total loss -65.586550963857, train mean loss 0.00019154879982529168, test mean loss [0.00018752 0.00018809 0.00018277 0.00033257 0.00019566 0.0002354
 0.00031792]
Model epoch 322: train total loss -65.47898902833046, train mean loss 0.00018108719301746548, test mean loss [0.00018097 0.00019292 0.00016763 0.0003283  0.00019842 0.00022328
 0.00031355]
Model epoch 323: train total loss -65.57173714033627, train mean loss 0.00015781609373097946, test mean loss [0.00018602 0.00019964 0.00016718 0.00033737 0.0001999  0.00022582
 0.00031059]
Model epoch 324: train total loss -65.43898159519497, train mean loss 0.00015309758434951814, test mean loss [0.00017356 0.00018471 0.00016779 0.00033065 0.00019568 0.00022296
 0.00037062]
Model epoch 325: train total loss -65.46882775948794, train mean loss 0.0001678137957157607, test mean loss [0.000194   0.00019494 0.00016488 0.00033656 0.00019485 0.00022251
 0.00032569]
Model epoch 326: train total loss -65.61472415910264, train mean loss 0.00014054933336503521, test mean loss [0.00017612 0.00019077 0.00018451 0.0003142  0.00019316 0.0002306
 0.00031814]
Model epoch 327: train total loss -65.56909840412675, train mean loss 0.00016981589021212914, test mean loss [0.00017994 0.00020924 0.00018158 0.0003251  0.00020266 0.00021978
 0.00030593]
Model epoch 328: train total loss -65.43855705684092, train mean loss 0.0001416613651942458, test mean loss [0.00018843 0.0001982  0.00017846 0.00034895 0.00020267 0.00022931
 0.00032011]
Model epoch 329: train total loss -65.24162312249153, train mean loss 0.0001550204518963332, test mean loss [0.00017938 0.00018845 0.00017167 0.00031816 0.00019811 0.00024358
 0.00031387]
Model epoch 330: train total loss -65.5019357807013, train mean loss 0.000159637469188349, test mean loss [0.00017899 0.00018865 0.0001838  0.00031673 0.00019052 0.00022998
 0.00031134]
Model epoch 331: train total loss -65.64902081558982, train mean loss 0.00016541123044215962, test mean loss [0.00018371 0.0001927  0.00016819 0.00031642 0.00019645 0.00022506
 0.00031364]
Model epoch 332: train total loss -65.67141608415812, train mean loss 0.0001587240112793311, test mean loss [0.00018284 0.00020017 0.00016316 0.00032428 0.00018701 0.00022568
 0.00030632]
Model epoch 333: train total loss -65.749738703882, train mean loss 0.00020274241741452756, test mean loss [0.0001881  0.00019328 0.00016686 0.00032629 0.0002003  0.00022371
 0.00030658]
Model epoch 334: train total loss -65.2750028889957, train mean loss 0.0001841482552725044, test mean loss [0.00017823 0.00019512 0.00016591 0.0003102  0.00019493 0.00022787
 0.00029876]
Model epoch 335: train total loss -65.39365168856177, train mean loss 0.00014721801188223978, test mean loss [0.00017596 0.00018708 0.00016952 0.0003113  0.00019218 0.00021762
 0.0002984 ]
Model epoch 336: train total loss -65.64001277031542, train mean loss 0.0001620228319950864, test mean loss [0.00018137 0.00019407 0.0001747  0.0003151  0.00020879 0.00022492
 0.00031481]
Model epoch 337: train total loss -65.58737618703731, train mean loss 0.00016010192893106928, test mean loss [0.00017518 0.00019347 0.00017086 0.00031908 0.00018359 0.00022645
 0.00031785]
Model epoch 338: train total loss -65.490153124889, train mean loss 0.0001441305770171649, test mean loss [0.0001741  0.00019573 0.00017299 0.00032043 0.00019409 0.00021466
 0.00030344]
Model epoch 339: train total loss -65.339583285469, train mean loss 0.00019232582853895492, test mean loss [0.00018367 0.00018722 0.00016709 0.00032635 0.0001934  0.00022331
 0.00029588]
Model epoch 340: train total loss -65.66927868717393, train mean loss 0.0001621995768166366, test mean loss [0.00018409 0.00019095 0.00016889 0.0003113  0.00019652 0.0002313
 0.00029855]
Model epoch 341: train total loss -65.41486172053412, train mean loss 0.00020583072963400098, test mean loss [0.00017839 0.00018256 0.00016607 0.00030056 0.00018932 0.00021829
 0.00029894]
Model epoch 342: train total loss -65.50782869700127, train mean loss 0.00014587386629152287, test mean loss [0.00018336 0.0001819  0.00019797 0.00030526 0.00018717 0.00021802
 0.00030636]
Model epoch 343: train total loss -65.68097738610514, train mean loss 0.0001499481272050696, test mean loss [0.00018452 0.00018789 0.0001647  0.00030746 0.00019017 0.00021163
 0.00029097]
Model epoch 344: train total loss -65.53339900110086, train mean loss 0.00016596046231374183, test mean loss [0.0001778  0.00017788 0.00017076 0.00029925 0.00018819 0.00021088
 0.00029079]
Model epoch 345: train total loss -65.33384009406176, train mean loss 0.00014372003011419135, test mean loss [0.00018223 0.00018216 0.00016344 0.00031083 0.00018672 0.00021471
 0.00029823]
Model epoch 346: train total loss -65.67918098017434, train mean loss 0.00018796982346630395, test mean loss [0.00018018 0.00019171 0.00017536 0.00031365 0.00018722 0.00021425
 0.00028983]
Model epoch 347: train total loss -65.38709347683883, train mean loss 0.00017542261160601442, test mean loss [0.00021123 0.00018613 0.0001664  0.00033919 0.00019125 0.00021866
 0.00029517]
Model epoch 348: train total loss -65.57044805817894, train mean loss 0.0001594076010654185, test mean loss [0.00017825 0.00018748 0.00017485 0.00032172 0.00018328 0.00021299
 0.00028546]
Model epoch 349: train total loss -65.522311036213, train mean loss 0.000191360792811318, test mean loss [0.00019693 0.00018305 0.00015932 0.00030591 0.00019836 0.00020941
 0.0002929 ]
Model epoch 350: train total loss -65.70178453083541, train mean loss 0.00015183864155784142, test mean loss [0.00017781 0.00017563 0.00017163 0.00030294 0.00018672 0.0002167
 0.00029146]
Model epoch 351: train total loss -65.21711553524379, train mean loss 0.00016907546667983394, test mean loss [0.00017742 0.00018983 0.00017844 0.00030512 0.00019476 0.00022003
 0.00029041]
Model epoch 352: train total loss -65.50164903042426, train mean loss 0.00014897480812294564, test mean loss [0.00018998 0.00019601 0.00017407 0.0002914  0.00019088 0.00021594
 0.00029058]
Model epoch 353: train total loss -65.26879155064297, train mean loss 0.00016983108720913022, test mean loss [0.00017447 0.0001863  0.00017317 0.00029172 0.0002131  0.00022937
 0.0002946 ]
Model epoch 354: train total loss -65.44666316799078, train mean loss 0.00014715709772469514, test mean loss [0.00017939 0.00018254 0.00016763 0.00029893 0.00019397 0.00021772
 0.00028444]
Model epoch 355: train total loss -65.47588038638176, train mean loss 0.00020313414533218815, test mean loss [0.000173   0.00017607 0.00016368 0.00031309 0.00018486 0.00021276
 0.00030069]
Model epoch 356: train total loss -65.58730583239937, train mean loss 0.0001580038259640872, test mean loss [0.00017826 0.00019256 0.00016961 0.00031114 0.00018382 0.00021631
 0.00028467]
Model epoch 357: train total loss -65.36784220374993, train mean loss 0.0001574047986976253, test mean loss [0.00017696 0.00018609 0.00016975 0.00031863 0.00019546 0.00021258
 0.00028738]
Model epoch 358: train total loss -65.5009145992361, train mean loss 0.00014346739441837756, test mean loss [0.00017698 0.00018051 0.00016941 0.00029745 0.0001915  0.00021137
 0.00028039]
Model epoch 359: train total loss -65.40959320412857, train mean loss 0.00019768398512351484, test mean loss [0.00017376 0.00017421 0.00016513 0.00031963 0.0001835  0.00020516
 0.00028942]
Model epoch 360: train total loss -65.53073329138799, train mean loss 0.00015399488338207695, test mean loss [0.00017833 0.000181   0.00016589 0.00028719 0.00021321 0.00021047
 0.00028273]
Model epoch 361: train total loss -65.27711340992953, train mean loss 0.000153014771486654, test mean loss [0.00018598 0.00018003 0.00016996 0.0002923  0.00019242 0.00020567
 0.0002813 ]
Model epoch 362: train total loss -65.53896868248539, train mean loss 0.00014954808891872083, test mean loss [0.00016925 0.00018172 0.00016334 0.00029284 0.00018558 0.00020562
 0.00028188]
Model epoch 363: train total loss -65.34795241558648, train mean loss 0.00014283922805917126, test mean loss [0.00018502 0.00017404 0.00016397 0.00028799 0.00018473 0.00021322
 0.00027493]
Model epoch 364: train total loss -65.47038857748832, train mean loss 0.00014544976582132898, test mean loss [0.00016987 0.00018561 0.00016081 0.00029069 0.00018145 0.00021976
 0.00028166]
Model epoch 365: train total loss -65.56851988116397, train mean loss 0.00015508904857030773, test mean loss [0.00016974 0.00017418 0.00016072 0.00028235 0.00018869 0.00020664
 0.00027539]
Model epoch 366: train total loss -65.4573821111972, train mean loss 0.0001453768098137027, test mean loss [0.00016516 0.00017584 0.00017783 0.00029565 0.00018275 0.00021407
 0.00027389]
Model epoch 367: train total loss -65.4933924849261, train mean loss 0.00013834191995326146, test mean loss [0.00017037 0.00017443 0.00017441 0.00028259 0.00018175 0.00020782
 0.0002769 ]
Model epoch 368: train total loss -65.7380256656342, train mean loss 0.00013916397368707642, test mean loss [0.00017905 0.00017846 0.00016351 0.0002778  0.00017614 0.00020437
 0.00027295]
Model epoch 369: train total loss -65.6661014346218, train mean loss 0.00016981316712789493, test mean loss [0.00017393 0.00017505 0.00015922 0.00028625 0.00017639 0.00020457
 0.00027341]
Model epoch 370: train total loss -65.40982748777583, train mean loss 0.00015249815487897785, test mean loss [0.00025061 0.00019518 0.00016243 0.00028558 0.00017845 0.00020581
 0.00027069]
Model epoch 371: train total loss -65.27205433573573, train mean loss 0.0001516320033679527, test mean loss [0.00016983 0.00017062 0.00016674 0.00029732 0.0001824  0.00020208
 0.00027872]
Model epoch 372: train total loss -65.87526761864525, train mean loss 0.00014248330375898357, test mean loss [0.00017165 0.00017522 0.00016359 0.00028714 0.00018914 0.00019746
 0.00027409]
Model epoch 373: train total loss -65.48018745338217, train mean loss 0.00018965003456413636, test mean loss [0.00017479 0.00017756 0.00017141 0.00028005 0.00018585 0.00019853
 0.00027411]
Model epoch 374: train total loss -65.56998327829915, train mean loss 0.00015652079922363665, test mean loss [0.00016414 0.00017325 0.00016205 0.00027867 0.00018644 0.00020451
 0.00026688]
Model epoch 375: train total loss -65.6475447275791, train mean loss 0.00016464305727068937, test mean loss [0.00017921 0.00016936 0.00017255 0.0003013  0.00018258 0.00020488
 0.00028228]
Model epoch 376: train total loss -65.79401818467056, train mean loss 0.00016064858785168234, test mean loss [0.00017925 0.00016967 0.00016365 0.0002999  0.00018086 0.00020294
 0.00026487]
Model epoch 377: train total loss -65.69836230414909, train mean loss 0.00015238037042016029, test mean loss [0.00017206 0.0001756  0.0001662  0.00028479 0.00017777 0.00021168
 0.00026633]
Model epoch 378: train total loss -65.69274472374269, train mean loss 0.0001412373363092358, test mean loss [0.00017568 0.00018128 0.00016744 0.00029033 0.00017621 0.00020621
 0.00026853]
Model epoch 379: train total loss -65.26116082946744, train mean loss 0.00016874121824489755, test mean loss [0.0001785  0.00017264 0.00017045 0.00027528 0.00018462 0.00020776
 0.0002759 ]
Model epoch 380: train total loss -65.41219353460488, train mean loss 0.00014356536092178788, test mean loss [0.00017288 0.00017735 0.00016799 0.00027752 0.00018115 0.00020403
 0.00027131]
Model trained in 381 epochs with 6000 transitions.
[2025-01-23 16:43:14,282][absl][INFO] - {'eval/walltime': 226.91980910301208, 'training/sps': 0.20089530256187008, 'training/walltime': 15334.295955896378, 'training/model_train_time': 3268.29354929924, 'training/other_time': 1708.585063457489, 'training/model_horizon': 10, 'training/hallucination_updates_per_training_step': 1000, 'training/env_buffer_size': Array(7000, dtype=int32), 'model/train_total_loss': Array(-65.41219353, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00014357, dtype=float64), 'model/test_total_loss': Array(-65.24988489, dtype=float64), 'model/test_mean_loss': Array(0.00020746, dtype=float64), 'model/train_epochs': 381, 'model/sec_per_epoch': 8.572104335769893, 'sac/actor_loss': Array(-26.53655763, dtype=float64), 'sac/alpha': Array(0.02576959, dtype=float32), 'sac/alpha_loss': Array(2.28577423e-05, dtype=float64), 'sac/buffer_current_size': Array(400000.03, dtype=float32), 'sac/critic_loss': Array(0.03831192, dtype=float64), 'eval/episode_forward_vel': Array(-14.93458661, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-0.1825681, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(3.4972859, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.00675521, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-6.42347811, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(3.90267603, dtype=float64), 'eval/episode_rew_roll': Array(2.77738586, dtype=float64), 'eval/episode_rew_side_motion': Array(4.32761232, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(4.35697622, dtype=float64), 'eval/episode_rew_yaw': Array(7.68509962, dtype=float64), 'eval/episode_rew_z_vel_change': Array(1.93403506, dtype=float64), 'eval/episode_reward': Array(21.03111125, dtype=float64), 'eval/episode_step_count': Array(2850., dtype=float64), 'eval/avg_episode_length': Array(76., dtype=float64), 'eval/epoch_eval_time': 30.709726095199585, 'eval/sps': 32.56297359670413}
Steps / Eval:  7000.0
Reward is  21.031111245376533
Model horizon updated to 12.
Hallucination updates per training step updated to 1000.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -37.193158564763586, train mean loss 0.024877966972879993, test mean loss [0.02507582 0.02800843 0.02432126 0.01916556 0.02687022 0.02080544
 0.0289464 ]
Model epoch 1: train total loss -45.620040496091086, train mean loss 0.019512061841520902, test mean loss [0.02290658 0.02414579 0.02049491 0.01628325 0.02580755 0.01734046
 0.02376039]
Model epoch 2: train total loss -50.24207877337159, train mean loss 0.017242504476971426, test mean loss [0.01938157 0.01863254 0.01644419 0.01269533 0.02246066 0.01400642
 0.01956855]
Model epoch 3: train total loss -53.69929435447519, train mean loss 0.01261009068098699, test mean loss [0.01607993 0.01421586 0.01349207 0.0093581  0.0187435  0.01086657
 0.01612736]
Model epoch 4: train total loss -55.21314807073434, train mean loss 0.010300611572922962, test mean loss [0.01291618 0.01113174 0.0112966  0.00688649 0.01528355 0.00852671
 0.01327899]
Traceback (most recent call last):
  File "/home/ant/ssrl/ssrl/scripts/go1_train.py", line 248, in <module>
    train_go1()
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/ant/ssrl/ssrl/scripts/go1_train.py", line 199, in train_go1
    state = train_fn(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 263, in train
    env_state) = sim_training_epoch_with_timing(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 947, in sim_training_epoch_with_timing
    training_state, model_metrics = train_model(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 661, in train_model
    test_total_loss, test_mean_loss) = model_training_epoch(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 745, in model_training_epoch
    test_total_losses, test_mean_losses) = model_training_epoch_jit(
  File "<string>", line 1, in <lambda>
KeyboardInterrupt