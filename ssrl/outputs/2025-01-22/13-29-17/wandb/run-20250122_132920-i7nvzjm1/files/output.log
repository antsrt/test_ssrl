run_name: null
sweep_name: null
env: Go1GoFast
algo: ssrl
gpus: '0'
num_seeds: 1
ssrl_dynamics_fn: contact_integrate_only
render_during_training: true
render_epoch_interval: 10
render_seed: 0
common:
  action_repeat: 1
  obs_history_length: 5
  normalize_observations: false
  forces_in_q_coords: true
actor_network:
  hidden_layers: 2
  hidden_size: 512
  activation: swish
  max_std: null
critic_network:
  hidden_layers: 5
  hidden_size: 256
env_common:
  policy_repeat: 4
  forward_vel_rew_weight: 2.0
  turn_rew_weight: 0.5
  pitch_rew_weight: 0.25
  roll_rew_weight: 0.25
  yaw_rew_weight: 0.5
  side_motion_rew_weight: 0.5
  z_vel_change_rew_weight: 0.15
  ang_vel_rew_weight: 0.0
  ang_change_rew_weight: 0.25
  joint_lim_rew_weight: 0.0
  torque_lim_rew_weight: 0.0
  joint_acc_rew_weight: 0.0
  action_rew_weight: 0.0
  cosmetic_rew_weight: 0.0
  energy_rew_weight: 0.25
  foot_z_rew_weight: 0.0
  torque_lim_penalty_weight: 0.1
  fallen_roll: 0.785
  fallen_pitch: 0.785
  include_height_in_obs: false
  gains_in_action_space: false
  reward_type: normalized
env_sac:
  policy_repeat: ${env_common.policy_repeat}
  forward_cmd_vel_type: constant
  forward_cmd_vel_range: 0.0
  forward_cmd_vel_period_range:
  - 40.0
  - 40.0
  turn_cmd_rate_range:
  - -0.0
  - 0.0
  initial_yaw_range:
  - -0.0
  - 0.0
  contact_time_const: 0.02
  contact_damping_ratio: 1.0
  friction_range:
  - 0.6
  - 0.6
  ground_roll_range:
  - 0.0
  - 0.0
  ground_pitch_range:
  - 0.0
  - 0.0
  joint_damping_perc_range:
  - 1.0
  - 1.0
  joint_gain_range:
  - 1.0
  - 1.0
  link_mass_perc_range:
  - 1.0
  - 1.0
  forward_vel_rew_weight: ${env_common.forward_vel_rew_weight}
  turn_rew_weight: ${env_common.turn_rew_weight}
  pitch_rew_weight: ${env_common.pitch_rew_weight}
  roll_rew_weight: ${env_common.roll_rew_weight}
  yaw_rew_weight: ${env_common.yaw_rew_weight}
  side_motion_rew_weight: ${env_common.side_motion_rew_weight}
  z_vel_change_rew_weight: ${env_common.z_vel_change_rew_weight}
  ang_vel_rew_weight: ${env_common.ang_vel_rew_weight}
  ang_change_rew_weight: ${env_common.ang_change_rew_weight}
  joint_lim_rew_weight: ${env_common.joint_lim_rew_weight}
  torque_lim_rew_weight: ${env_common.torque_lim_rew_weight}
  joint_acc_rew_weight: ${env_common.joint_acc_rew_weight}
  action_rew_weight: ${env_common.action_rew_weight}
  cosmetic_rew_weight: ${env_common.cosmetic_rew_weight}
  energy_rew_weight: ${env_common.energy_rew_weight}
  foot_z_rew_weight: ${env_common.foot_z_rew_weight}
  torque_lim_penalty_weight: ${env_common.torque_lim_penalty_weight}
  fallen_roll: ${env_common.fallen_roll}
  fallen_pitch: ${env_common.fallen_pitch}
  forces_in_q_coords: ${common.forces_in_q_coords}
  include_height_in_obs: ${env_common.include_height_in_obs}
  gains_in_action_space: ${env_common.gains_in_action_space}
  reward_type: ${env_common.reward_type}
sac:
  num_timesteps: 10000000
  episode_length: 1000
  action_repeat: ${common.action_repeat}
  obs_history_length: ${common.obs_history_length}
  num_envs: 1
  num_eval_envs: 500
  learning_rate: 0.0001
  discounting: 0.99
  seed: 0
  batch_size: 200
  num_evals: 10
  normalize_observations: ${common.normalize_observations}
  reward_scaling: 1
  tau: 0.001
  min_replay_size: 10000
  max_replay_size: 200000
  grad_updates_per_step: 20
  deterministic_eval: true
env_ssrl:
  policy_repeat: ${env_common.policy_repeat}
  forward_cmd_vel_type: constant
  forward_cmd_vel_range: 0.0
  forward_cmd_vel_period_range:
  - 40.0
  - 40.0
  turn_cmd_rate_range:
  - -0.0
  - 0.0
  initial_yaw_range:
  - -0.0
  - 0.0
  contact_time_const: 0.02
  contact_damping_ratio: 1.0
  friction_range:
  - 0.6
  - 0.6
  ground_roll_range:
  - 0.0
  - 0.0
  ground_pitch_range:
  - 0.0
  - 0.0
  joint_damping_perc_range:
  - 1.0
  - 1.0
  joint_gain_range:
  - 1.0
  - 1.0
  link_mass_perc_range:
  - 1.0
  - 1.0
  forward_vel_rew_weight: ${env_common.forward_vel_rew_weight}
  turn_rew_weight: ${env_common.turn_rew_weight}
  pitch_rew_weight: ${env_common.pitch_rew_weight}
  roll_rew_weight: ${env_common.roll_rew_weight}
  yaw_rew_weight: ${env_common.yaw_rew_weight}
  side_motion_rew_weight: ${env_common.side_motion_rew_weight}
  z_vel_change_rew_weight: ${env_common.z_vel_change_rew_weight}
  ang_vel_rew_weight: ${env_common.ang_vel_rew_weight}
  ang_change_rew_weight: ${env_common.ang_change_rew_weight}
  joint_lim_rew_weight: ${env_common.joint_lim_rew_weight}
  torque_lim_rew_weight: ${env_common.torque_lim_rew_weight}
  joint_acc_rew_weight: ${env_common.joint_acc_rew_weight}
  action_rew_weight: ${env_common.action_rew_weight}
  cosmetic_rew_weight: ${env_common.cosmetic_rew_weight}
  energy_rew_weight: ${env_common.energy_rew_weight}
  foot_z_rew_weight: ${env_common.foot_z_rew_weight}
  torque_lim_penalty_weight: ${env_common.torque_lim_penalty_weight}
  fallen_roll: ${env_common.fallen_roll}
  fallen_pitch: ${env_common.fallen_pitch}
  forces_in_q_coords: ${common.forces_in_q_coords}
  include_height_in_obs: ${env_common.include_height_in_obs}
  body_height_in_action_space: true
  gains_in_action_space: ${env_common.gains_in_action_space}
  reward_type: ${env_common.reward_type}
  healthy_delta_radius: 2.0
  healthy_delta_yaw: 1.57
ssrl_start_with_sac: false
ssrl:
  episode_length: 1000
  policy_repeat: 1
  num_epochs: 40
  model_trains_per_epoch: 1
  training_steps_per_model_train: 1
  env_steps_per_training_step: 1000
  model_rollouts_per_hallucination_update: 400
  sac_grad_updates_per_hallucination_update: 60
  init_exploration_steps: 1000
  clear_model_buffer_after_model_train: false
  action_repeat: ${common.action_repeat}
  obs_history_length: ${common.obs_history_length}
  num_envs: 1
  num_evals: 41
  num_eval_envs: 1
  policy_normalize_observations: ${common.normalize_observations}
  model_learning_rate: 0.001
  model_training_batch_size: 200
  model_training_max_sgd_steps_per_epoch: null
  model_training_max_epochs: 1000
  model_training_convergence_criteria: 0.01
  model_training_consec_converged_epochs: 6
  model_training_abs_criteria: null
  model_training_test_ratio: 0.2
  model_training_weight_decay: true
  model_training_stop_gradient: false
  model_loss_horizon: 4
  model_check_done_condition: true
  max_env_buffer_size: 15000
  max_model_buffer_size: 400000
  sac_learning_rate: 0.0002
  sac_discounting: 0.99
  sac_batch_size: 256
  real_ratio: 0.06
  sac_reward_scaling: 1.0
  sac_tau: 0.001
  sac_fixed_alpha: None
  seed: 2
  deterministic_in_env: true
  deterministic_eval: true
  hallucination_max_std: -1.0
  zero_final_layer_of_policy: false
ssrl_model:
  hidden_size: 400
  ensemble_size: 7
  num_elites: 5
  probabilistic: true
ssrl_linear_threshold_fn:
  start_epoch: 0
  end_epoch: 10
  start_model_horizon: 1
  end_model_horizon: 20
ssrl_hupts_fn:
  start_epoch: 0
  end_epoch: 4
  start_hupts: 10
  end_hupts: 1000
render:
  policy: ssrl
wandb:
  entity: an-tsaritsin-itmo-university
  log_sac: false
  log_ssrl: true
save_policy:
  sac: false
  sac_all: false
  ssrl: false
  ssrl_all: false
torque_validate:
  hardware_data: true
Running on GPU 0
[2025-01-22 13:29:23,009][root][INFO] - Converting mesh (1480430270348075028, 8356747892524029152) into convex hull.
[2025-01-22 13:29:28,587][root][INFO] - Converting mesh (-6444380290640729702, -5976922419355068616) into convex hull.
[2025-01-22 13:29:31,094][root][INFO] - Converting mesh (1673135400350514177, 8753587636396306574) into convex hull.
[2025-01-22 13:29:34,763][root][INFO] - Converting mesh (2935570128349821522, -8854466991956336696) into convex hull.
[2025-01-22 13:29:39,078][root][INFO] - Converting mesh (-6878648828418003997, -1377683901893822833) into convex hull.
[2025-01-22 13:30:32,080][absl][INFO] - {'eval/walltime': 44.71629309654236, 'eval/episode_forward_vel': Array(-107.29903684, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-0.10782431, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(52.46575552, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.44550945, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-46.15012337, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(53.26432612, dtype=float64), 'eval/episode_rew_roll': Array(52.93865847, dtype=float64), 'eval/episode_rew_side_motion': Array(59.75179275, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(65.75532968, dtype=float64), 'eval/episode_rew_yaw': Array(6.67624879, dtype=float64), 'eval/episode_rew_z_vel_change': Array(26.39079833, dtype=float64), 'eval/episode_reward': Array(271.54155796, dtype=float64), 'eval/episode_step_count': Array(499500., dtype=float64), 'eval/avg_episode_length': Array(1000., dtype=float64), 'eval/epoch_eval_time': 44.71629309654236, 'eval/sps': 22.363213288744724}
Steps / Eval:  0
Reward is  271.5415579582898
Total reward is  272.1635891896272
[2025-01-22 13:32:49,322][absl][INFO] - env buffer size after init exploration 1000
Model epoch 0: train total loss -2.4318797428048833, train mean loss 0.0803232080904629, test mean loss [0.0906078  0.09063566 0.09062157 0.09058327 0.09062278 0.09062113
 0.09060134]
Model epoch 1: train total loss -3.509977983728859, train mean loss 0.07839467106790095, test mean loss [0.08810848 0.08889389 0.08815247 0.08760606 0.08846426 0.08830055
 0.08772132]
Model epoch 2: train total loss -10.325116983499775, train mean loss 0.07182702049253845, test mean loss [0.08088707 0.07987435 0.0784058  0.07921007 0.07988769 0.0799564
 0.07920732]
Model epoch 3: train total loss -23.15087528438039, train mean loss 0.0715489811724074, test mean loss [0.08021293 0.07849249 0.07822957 0.08133864 0.07697219 0.07829182
 0.08225227]
Model epoch 4: train total loss -32.02146471815724, train mean loss 0.07051962999410492, test mean loss [0.07725349 0.07878033 0.07779006 0.08052403 0.07849037 0.07724474
 0.08124466]
Model epoch 5: train total loss -34.73532168463947, train mean loss 0.07095996953980954, test mean loss [0.07767793 0.07869756 0.0778103  0.07862082 0.07802658 0.07809256
 0.07896178]
Model epoch 6: train total loss -35.49636148527356, train mean loss 0.06920721802035261, test mean loss [0.07667589 0.07803403 0.07575053 0.07731476 0.0760631  0.07660761
 0.07810122]
Model epoch 7: train total loss -36.55696836327107, train mean loss 0.06828303604307005, test mean loss [0.07503134 0.07663711 0.07423749 0.07602584 0.07583933 0.07610825
 0.0777736 ]
Model epoch 8: train total loss -37.40653604682554, train mean loss 0.06635465617932991, test mean loss [0.07337374 0.07567028 0.07372747 0.07493689 0.07648363 0.07488536
 0.07673099]
Model epoch 9: train total loss -38.00169756646959, train mean loss 0.06536289345346408, test mean loss [0.07276252 0.07425539 0.07392356 0.07502879 0.0761947  0.07271409
 0.07614077]
Model epoch 10: train total loss -38.39478949679256, train mean loss 0.06444699611093672, test mean loss [0.07152689 0.07207504 0.07083826 0.07544159 0.07285391 0.06868318
 0.07525842]
Model epoch 11: train total loss -38.99467985962306, train mean loss 0.06246559487032184, test mean loss [0.0675225  0.0686743  0.06734067 0.07538527 0.06925646 0.06463918
 0.07451193]
Model epoch 12: train total loss -39.48117912362354, train mean loss 0.06047167813920192, test mean loss [0.063783   0.06594809 0.06347537 0.07366102 0.06595557 0.06106217
 0.07316774]
Model epoch 13: train total loss -40.099737853182376, train mean loss 0.058482468005231686, test mean loss [0.06126256 0.06153922 0.05921187 0.07081537 0.06125937 0.05618268
 0.07136254]
Model epoch 14: train total loss -40.90671348906759, train mean loss 0.05366184722396567, test mean loss [0.05936834 0.05739217 0.05424196 0.06718946 0.05736203 0.05206694
 0.06969452]
Model epoch 15: train total loss -41.622431946977905, train mean loss 0.05170277641737253, test mean loss [0.05776076 0.05388295 0.0499131  0.06318743 0.05518312 0.04896588
 0.06783844]
Model epoch 16: train total loss -42.319857532892875, train mean loss 0.04935382121507295, test mean loss [0.05613535 0.05073604 0.04670378 0.06008975 0.04980712 0.04400148
 0.06446028]
Model epoch 17: train total loss -42.951668306551475, train mean loss 0.04602517049539881, test mean loss [0.05243313 0.04798574 0.04225757 0.05773411 0.04865016 0.04024537
 0.06060026]
Model epoch 18: train total loss -43.47397635231358, train mean loss 0.04366535596165865, test mean loss [0.04802952 0.04585229 0.04006718 0.05432056 0.04668856 0.03951064
 0.05560085]
Model epoch 19: train total loss -44.061928236235566, train mean loss 0.04152169704417913, test mean loss [0.04510155 0.04383455 0.03845493 0.05165798 0.04603184 0.03778435
 0.05110793]
Model epoch 20: train total loss -44.66601648162565, train mean loss 0.039358490492816846, test mean loss [0.04299073 0.04228525 0.0361549  0.04873528 0.04317528 0.03582484
 0.04817073]
Model epoch 21: train total loss -44.870066099068254, train mean loss 0.03783790556169283, test mean loss [0.04091997 0.04042847 0.03435693 0.04648123 0.04127729 0.03586984
 0.0456675 ]
Model epoch 22: train total loss -45.37276065837193, train mean loss 0.036510246589183004, test mean loss [0.03878769 0.03821417 0.03336296 0.04442385 0.04064437 0.03440668
 0.04260102]
Model epoch 23: train total loss -45.84804838941161, train mean loss 0.03428664304374159, test mean loss [0.03759872 0.03583107 0.03325315 0.0435116  0.0381481  0.03296258
 0.04073799]
Model epoch 24: train total loss -46.07866253016817, train mean loss 0.03373186675731824, test mean loss [0.03647686 0.03492418 0.03243653 0.04210969 0.0364504  0.03194185
 0.03852625]
Model epoch 25: train total loss -46.48712674363819, train mean loss 0.03293887143363636, test mean loss [0.03505491 0.03348474 0.03110239 0.04059056 0.03455619 0.03110743
 0.03697661]
Model epoch 26: train total loss -46.440022306000714, train mean loss 0.03169978688052382, test mean loss [0.03426707 0.03211163 0.03056347 0.0405046  0.03328045 0.03055627
 0.03629623]
Model epoch 27: train total loss -46.89394881300748, train mean loss 0.03118885637558966, test mean loss [0.03322366 0.0311469  0.03107261 0.04048562 0.03248484 0.02998769
 0.03448762]
Model epoch 28: train total loss -47.25691494017638, train mean loss 0.03040562065043344, test mean loss [0.03233635 0.03003982 0.03007545 0.03828988 0.03172968 0.03021721
 0.03319398]
Model epoch 29: train total loss -47.56302153333154, train mean loss 0.029762116555066748, test mean loss [0.03109366 0.02917045 0.03021139 0.03751687 0.03146491 0.0292275
 0.03278077]
Model epoch 30: train total loss -47.94757834182168, train mean loss 0.029194691224386164, test mean loss [0.03027808 0.02849898 0.02926124 0.03650514 0.03080294 0.02853033
 0.03151648]
Model epoch 31: train total loss -48.33412304134662, train mean loss 0.028475216214632355, test mean loss [0.02999106 0.02766599 0.02822723 0.03546668 0.0301139  0.02718864
 0.0306651 ]
Model epoch 32: train total loss -48.60181794197692, train mean loss 0.02772566578632195, test mean loss [0.0286745  0.02717374 0.02817992 0.03432799 0.02975187 0.02639917
 0.02961565]
Model epoch 33: train total loss -48.80033300999077, train mean loss 0.02702563663293563, test mean loss [0.02850643 0.02702121 0.02776247 0.03376022 0.02901726 0.02563521
 0.02868102]
Model epoch 34: train total loss -49.0236685899418, train mean loss 0.026517924660943944, test mean loss [0.02773465 0.02656171 0.02755414 0.03355366 0.02810303 0.02492583
 0.02791975]
Model epoch 35: train total loss -49.141589099444936, train mean loss 0.02656171183029592, test mean loss [0.02693087 0.02624254 0.02669888 0.03282945 0.02763353 0.02487396
 0.02737536]
Model epoch 36: train total loss -49.45915450317225, train mean loss 0.025380583586179936, test mean loss [0.02627333 0.02628555 0.02573711 0.03201255 0.02762541 0.02454061
 0.02793368]
Model epoch 37: train total loss -49.74908439802403, train mean loss 0.02512680488633971, test mean loss [0.02550303 0.02539504 0.02523816 0.0313306  0.02735175 0.02359675
 0.02689203]
Model epoch 38: train total loss -49.88912521306833, train mean loss 0.02475025829287189, test mean loss [0.0249216  0.02475987 0.02460994 0.03073178 0.02599343 0.02354751
 0.02660361]
Model epoch 39: train total loss -50.18889102451129, train mean loss 0.02389300006032481, test mean loss [0.02427969 0.02435797 0.02453787 0.03035366 0.02535876 0.02279646
 0.02586203]
Model epoch 40: train total loss -50.432625235485666, train mean loss 0.023444728417615513, test mean loss [0.02453261 0.02385379 0.02344412 0.02943048 0.02522006 0.02243797
 0.02499847]
Model epoch 41: train total loss -50.617660520273596, train mean loss 0.022949421724375925, test mean loss [0.02442187 0.02349745 0.02364921 0.02850277 0.02487135 0.02225075
 0.02419718]
Model epoch 42: train total loss -50.74287048950657, train mean loss 0.022867847020290488, test mean loss [0.02383474 0.02348087 0.02361773 0.02780472 0.02459565 0.02187955
 0.02341824]
Model epoch 43: train total loss -50.8746265478671, train mean loss 0.02275337023001813, test mean loss [0.02341676 0.02303834 0.02322603 0.02733953 0.02464605 0.02154402
 0.02289654]
Model epoch 44: train total loss -51.13656837169103, train mean loss 0.022119186207781645, test mean loss [0.02323352 0.02273469 0.02296329 0.0268495  0.02415671 0.0211975
 0.02217274]
Model epoch 45: train total loss -51.42040615060099, train mean loss 0.021679288711429826, test mean loss [0.02289759 0.0226398  0.02239241 0.02629355 0.0239487  0.02117374
 0.02166554]
Model epoch 46: train total loss -51.33947505508876, train mean loss 0.021933007564151567, test mean loss [0.02216142 0.02214209 0.0224232  0.02598078 0.02380518 0.02102688
 0.02106925]
Model epoch 47: train total loss -51.528190659399144, train mean loss 0.02104256402863542, test mean loss [0.02230644 0.02190111 0.02191704 0.02557876 0.02331954 0.02070846
 0.02070101]
Model epoch 48: train total loss -51.40075599852755, train mean loss 0.021029827228859384, test mean loss [0.02177675 0.02145579 0.02166306 0.02576573 0.02303848 0.02082349
 0.02077986]
Model epoch 49: train total loss -51.686946886780675, train mean loss 0.02058486933942511, test mean loss [0.02155214 0.02126187 0.02153216 0.0256057  0.02270782 0.02053911
 0.02085935]
Model epoch 50: train total loss -51.975297579876234, train mean loss 0.020669101937113993, test mean loss [0.02119285 0.0203925  0.02156182 0.02510524 0.02225289 0.02007664
 0.02006195]
Model epoch 51: train total loss -51.94313711963409, train mean loss 0.020177919156492922, test mean loss [0.02110268 0.0200654  0.02115204 0.02472027 0.02146932 0.01999686
 0.01994814]
Model epoch 52: train total loss -52.22462377036693, train mean loss 0.019534430750413275, test mean loss [0.02077772 0.02005585 0.02155322 0.02400922 0.02169942 0.01965973
 0.0191858 ]
Model epoch 53: train total loss -52.36694619625673, train mean loss 0.019715987791592445, test mean loss [0.02082147 0.01962711 0.02111223 0.02358667 0.0213188  0.01941115
 0.01899295]
Model epoch 54: train total loss -52.439960937096494, train mean loss 0.019491889925829092, test mean loss [0.02062422 0.01996848 0.02108948 0.02330387 0.02082839 0.01897685
 0.01864507]
Model epoch 55: train total loss -52.558488982824585, train mean loss 0.019395781044281465, test mean loss [0.01982382 0.0196343  0.0209209  0.02274411 0.02079089 0.01857976
 0.01859858]
Model epoch 56: train total loss -52.76106343311948, train mean loss 0.019340998443885354, test mean loss [0.01943109 0.01926446 0.02034384 0.02285072 0.02048332 0.01841186
 0.01818176]
Model epoch 57: train total loss -53.01190326586082, train mean loss 0.018865098689891713, test mean loss [0.01922738 0.01876696 0.02009567 0.02247884 0.02033472 0.01813989
 0.0179439 ]
Model epoch 58: train total loss -52.965888599173525, train mean loss 0.01866546161103372, test mean loss [0.01961581 0.01796903 0.02012702 0.02239635 0.02008273 0.01798473
 0.01722625]
Model epoch 59: train total loss -53.100750834260275, train mean loss 0.018296636724881896, test mean loss [0.01968217 0.0178503  0.01951492 0.02205072 0.01984953 0.0175283
 0.01720885]
Model epoch 60: train total loss -53.11689364680594, train mean loss 0.018144137366587418, test mean loss [0.01857625 0.01772866 0.01943127 0.02209918 0.01962349 0.01696715
 0.01713234]
Model epoch 61: train total loss -53.25960016526207, train mean loss 0.017987938796853065, test mean loss [0.01819267 0.01762789 0.01920264 0.02191637 0.01910589 0.01711178
 0.01658999]
Model epoch 62: train total loss -53.33398365755419, train mean loss 0.017551652968615734, test mean loss [0.01755236 0.01731074 0.01894145 0.02125885 0.01893295 0.01694765
 0.01674171]
Model epoch 63: train total loss -53.492235041601305, train mean loss 0.01697333678558892, test mean loss [0.01751236 0.0170149  0.01866716 0.02084867 0.01855904 0.01626596
 0.01664288]
Model epoch 64: train total loss -53.52884971847855, train mean loss 0.017072293400851455, test mean loss [0.01709101 0.01628577 0.01861476 0.02090072 0.01855564 0.01617088
 0.01593186]
Model epoch 65: train total loss -53.5461418863968, train mean loss 0.01667176652485904, test mean loss [0.01723241 0.01635629 0.0184004  0.02062364 0.018283   0.01571798
 0.01582944]
Model epoch 66: train total loss -53.80995308805724, train mean loss 0.0165812725202858, test mean loss [0.01706125 0.01622845 0.01789028 0.02062125 0.01820886 0.01571484
 0.01562929]
Model epoch 67: train total loss -53.833718556427144, train mean loss 0.016695899390269008, test mean loss [0.01676378 0.0157589  0.01765813 0.02040952 0.01796054 0.01549147
 0.01525372]
Model epoch 68: train total loss -54.03874505027781, train mean loss 0.015742791309838525, test mean loss [0.01646315 0.01541708 0.01770257 0.01985983 0.01805397 0.01485583
 0.01477769]
Model epoch 69: train total loss -54.13402816307372, train mean loss 0.01589606413121895, test mean loss [0.01634804 0.01525379 0.01739014 0.01945007 0.01775029 0.01474164
 0.01452598]
Model epoch 70: train total loss -54.30315763241967, train mean loss 0.01536576437574325, test mean loss [0.01601476 0.01475745 0.01690702 0.01959519 0.01743822 0.01416877
 0.01428023]
Model epoch 71: train total loss -54.37943106851589, train mean loss 0.014852230702793798, test mean loss [0.01559662 0.01443725 0.01714884 0.01900163 0.01689308 0.01423591
 0.01402019]
Model epoch 72: train total loss -54.28747163125819, train mean loss 0.01556433084318061, test mean loss [0.01551606 0.01421147 0.01694595 0.0187809  0.01664807 0.01415355
 0.01347253]
Model epoch 73: train total loss -54.47582642505143, train mean loss 0.014854353208287029, test mean loss [0.01517252 0.01409422 0.01635774 0.01899359 0.01635808 0.01385102
 0.0134448 ]
Model epoch 74: train total loss -54.6583249021124, train mean loss 0.014489168856129372, test mean loss [0.01496985 0.01362866 0.01591073 0.0189641  0.01618601 0.01384803
 0.01313838]
Model epoch 75: train total loss -54.51142742209389, train mean loss 0.014830313832629598, test mean loss [0.01466235 0.01331611 0.01588306 0.01865863 0.01600883 0.01319007
 0.01304083]
Model epoch 76: train total loss -54.625355342757274, train mean loss 0.014483498866559396, test mean loss [0.01427325 0.01315594 0.01581783 0.01858262 0.01602469 0.01275304
 0.0128642 ]
Model epoch 77: train total loss -54.769291815056135, train mean loss 0.013813810102514357, test mean loss [0.01399821 0.01287789 0.01532831 0.0187924  0.01571846 0.01241438
 0.01246939]
Model epoch 78: train total loss -54.90094910774197, train mean loss 0.01398417834639546, test mean loss [0.01376233 0.01262547 0.01556112 0.01834469 0.01540106 0.01201075
 0.01245901]
Model epoch 79: train total loss -54.91300684666956, train mean loss 0.013650045323071996, test mean loss [0.0134773  0.01257227 0.0150617  0.01806582 0.01529272 0.01191458
 0.01200781]
Model epoch 80: train total loss -55.09984178716933, train mean loss 0.013529719285002625, test mean loss [0.01339237 0.0122931  0.0148967  0.01785889 0.01503061 0.01179019
 0.01160257]
Model epoch 81: train total loss -55.13728403756067, train mean loss 0.013375008528697111, test mean loss [0.01295651 0.01204075 0.01486431 0.01770431 0.01483793 0.01146197
 0.01157956]
Model epoch 82: train total loss -55.298179124651924, train mean loss 0.012923619549013082, test mean loss [0.01285699 0.0118306  0.01468071 0.01745332 0.01473759 0.01107973
 0.01144284]
Model epoch 83: train total loss -55.26032133001437, train mean loss 0.01285251446272865, test mean loss [0.01261808 0.01198078 0.01451613 0.01726763 0.01449612 0.01076627
 0.01119526]
Model epoch 84: train total loss -55.29488923392138, train mean loss 0.012694676000400364, test mean loss [0.01232995 0.01145277 0.01397216 0.01708582 0.0139905  0.01093661
 0.01086792]
Model epoch 85: train total loss -55.46118518217393, train mean loss 0.012295436502728959, test mean loss [0.01227405 0.01136662 0.01414957 0.01720276 0.01404264 0.01047078
 0.01040179]
Model epoch 86: train total loss -55.42933459339761, train mean loss 0.012325887091578771, test mean loss [0.01198843 0.01119298 0.01404991 0.01683242 0.01362027 0.01042424
 0.01054128]
Model epoch 87: train total loss -55.6402458982215, train mean loss 0.011957411240316079, test mean loss [0.01171894 0.01101914 0.01349369 0.01653063 0.01373027 0.01017954
 0.01032483]
Model epoch 88: train total loss -55.69729483100406, train mean loss 0.012078883507881801, test mean loss [0.01162954 0.01060662 0.01332619 0.01668907 0.01359831 0.00973564
 0.00978224]
Model epoch 89: train total loss -55.92384205664531, train mean loss 0.011714209579230727, test mean loss [0.01100043 0.01046239 0.01323051 0.01652192 0.01297248 0.0097879
 0.00977947]
Model epoch 90: train total loss -55.96874537073203, train mean loss 0.011317912310962918, test mean loss [0.01132176 0.01019961 0.01296773 0.01607397 0.01290018 0.00941328
 0.00971695]
Model epoch 91: train total loss -55.99095404072579, train mean loss 0.011306196395756415, test mean loss [0.01087625 0.01007606 0.01251069 0.01623404 0.01279607 0.00921404
 0.00946432]
Model epoch 92: train total loss -55.965422238571534, train mean loss 0.011254886152405365, test mean loss [0.01054603 0.00969827 0.0124128  0.01586138 0.01303713 0.00904492
 0.00907579]
Model epoch 93: train total loss -56.06882153824852, train mean loss 0.011102127014454675, test mean loss [0.01009583 0.00973085 0.01220454 0.0156062  0.01275903 0.00890806
 0.0092352 ]
Model epoch 94: train total loss -56.178240016553985, train mean loss 0.010964293773087705, test mean loss [0.0100799  0.00936031 0.01188255 0.01544137 0.01251422 0.00887922
 0.00897976]
Model epoch 95: train total loss -56.23000821367039, train mean loss 0.010659762897682517, test mean loss [0.00991756 0.00926615 0.01185262 0.01541452 0.01219438 0.00839233
 0.00891792]
Model epoch 96: train total loss -56.300564385159156, train mean loss 0.010484729388919393, test mean loss [0.00955023 0.00916033 0.01158478 0.01528241 0.01193041 0.00810137
 0.00890082]
Model epoch 97: train total loss -56.46452250531128, train mean loss 0.010254643666522742, test mean loss [0.00951774 0.00883191 0.01137478 0.01509246 0.01191695 0.00823958
 0.00840307]
Model epoch 98: train total loss -56.38096569982572, train mean loss 0.009831264767062487, test mean loss [0.00950346 0.00861356 0.01132035 0.01471566 0.01161926 0.00814012
 0.00819097]
Model epoch 99: train total loss -56.43131129660412, train mean loss 0.009795845104545994, test mean loss [0.00915337 0.00833799 0.01140316 0.01437184 0.01170717 0.00800179
 0.00806617]
Model epoch 100: train total loss -56.63727713684253, train mean loss 0.009770096201069979, test mean loss [0.00889391 0.00808275 0.01114816 0.01417051 0.01112615 0.00766549
 0.00772693]
Model epoch 101: train total loss -56.5720655085232, train mean loss 0.009733311220699946, test mean loss [0.00866706 0.00793519 0.01104512 0.01395101 0.01105078 0.00767173
 0.00751952]
Model epoch 102: train total loss -56.59680396689101, train mean loss 0.009577404723243246, test mean loss [0.00861445 0.00756654 0.01105083 0.013855   0.011082   0.00757452
 0.00738751]
Model epoch 103: train total loss -56.726809663847106, train mean loss 0.009145062469611352, test mean loss [0.00835756 0.00778039 0.01062121 0.01357632 0.01058267 0.00769462
 0.00726582]
Model epoch 104: train total loss -56.763481763316356, train mean loss 0.008913332719210437, test mean loss [0.00824831 0.00759084 0.01066105 0.01419392 0.01041432 0.00719508
 0.00702141]
Model epoch 105: train total loss -56.81435508960699, train mean loss 0.009082119212653962, test mean loss [0.00798556 0.00735901 0.01018927 0.01364497 0.01076639 0.00673024
 0.00706278]
Model epoch 106: train total loss -56.94846388711381, train mean loss 0.008829972908299684, test mean loss [0.00777894 0.00714304 0.01015588 0.01338168 0.01031187 0.00692215
 0.00699046]
Model epoch 107: train total loss -56.92969906669768, train mean loss 0.008743288317401473, test mean loss [0.00736213 0.00718765 0.00993133 0.01299406 0.01025524 0.00684223
 0.00675176]
Model epoch 108: train total loss -57.15645480712946, train mean loss 0.00837902133621987, test mean loss [0.00741997 0.00679156 0.00981296 0.01285381 0.01010071 0.0068007
 0.00644603]
Model epoch 109: train total loss -57.04423477800483, train mean loss 0.008561727912272452, test mean loss [0.00730158 0.00661388 0.0096576  0.01265624 0.00998194 0.00655701
 0.0065007 ]
Model epoch 110: train total loss -57.21537705267877, train mean loss 0.008278915484243572, test mean loss [0.00696094 0.00613928 0.00946913 0.01257992 0.00987486 0.00642284
 0.00635967]
Model epoch 111: train total loss -57.22352898795955, train mean loss 0.008090395178738264, test mean loss [0.00711704 0.0064508  0.0092409  0.01250486 0.00938053 0.00637809
 0.00645096]
Model epoch 112: train total loss -57.42084896739736, train mean loss 0.007862884125272683, test mean loss [0.00698743 0.00621211 0.00878678 0.01229125 0.00934757 0.00597348
 0.00609275]
Model epoch 113: train total loss -57.3491152300856, train mean loss 0.007692255698166271, test mean loss [0.00675292 0.0059918  0.00869213 0.0121588  0.00919828 0.00597026
 0.00583838]
Model epoch 114: train total loss -57.49122478814623, train mean loss 0.0077572675450441496, test mean loss [0.00657238 0.00586659 0.00880302 0.01181506 0.00906723 0.00594446
 0.00588483]
Model epoch 115: train total loss -57.365879607407486, train mean loss 0.007507541192957839, test mean loss [0.00642011 0.00563965 0.00881291 0.01218333 0.00877387 0.00562992
 0.00587035]
Model epoch 116: train total loss -57.53409252487424, train mean loss 0.007477676450882896, test mean loss [0.00598834 0.00562426 0.00903201 0.0118643  0.00877883 0.00552679
 0.00570195]
Model epoch 117: train total loss -57.61518417437939, train mean loss 0.007290321017369937, test mean loss [0.00595159 0.00554573 0.00868173 0.01160694 0.00839344 0.00534121
 0.00538147]
Model epoch 118: train total loss -57.57214170821798, train mean loss 0.007171261770723356, test mean loss [0.00590723 0.00552891 0.00836864 0.01196302 0.00841334 0.004956
 0.0052948 ]
Model epoch 119: train total loss -57.67238525074776, train mean loss 0.006865689322890913, test mean loss [0.00571076 0.00509921 0.00829412 0.01133298 0.00806543 0.00517356
 0.00539637]
Model epoch 120: train total loss -57.61728947012117, train mean loss 0.006869890216438763, test mean loss [0.00561918 0.00519376 0.0081559  0.01122539 0.00802032 0.00504251
 0.00514595]
Model epoch 121: train total loss -57.66799127799688, train mean loss 0.006864506572533613, test mean loss [0.00552291 0.00508853 0.00803158 0.0111769  0.00813786 0.00500674
 0.00507714]
Model epoch 122: train total loss -57.858304489686155, train mean loss 0.006873015191675253, test mean loss [0.00549197 0.00485849 0.00777638 0.0111253  0.00793704 0.00498878
 0.00504364]
Model epoch 123: train total loss -57.99667470262313, train mean loss 0.006553288743128329, test mean loss [0.00525389 0.00479053 0.00758566 0.01079677 0.00775363 0.00474074
 0.00521501]
Model epoch 124: train total loss -57.90038128062054, train mean loss 0.006564088615268653, test mean loss [0.00527255 0.00466721 0.0073903  0.01073586 0.00761537 0.0049117
 0.00468515]
Model epoch 125: train total loss -57.958836552028394, train mean loss 0.006120439447871706, test mean loss [0.00494114 0.00436159 0.00744777 0.01063131 0.00774215 0.00486171
 0.00451521]
Model epoch 126: train total loss -57.90557461617845, train mean loss 0.006316275036752455, test mean loss [0.00487684 0.00415056 0.00709202 0.01034003 0.00766296 0.00482539
 0.00447648]
Model epoch 127: train total loss -58.09707051625226, train mean loss 0.0062248857534410226, test mean loss [0.0047738  0.00413559 0.0072114  0.01024576 0.0072471  0.00460815
 0.00450395]
Model epoch 128: train total loss -58.224487153591994, train mean loss 0.006032394525669954, test mean loss [0.00478468 0.00387856 0.00683312 0.01019434 0.00730892 0.00440135
 0.00446899]
Model epoch 129: train total loss -58.06976374598943, train mean loss 0.005958279459556166, test mean loss [0.0045051  0.00403095 0.00687521 0.01009453 0.00718537 0.00410774
 0.00418279]
Model epoch 130: train total loss -58.262443893728666, train mean loss 0.005923672260447843, test mean loss [0.00469042 0.00386426 0.00675124 0.00969535 0.00696977 0.0043344
 0.00414515]
Model epoch 131: train total loss -58.230535531193546, train mean loss 0.005887374496249474, test mean loss [0.00440099 0.00362551 0.00653311 0.00978949 0.00701684 0.00429726
 0.00413657]
Model epoch 132: train total loss -58.337865301156526, train mean loss 0.0058256631744243665, test mean loss [0.00415762 0.00335373 0.00648136 0.00965874 0.0069275  0.00401482
 0.00399552]
Model epoch 133: train total loss -58.40613982120451, train mean loss 0.005528698042404394, test mean loss [0.00427475 0.00336643 0.00649021 0.00955906 0.00654911 0.00452351
 0.00400917]
Model epoch 134: train total loss -58.39975783919532, train mean loss 0.005334131832410482, test mean loss [0.00424851 0.00328216 0.00641934 0.00925922 0.00651564 0.00418726
 0.00397356]
Model epoch 135: train total loss -58.435506043818755, train mean loss 0.0054855056909218535, test mean loss [0.0040342  0.0033159  0.00634024 0.00932602 0.00621157 0.00394775
 0.00387491]
Model epoch 136: train total loss -58.66246157295508, train mean loss 0.005185332075547395, test mean loss [0.00408375 0.00298797 0.00594026 0.00916461 0.00629623 0.00393851
 0.00380045]
Model epoch 137: train total loss -58.66973815482493, train mean loss 0.005211653913376393, test mean loss [0.00402698 0.00301584 0.00604573 0.00921776 0.00627095 0.00372144
 0.00373021]
Model epoch 138: train total loss -58.61156089182725, train mean loss 0.00511549931848623, test mean loss [0.00384909 0.00286233 0.00631721 0.00871746 0.00608696 0.00366634
 0.00378908]
Model epoch 139: train total loss -58.68639583424103, train mean loss 0.00494927193421955, test mean loss [0.00378517 0.00282892 0.00580173 0.00854071 0.00608179 0.00367818
 0.00357079]
Model epoch 140: train total loss -58.65383311156342, train mean loss 0.004864181181937058, test mean loss [0.00378679 0.00288744 0.00562355 0.0085617  0.00577075 0.00360049
 0.00360467]
Model epoch 141: train total loss -58.59809749919955, train mean loss 0.004893681160803557, test mean loss [0.00357303 0.0027128  0.00564865 0.00848609 0.00568505 0.00341053
 0.00356615]
Model epoch 142: train total loss -58.52667500243787, train mean loss 0.0048256138777372426, test mean loss [0.00372795 0.00273367 0.00556788 0.00849732 0.00529959 0.00336385
 0.00325147]
Model epoch 143: train total loss -58.82172876631621, train mean loss 0.004948556790041852, test mean loss [0.00360514 0.00268615 0.00543167 0.00837832 0.00571317 0.0031343
 0.00360477]
Model epoch 144: train total loss -58.93733915192914, train mean loss 0.004549145009065861, test mean loss [0.00360564 0.00266906 0.00535952 0.00804213 0.00537192 0.00314914
 0.00327155]
Model epoch 145: train total loss -58.98494629245965, train mean loss 0.0045185321095832605, test mean loss [0.00340241 0.0025698  0.00509373 0.00809471 0.00526211 0.00308705
 0.00325767]
Model epoch 146: train total loss -59.05916951323867, train mean loss 0.004476820169242699, test mean loss [0.00343672 0.00251181 0.00523686 0.0080952  0.00509104 0.00302615
 0.0031091 ]
Model epoch 147: train total loss -59.093218296419806, train mean loss 0.004417613439642491, test mean loss [0.00327988 0.00236167 0.00500988 0.00789637 0.00521447 0.0029724
 0.00318663]
Model epoch 148: train total loss -59.061080063944054, train mean loss 0.004527585836264873, test mean loss [0.00325262 0.00232047 0.0051345  0.00753479 0.00523075 0.0029048
 0.00295788]
Model epoch 149: train total loss -59.188689991622944, train mean loss 0.004299305288784334, test mean loss [0.00320169 0.00229175 0.00476496 0.00761877 0.00498411 0.00277958
 0.00301883]
Model epoch 150: train total loss -59.01668379041866, train mean loss 0.004219533815838151, test mean loss [0.00319452 0.00237855 0.00468045 0.00748887 0.00498143 0.00288186
 0.00288298]
Model epoch 151: train total loss -59.15923360870849, train mean loss 0.004045426468467002, test mean loss [0.00316369 0.0022341  0.00463136 0.0071419  0.00487433 0.00276429
 0.00316474]
Model epoch 152: train total loss -59.12486353429488, train mean loss 0.004009849245610383, test mean loss [0.00299647 0.00232564 0.00467162 0.00719258 0.0047874  0.00262105
 0.00298719]
Model epoch 153: train total loss -58.98868543287534, train mean loss 0.004156675950903916, test mean loss [0.00301018 0.00211337 0.00474074 0.00701783 0.00461591 0.00264224
 0.0028469 ]
Model epoch 154: train total loss -59.32918373384531, train mean loss 0.004096280539987873, test mean loss [0.00292589 0.00199351 0.00457365 0.00689767 0.0046346  0.00259934
 0.00291831]
Model epoch 155: train total loss -59.36011910874112, train mean loss 0.003912433695770661, test mean loss [0.00287072 0.00204628 0.00429513 0.00679095 0.00453564 0.0023405
 0.00285818]
Model epoch 156: train total loss -59.04588676380211, train mean loss 0.00394680200563429, test mean loss [0.00285872 0.00205194 0.00479446 0.00667288 0.00460638 0.00244932
 0.00284618]
Model epoch 157: train total loss -59.28024359393581, train mean loss 0.0037640887028878387, test mean loss [0.0028264  0.00194411 0.00450596 0.0064837  0.00447225 0.00247362
 0.00271507]
Model epoch 158: train total loss -58.991403332813846, train mean loss 0.004053723049180171, test mean loss [0.00380464 0.0018208  0.0045312  0.00654328 0.00429941 0.00229722
 0.00272101]
Model epoch 159: train total loss -59.206104102739864, train mean loss 0.003702835777025147, test mean loss [0.0028996  0.00175391 0.00439438 0.00629894 0.00417564 0.00240304
 0.00275326]
Model epoch 160: train total loss -59.31148277170188, train mean loss 0.0036267526562316775, test mean loss [0.00292198 0.00177837 0.00415805 0.00620788 0.00428797 0.00224603
 0.00267807]
Model epoch 161: train total loss -59.45103599217923, train mean loss 0.0036085858134838316, test mean loss [0.00272015 0.00175703 0.00433484 0.00623402 0.00416005 0.00228501
 0.00259846]
Model epoch 162: train total loss -59.48956706184417, train mean loss 0.003567435384813207, test mean loss [0.00258257 0.00169758 0.00409068 0.00608924 0.00397123 0.00216847
 0.00264941]
Model epoch 163: train total loss -59.507213343689784, train mean loss 0.00353771736653278, test mean loss [0.00268325 0.00180937 0.00385262 0.00635359 0.00395277 0.00205715
 0.00270058]
Model epoch 164: train total loss -59.71827203949847, train mean loss 0.0035174257865777992, test mean loss [0.0026054  0.00168103 0.00381913 0.00598641 0.0038764  0.0021454
 0.00248736]
Model epoch 165: train total loss -59.58013296832218, train mean loss 0.0034782950610511543, test mean loss [0.00247178 0.00172745 0.0037002  0.00588954 0.00387555 0.00239198
 0.00241465]
Model epoch 166: train total loss -59.53902429355719, train mean loss 0.00336161284493867, test mean loss [0.00247962 0.00160158 0.00371322 0.00573925 0.00394606 0.00205137
 0.00247604]
Model epoch 167: train total loss -59.62083743221376, train mean loss 0.003410836856602998, test mean loss [0.00236325 0.00150856 0.0036742  0.00558755 0.00384138 0.00203211
 0.00240772]
Model epoch 168: train total loss -59.894618564317156, train mean loss 0.003302536886917947, test mean loss [0.00235765 0.00154642 0.00370063 0.00529481 0.00369835 0.00195688
 0.00232726]
Model epoch 169: train total loss -59.77443528675714, train mean loss 0.0031915030347174573, test mean loss [0.00242195 0.00160633 0.00353    0.00524669 0.00358111 0.00188164
 0.00247603]
Model epoch 170: train total loss -59.94897881795857, train mean loss 0.003030046078913032, test mean loss [0.00237299 0.00161678 0.00355519 0.00520686 0.00349767 0.00185527
 0.00227784]
Model epoch 171: train total loss -59.92685052419573, train mean loss 0.0031475301458493508, test mean loss [0.00232367 0.00146974 0.00343352 0.00509177 0.00361762 0.00174923
 0.00234572]
Model epoch 172: train total loss -60.111456399121735, train mean loss 0.00300783676844944, test mean loss [0.00216747 0.00144208 0.00333776 0.00498178 0.00357701 0.00181561
 0.00234803]
Model epoch 173: train total loss -60.12583723234113, train mean loss 0.002910282460084278, test mean loss [0.00208979 0.00146421 0.00324495 0.00470769 0.003639   0.00174493
 0.00223446]
Model epoch 174: train total loss -59.97013186174188, train mean loss 0.0030380139377897183, test mean loss [0.00216241 0.00140179 0.00332864 0.00475785 0.00342269 0.0016869
 0.00218379]
Model epoch 175: train total loss -60.207899598690624, train mean loss 0.002929343295730103, test mean loss [0.00211129 0.00135933 0.0031107  0.00462825 0.00328003 0.00163266
 0.00220579]
Model epoch 176: train total loss -60.04151447627141, train mean loss 0.0028593209493822753, test mean loss [0.00207596 0.00135707 0.0030003  0.00498912 0.00341688 0.00155069
 0.00216666]
Model epoch 177: train total loss -60.17296898817197, train mean loss 0.0028178461992759626, test mean loss [0.00207972 0.00135317 0.00301311 0.00464895 0.00324932 0.00157036
 0.00206324]
Model epoch 178: train total loss -59.96061658922103, train mean loss 0.0026956518794452587, test mean loss [0.00200983 0.00133364 0.00299463 0.00441721 0.00316337 0.00169093
 0.00211843]
Model epoch 179: train total loss -60.10031043343389, train mean loss 0.0025558213321913246, test mean loss [0.00206046 0.00130414 0.00295431 0.00450008 0.00308848 0.00179312
 0.00202683]
Model epoch 180: train total loss -60.131992452784026, train mean loss 0.0027530103809140245, test mean loss [0.00206806 0.00132512 0.0028691  0.00451604 0.00297439 0.00159098
 0.00193752]
Model epoch 181: train total loss -60.10733650867526, train mean loss 0.0024752620301240927, test mean loss [0.00210302 0.00121327 0.00281312 0.00433211 0.00296836 0.00165624
 0.0020609 ]
Model epoch 182: train total loss -60.10833115018695, train mean loss 0.0026618361099140786, test mean loss [0.00192605 0.00128031 0.00280929 0.00418    0.00326255 0.00157479
 0.0019091 ]
Model epoch 183: train total loss -59.715864867715204, train mean loss 0.002655711279722512, test mean loss [0.00185981 0.00131205 0.00381215 0.00420973 0.00301089 0.00144966
 0.00193249]
Model epoch 184: train total loss -60.06271866945935, train mean loss 0.0027811972969682213, test mean loss [0.00189238 0.00129122 0.00324446 0.00394577 0.0029458  0.00147735
 0.00197202]
Model epoch 185: train total loss -59.481041767154935, train mean loss 0.0029184531577704006, test mean loss [0.00233361 0.00124595 0.00302601 0.00387241 0.00289595 0.00345244
 0.00199665]
Model epoch 186: train total loss -59.351158388102824, train mean loss 0.0028134127575155984, test mean loss [0.0019847  0.00118684 0.00268314 0.00381256 0.00269023 0.00377145
 0.0019035 ]
Model epoch 187: train total loss -59.677403916364334, train mean loss 0.0028436311557547005, test mean loss [0.00200888 0.00116519 0.00255807 0.00389662 0.0027039  0.00354231
 0.00195059]
Model epoch 188: train total loss -60.01105079884176, train mean loss 0.0026690440707285643, test mean loss [0.00184618 0.00113984 0.00254831 0.0037782  0.00266012 0.00318254
 0.00186612]
Model epoch 189: train total loss -60.12841530808945, train mean loss 0.0026661046552967148, test mean loss [0.00181549 0.0011127  0.00244512 0.00375726 0.00284136 0.00287794
 0.00187675]
Model epoch 190: train total loss -60.264934838750456, train mean loss 0.002438275621999483, test mean loss [0.00178773 0.0011325  0.00247955 0.00351853 0.00269149 0.00272523
 0.00183489]
Model epoch 191: train total loss -60.36227296951521, train mean loss 0.0023615889887072875, test mean loss [0.00172325 0.0010675  0.00245275 0.00361814 0.00269041 0.00237057
 0.00180183]
Model epoch 192: train total loss -60.4802301051576, train mean loss 0.0024921132300057968, test mean loss [0.00178873 0.00106508 0.00239291 0.00345611 0.00252005 0.0020845
 0.0017707 ]
Model epoch 193: train total loss -60.627715655373926, train mean loss 0.002314684128407179, test mean loss [0.00173188 0.00107858 0.00239604 0.00348126 0.00253916 0.00198007
 0.00169615]
Model epoch 194: train total loss -60.59348740131753, train mean loss 0.00232449807682244, test mean loss [0.00166492 0.00100895 0.00251862 0.00334932 0.00249373 0.00176403
 0.00175697]
Model epoch 195: train total loss -60.64195387628609, train mean loss 0.002332507102724726, test mean loss [0.00162139 0.00104116 0.00240437 0.00327171 0.00239206 0.0017416
 0.00172628]
Model epoch 196: train total loss -60.64670023077659, train mean loss 0.0022500160883934016, test mean loss [0.00168555 0.001042   0.00240419 0.0031942  0.00247517 0.00159658
 0.00162981]
Model epoch 197: train total loss -60.71411041829861, train mean loss 0.002223939961500573, test mean loss [0.00166924 0.00099001 0.0023438  0.00321688 0.00238087 0.00148588
 0.00164674]
Model epoch 198: train total loss -60.662211147130414, train mean loss 0.0021672537580868347, test mean loss [0.00157628 0.00097258 0.00237969 0.00318365 0.00239907 0.00152903
 0.00164865]
Model epoch 199: train total loss -60.88600447534925, train mean loss 0.002210387160498621, test mean loss [0.00157135 0.00095029 0.00235046 0.00312014 0.00227042 0.00146666
 0.00161139]
Model epoch 200: train total loss -60.8704088999959, train mean loss 0.0020756809520177805, test mean loss [0.00153561 0.00094791 0.0023156  0.00314479 0.0022639  0.00135547
 0.00165286]
Model epoch 201: train total loss -60.93997912165259, train mean loss 0.0021693440337848626, test mean loss [0.00161089 0.00092874 0.0021645  0.00294584 0.00233037 0.00131858
 0.00152779]
Model epoch 202: train total loss -60.90494313648192, train mean loss 0.0019859806537076224, test mean loss [0.00152143 0.00089369 0.00209598 0.00318669 0.00239416 0.00130808
 0.00157135]
Model epoch 203: train total loss -60.74392567140038, train mean loss 0.0019632589298380506, test mean loss [0.00144069 0.00088849 0.00207548 0.00299823 0.00229258 0.00129105
 0.00166445]
Model epoch 204: train total loss -60.63787425879426, train mean loss 0.002083866983055087, test mean loss [0.00147729 0.00092514 0.00208762 0.0029621  0.00219667 0.00114214
 0.00154299]
Model epoch 205: train total loss -60.4386948269298, train mean loss 0.0021665009736605216, test mean loss [0.00241615 0.00091166 0.00207276 0.00293016 0.00214577 0.00126153
 0.00152389]
Model epoch 206: train total loss -60.643058726121346, train mean loss 0.0019606051068804756, test mean loss [0.00187159 0.00095867 0.0021436  0.00297109 0.00220856 0.00126113
 0.00150099]
Model epoch 207: train total loss -60.81919501497015, train mean loss 0.0018583191543000293, test mean loss [0.00160216 0.00095301 0.002069   0.00302388 0.00219035 0.00114786
 0.00151813]
Model epoch 208: train total loss -60.95730531683163, train mean loss 0.0019281438231535917, test mean loss [0.00158159 0.00088418 0.00198739 0.00291597 0.00204356 0.00113101
 0.0014876 ]
Model epoch 209: train total loss -61.0966272015965, train mean loss 0.0019526904458138732, test mean loss [0.00157011 0.00085916 0.00199846 0.00272927 0.00210832 0.001097
 0.00141968]
Model epoch 210: train total loss -61.0954441515204, train mean loss 0.001767677204896467, test mean loss [0.00149064 0.00085711 0.0021147  0.00283258 0.00209166 0.00128924
 0.00141227]
Model epoch 211: train total loss -60.460589906177525, train mean loss 0.0020121156879924144, test mean loss [0.00157545 0.00083739 0.00197975 0.0029699  0.00205294 0.00114251
 0.00154734]
Model epoch 212: train total loss -60.72382437636821, train mean loss 0.0019482691419393727, test mean loss [0.00150852 0.00082795 0.00208659 0.00284306 0.00201992 0.00113056
 0.00143066]
Model epoch 213: train total loss -60.84159161885583, train mean loss 0.0018815887249048493, test mean loss [0.00158109 0.00078506 0.00202977 0.0026957  0.00195394 0.0011258
 0.00138975]
Model epoch 214: train total loss -60.98804523227326, train mean loss 0.0018139426759042586, test mean loss [0.00140377 0.00078517 0.00203001 0.00259237 0.00200085 0.00105539
 0.00134858]
Model epoch 215: train total loss -61.154607539739985, train mean loss 0.0017582474771294485, test mean loss [0.0013277  0.00075778 0.00193707 0.00257824 0.00197467 0.00100156
 0.00136337]
Model epoch 216: train total loss -61.238048225516565, train mean loss 0.0017705916110214793, test mean loss [0.00127726 0.00075921 0.00195557 0.00257721 0.00200878 0.00095135
 0.00128881]
Model epoch 217: train total loss -61.3232436538079, train mean loss 0.0016468265636201858, test mean loss [0.00125663 0.00074096 0.00189573 0.00245878 0.001908   0.0009959
 0.00130955]
Model epoch 218: train total loss -61.48861768298241, train mean loss 0.0017036007201610352, test mean loss [0.00119485 0.00080966 0.00176685 0.00243293 0.00197709 0.00093106
 0.00129342]
Model epoch 219: train total loss -61.426786467896065, train mean loss 0.0017268495543329128, test mean loss [0.00117207 0.00076281 0.00181045 0.00247178 0.00188616 0.00096218
 0.00127507]
Model epoch 220: train total loss -61.45812488586312, train mean loss 0.0016728108032399726, test mean loss [0.00114604 0.00072679 0.00186818 0.00238251 0.00183482 0.00088881
 0.00125805]
Model epoch 221: train total loss -61.33814259102622, train mean loss 0.001599382089872985, test mean loss [0.00109623 0.00073001 0.0018109  0.0024131  0.00186587 0.00105567
 0.00122089]
Model epoch 222: train total loss -61.39240961305449, train mean loss 0.0015962281811299473, test mean loss [0.00116334 0.00071865 0.00185734 0.00241641 0.00184108 0.00090059
 0.00126056]
Model epoch 223: train total loss -61.19894339411379, train mean loss 0.0016381817655227173, test mean loss [0.00120482 0.00068444 0.0018682  0.0022855  0.00185383 0.00086673
 0.00122063]
Model epoch 224: train total loss -61.161974503892786, train mean loss 0.0017317560464191787, test mean loss [0.0013269  0.00072066 0.00178327 0.00230886 0.00193296 0.00083711
 0.00122098]
Model epoch 225: train total loss -61.2419297170673, train mean loss 0.001512379366993442, test mean loss [0.0011248  0.00073075 0.00178079 0.00225625 0.00195713 0.00085066
 0.00117619]
Model epoch 226: train total loss -61.10275637192051, train mean loss 0.001638927019206752, test mean loss [0.00109726 0.00068989 0.0017162  0.00216391 0.00186659 0.00080527
 0.00120182]
Model epoch 227: train total loss -61.260133170657205, train mean loss 0.0015700525189938912, test mean loss [0.00113636 0.00071337 0.00170784 0.00208982 0.00183242 0.00080173
 0.00117636]
Model epoch 228: train total loss -61.46558063936199, train mean loss 0.001483707754650606, test mean loss [0.00105866 0.00065122 0.00169299 0.00216112 0.0018054  0.00075628
 0.00115488]
Model epoch 229: train total loss -61.61787410184363, train mean loss 0.0015096153084958896, test mean loss [0.00105586 0.0006658  0.0016889  0.00199495 0.00183566 0.00077319
 0.0011832 ]
Model epoch 230: train total loss -61.585319591977935, train mean loss 0.0014390445716951786, test mean loss [0.00102389 0.00065067 0.0015948  0.00199445 0.00170906 0.00076442
 0.00114157]
Model epoch 231: train total loss -61.596954101340934, train mean loss 0.0013287482202359452, test mean loss [0.00097922 0.00062455 0.00168833 0.00205085 0.00166419 0.00072773
 0.00115932]
Model epoch 232: train total loss -61.40203263303313, train mean loss 0.0014166502254673208, test mean loss [0.00097542 0.00065888 0.00172819 0.00197597 0.00172293 0.00072342
 0.00112634]
Model epoch 233: train total loss -61.42254439417391, train mean loss 0.0014173971585222016, test mean loss [0.00089633 0.00060393 0.00158601 0.0019573  0.00171512 0.00081054
 0.0011065 ]
Model epoch 234: train total loss -61.60805739419165, train mean loss 0.001355171687532048, test mean loss [0.00092266 0.00063494 0.00168464 0.00195643 0.00170966 0.00078339
 0.00109537]
Model epoch 235: train total loss -61.57804696365358, train mean loss 0.0014680686433994825, test mean loss [0.00105415 0.00063418 0.00160674 0.00194728 0.00164127 0.00073302
 0.00108445]
Model epoch 236: train total loss -61.43137297887027, train mean loss 0.0013683053614154646, test mean loss [0.00098132 0.00059626 0.00157063 0.00201904 0.00160132 0.00074996
 0.00108254]
Model epoch 237: train total loss -61.74414250933014, train mean loss 0.0014336683350443338, test mean loss [0.00092543 0.00060097 0.00157156 0.00197071 0.00156852 0.00068856
 0.00109208]
Model epoch 238: train total loss -61.5605141532004, train mean loss 0.0014293516482051522, test mean loss [0.00093588 0.00060002 0.00155159 0.00197349 0.00157625 0.00065175
 0.00107232]
Model epoch 239: train total loss -61.576064785116216, train mean loss 0.0013606219696804213, test mean loss [0.00091316 0.0005984  0.00151365 0.00189437 0.00164139 0.00066563
 0.00103577]
Model epoch 240: train total loss -61.56193322523138, train mean loss 0.0013706108480389752, test mean loss [0.00089651 0.0005977  0.00160907 0.00188653 0.00163555 0.00065455
 0.00108854]
Model epoch 241: train total loss -61.55638257933586, train mean loss 0.0012987629907949868, test mean loss [0.00088123 0.00060034 0.00159255 0.00183331 0.00153179 0.0006346
 0.00102499]
Model epoch 242: train total loss -61.856000294796765, train mean loss 0.0013404144501547414, test mean loss [0.00084824 0.00058553 0.00145407 0.00188122 0.00154454 0.00060938
 0.00104112]
Model epoch 243: train total loss -61.683132264808116, train mean loss 0.0012912424660618729, test mean loss [0.00086626 0.00056909 0.00142684 0.00193401 0.00153394 0.00060195
 0.00101756]
Model epoch 244: train total loss -61.65232862709666, train mean loss 0.0013080294876341026, test mean loss [0.00085018 0.00055623 0.00148537 0.00181453 0.00152748 0.00075257
 0.00098537]
Model epoch 245: train total loss -61.60505784473459, train mean loss 0.001301767761783195, test mean loss [0.00082796 0.00056529 0.00150431 0.00182804 0.00150675 0.0006478
 0.00099199]
Model epoch 246: train total loss -61.63879502764593, train mean loss 0.0011726317519483104, test mean loss [0.00079573 0.00057906 0.00142317 0.00172549 0.00150898 0.00060964
 0.00103799]
Model epoch 247: train total loss -62.04210340335571, train mean loss 0.0011933726956699592, test mean loss [0.00077936 0.00057229 0.00142166 0.00179675 0.00146906 0.00059109
 0.00099039]
Model epoch 248: train total loss -61.73266497763412, train mean loss 0.0012037267814505904, test mean loss [0.00075643 0.00062647 0.00136278 0.00173173 0.00148121 0.00055596
 0.00097846]
Model epoch 249: train total loss -61.927364431400626, train mean loss 0.0011732962600601432, test mean loss [0.000748   0.00055347 0.00134016 0.00176434 0.00156466 0.00057807
 0.00097524]
Model epoch 250: train total loss -62.057641722898836, train mean loss 0.0012198039996994244, test mean loss [0.00074795 0.00053261 0.00132393 0.00169653 0.00139812 0.00056333
 0.00097702]
Model epoch 251: train total loss -61.980365604923804, train mean loss 0.0011528158000504711, test mean loss [0.0007259  0.00087889 0.00134112 0.00171646 0.00142032 0.00053733
 0.00095808]
Model epoch 252: train total loss -61.814856874243745, train mean loss 0.0012075951945414388, test mean loss [0.00078632 0.00066188 0.00133853 0.00169018 0.00134466 0.00056488
 0.00093137]
Model epoch 253: train total loss -61.711215446416496, train mean loss 0.0011772461284388358, test mean loss [0.00071268 0.00067595 0.00127543 0.00162378 0.00134655 0.00052518
 0.00091568]
Model epoch 254: train total loss -61.92853573344418, train mean loss 0.0012172016069132866, test mean loss [0.00070281 0.00063601 0.00134711 0.00158655 0.00131365 0.00052148
 0.00092687]
Model epoch 255: train total loss -61.8604026195038, train mean loss 0.0011786347999518392, test mean loss [0.00074583 0.00061049 0.00131411 0.00161519 0.0013213  0.00053597
 0.00092579]
Model epoch 256: train total loss -61.53140289266008, train mean loss 0.001169738641249062, test mean loss [0.00072759 0.00059793 0.00128605 0.00154903 0.00129186 0.00053382
 0.00095305]
Model epoch 257: train total loss -61.909655406958635, train mean loss 0.0010994338031559282, test mean loss [0.00073076 0.00057724 0.00124532 0.00157576 0.00125541 0.00050533
 0.000924  ]
Model epoch 258: train total loss -61.81441751366952, train mean loss 0.0012341958498728565, test mean loss [0.0006988  0.00057228 0.00118552 0.00156442 0.00126139 0.00049755
 0.00092075]
Model epoch 259: train total loss -61.90176138168637, train mean loss 0.0011029704100570341, test mean loss [0.00065324 0.00054505 0.00144612 0.00155586 0.00125739 0.00050557
 0.0009343 ]
Model epoch 260: train total loss -61.89910800243291, train mean loss 0.0010870438861659314, test mean loss [0.00065395 0.00055313 0.00126801 0.00153105 0.00125412 0.00052629
 0.00090853]
Model epoch 261: train total loss -61.8927525819116, train mean loss 0.0010557612423522976, test mean loss [0.00064609 0.00051821 0.00125626 0.00147186 0.0013108  0.00048937
 0.00088796]
Model epoch 262: train total loss -62.00848730117932, train mean loss 0.0011063298561844442, test mean loss [0.00061429 0.00051792 0.0011971  0.00149011 0.00122068 0.00048539
 0.00087993]
Model epoch 263: train total loss -62.01454471611905, train mean loss 0.0010593644386689737, test mean loss [0.00061078 0.00051914 0.00116742 0.00148097 0.00115935 0.00045769
 0.0008722 ]
Model epoch 264: train total loss -62.23227334532711, train mean loss 0.001128558409735765, test mean loss [0.00060372 0.00051319 0.00114122 0.00141206 0.00125175 0.00046949
 0.00087341]
Model epoch 265: train total loss -62.16088065375935, train mean loss 0.0010149773030079887, test mean loss [0.00060571 0.00051891 0.00110413 0.00142412 0.00114606 0.00046154
 0.00085693]
Model epoch 266: train total loss -62.29382465132394, train mean loss 0.0010584134120583853, test mean loss [0.00066434 0.00051823 0.00117557 0.00139807 0.00112898 0.00048965
 0.00086283]
Model epoch 267: train total loss -62.20854091820008, train mean loss 0.0009906319670056382, test mean loss [0.00061518 0.00049641 0.00112656 0.0014124  0.00129072 0.00047657
 0.00083054]
Model epoch 268: train total loss -62.11772495629475, train mean loss 0.0010568065138520698, test mean loss [0.0005996  0.00049006 0.00107454 0.00142434 0.00111104 0.00048216
 0.00081718]
Model epoch 269: train total loss -62.0398541740375, train mean loss 0.0010198858603747863, test mean loss [0.00056726 0.00050841 0.00107441 0.0014007  0.00112934 0.00044512
 0.00083187]
Model epoch 270: train total loss -62.23570797805323, train mean loss 0.0010992397438032186, test mean loss [0.00057973 0.00050462 0.00111267 0.00143297 0.00106412 0.00043688
 0.00082704]
Model epoch 271: train total loss -62.293381954797006, train mean loss 0.001014909409693723, test mean loss [0.00055512 0.00048129 0.00107729 0.00140318 0.00100172 0.00043913
 0.00085172]
Model epoch 272: train total loss -62.39373968862987, train mean loss 0.0010093810765814805, test mean loss [0.00054615 0.00046501 0.00105896 0.00138763 0.00098078 0.00042769
 0.00085672]
Model epoch 273: train total loss -62.3377694726834, train mean loss 0.0010762276112605785, test mean loss [0.00054989 0.0004677  0.00110685 0.00136658 0.0010316  0.00041688
 0.00084646]
Model epoch 274: train total loss -62.131533313110936, train mean loss 0.0010618568838683562, test mean loss [0.00054072 0.00048236 0.00106199 0.0013595  0.00107484 0.00042173
 0.00084136]
Model epoch 275: train total loss -62.39296065641713, train mean loss 0.0009472288344238504, test mean loss [0.0005398  0.0004713  0.0010609  0.00133127 0.00102411 0.00044507
 0.00083757]
Model epoch 276: train total loss -62.44492850891364, train mean loss 0.0009194897423941934, test mean loss [0.00052361 0.00046828 0.00102815 0.00130776 0.00102653 0.00042914
 0.00081178]
Model epoch 277: train total loss -62.499093522513, train mean loss 0.0009711758328974911, test mean loss [0.00051811 0.00045392 0.00103318 0.00128554 0.00102493 0.00063956
 0.00081631]
Model epoch 278: train total loss -62.19083507442985, train mean loss 0.0009815221934393347, test mean loss [0.00054487 0.00044978 0.00101362 0.00122252 0.00098066 0.00047388
 0.00089366]
Model epoch 279: train total loss -62.35224037484036, train mean loss 0.0009895096555279335, test mean loss [0.00053016 0.00044814 0.00098504 0.00123707 0.00091388 0.00042341
 0.00081678]
Model epoch 280: train total loss -62.56998553403008, train mean loss 0.0008784706082880768, test mean loss [0.00050566 0.00043858 0.00098262 0.00125804 0.00091187 0.00042884
 0.00080269]
Model epoch 281: train total loss -62.2598039055895, train mean loss 0.0009436558515981746, test mean loss [0.0005174  0.00050944 0.00093449 0.00127073 0.00093901 0.00063049
 0.00087518]
Model epoch 282: train total loss -61.857549553428, train mean loss 0.0009380300284887266, test mean loss [0.00050124 0.00044921 0.00094914 0.00131383 0.00090538 0.00047495
 0.00112076]
Model epoch 283: train total loss -61.257230094960136, train mean loss 0.0010664193543226013, test mean loss [0.00051553 0.00043829 0.00208339 0.00128811 0.00088982 0.0004768
 0.00094952]
Model epoch 284: train total loss -61.60483907511706, train mean loss 0.0011353864364400342, test mean loss [0.0005021  0.00043375 0.0025397  0.00124373 0.00086364 0.00049238
 0.0008384 ]
Model epoch 285: train total loss -60.88673557547283, train mean loss 0.0011300866678158553, test mean loss [0.00048752 0.00047365 0.00213569 0.00120283 0.00084239 0.00049211
 0.00082833]
Model epoch 286: train total loss -61.859427735945204, train mean loss 0.0009849522796003514, test mean loss [0.00050247 0.00075687 0.0017778  0.0012662  0.00082424 0.00049106
 0.0008399 ]
Model epoch 287: train total loss -61.82281567872593, train mean loss 0.0009916879097746846, test mean loss [0.00050294 0.00061005 0.00142564 0.00119883 0.00084046 0.00046708
 0.00078614]
Model epoch 288: train total loss -62.054935663430015, train mean loss 0.0009954865633608424, test mean loss [0.00051836 0.0005323  0.00127812 0.00109908 0.00082849 0.00045177
 0.00078451]
Model epoch 289: train total loss -62.043046003848424, train mean loss 0.0009339517313681484, test mean loss [0.00049389 0.00056099 0.00126979 0.00113316 0.00087971 0.00042218
 0.0007971 ]
Model epoch 290: train total loss -62.004865628168766, train mean loss 0.000985344819100066, test mean loss [0.00049029 0.00057624 0.00119643 0.00115505 0.00126862 0.00044209
 0.00077083]
Model epoch 291: train total loss -62.16623377516911, train mean loss 0.0009595628259763058, test mean loss [0.00048845 0.00055419 0.00116158 0.00109846 0.00106244 0.00040697
 0.00076015]
Model epoch 292: train total loss -62.28884829273812, train mean loss 0.0009269049393609768, test mean loss [0.00048198 0.00060655 0.00111719 0.00115496 0.00095335 0.00039616
 0.00077714]
Model epoch 293: train total loss -62.33407639135667, train mean loss 0.0009031146498678108, test mean loss [0.00045661 0.0005254  0.00111741 0.00113043 0.0008547  0.00040828
 0.00075069]
Model epoch 294: train total loss -62.49899811526037, train mean loss 0.0008910067332722119, test mean loss [0.00051155 0.00052288 0.00105056 0.00112925 0.00084468 0.00039525
 0.00073409]
Model epoch 295: train total loss -62.58589655354006, train mean loss 0.0008276407360880934, test mean loss [0.00048986 0.00047251 0.00098564 0.0010753  0.00077401 0.00039697
 0.00076418]
Model epoch 296: train total loss -62.63651168202305, train mean loss 0.0008112840866421782, test mean loss [0.00046432 0.00044089 0.00092964 0.00111957 0.00073067 0.00038001
 0.00073738]
Model epoch 297: train total loss -62.680122302253686, train mean loss 0.0008318878378605581, test mean loss [0.00046341 0.00044178 0.00092499 0.00107635 0.00070556 0.00038259
 0.00072265]
Model epoch 298: train total loss -62.774522721316295, train mean loss 0.0008259998819096114, test mean loss [0.00044978 0.00044376 0.00087213 0.00101783 0.00072696 0.00040547
 0.00072473]
Model epoch 299: train total loss -62.79642349673061, train mean loss 0.0008233169999395854, test mean loss [0.00046366 0.00044142 0.00087169 0.00099947 0.00070724 0.00038813
 0.0007548 ]
Model epoch 300: train total loss -62.76514066400853, train mean loss 0.0008683387281888392, test mean loss [0.00045363 0.00042994 0.00082201 0.00102042 0.00071314 0.00036669
 0.00073816]
Model epoch 301: train total loss -62.65350236060805, train mean loss 0.0007674618131213995, test mean loss [0.00044034 0.00043518 0.00081378 0.0010118  0.00067833 0.00036594
 0.00072393]
Model epoch 302: train total loss -62.86864270743562, train mean loss 0.0008364754293037246, test mean loss [0.00043941 0.00043212 0.0007852  0.00098359 0.0006752  0.00037597
 0.00073248]
Model epoch 303: train total loss -62.85707465497105, train mean loss 0.0007777865389826221, test mean loss [0.00043486 0.00041866 0.00073119 0.00102451 0.00066476 0.00037892
 0.00071206]
Model epoch 304: train total loss -62.444686591941554, train mean loss 0.0007952889160699095, test mean loss [0.00045673 0.00040345 0.00074464 0.00096168 0.00064272 0.00035718
 0.00082018]
Model epoch 305: train total loss -62.55802547730806, train mean loss 0.0007632562443071193, test mean loss [0.00043629 0.000405   0.00072249 0.00093755 0.00072192 0.00036074
 0.00076805]
Model epoch 306: train total loss -62.69722688074858, train mean loss 0.0007187220563688075, test mean loss [0.00043197 0.0004432  0.00069921 0.00094232 0.00064842 0.00034952
 0.00077105]
Model epoch 307: train total loss -62.65201450211249, train mean loss 0.0007858958729636954, test mean loss [0.00043051 0.00061853 0.00070817 0.0009225  0.00065675 0.00034431
 0.00073209]
Model epoch 308: train total loss -62.4662577199043, train mean loss 0.0007727853518534198, test mean loss [0.00044198 0.00050755 0.00068988 0.00107513 0.00063823 0.00035878
 0.00071998]
Model epoch 309: train total loss -62.05355240899366, train mean loss 0.0008269231928562925, test mean loss [0.00043329 0.00046815 0.00067307 0.00096494 0.00059591 0.00035182
 0.0009403 ]
Model epoch 310: train total loss -62.151686571424136, train mean loss 0.0008167838207583543, test mean loss [0.00042919 0.00044278 0.0006838  0.00097339 0.00062291 0.00034666
 0.00083984]
Model epoch 311: train total loss -62.45206014645789, train mean loss 0.0007690235906333872, test mean loss [0.00042013 0.00043625 0.00068698 0.00096817 0.000585   0.00034156
 0.00084137]
Model epoch 312: train total loss -62.603103968396404, train mean loss 0.0007374276301397971, test mean loss [0.00045638 0.00041531 0.00064753 0.00090969 0.00059399 0.00035713
 0.00086083]
Model epoch 313: train total loss -62.753390939975816, train mean loss 0.0007553985704561893, test mean loss [0.00044429 0.0004107  0.00063604 0.00091804 0.00056202 0.00033879
 0.00087981]
Model epoch 314: train total loss -62.94960677143692, train mean loss 0.0007388338466249846, test mean loss [0.00042418 0.00040479 0.00064262 0.00087667 0.00055224 0.00032856
 0.00089741]
Model epoch 315: train total loss -63.05455689942856, train mean loss 0.0006960707626607927, test mean loss [0.00042152 0.00039434 0.00062265 0.00085166 0.00055715 0.00033078
 0.0008557 ]
Model epoch 316: train total loss -62.97094594167652, train mean loss 0.0007039742097318871, test mean loss [0.00041284 0.00039325 0.00058841 0.00081461 0.0005935  0.00034232
 0.00084232]
Model epoch 317: train total loss -62.911173590763134, train mean loss 0.0007301017591096995, test mean loss [0.00041203 0.00039777 0.00060564 0.00082653 0.0005342  0.00034933
 0.00079778]
Model epoch 318: train total loss -62.775787012539, train mean loss 0.0007040489999646126, test mean loss [0.0004212  0.00041494 0.00059561 0.00082158 0.00054483 0.00032976
 0.00077154]
Model epoch 319: train total loss -63.02424984044993, train mean loss 0.0006347267723197512, test mean loss [0.00042224 0.00039803 0.00055957 0.00078038 0.00052599 0.00039415
 0.00075552]
Model epoch 320: train total loss -62.61170506293082, train mean loss 0.0006914617855401791, test mean loss [0.00040214 0.00039845 0.00056766 0.00078538 0.00056642 0.00033846
 0.00073531]
Model epoch 321: train total loss -62.7124236363333, train mean loss 0.000682058524330202, test mean loss [0.00040043 0.00041541 0.00057984 0.00080481 0.00050534 0.00033877
 0.00069929]
Model epoch 322: train total loss -62.72911144599981, train mean loss 0.0006530039394667945, test mean loss [0.00040511 0.00039984 0.00059166 0.00080861 0.00053198 0.00033753
 0.00071119]
Model epoch 323: train total loss -62.89321260985872, train mean loss 0.0006920518611916743, test mean loss [0.00038956 0.00038466 0.0005375  0.00078514 0.00052539 0.00033682
 0.00070021]
Model epoch 324: train total loss -62.98598403472254, train mean loss 0.00061000710144839, test mean loss [0.00041516 0.000389   0.00052858 0.00082461 0.00051    0.00031153
 0.00067343]
Model epoch 325: train total loss -62.93853586920794, train mean loss 0.000649229790707976, test mean loss [0.00039902 0.00041508 0.00056685 0.00073742 0.00050625 0.00033214
 0.00067871]
Model epoch 326: train total loss -62.92046804113495, train mean loss 0.0006863563312056198, test mean loss [0.00040026 0.00038073 0.00051137 0.00071038 0.00049539 0.0003524
 0.00067723]
Model epoch 327: train total loss -62.8328423685777, train mean loss 0.0006573390340223233, test mean loss [0.00038795 0.00038004 0.00051909 0.00074806 0.00048606 0.00032746
 0.00067447]
Model epoch 328: train total loss -63.03994983741179, train mean loss 0.0007054664392463365, test mean loss [0.00037819 0.00036999 0.00049323 0.00080158 0.00045076 0.00031129
 0.00065444]
Model epoch 329: train total loss -63.40559354905276, train mean loss 0.0006482100878967913, test mean loss [0.00037535 0.00037951 0.00049438 0.00076404 0.00044125 0.00030579
 0.00065378]
Model epoch 330: train total loss -63.281872651319155, train mean loss 0.00061544199618977, test mean loss [0.00044909 0.00037469 0.00044911 0.00074569 0.00044335 0.00032001
 0.00065209]
Model epoch 331: train total loss -62.85708196150264, train mean loss 0.0006193421751753223, test mean loss [0.00060071 0.00038548 0.00044855 0.0006963  0.00043671 0.00030531
 0.00065356]
Model epoch 332: train total loss -62.8962932749393, train mean loss 0.0006154453969343291, test mean loss [0.00049983 0.00037622 0.00046655 0.00068583 0.00044436 0.00030312
 0.00064663]
Model epoch 333: train total loss -62.991550484468775, train mean loss 0.0006181419285518578, test mean loss [0.00049066 0.00039521 0.00049611 0.00069219 0.00045916 0.00029115
 0.00063694]
Model epoch 334: train total loss -62.33892943580713, train mean loss 0.0006929769598420732, test mean loss [0.0004608  0.00036806 0.0004772  0.00183062 0.00043493 0.00030162
 0.00065958]
Model epoch 335: train total loss -61.9145933016693, train mean loss 0.0008409952319523448, test mean loss [0.00045711 0.00037658 0.00045095 0.00299711 0.00043261 0.00116192
 0.00063828]
Model epoch 336: train total loss -61.610927046259555, train mean loss 0.0012896257614924162, test mean loss [0.00081423 0.00037185 0.00044475 0.00282567 0.00040979 0.00410083
 0.00062366]
Model epoch 337: train total loss -61.48972047301825, train mean loss 0.001324466100078799, test mean loss [0.00074058 0.00035291 0.0004695  0.00245436 0.00040881 0.00445248
 0.00063296]
Model epoch 338: train total loss -61.70824303409768, train mean loss 0.0012025227373908232, test mean loss [0.00063282 0.00035511 0.00043344 0.00201733 0.00038452 0.00386306
 0.00062933]
Model epoch 339: train total loss -62.0808315234087, train mean loss 0.0010520819273912025, test mean loss [0.00061896 0.00034641 0.00045735 0.001584   0.00039442 0.00303315
 0.00061033]
Model epoch 340: train total loss -62.288220935624906, train mean loss 0.0010399563909631242, test mean loss [0.00063746 0.00034855 0.00044169 0.00137058 0.00040953 0.00255938
 0.00063508]
Model epoch 341: train total loss -62.261503355999636, train mean loss 0.000894107085225793, test mean loss [0.0006447  0.0003605  0.00045233 0.00118058 0.00059563 0.00193414
 0.0006244 ]
Model epoch 342: train total loss -62.55580134509745, train mean loss 0.0008256307339281799, test mean loss [0.00060596 0.0003554  0.00039608 0.00113371 0.0004154  0.00153003
 0.00061974]
Model epoch 343: train total loss -62.82052857481087, train mean loss 0.0007686742831310588, test mean loss [0.0005694  0.00034982 0.00040056 0.00105953 0.0004452  0.00123093
 0.00061406]
Model epoch 344: train total loss -62.72582169536063, train mean loss 0.0007317938594451928, test mean loss [0.00055012 0.00034479 0.00040511 0.00101817 0.00042351 0.00102134
 0.00061612]
Model epoch 345: train total loss -62.94759570562765, train mean loss 0.0007040989468015676, test mean loss [0.0005228  0.00033818 0.00040174 0.00099332 0.00039497 0.00091514
 0.00060739]
Model epoch 346: train total loss -62.849593191689884, train mean loss 0.0007243456924073845, test mean loss [0.00049171 0.00033452 0.00043854 0.00091205 0.00038707 0.0008563
 0.00061468]
Model epoch 347: train total loss -62.990185225393674, train mean loss 0.0007315897031339982, test mean loss [0.00049322 0.00032098 0.00043735 0.00088058 0.0003773  0.0008246
 0.00059412]
Model epoch 348: train total loss -62.46769436478734, train mean loss 0.0007086214824698974, test mean loss [0.00049924 0.00036535 0.00042206 0.00087204 0.00039378 0.00078882
 0.00058436]
Model epoch 349: train total loss -62.79291844088037, train mean loss 0.0006188631938163102, test mean loss [0.00049611 0.0003481  0.00039477 0.0008469  0.00039386 0.00074874
 0.00057811]
Model epoch 350: train total loss -63.03604316686619, train mean loss 0.0005963421588093964, test mean loss [0.00048424 0.00037257 0.00040028 0.0008336  0.00038216 0.00070577
 0.0005767 ]
Model epoch 351: train total loss -63.166469225814474, train mean loss 0.0005784837069524856, test mean loss [0.00045129 0.00034298 0.00036424 0.00079021 0.0003733  0.00073243
 0.00058082]
Model epoch 352: train total loss -63.309551596873845, train mean loss 0.0006145343656959982, test mean loss [0.00042862 0.00033771 0.00036752 0.0007697  0.0003989  0.00071348
 0.00057408]
Model epoch 353: train total loss -63.312276107850444, train mean loss 0.0006598273109598865, test mean loss [0.00044662 0.00034634 0.00037139 0.0007455  0.00039164 0.00066555
 0.00057761]
Model epoch 354: train total loss -63.41309645423817, train mean loss 0.0005576920678247132, test mean loss [0.00043183 0.00034097 0.00036114 0.0007211  0.0003683  0.00064685
 0.00055699]
Model epoch 355: train total loss -63.364799421557, train mean loss 0.0005772301556147895, test mean loss [0.00040472 0.00034625 0.00037164 0.00070336 0.00035337 0.00063414
 0.00057759]
Model epoch 356: train total loss -63.39154995439371, train mean loss 0.0005576583905749158, test mean loss [0.00038744 0.00033336 0.00036515 0.00068527 0.00034429 0.00059241
 0.00056028]
Model epoch 357: train total loss -63.0719818499079, train mean loss 0.0006045770125261391, test mean loss [0.00058143 0.00031229 0.00036474 0.00069323 0.0003408  0.00060497
 0.00057463]
Model epoch 358: train total loss -63.115446311121374, train mean loss 0.0005536695343405736, test mean loss [0.00050606 0.00031794 0.00036098 0.00065194 0.00036056 0.00061257
 0.00055671]
Model epoch 359: train total loss -63.196461030955916, train mean loss 0.0006202529797449787, test mean loss [0.00049005 0.0003298  0.00034523 0.00062256 0.0003378  0.00058791
 0.00055942]
Model epoch 360: train total loss -63.296342907518586, train mean loss 0.0005567889242629681, test mean loss [0.00043842 0.00032026 0.00034927 0.00061832 0.00036953 0.00055087
 0.00055057]
Model epoch 361: train total loss -63.036521774182, train mean loss 0.0005598592266984974, test mean loss [0.00040395 0.00034333 0.00034775 0.00060372 0.00034581 0.00056842
 0.00056057]
Model epoch 362: train total loss -63.18847277139828, train mean loss 0.0006108574485379701, test mean loss [0.00038617 0.00034006 0.0003447  0.00056975 0.00033958 0.000563
 0.00055125]
Model epoch 363: train total loss -63.29497703014333, train mean loss 0.0005784940121274897, test mean loss [0.00037849 0.00033984 0.00035196 0.00054676 0.00035407 0.00052134
 0.00054549]
Model epoch 364: train total loss -63.31469014699506, train mean loss 0.0005690028128764768, test mean loss [0.00038294 0.00031629 0.00033101 0.00054695 0.00035321 0.00051822
 0.00055135]
Model epoch 365: train total loss -63.56481231253808, train mean loss 0.0005104468144696598, test mean loss [0.00037536 0.00031543 0.00033933 0.00050651 0.00032628 0.00051954
 0.00055889]
Model epoch 366: train total loss -63.5021366864482, train mean loss 0.0004971305255173329, test mean loss [0.00038123 0.00031106 0.0003232  0.00048819 0.00033779 0.00053
 0.00055005]
Model epoch 367: train total loss -62.69814580971124, train mean loss 0.0005575549710459079, test mean loss [0.00037083 0.00034155 0.00034001 0.00048222 0.00034078 0.00055363
 0.00055472]
Model epoch 368: train total loss -63.22724654274652, train mean loss 0.0005775326737875255, test mean loss [0.00035097 0.0004103  0.00033102 0.00047454 0.00033389 0.00054137
 0.00056167]
Model epoch 369: train total loss -63.12894294898472, train mean loss 0.0005213960457783853, test mean loss [0.00036542 0.00037718 0.000321   0.00051602 0.00033227 0.00050708
 0.00054344]
Model epoch 370: train total loss -63.44153325219583, train mean loss 0.000522755493108849, test mean loss [0.00035405 0.00035738 0.00031904 0.00046739 0.00032268 0.00049898
 0.00053669]
Model epoch 371: train total loss -63.17844159058942, train mean loss 0.0005079551116032588, test mean loss [0.00034568 0.00035579 0.00032824 0.00044332 0.00032244 0.00044146
 0.00057055]
Model epoch 372: train total loss -63.47532947587022, train mean loss 0.0004358720060027252, test mean loss [0.0003426  0.00036184 0.00032046 0.0004395  0.00032319 0.00045975
 0.00055207]
Model epoch 373: train total loss -63.439501139407874, train mean loss 0.0004905278192826276, test mean loss [0.00033829 0.00035712 0.00031466 0.00044951 0.00032688 0.00054056
 0.00055047]
Model epoch 374: train total loss -63.49395774323528, train mean loss 0.00045890038605406625, test mean loss [0.00033678 0.0003408  0.00031854 0.00045843 0.00032891 0.00050335
 0.00055888]
Model epoch 375: train total loss -62.95242519218397, train mean loss 0.0005091210022719897, test mean loss [0.0004131  0.00034348 0.00030928 0.0004514  0.00032462 0.00047482
 0.00052611]
Model epoch 376: train total loss -63.46455913897947, train mean loss 0.0004928819801564784, test mean loss [0.0003524  0.00035225 0.00030465 0.0004541  0.00031906 0.00042298
 0.00053598]
Model epoch 377: train total loss -63.580851011441744, train mean loss 0.00048811302049953055, test mean loss [0.00034688 0.00032774 0.00031155 0.00043293 0.00033854 0.00045079
 0.00054402]
Model epoch 378: train total loss -63.54296249202182, train mean loss 0.00047383365964325224, test mean loss [0.00033084 0.00030487 0.00033594 0.00043795 0.00033462 0.00042371
 0.00056716]
Model epoch 379: train total loss -63.55489436241463, train mean loss 0.0004632868856557426, test mean loss [0.00033227 0.00030947 0.00033161 0.00042882 0.0003109  0.00039183
 0.00054847]
Model epoch 380: train total loss -63.574567893907584, train mean loss 0.0004949171437920324, test mean loss [0.00032707 0.0002968  0.00031655 0.00042028 0.00030732 0.00037351
 0.00051555]
Model epoch 381: train total loss -63.66773862231776, train mean loss 0.00045805867529203687, test mean loss [0.00032302 0.00029526 0.00031095 0.00040561 0.00030526 0.00040576
 0.00052091]
Model epoch 382: train total loss -63.69593108253494, train mean loss 0.0004613066520438394, test mean loss [0.0003259  0.00029479 0.00031457 0.00044126 0.00030805 0.00039036
 0.00052363]
Model epoch 383: train total loss -63.55056779941039, train mean loss 0.0004371870042995746, test mean loss [0.00032672 0.00029485 0.00031979 0.00042324 0.00030315 0.0003538
 0.00053403]
Model epoch 384: train total loss -63.65287993100243, train mean loss 0.0004422366974710776, test mean loss [0.00031978 0.00029834 0.00031163 0.00039581 0.0003196  0.00033176
 0.00051574]
Model epoch 385: train total loss -63.91072812793397, train mean loss 0.00043706578043692574, test mean loss [0.0003158  0.00029132 0.00029756 0.00041922 0.00030138 0.00030364
 0.00051471]
Model epoch 386: train total loss -63.84669928078773, train mean loss 0.00041604738685462815, test mean loss [0.00031666 0.00029001 0.00030139 0.0004149  0.00032607 0.00032051
 0.0005005 ]
Model epoch 387: train total loss -63.83960365227959, train mean loss 0.00044527496744552875, test mean loss [0.00033182 0.00029419 0.00032964 0.00039221 0.00030702 0.00029387
 0.00051161]
Model epoch 388: train total loss -63.818069512997056, train mean loss 0.00046261896098814093, test mean loss [0.00032429 0.000281   0.00029685 0.00039985 0.00033983 0.00027755
 0.000508  ]
Model epoch 389: train total loss -63.86904468111509, train mean loss 0.0004413448005323066, test mean loss [0.00030984 0.00027796 0.00031253 0.00040042 0.00033686 0.00027965
 0.00050512]
Model epoch 390: train total loss -63.788897547046616, train mean loss 0.0004057420629276401, test mean loss [0.00031342 0.00028091 0.00031476 0.00039209 0.00030512 0.00025861
 0.00049189]
Model epoch 391: train total loss -63.695060545093135, train mean loss 0.0004670971442864896, test mean loss [0.00030774 0.00028432 0.00029205 0.00040148 0.00031335 0.00026439
 0.00050217]
Model epoch 392: train total loss -63.929895499174776, train mean loss 0.0004191081921989838, test mean loss [0.00030131 0.00027726 0.00028102 0.00038908 0.00030153 0.00026238
 0.00049899]
Model epoch 393: train total loss -63.96724174065945, train mean loss 0.00044540439403679434, test mean loss [0.00031114 0.00028378 0.00030318 0.00041225 0.00032061 0.00026081
 0.0004847 ]
Model epoch 394: train total loss -63.68263086178562, train mean loss 0.00046451915629011615, test mean loss [0.00033426 0.00027911 0.00029174 0.00040997 0.00029064 0.00026497
 0.00052375]
Model epoch 395: train total loss -63.81950630735347, train mean loss 0.00039265858993271855, test mean loss [0.0003071  0.00028419 0.00030913 0.00036887 0.00029873 0.00026929
 0.00050045]
Model epoch 396: train total loss -63.8551949867858, train mean loss 0.0004112497604999081, test mean loss [0.00030927 0.00027527 0.00028908 0.0003892  0.00029959 0.00027241
 0.00048184]
Model epoch 397: train total loss -63.875288300986455, train mean loss 0.00045529386992612344, test mean loss [0.00029968 0.00026874 0.00028842 0.00037089 0.00029798 0.00027367
 0.00049378]
Model epoch 398: train total loss -63.77201473907439, train mean loss 0.00041012799993075174, test mean loss [0.00029544 0.00028796 0.00028998 0.00038599 0.00029107 0.00026156
 0.00047891]
Model epoch 399: train total loss -63.93906110063806, train mean loss 0.0004151567607834929, test mean loss [0.00028708 0.00030613 0.00028545 0.00038288 0.00030581 0.00025273
 0.00047359]
Model epoch 400: train total loss -63.67551040876003, train mean loss 0.000427069203869819, test mean loss [0.00032586 0.00028064 0.00027985 0.00037317 0.00046849 0.00026047
 0.00049402]
Model epoch 401: train total loss -63.49157612410616, train mean loss 0.0004522710055519293, test mean loss [0.00033039 0.00027162 0.00029869 0.00038679 0.00035194 0.00026489
 0.00047312]
Model epoch 402: train total loss -63.54701875438076, train mean loss 0.00041329203465390014, test mean loss [0.00031799 0.00027491 0.00027743 0.00038407 0.0003478  0.0002619
 0.00047219]
Model epoch 403: train total loss -63.80635176234949, train mean loss 0.0004202615385646374, test mean loss [0.00031312 0.0002762  0.00027182 0.00037226 0.00030343 0.00025261
 0.00048024]
Model epoch 404: train total loss -63.865607889276426, train mean loss 0.0004590101334435851, test mean loss [0.00029887 0.0002654  0.00028471 0.00036542 0.00029837 0.00025975
 0.0004751 ]
Model epoch 405: train total loss -63.562325326474415, train mean loss 0.00042106585079474697, test mean loss [0.00029269 0.00027931 0.00027263 0.00038535 0.00028201 0.00033725
 0.00048459]
Model epoch 406: train total loss -62.30259076940951, train mean loss 0.0004453007450941382, test mean loss [0.00029188 0.00026788 0.00028207 0.00038269 0.00040274 0.00028372
 0.00047662]
Model epoch 407: train total loss -63.270768878482755, train mean loss 0.0004495556038171478, test mean loss [0.00028279 0.0002737  0.00026552 0.00037045 0.00048933 0.00026687
 0.00047989]
Model epoch 408: train total loss -63.30719820035334, train mean loss 0.0004300376204022009, test mean loss [0.0002996  0.00029743 0.00027167 0.00038375 0.00042726 0.00024922
 0.00047017]
Model epoch 409: train total loss -62.88235638286799, train mean loss 0.00041074708229253524, test mean loss [0.0004141  0.00027771 0.00027673 0.00037606 0.00041062 0.00024945
 0.00045192]
Model epoch 410: train total loss -62.86455428892621, train mean loss 0.0004252436667960841, test mean loss [0.00044367 0.00026682 0.0002655  0.0003826  0.00040245 0.00025282
 0.00048089]
Model epoch 411: train total loss -63.173102131661125, train mean loss 0.0004421686865033181, test mean loss [0.00047893 0.0002622  0.00028131 0.00037163 0.00039827 0.00025073
 0.00049589]
Model epoch 412: train total loss -63.401913869089974, train mean loss 0.00041138452572163917, test mean loss [0.000386   0.00028182 0.00026751 0.00037992 0.00037085 0.0002515
 0.00048644]
Model epoch 413: train total loss -63.6669885198375, train mean loss 0.00038314926711375906, test mean loss [0.00033292 0.00029917 0.00028866 0.00036416 0.00035494 0.00023857
 0.00047383]
Model epoch 414: train total loss -63.53201277090098, train mean loss 0.0004297834611382373, test mean loss [0.0003251  0.00030453 0.00027279 0.00035008 0.00033145 0.0002425
 0.00045635]
Model epoch 415: train total loss -63.56282136635017, train mean loss 0.0004405214094850322, test mean loss [0.00032496 0.00028388 0.00026605 0.00037334 0.00033414 0.00024362
 0.00045976]
Model epoch 416: train total loss -63.68158624591866, train mean loss 0.0003854234558539603, test mean loss [0.00031037 0.0002755  0.00028912 0.00035659 0.00032138 0.00023483
 0.00046925]
Model epoch 417: train total loss -63.948627599985294, train mean loss 0.00035663747341032736, test mean loss [0.00030391 0.00026021 0.00027576 0.00035839 0.00031683 0.00023868
 0.00045106]
Model epoch 418: train total loss -63.97973865431564, train mean loss 0.0003931327504325849, test mean loss [0.00029504 0.00026869 0.00027533 0.00036157 0.0003195  0.00022697
 0.0004425 ]
Model epoch 419: train total loss -63.85447799330822, train mean loss 0.0003636814858842913, test mean loss [0.00029171 0.00027683 0.00026185 0.00034302 0.00030369 0.00024085
 0.00044285]
Model epoch 420: train total loss -64.13455406187184, train mean loss 0.00032863265359509925, test mean loss [0.00029371 0.00025304 0.00028104 0.00034672 0.00029711 0.00023978
 0.00043591]
Model epoch 421: train total loss -64.19069342726903, train mean loss 0.0003555558222379667, test mean loss [0.00028079 0.00025744 0.00026778 0.00035811 0.00030018 0.00023231
 0.00043944]
Model epoch 422: train total loss -64.19962361490386, train mean loss 0.00037252950006288, test mean loss [0.00030319 0.00025954 0.00025873 0.00034225 0.00030469 0.00022789
 0.00044404]
Model epoch 423: train total loss -64.21340022473564, train mean loss 0.0003332991365948472, test mean loss [0.0002862  0.0002587  0.00027728 0.00033271 0.0002979  0.00023475
 0.00044004]
Model epoch 424: train total loss -63.90150784116275, train mean loss 0.0003728933269516423, test mean loss [0.00028198 0.0002589  0.0002768  0.00033323 0.00029821 0.0002528
 0.00043109]
Model epoch 425: train total loss -63.95443245553629, train mean loss 0.00036511397131438295, test mean loss [0.00027844 0.00025784 0.00025981 0.00034897 0.00028862 0.00024307
 0.00043481]
Model epoch 426: train total loss -63.98383831834949, train mean loss 0.0003656188330201191, test mean loss [0.00028444 0.00024166 0.00026477 0.00035695 0.00028096 0.00024901
 0.00042166]
Model epoch 427: train total loss -64.17973183262268, train mean loss 0.00035821966645001936, test mean loss [0.00028334 0.00024393 0.00025668 0.00034865 0.00028938 0.00024276
 0.00043676]
Model epoch 428: train total loss -63.98618804889198, train mean loss 0.00037521736376857246, test mean loss [0.00027321 0.00024946 0.00029315 0.00034631 0.00029185 0.00023677
 0.0004291 ]
Model epoch 429: train total loss -64.16844812986238, train mean loss 0.00038254207796837013, test mean loss [0.00027655 0.0002535  0.00028941 0.00034008 0.00028449 0.00022265
 0.00043823]
Model epoch 430: train total loss -63.22422833690818, train mean loss 0.00039749090735596534, test mean loss [0.00027491 0.00024198 0.00027111 0.00097498 0.00030064 0.00023229
 0.0004099 ]
Model epoch 431: train total loss -63.658676014931615, train mean loss 0.0004482738353110995, test mean loss [0.00026564 0.00024523 0.0002693  0.0010234  0.00029579 0.00024633
 0.00041843]
Model epoch 432: train total loss -63.79566197302852, train mean loss 0.0004844950020478404, test mean loss [0.00027179 0.00024302 0.0002611  0.00107901 0.00028596 0.00022652
 0.00041432]
Model epoch 433: train total loss -63.895663723925324, train mean loss 0.0004292273445242773, test mean loss [0.00026947 0.0002422  0.00027168 0.0009704  0.00027599 0.00022149
 0.00041674]
Model epoch 434: train total loss -62.72774165310702, train mean loss 0.00047811316563268504, test mean loss [0.00026795 0.0002417  0.00044691 0.00089779 0.00027321 0.00022112
 0.00042394]
Model epoch 435: train total loss -63.32307570679159, train mean loss 0.0006535796621915098, test mean loss [0.00026982 0.0002555  0.00230779 0.00091635 0.00026842 0.00021733
 0.00041633]
Model epoch 436: train total loss -63.373064267928264, train mean loss 0.0007477950585900549, test mean loss [0.00027307 0.00025109 0.0028881  0.0008706  0.00027724 0.00021793
 0.00041583]
Model epoch 437: train total loss -63.44284809900883, train mean loss 0.0006754119611898639, test mean loss [0.00026772 0.00024729 0.00283549 0.00079721 0.00028354 0.00026587
 0.00040825]
Model epoch 438: train total loss -63.67340660751567, train mean loss 0.0007323277069228903, test mean loss [0.00025816 0.00023896 0.0024608  0.00076004 0.00030424 0.00023673
 0.00041356]
Model epoch 439: train total loss -63.62215583879516, train mean loss 0.0006488046726773673, test mean loss [0.00025627 0.00023735 0.00218045 0.00074514 0.00028243 0.00021864
 0.00042979]
Model epoch 440: train total loss -63.69389475595584, train mean loss 0.0005799058278329781, test mean loss [0.00026673 0.00025434 0.00185055 0.00070031 0.00027385 0.00021914
 0.00040583]
Model epoch 441: train total loss -63.691406961081604, train mean loss 0.0005316764801033457, test mean loss [0.00025674 0.0002608  0.00152907 0.00066943 0.00029608 0.00023061
 0.00040317]
Model epoch 442: train total loss -63.711463630303605, train mean loss 0.0005121843678683595, test mean loss [0.00025426 0.00024911 0.0012249  0.00066636 0.00027158 0.00023584
 0.00039115]
Model epoch 443: train total loss -63.80176329088482, train mean loss 0.000494692824183729, test mean loss [0.00026028 0.00024208 0.00102705 0.00066125 0.00027997 0.00022952
 0.00039704]
Model epoch 444: train total loss -63.76150672007358, train mean loss 0.0004507979427208337, test mean loss [0.00029033 0.00024114 0.00085243 0.00062043 0.0002668  0.00022482
 0.00039662]
Model epoch 445: train total loss -63.666062221988874, train mean loss 0.0004362629912882083, test mean loss [0.00031972 0.00024666 0.00076499 0.00061159 0.00026716 0.00022928
 0.00038683]
Model epoch 446: train total loss -63.88879948171274, train mean loss 0.0004503342054423486, test mean loss [0.00032779 0.00023733 0.00068976 0.00059072 0.00025588 0.00021929
 0.00039324]
Model epoch 447: train total loss -63.65112859590659, train mean loss 0.000448153954499041, test mean loss [0.000307   0.0002603  0.00061332 0.00058391 0.00025401 0.00022529
 0.00041352]
Model epoch 448: train total loss -63.88073920658298, train mean loss 0.0004254097410052683, test mean loss [0.00028716 0.00026691 0.00058674 0.00056991 0.00025786 0.00023238
 0.00040142]
Model epoch 449: train total loss -64.07293110392204, train mean loss 0.00043599383077703183, test mean loss [0.00027899 0.000267   0.00055563 0.00056518 0.00024679 0.00021714
 0.00039738]
Model epoch 450: train total loss -64.12968111238177, train mean loss 0.00038786583256129, test mean loss [0.00026813 0.00026189 0.00054424 0.00057075 0.0002543  0.00021492
 0.00038406]
Model epoch 451: train total loss -64.25052051414832, train mean loss 0.0003822653575535855, test mean loss [0.00026102 0.0002523  0.00050069 0.00058151 0.00026086 0.00020968
 0.00038778]
Model epoch 452: train total loss -64.34647836058899, train mean loss 0.0003725879875744912, test mean loss [0.00025732 0.00024136 0.00050385 0.00057203 0.00026465 0.0002241
 0.00038662]
Model epoch 453: train total loss -64.25322368990408, train mean loss 0.00041121483415904205, test mean loss [0.00039907 0.00023847 0.00049992 0.000555   0.00026365 0.00021
 0.00038863]
Model epoch 454: train total loss -63.55590863803043, train mean loss 0.0004399926579712385, test mean loss [0.00042692 0.00023419 0.00049786 0.00053046 0.00024887 0.00043233
 0.00039153]
Model epoch 455: train total loss -63.37006307409419, train mean loss 0.0004197041071384588, test mean loss [0.00046144 0.00042406 0.00050575 0.0005028  0.00025999 0.00030498
 0.00037501]
Model epoch 456: train total loss -63.66868118068124, train mean loss 0.0004348572092307517, test mean loss [0.00040579 0.00027482 0.00047274 0.0004956  0.00025461 0.00028317
 0.00037377]
Model epoch 457: train total loss -63.585649208892974, train mean loss 0.00044542142744142323, test mean loss [0.00035105 0.0002906  0.0004822  0.00047994 0.00024648 0.00025422
 0.00039216]
Model epoch 458: train total loss -63.85506613774677, train mean loss 0.0003758715612016899, test mean loss [0.00032887 0.00026737 0.00045086 0.00046806 0.0002497  0.00023684
 0.00039937]
Model epoch 459: train total loss -63.862949089551435, train mean loss 0.0003801190474847154, test mean loss [0.00031688 0.00025276 0.00045776 0.00046429 0.00026694 0.00023371
 0.00038935]
Model epoch 460: train total loss -64.1520854923896, train mean loss 0.00035783369169273255, test mean loss [0.0003046  0.00024733 0.00045757 0.00046988 0.00024993 0.00021831
 0.00037668]
Model epoch 461: train total loss -63.96678122436185, train mean loss 0.00042408291204607484, test mean loss [0.00028992 0.0002406  0.00044713 0.00049433 0.00024729 0.00040096
 0.00036329]
Model epoch 462: train total loss -64.20548211308443, train mean loss 0.0003921721304912612, test mean loss [0.00028381 0.00025275 0.00042839 0.00046658 0.00023896 0.00025587
 0.00037725]
Model epoch 463: train total loss -63.75637387623796, train mean loss 0.0003982556927934775, test mean loss [0.00030695 0.00024649 0.00042693 0.0004429  0.00023651 0.00023922
 0.00037663]
Model epoch 464: train total loss -64.18449944499054, train mean loss 0.000352451782704026, test mean loss [0.00028918 0.00024359 0.00042476 0.00042154 0.00023184 0.00022777
 0.00035932]
Model epoch 465: train total loss -64.2040902276159, train mean loss 0.00035144164901949513, test mean loss [0.00028621 0.00024199 0.0004201  0.00040635 0.00024172 0.00023444
 0.00035335]
Model epoch 466: train total loss -64.13404354809732, train mean loss 0.000372021543417508, test mean loss [0.00028236 0.00023769 0.00046653 0.00042177 0.00024011 0.00023148
 0.00037304]
Model epoch 467: train total loss -64.1711956577314, train mean loss 0.0003984388682740621, test mean loss [0.00027509 0.0002338  0.00041765 0.00040819 0.00024121 0.00022978
 0.00036758]
Model epoch 468: train total loss -64.14433192168654, train mean loss 0.00036248363179030354, test mean loss [0.00025862 0.00023235 0.00039984 0.00037937 0.00023306 0.00025681
 0.00035247]
Model epoch 469: train total loss -64.34376270577022, train mean loss 0.0003578199903872317, test mean loss [0.00025046 0.00022539 0.0004092  0.000371   0.00023192 0.00024475
 0.00034849]
Model epoch 470: train total loss -64.27468066435081, train mean loss 0.0003677135425618281, test mean loss [0.00024803 0.00023014 0.00038525 0.00034162 0.00023304 0.00024569
 0.00035033]
Model epoch 471: train total loss -63.873852977630946, train mean loss 0.00036116421299645405, test mean loss [0.00024015 0.00021677 0.00036935 0.00043101 0.00024595 0.00022651
 0.00035518]
Model epoch 472: train total loss -64.07686684535369, train mean loss 0.00032543325502585425, test mean loss [0.00024013 0.00021827 0.00037566 0.00041614 0.00023844 0.00022557
 0.00035849]
Model epoch 473: train total loss -63.93179340399499, train mean loss 0.0003591163185461922, test mean loss [0.00024655 0.00021472 0.00038734 0.00047454 0.00023854 0.00023084
 0.00034774]
Model epoch 474: train total loss -63.97524004894104, train mean loss 0.000342355465519257, test mean loss [0.00024999 0.00021968 0.00039804 0.00041674 0.00024176 0.00022968
 0.00034309]
Model epoch 475: train total loss -64.02749276968146, train mean loss 0.000347116538122677, test mean loss [0.00023931 0.0002347  0.00038022 0.00040277 0.00022776 0.0002099
 0.00034352]
Model epoch 476: train total loss -64.29548323775076, train mean loss 0.0003452909487492993, test mean loss [0.0002425  0.00023479 0.00036897 0.00037987 0.00023711 0.00020629
 0.00034739]
Model epoch 477: train total loss -64.38864018990976, train mean loss 0.0003216659623376742, test mean loss [0.00023347 0.0002248  0.00036242 0.00037148 0.00023543 0.00021065
 0.0003489 ]
Model epoch 478: train total loss -64.59397828782292, train mean loss 0.00033715523970985587, test mean loss [0.00025543 0.00021899 0.00034791 0.00033625 0.00022916 0.00020159
 0.00035214]
Model epoch 479: train total loss -64.49247599142056, train mean loss 0.00032695778129156146, test mean loss [0.00024454 0.00021683 0.00034172 0.00032357 0.0002296  0.00019793
 0.00034077]
Model epoch 480: train total loss -64.42368747745572, train mean loss 0.00034625844769613207, test mean loss [0.00023832 0.00023363 0.00033313 0.0003214  0.00024269 0.00020525
 0.00033362]
Model epoch 481: train total loss -64.46789431280554, train mean loss 0.0003266774527975126, test mean loss [0.00023188 0.00022758 0.00033092 0.00032153 0.00024705 0.00022031
 0.00034894]
Model epoch 482: train total loss -64.42515346881996, train mean loss 0.0003310689451647425, test mean loss [0.00024666 0.00022513 0.0003297  0.00032421 0.00023852 0.00020508
 0.00033144]
Model epoch 483: train total loss -64.57326132789869, train mean loss 0.0003255350725619475, test mean loss [0.00024484 0.00021414 0.00031922 0.00029492 0.00023257 0.00020294
 0.00033545]
Model epoch 484: train total loss -64.61827809088363, train mean loss 0.00030355261453220514, test mean loss [0.000238   0.00021474 0.00032893 0.0003174  0.00023044 0.00019512
 0.0003282 ]
Model epoch 485: train total loss -64.52529263424947, train mean loss 0.0003133107775354067, test mean loss [0.00023044 0.00022023 0.00030367 0.00030414 0.00022823 0.00020516
 0.00033874]
Model epoch 486: train total loss -64.56719068272955, train mean loss 0.0003124245314791841, test mean loss [0.00023576 0.00023031 0.00029384 0.00030602 0.00022653 0.00019214
 0.00034484]
Model epoch 487: train total loss -64.82152392604917, train mean loss 0.0002733243627989565, test mean loss [0.00023284 0.00021734 0.00027384 0.00030058 0.00023779 0.00019965
 0.00034078]
Model epoch 488: train total loss -64.53930070024381, train mean loss 0.00029608432807031273, test mean loss [0.00023496 0.00022055 0.0002675  0.00028691 0.00023212 0.0002377
 0.00032934]
Model epoch 489: train total loss -64.56867690515058, train mean loss 0.0002812402490741607, test mean loss [0.00023213 0.00021769 0.00026476 0.00029263 0.00022747 0.00025327
 0.00033749]
Model epoch 490: train total loss -64.57303957475965, train mean loss 0.0002939877207423656, test mean loss [0.00022395 0.00021177 0.00025024 0.00028434 0.00023016 0.00024223
 0.00033816]
Model epoch 491: train total loss -64.7509561189822, train mean loss 0.0002991223207905073, test mean loss [0.0002235  0.00021156 0.00025679 0.0002832  0.0002266  0.00021768
 0.00032508]
Model epoch 492: train total loss -64.76862625877894, train mean loss 0.0002876428109562727, test mean loss [0.00022066 0.00020939 0.00025012 0.0002822  0.00021462 0.00020775
 0.00032268]
Model epoch 493: train total loss -64.68748884662068, train mean loss 0.00027201699876181656, test mean loss [0.00023112 0.00021004 0.00025597 0.00028101 0.00028275 0.00020114
 0.00032412]
Model epoch 494: train total loss -64.44030369066995, train mean loss 0.00027983039156290174, test mean loss [0.00022699 0.00021206 0.00025518 0.00027865 0.00023885 0.00019248
 0.00032788]
Model epoch 495: train total loss -64.34582868287582, train mean loss 0.0002984325588034606, test mean loss [0.00022183 0.00021857 0.00023262 0.0002792  0.00023138 0.00045852
 0.00033392]
Model epoch 496: train total loss -64.3010446137844, train mean loss 0.0002700030883549342, test mean loss [0.00022496 0.00019936 0.00022991 0.00028603 0.00022486 0.00030353
 0.00031491]
Model epoch 497: train total loss -64.25582537114441, train mean loss 0.0002994368617354156, test mean loss [0.00022769 0.00020718 0.00022699 0.00027507 0.00022188 0.00029924
 0.00031101]
Model epoch 498: train total loss -63.91619663161102, train mean loss 0.00028791673079035725, test mean loss [0.00022125 0.00020913 0.0003803  0.00028041 0.00022017 0.00029047
 0.00031788]
Model epoch 499: train total loss -64.07562246522218, train mean loss 0.00027521855573372453, test mean loss [0.00021687 0.00021267 0.00027652 0.00027836 0.00028052 0.00029861
 0.00030871]
Model epoch 500: train total loss -64.07406562268062, train mean loss 0.00031602922124261256, test mean loss [0.00021936 0.00020884 0.00027273 0.00029762 0.00025724 0.00028576
 0.00031068]
Model epoch 501: train total loss -64.21760410415656, train mean loss 0.00033309012895097124, test mean loss [0.00022861 0.00022171 0.00025504 0.00029125 0.00023978 0.00029017
 0.00031202]
Model epoch 502: train total loss -64.37185446604227, train mean loss 0.00030324456128840067, test mean loss [0.00023004 0.00020877 0.00023743 0.00028196 0.00022121 0.00028142
 0.00030966]
Model epoch 503: train total loss -64.62704009310856, train mean loss 0.00026553151958636146, test mean loss [0.00021577 0.0001987  0.00023981 0.0002871  0.00022656 0.00028862
 0.00030606]
Model epoch 504: train total loss -64.74401217323884, train mean loss 0.00030115452428309755, test mean loss [0.00021348 0.0002014  0.00022545 0.00027696 0.0002185  0.00028187
 0.00030729]
Model epoch 505: train total loss -64.71664327545545, train mean loss 0.00028250392445153147, test mean loss [0.00020957 0.00020898 0.00023577 0.00028366 0.00021305 0.00026267
 0.00030157]
Model epoch 506: train total loss -64.63330958855192, train mean loss 0.00030158453202423557, test mean loss [0.00022402 0.00020185 0.00024343 0.00028645 0.00021237 0.00025328
 0.00029358]
Model epoch 507: train total loss -63.47415379413689, train mean loss 0.000315339204585737, test mean loss [0.00021635 0.00020599 0.00027225 0.00028774 0.00024078 0.00023717
 0.00029598]
Model epoch 508: train total loss -64.26873361405121, train mean loss 0.0002893706856107439, test mean loss [0.00021667 0.00019581 0.00025838 0.00027057 0.0002685  0.0002318
 0.00030754]
Model epoch 509: train total loss -64.10433934948807, train mean loss 0.00030639065634717444, test mean loss [0.00021628 0.00019822 0.00028852 0.00028203 0.00025617 0.00022675
 0.00030638]
Model epoch 510: train total loss -64.2473652249735, train mean loss 0.000274912997168813, test mean loss [0.0002194  0.00020802 0.00025163 0.00028248 0.00023968 0.00022213
 0.00031115]
Model epoch 511: train total loss -64.39741905180733, train mean loss 0.00029004573014440474, test mean loss [0.00022357 0.00021669 0.00024956 0.00030544 0.00023549 0.00020692
 0.0002966 ]
Model epoch 512: train total loss -64.3951522791121, train mean loss 0.00028393503412591306, test mean loss [0.0002168  0.00021106 0.00024458 0.00028457 0.00022311 0.00020787
 0.00029786]
Model epoch 513: train total loss -64.56995528443642, train mean loss 0.0002932286279237653, test mean loss [0.00020567 0.00020259 0.00023634 0.00030149 0.00022158 0.00020914
 0.00029648]
Model epoch 514: train total loss -64.65137001331176, train mean loss 0.0002837916987580928, test mean loss [0.00020584 0.00019353 0.00022472 0.00028762 0.00021851 0.00019806
 0.00030443]
Model epoch 515: train total loss -64.76162463738366, train mean loss 0.00026824653651969345, test mean loss [0.00020359 0.00020081 0.00022    0.00026735 0.00022354 0.00020163
 0.00029829]
Model epoch 516: train total loss -64.70034796398639, train mean loss 0.0002809936431723317, test mean loss [0.00022325 0.0002044  0.00021681 0.00033613 0.00020696 0.00019481
 0.00029541]
Model epoch 517: train total loss -63.912523761411634, train mean loss 0.0005839916109072995, test mean loss [0.00020725 0.00020762 0.00022236 0.00344742 0.00022056 0.00019642
 0.00028295]
Model epoch 518: train total loss -63.77865820757712, train mean loss 0.0006871840785973844, test mean loss [0.00021729 0.00021026 0.00021214 0.00412029 0.00022135 0.00018895
 0.00028491]
Model epoch 519: train total loss -63.91937297871476, train mean loss 0.0006208706828667145, test mean loss [0.0002055  0.00020657 0.00020875 0.00367656 0.00023695 0.00018676
 0.00029542]
Model epoch 520: train total loss -63.971132995191574, train mean loss 0.0005810278733330087, test mean loss [0.00020736 0.00021089 0.00020843 0.00321225 0.00021778 0.00018782
 0.00029736]
Model epoch 521: train total loss -63.975359467895736, train mean loss 0.0006326042072247085, test mean loss [0.00021012 0.00019556 0.00020746 0.00249    0.00021003 0.0002017
 0.0002858 ]
Model epoch 522: train total loss -64.1659087505185, train mean loss 0.0005120019370364936, test mean loss [0.00022101 0.00019118 0.00022182 0.00192799 0.00020784 0.00019132
 0.00029195]
Model epoch 523: train total loss -64.32317300265589, train mean loss 0.0004143423140948388, test mean loss [0.00022033 0.00020216 0.00019918 0.00152716 0.00020305 0.00018959
 0.00029684]
Model epoch 524: train total loss -64.48753877638953, train mean loss 0.00035237692600414603, test mean loss [0.00021393 0.00021251 0.00020073 0.00130371 0.00020387 0.00018621
 0.00028088]
Model epoch 525: train total loss -64.59276271127388, train mean loss 0.0003712811139577065, test mean loss [0.0002117  0.00020117 0.00020857 0.00113989 0.00021564 0.00017963
 0.00027734]
Model epoch 526: train total loss -64.4806029607481, train mean loss 0.00034205040779998426, test mean loss [0.00020894 0.00021122 0.00020768 0.00106598 0.00023371 0.00019071
 0.00028397]
Model epoch 527: train total loss -64.47405685192167, train mean loss 0.00030824990094274475, test mean loss [0.00019758 0.00020295 0.000207   0.00100935 0.00021907 0.00018335
 0.00030549]
Model epoch 528: train total loss -64.70232315372607, train mean loss 0.0003279224193094604, test mean loss [0.00020419 0.00019027 0.00020575 0.00095314 0.00020828 0.00019317
 0.000287  ]
Model epoch 529: train total loss -64.8191269084365, train mean loss 0.0003249068289875868, test mean loss [0.00020026 0.00019059 0.00019808 0.00090973 0.00020289 0.00018901
 0.00029217]
Model epoch 530: train total loss -64.6114294488635, train mean loss 0.0003236386791108751, test mean loss [0.00021871 0.00025375 0.00020008 0.00087941 0.00020099 0.00018004
 0.0002799 ]
Model epoch 531: train total loss -64.7187027452643, train mean loss 0.00030951321146637054, test mean loss [0.00020514 0.00022602 0.00019899 0.00083283 0.00020638 0.00017794
 0.00028564]
Model epoch 532: train total loss -64.73938619977582, train mean loss 0.00030442334990238073, test mean loss [0.00020588 0.0002119  0.00019671 0.00082548 0.00019253 0.00018298
 0.00028095]
Model epoch 533: train total loss -64.59337402138566, train mean loss 0.0003169868096738328, test mean loss [0.00019892 0.00020191 0.0002104  0.00081373 0.00020588 0.00018234
 0.00028181]
Model epoch 534: train total loss -64.68642516939737, train mean loss 0.0003328724049790112, test mean loss [0.00020202 0.00020056 0.00020749 0.00081897 0.00020557 0.00018282
 0.00027414]
Model epoch 535: train total loss -64.70466437036772, train mean loss 0.00031043597121778216, test mean loss [0.00019689 0.00020053 0.0002065  0.00080354 0.00021281 0.00017829
 0.00027018]
Model epoch 536: train total loss -64.76533484748752, train mean loss 0.0003457518115592755, test mean loss [0.000197   0.00019859 0.00020544 0.00075766 0.00020024 0.00018042
 0.00027129]
Model epoch 537: train total loss -64.90133426251538, train mean loss 0.0003064009858164136, test mean loss [0.00020192 0.00021635 0.00019791 0.0007929  0.00019649 0.00018575
 0.00026664]
Model epoch 538: train total loss -64.71663374899232, train mean loss 0.00031535895839311347, test mean loss [0.00019594 0.00020777 0.00019733 0.00077104 0.00019589 0.00017916
 0.00028374]
Model epoch 539: train total loss -64.95431830451032, train mean loss 0.0002842064603644337, test mean loss [0.00019326 0.00021708 0.00021033 0.00078113 0.00018681 0.00017959
 0.00027131]
Model epoch 540: train total loss -64.77085930443256, train mean loss 0.0002992221952835035, test mean loss [0.00019599 0.00019594 0.00019853 0.00075048 0.00018637 0.00018332
 0.00026554]
Model epoch 541: train total loss -64.94306735353845, train mean loss 0.00030550012068358633, test mean loss [0.0001992  0.00019077 0.00019979 0.00075205 0.0001909  0.00018773
 0.00026444]
Model epoch 542: train total loss -64.86442498852186, train mean loss 0.0003051415371418894, test mean loss [0.00020799 0.00019527 0.00020014 0.0007478  0.00019753 0.00018073
 0.00026377]
Model epoch 543: train total loss -64.90261801399865, train mean loss 0.0003102400259392055, test mean loss [0.00020032 0.00018886 0.00020453 0.00070872 0.00022152 0.00018702
 0.0002618 ]
Model epoch 544: train total loss -64.75262555072221, train mean loss 0.00028790434828781267, test mean loss [0.00019319 0.00019125 0.00019663 0.00080518 0.00020988 0.00018111
 0.00026538]
Model epoch 545: train total loss -64.11828782324646, train mean loss 0.00034178168387956776, test mean loss [0.00018984 0.00018883 0.00019887 0.0010038  0.00020513 0.00017861
 0.00031588]
Model epoch 546: train total loss -64.41767243906216, train mean loss 0.00038147214931419295, test mean loss [0.00019202 0.0001874  0.00019458 0.00101127 0.00021034 0.00018052
 0.0002919 ]
Model epoch 547: train total loss -64.5496922740628, train mean loss 0.0003267340279355144, test mean loss [0.00018899 0.00018561 0.00019605 0.00098657 0.00019911 0.00017338
 0.00029914]
Model epoch 548: train total loss -64.64401964747587, train mean loss 0.00032212811359866685, test mean loss [0.00018772 0.00019721 0.00018943 0.00092572 0.00021356 0.0001718
 0.00028422]
Model epoch 549: train total loss -64.69014423770867, train mean loss 0.00031502091173669277, test mean loss [0.00019378 0.00018925 0.00019187 0.00084785 0.00019446 0.00017773
 0.00027184]
Model epoch 550: train total loss -64.46577143559014, train mean loss 0.00028501030437562153, test mean loss [0.00025548 0.00018855 0.00019883 0.00089186 0.00021223 0.0001781
 0.00026433]
Model epoch 551: train total loss -64.61641119079661, train mean loss 0.00032935743564461653, test mean loss [0.00021374 0.00018525 0.00019138 0.00081214 0.00024243 0.00017731
 0.00026174]
Model epoch 552: train total loss -64.68569112302224, train mean loss 0.00030933426215993035, test mean loss [0.00019804 0.0001885  0.00019379 0.00081279 0.00022113 0.00017419
 0.00025996]
Model epoch 553: train total loss -64.6294790638898, train mean loss 0.0003358456203356633, test mean loss [0.00019306 0.00018045 0.00018828 0.00081628 0.00021376 0.00019098
 0.0003139 ]
Model epoch 554: train total loss -64.62218561436313, train mean loss 0.0002976307209913544, test mean loss [0.00019258 0.00018318 0.00019509 0.00077602 0.00019919 0.00018404
 0.00031368]
Model epoch 555: train total loss -64.67345487514677, train mean loss 0.00031857817313390654, test mean loss [0.00018715 0.00018705 0.0002166  0.0007668  0.00019805 0.00017011
 0.00029356]
Model epoch 556: train total loss -64.59298072678952, train mean loss 0.000305373459930081, test mean loss [0.000191   0.00017782 0.00019324 0.00078056 0.00019047 0.00017582
 0.0002868 ]
Model epoch 557: train total loss -64.76113002426932, train mean loss 0.00030339530039065097, test mean loss [0.00018828 0.00018483 0.00019832 0.00078042 0.0001975  0.00017327
 0.00027787]
Model epoch 558: train total loss -64.83950895824387, train mean loss 0.00029893202298631794, test mean loss [0.00019926 0.00018    0.00019595 0.00075393 0.00018392 0.00017948
 0.00026959]
Model epoch 559: train total loss -64.87291230683343, train mean loss 0.00029994894962781667, test mean loss [0.00020313 0.00018875 0.00019775 0.0007586  0.00019005 0.00017764
 0.00027561]
Model epoch 560: train total loss -64.76483560619786, train mean loss 0.0003029958590151113, test mean loss [0.00019595 0.00018239 0.00019277 0.00078758 0.00021903 0.00018246
 0.00026839]
Model epoch 561: train total loss -64.87338313976154, train mean loss 0.0002974133802256006, test mean loss [0.00018909 0.00018475 0.00018301 0.00073776 0.00021185 0.00017105
 0.00025589]
Model epoch 562: train total loss -64.88330817381559, train mean loss 0.00031673269250277443, test mean loss [0.00018585 0.0001805  0.00018878 0.00073605 0.00019036 0.00016737
 0.00025867]
Model epoch 563: train total loss -64.7150624590567, train mean loss 0.00030586368870732416, test mean loss [0.00017744 0.00017799 0.00018644 0.00072349 0.00018937 0.00017605
 0.00027391]
Model epoch 564: train total loss -64.88176349987974, train mean loss 0.00028366242717292963, test mean loss [0.00018398 0.00017942 0.00018656 0.00072802 0.00019332 0.00016994
 0.00028059]
Model epoch 565: train total loss -64.99970558940166, train mean loss 0.00026764041303229465, test mean loss [0.00018366 0.00017939 0.00018626 0.00071745 0.00019297 0.00016919
 0.00025471]
Model epoch 566: train total loss -64.81158722803784, train mean loss 0.0002678151744526505, test mean loss [0.00018194 0.00018909 0.00020702 0.00070293 0.00020902 0.00018332
 0.00025824]
Model epoch 567: train total loss -64.79246144372601, train mean loss 0.0002859130106910651, test mean loss [0.00017907 0.00019076 0.00021028 0.0006977  0.00019717 0.00016981
 0.00025049]
Model epoch 568: train total loss -64.93520583009233, train mean loss 0.00028115222540482345, test mean loss [0.00017764 0.00018972 0.00020135 0.00073052 0.00021326 0.00016497
 0.00024868]
Model epoch 569: train total loss -64.8829178404497, train mean loss 0.0002712969251925742, test mean loss [0.00017662 0.00017879 0.00018947 0.00072102 0.0001961  0.00017716
 0.00024902]
Model epoch 570: train total loss -64.64845517669329, train mean loss 0.0003014846705670631, test mean loss [0.00018284 0.00017463 0.00019024 0.00070348 0.00019112 0.00017214
 0.00030099]
Model epoch 571: train total loss -64.90382976337476, train mean loss 0.00028071604435311653, test mean loss [0.00017859 0.00017423 0.00018974 0.00070785 0.00018704 0.00017122
 0.00027588]
Model epoch 572: train total loss -64.83898660493611, train mean loss 0.0002841472543543727, test mean loss [0.00017984 0.00018063 0.00018402 0.00072705 0.00018367 0.00017375
 0.00027476]
Model epoch 573: train total loss -64.90579715568632, train mean loss 0.00026558529594247597, test mean loss [0.00018794 0.00018928 0.00018049 0.00071179 0.00017929 0.00017665
 0.00025719]
Model epoch 574: train total loss -64.98054427135253, train mean loss 0.00027911332843630305, test mean loss [0.0001781  0.0001988  0.00018951 0.00071723 0.00017835 0.00017353
 0.00025544]
Model epoch 575: train total loss -65.08497148047717, train mean loss 0.00027561422251869404, test mean loss [0.00017759 0.00018023 0.00018751 0.00070855 0.00018624 0.00017255
 0.00025382]
Model epoch 576: train total loss -65.14259209971306, train mean loss 0.00028538486325954096, test mean loss [0.00017935 0.00018265 0.00017908 0.00070203 0.00018516 0.00017163
 0.00024783]
Model epoch 577: train total loss -64.98784000682484, train mean loss 0.0002772204866123145, test mean loss [0.00018503 0.0001758  0.00017713 0.00069152 0.00018068 0.00016692
 0.00023957]
Model epoch 578: train total loss -65.05535983418321, train mean loss 0.0002672078142753554, test mean loss [0.00017899 0.00017005 0.00018087 0.00072427 0.00018307 0.00017038
 0.00023759]
Model epoch 579: train total loss -65.20113385230685, train mean loss 0.0002558432209760337, test mean loss [0.00018307 0.0001724  0.00018936 0.00071196 0.0001755  0.00016838
 0.00024328]
Model epoch 580: train total loss -65.01824413469859, train mean loss 0.0002686612322263883, test mean loss [0.0001742  0.00019482 0.00018312 0.00070196 0.00017172 0.00017884
 0.00023948]
Model epoch 581: train total loss -65.012258729714, train mean loss 0.00028271846811035506, test mean loss [0.00017168 0.00018256 0.00017834 0.00070943 0.00017324 0.0001691
 0.0002405 ]
Model epoch 582: train total loss -65.03097041857187, train mean loss 0.0002904391387294027, test mean loss [0.00017927 0.0001878  0.00018423 0.00070123 0.00017985 0.00016761
 0.00022746]
Model epoch 583: train total loss -65.33387291636002, train mean loss 0.00027497792465453727, test mean loss [0.00017261 0.00017924 0.0001826  0.00068969 0.00018425 0.0001649
 0.00023434]
Model epoch 584: train total loss -65.1441092874985, train mean loss 0.0002695538113555438, test mean loss [0.000172   0.00017764 0.00019042 0.0007032  0.00017562 0.00016262
 0.000238  ]
Model epoch 585: train total loss -64.99940378990327, train mean loss 0.0002843664506048419, test mean loss [0.00019429 0.00017291 0.00020153 0.00069215 0.00018088 0.00016028
 0.00025244]
Model epoch 586: train total loss -65.0900909203221, train mean loss 0.0002648620539630969, test mean loss [0.00016906 0.00018457 0.00019013 0.00065836 0.00018181 0.00016843
 0.00024319]
Model epoch 587: train total loss -65.12876090626652, train mean loss 0.00027388242709105445, test mean loss [0.00017737 0.00017621 0.00018466 0.0006936  0.00017874 0.00016246
 0.00023229]
Model epoch 588: train total loss -65.32785377165699, train mean loss 0.0002508995696553058, test mean loss [0.00017621 0.00016667 0.00018462 0.00071173 0.00017453 0.00016285
 0.00022754]
Model epoch 589: train total loss -65.34178711155882, train mean loss 0.00027358572393411536, test mean loss [0.00017435 0.00017433 0.00019414 0.00069354 0.00017212 0.00016583
 0.00022989]
Model epoch 590: train total loss -65.15941462200428, train mean loss 0.0002683204150707981, test mean loss [0.00016724 0.00017507 0.00018465 0.00070493 0.00019342 0.00016677
 0.00022587]
Model epoch 591: train total loss -65.02042993247902, train mean loss 0.0002528475687011117, test mean loss [0.00017483 0.00017039 0.00017497 0.00068203 0.00017851 0.00019725
 0.00022537]
Model epoch 592: train total loss -65.0385386828035, train mean loss 0.0002747811602159243, test mean loss [0.00017573 0.00017569 0.00017311 0.00063512 0.00017436 0.00017003
 0.00023153]
Model epoch 593: train total loss -64.99436632466475, train mean loss 0.00026603218847297776, test mean loss [0.00020385 0.00016491 0.0001728  0.00063933 0.00017346 0.000165
 0.00022549]
Model epoch 594: train total loss -65.18290483227219, train mean loss 0.0002711937419403356, test mean loss [0.00020468 0.00016459 0.00017064 0.00069575 0.00017391 0.00016449
 0.00022462]
Model epoch 595: train total loss -65.15778117468426, train mean loss 0.00026309600800488207, test mean loss [0.00018038 0.00017186 0.00018914 0.00070636 0.0001703  0.00015799
 0.00022093]
Model epoch 596: train total loss -65.11621550463904, train mean loss 0.00024836893187492803, test mean loss [0.00017373 0.00018289 0.00017639 0.00064959 0.00017474 0.00015828
 0.00022253]
Model epoch 597: train total loss -65.14552914838423, train mean loss 0.0002496691779304925, test mean loss [0.0001761  0.000177   0.00018548 0.00065548 0.00017394 0.00015803
 0.00022518]
Model epoch 598: train total loss -65.21773516354249, train mean loss 0.00025237954065786175, test mean loss [0.00016876 0.00017138 0.00018008 0.00066    0.00018115 0.00016111
 0.00023152]
Model epoch 599: train total loss -64.90070428220736, train mean loss 0.0002765831913569221, test mean loss [0.00016559 0.00016528 0.00017988 0.00064993 0.00017051 0.00024994
 0.00022699]
Model epoch 600: train total loss -65.10927905888576, train mean loss 0.0002682798931967945, test mean loss [0.00016828 0.00017041 0.00017633 0.00064926 0.0001692  0.00019247
 0.0002241 ]
Model epoch 601: train total loss -64.46172391249623, train mean loss 0.00027927416044097695, test mean loss [0.00023165 0.00026971 0.00021077 0.00064428 0.00017408 0.00019035
 0.00022106]
Model epoch 602: train total loss -64.73885302626817, train mean loss 0.000259575295972989, test mean loss [0.00023534 0.00018664 0.0001882  0.00063231 0.00016554 0.00017728
 0.00021678]
Model epoch 603: train total loss -64.89970259462805, train mean loss 0.00025876253109100695, test mean loss [0.00018815 0.00018059 0.00017376 0.00064954 0.0001729  0.00016916
 0.0002182 ]
Model epoch 604: train total loss -65.02959820892175, train mean loss 0.0002560151535245299, test mean loss [0.00018652 0.00017611 0.00017142 0.00064042 0.00018169 0.00016378
 0.00020974]
Model epoch 605: train total loss -65.08249250771895, train mean loss 0.0002545760997946493, test mean loss [0.00017876 0.00017708 0.00016919 0.00062045 0.00017059 0.00016307
 0.00022168]
Model epoch 606: train total loss -64.95949313660286, train mean loss 0.00028606240477915476, test mean loss [0.00017198 0.00016816 0.00017163 0.00065083 0.00016896 0.0001557
 0.0002158 ]
Model epoch 607: train total loss -65.05135811274748, train mean loss 0.00024881463451136373, test mean loss [0.00017649 0.00016868 0.00019593 0.00067334 0.00018167 0.00015626
 0.0002241 ]
Model epoch 608: train total loss -64.79039587783255, train mean loss 0.00026325467407758524, test mean loss [0.00016735 0.00017621 0.00020554 0.00066209 0.00016944 0.0001551
 0.0002161 ]
Model epoch 609: train total loss -64.75128440240222, train mean loss 0.00026541176948616474, test mean loss [0.00018276 0.00017764 0.00019984 0.00068796 0.00016167 0.00020388
 0.00021433]
Model epoch 610: train total loss -64.36925362861962, train mean loss 0.0002489814506891356, test mean loss [0.0001704  0.00018693 0.00019781 0.00066631 0.0001689  0.00027889
 0.00022168]
Model epoch 611: train total loss -64.3654402064651, train mean loss 0.00029270814845967086, test mean loss [0.00017054 0.0001872  0.00017996 0.0006577  0.00021911 0.00035049
 0.00022131]
Model epoch 612: train total loss -64.37500805816573, train mean loss 0.00028056309063312064, test mean loss [0.00017393 0.00018565 0.00017764 0.00066592 0.00019247 0.0003864
 0.00021692]
Model epoch 613: train total loss -64.75121863080172, train mean loss 0.00027531435166999215, test mean loss [0.00017076 0.00016791 0.00018216 0.00065739 0.00017465 0.00033319
 0.00022229]
Model epoch 614: train total loss -64.94245303664175, train mean loss 0.00028459180481267657, test mean loss [0.00016752 0.00017865 0.00017885 0.00064728 0.00016787 0.00032186
 0.00021576]
Model epoch 615: train total loss -65.00873208139076, train mean loss 0.00028090624031052396, test mean loss [0.0001651  0.00016377 0.00017497 0.00065044 0.00016564 0.00029552
 0.00021383]
Model epoch 616: train total loss -65.06581013012303, train mean loss 0.0002567384448378059, test mean loss [0.00016604 0.000168   0.00017447 0.00066227 0.0001623  0.0002652
 0.00021178]
Model epoch 617: train total loss -65.06114666766629, train mean loss 0.00025122851826967976, test mean loss [0.00017029 0.00016808 0.00016893 0.00065403 0.00019035 0.00025569
 0.00020831]
Model epoch 618: train total loss -64.87863539072198, train mean loss 0.0002686557121188496, test mean loss [0.0001775  0.00017955 0.00017228 0.00066761 0.00021113 0.00024023
 0.00021267]
Model epoch 619: train total loss -65.03828050996425, train mean loss 0.0002563740045241438, test mean loss [0.00016841 0.00016523 0.00016782 0.00065596 0.00020776 0.00023714
 0.0002153 ]
Model epoch 620: train total loss -65.07709811209335, train mean loss 0.00027499620698827836, test mean loss [0.00018107 0.00018069 0.00017164 0.000645   0.00019259 0.00021937
 0.00021242]
Model epoch 621: train total loss -65.21341090287613, train mean loss 0.0002681048085993324, test mean loss [0.00017365 0.00018599 0.00016728 0.00062827 0.00017902 0.00020106
 0.00020485]
Model epoch 622: train total loss -65.27495191188935, train mean loss 0.0002542508530544874, test mean loss [0.00016159 0.00016346 0.000166   0.00061856 0.00017672 0.00020172
 0.00020305]
Model epoch 623: train total loss -65.19105243906706, train mean loss 0.0002639570708631744, test mean loss [0.00016496 0.0001665  0.00016816 0.00061446 0.00017779 0.00018712
 0.00020447]
Model epoch 624: train total loss -65.34255352661123, train mean loss 0.00025132838050893425, test mean loss [0.00016203 0.00016612 0.00016326 0.0006166  0.00016965 0.00018536
 0.00020466]
Model epoch 625: train total loss -65.29159328968366, train mean loss 0.0002562134935153564, test mean loss [0.00015894 0.00015925 0.00017016 0.00061195 0.00017996 0.00019437
 0.00022843]
Model epoch 626: train total loss -65.32526345439683, train mean loss 0.0002582320098666784, test mean loss [0.00016263 0.00016194 0.00016954 0.00060886 0.00017535 0.0001917
 0.00021914]
Model epoch 627: train total loss -65.37735298793292, train mean loss 0.00023632594941829893, test mean loss [0.0001612  0.00016163 0.0001667  0.00058065 0.00018375 0.00018002
 0.00021285]
Model epoch 628: train total loss -65.46448162346182, train mean loss 0.00023290207600643037, test mean loss [0.0001657  0.00015501 0.00016761 0.00059042 0.00016954 0.00017521
 0.00020645]
Model epoch 629: train total loss -65.32223209427465, train mean loss 0.0002222805160412639, test mean loss [0.00017259 0.00015742 0.00016756 0.00058979 0.00016536 0.00016637
 0.00020381]
Model epoch 630: train total loss -65.36151006471441, train mean loss 0.00022962395903497332, test mean loss [0.00016929 0.00016575 0.00016147 0.00060054 0.0001603  0.00017321
 0.00019946]
Model epoch 631: train total loss -65.4117590907132, train mean loss 0.00023819983798265622, test mean loss [0.00017127 0.00015865 0.00016504 0.00058102 0.00015778 0.00016997
 0.00019701]
Model epoch 632: train total loss -65.45389919241472, train mean loss 0.00022839326776605048, test mean loss [0.00015727 0.00015748 0.00016421 0.0005658  0.00016033 0.00016105
 0.00019816]
Model epoch 633: train total loss -65.53549693078145, train mean loss 0.00021978899229469265, test mean loss [0.00015715 0.00015204 0.00015811 0.00058853 0.00015427 0.0001639
 0.00020522]
Model epoch 634: train total loss -65.56875798247701, train mean loss 0.00021182891146033058, test mean loss [0.00015788 0.00015341 0.000167   0.00057399 0.00016107 0.00015423
 0.00020135]
Model epoch 635: train total loss -65.4201361186998, train mean loss 0.00023026083917808486, test mean loss [0.00015654 0.00016124 0.00017142 0.00057353 0.00019143 0.0001569
 0.00022727]
Model epoch 636: train total loss -65.217713289873, train mean loss 0.00023622460659487792, test mean loss [0.00015932 0.00016124 0.00016537 0.00056914 0.00017294 0.00016382
 0.00020447]
Model epoch 637: train total loss -65.27414735658633, train mean loss 0.0002263352892352316, test mean loss [0.00018601 0.00015713 0.00015938 0.00056047 0.00016133 0.00016858
 0.00020542]
Model epoch 638: train total loss -65.11224054588861, train mean loss 0.00023175366730963744, test mean loss [0.00019781 0.00015716 0.00016784 0.00055599 0.0001621  0.00016471
 0.0001961 ]
Model epoch 639: train total loss -65.36039552710268, train mean loss 0.00022224565880818846, test mean loss [0.00017252 0.00015583 0.00016425 0.00057368 0.0001585  0.00016454
 0.0002026 ]
Model trained in 640 epochs with 1000 transitions.
[2025-01-22 13:53:41,864][absl][INFO] - {'eval/walltime': 75.10627174377441, 'training/sps': 0.8182316755495755, 'training/walltime': 1222.1477484703064, 'training/model_train_time': 1152.3617541790009, 'training/other_time': 68.93386125564575, 'training/model_horizon': 1, 'training/hallucination_updates_per_training_step': 10, 'training/env_buffer_size': Array(2000, dtype=int32), 'model/train_total_loss': Array(-65.36039553, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00022225, dtype=float64), 'model/test_total_loss': Array(-64.10340977, dtype=float64), 'model/test_mean_loss': Array(0.00022742, dtype=float64), 'model/train_epochs': 640, 'model/sec_per_epoch': 1.7979274686425923, 'sac/actor_loss': Array(-11.74723203, dtype=float64), 'sac/alpha': Array(0.9169393, dtype=float32), 'sac/alpha_loss': Array(9.71192836, dtype=float64), 'sac/buffer_current_size': Array(3600., dtype=float32), 'sac/critic_loss': Array(0.67628667, dtype=float64), 'eval/episode_forward_vel': Array(-205.53404144, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-0.12904982, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(51.56675258, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.99662539, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-88.40173825, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(52.55321808, dtype=float64), 'eval/episode_rew_roll': Array(52.18607162, dtype=float64), 'eval/episode_rew_side_motion': Array(64.76795187, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(63.93103206, dtype=float64), 'eval/episode_rew_yaw': Array(78.51709281, dtype=float64), 'eval/episode_rew_z_vel_change': Array(25.4793387, dtype=float64), 'eval/episode_reward': Array(301.77750043, dtype=float64), 'eval/episode_step_count': Array(499500., dtype=float64), 'eval/avg_episode_length': Array(1000., dtype=float64), 'eval/epoch_eval_time': 30.389978647232056, 'eval/sps': 32.905584160095515}
Steps / Eval:  2000.0
Reward is  301.7775004252874
Model horizon updated to 2.
Hallucination updates per training step updated to 257.
SAC buffer resized to 205600 samples.
Model epoch 0: train total loss -61.954325414722334, train mean loss 0.00029893068894128286, test mean loss [0.00027017 0.00025227 0.000272   0.00058741 0.00024675 0.00024383
 0.00025715]
Model epoch 1: train total loss -63.273412623755355, train mean loss 0.0002841315079529771, test mean loss [0.00025781 0.00022275 0.00022758 0.00059402 0.00023046 0.00021436
 0.00024365]
Model epoch 2: train total loss -63.71657898088716, train mean loss 0.0002784055075280138, test mean loss [0.00024167 0.00021057 0.00021554 0.00057818 0.00022018 0.0002031
 0.00023767]
Model epoch 3: train total loss -64.10680486760918, train mean loss 0.0002621918366083979, test mean loss [0.00023009 0.00019708 0.00021056 0.00055449 0.00021375 0.00020168
 0.00022015]
Model epoch 4: train total loss -64.32668872988765, train mean loss 0.00024937422913216703, test mean loss [0.0002253  0.00019689 0.00020257 0.00050797 0.00020629 0.00019229
 0.00022198]
Model epoch 5: train total loss -64.35376860480294, train mean loss 0.00025125968680999813, test mean loss [0.00022373 0.00020002 0.00020355 0.00049079 0.00020686 0.00019453
 0.00021041]
Model epoch 6: train total loss -64.47028559581389, train mean loss 0.0002617492850287256, test mean loss [0.00020955 0.0001929  0.00019721 0.00050184 0.00020829 0.00019167
 0.00021153]
Model epoch 7: train total loss -64.62296935392257, train mean loss 0.0002219968404602202, test mean loss [0.00020829 0.00018916 0.00019188 0.00049634 0.00019554 0.00018784
 0.00020858]
Model epoch 8: train total loss -64.57673237726124, train mean loss 0.0002598026127390871, test mean loss [0.00021394 0.00018506 0.00019106 0.00048477 0.00019878 0.00018645
 0.00020726]
Model epoch 9: train total loss -64.69883619140373, train mean loss 0.0002279360105731823, test mean loss [0.00022212 0.0001969  0.00019382 0.0004648  0.0001943  0.00018986
 0.0002128 ]
Model epoch 10: train total loss -64.50509212890081, train mean loss 0.00024076403835920535, test mean loss [0.00021309 0.0001947  0.00019242 0.00043668 0.00019475 0.00019212
 0.00021935]
Model epoch 11: train total loss -64.61881472448574, train mean loss 0.00022843223719216533, test mean loss [0.00020922 0.00018893 0.00018907 0.00042365 0.00019083 0.00018508
 0.00021532]
Model epoch 12: train total loss -64.54999814387416, train mean loss 0.00022723687988055857, test mean loss [0.00021156 0.00018582 0.00018509 0.00044549 0.00018941 0.00018662
 0.00020384]
Model epoch 13: train total loss -64.37583203808985, train mean loss 0.0002256744705774703, test mean loss [0.00021368 0.00019255 0.00020156 0.00040652 0.00019422 0.00018214
 0.00020009]
Model epoch 14: train total loss -64.59898840806507, train mean loss 0.00022568389316628308, test mean loss [0.00020918 0.00018435 0.00019149 0.00040211 0.00020223 0.0001907
 0.0002142 ]
Model epoch 15: train total loss -64.61985376026291, train mean loss 0.00023667071539922686, test mean loss [0.00021065 0.00019777 0.00018664 0.00040091 0.00019176 0.00018247
 0.00020259]
Model epoch 16: train total loss -64.66726891313459, train mean loss 0.00022107724153393068, test mean loss [0.00020258 0.00018658 0.0001976  0.00039574 0.00019526 0.00017957
 0.0001959 ]
Model epoch 17: train total loss -64.6203276160912, train mean loss 0.00020839042470085795, test mean loss [0.0002048  0.00018674 0.00018834 0.00035285 0.0002049  0.00018568
 0.00020082]
Model epoch 18: train total loss -64.70042180413914, train mean loss 0.00020893425885875572, test mean loss [0.0002072  0.00018982 0.00018394 0.00035141 0.00019263 0.00017778
 0.00020095]
Model epoch 19: train total loss -64.4388609903213, train mean loss 0.00021289716189724076, test mean loss [0.00020168 0.00019132 0.00018636 0.00033875 0.00019415 0.00018413
 0.00020134]
Model epoch 20: train total loss -64.62319986234476, train mean loss 0.0002104605642656824, test mean loss [0.00019928 0.00018596 0.00019371 0.00033667 0.00018936 0.0001864
 0.00019934]
Model epoch 21: train total loss -64.61260300492684, train mean loss 0.00021138703372868532, test mean loss [0.00019914 0.000183   0.00018776 0.00032368 0.00018604 0.00017352
 0.00020916]
Model epoch 22: train total loss -64.74282850446772, train mean loss 0.00020636780379918533, test mean loss [0.00020371 0.00018756 0.00018448 0.00031524 0.00018455 0.00017121
 0.00020011]
Model epoch 23: train total loss -64.58211435611999, train mean loss 0.0001994755462739937, test mean loss [0.00020844 0.00018065 0.00020295 0.00030154 0.00018353 0.00020356
 0.00019654]
Model epoch 24: train total loss -64.78659281042981, train mean loss 0.00020843325648227718, test mean loss [0.00020411 0.00018805 0.00018423 0.00028194 0.00018597 0.00017721
 0.00019694]
Model epoch 25: train total loss -64.81236263253626, train mean loss 0.00019476857039801807, test mean loss [0.00020181 0.0001819  0.00019062 0.00027633 0.00018564 0.00017955
 0.00019304]
Model epoch 26: train total loss -64.68469140755664, train mean loss 0.00019570213707849286, test mean loss [0.00019335 0.00018325 0.00018926 0.00026496 0.00018566 0.00017584
 0.00019662]
Model epoch 27: train total loss -64.71708488801406, train mean loss 0.0001890513192242988, test mean loss [0.00019861 0.00018497 0.00018414 0.00024683 0.00018875 0.00018078
 0.00019842]
Model epoch 28: train total loss -64.78996014588611, train mean loss 0.00018973784876272654, test mean loss [0.00020361 0.00018668 0.00018115 0.00024036 0.00018331 0.00017164
 0.00019046]
Model epoch 29: train total loss -64.87851930826719, train mean loss 0.00019509245618861215, test mean loss [0.00020639 0.00018082 0.00018316 0.00024045 0.000183   0.00017222
 0.00019019]
Model epoch 30: train total loss -64.82660598997961, train mean loss 0.00018798050992229541, test mean loss [0.00019561 0.00017877 0.00017756 0.00022908 0.00018391 0.00017665
 0.00019328]
Model epoch 31: train total loss -64.94555096768904, train mean loss 0.000177135411219404, test mean loss [0.00019296 0.00017822 0.00018513 0.00022324 0.00018662 0.0001727
 0.00018718]
Model epoch 32: train total loss -64.71930375896227, train mean loss 0.00019012083244913483, test mean loss [0.00019172 0.00018492 0.0001928  0.00022199 0.00018509 0.00018573
 0.00018334]
Model epoch 33: train total loss -64.8376915031011, train mean loss 0.00018326476743727626, test mean loss [0.00019814 0.00017514 0.00019255 0.0002167  0.00018085 0.00018394
 0.00018258]
Model epoch 34: train total loss -64.88095075562151, train mean loss 0.0001762693807917886, test mean loss [0.00019385 0.00018138 0.00018241 0.0002134  0.00019176 0.00016943
 0.00018802]
Model epoch 35: train total loss -64.75691559412638, train mean loss 0.00018298105305068158, test mean loss [0.0002053  0.00017585 0.0001859  0.00021085 0.00018425 0.00016626
 0.00018055]
Model epoch 36: train total loss -64.84597204656731, train mean loss 0.00016908257341145022, test mean loss [0.00019433 0.00017234 0.00020267 0.0002078  0.00017843 0.00017105
 0.00018578]
Model epoch 37: train total loss -64.86287904113377, train mean loss 0.00017947056642055525, test mean loss [0.00020023 0.00017131 0.00019789 0.00020463 0.00017988 0.00017077
 0.00018328]
Model epoch 38: train total loss -64.8706590149015, train mean loss 0.00017693314883716836, test mean loss [0.00019538 0.00017436 0.0001893  0.00020982 0.00017569 0.00016839
 0.00018523]
Model epoch 39: train total loss -64.9304144524479, train mean loss 0.00016923073241676074, test mean loss [0.00019345 0.00017842 0.00018768 0.0001994  0.00018326 0.00016959
 0.00018169]
Model epoch 40: train total loss -64.93636093644385, train mean loss 0.00017857684136619376, test mean loss [0.00019476 0.00017886 0.00018439 0.00020302 0.00018185 0.00016459
 0.00018119]
Model epoch 41: train total loss -64.85236798482865, train mean loss 0.00017431726285494701, test mean loss [0.00019835 0.00017297 0.00017982 0.00020387 0.00017701 0.00017214
 0.000193  ]
Model epoch 42: train total loss -64.81515559196804, train mean loss 0.00017527417921394992, test mean loss [0.00019146 0.00017689 0.00018712 0.00020522 0.00017741 0.00016482
 0.00018259]
Model epoch 43: train total loss -64.97076875633631, train mean loss 0.00017645238614084874, test mean loss [0.00018966 0.00017075 0.00018689 0.0002104  0.00017726 0.00016738
 0.00018479]
Model epoch 44: train total loss -64.96767630333609, train mean loss 0.00016204660077636835, test mean loss [0.00019915 0.00017053 0.00017892 0.00020431 0.00018438 0.0001594
 0.00018401]
Model epoch 45: train total loss -64.84494628282295, train mean loss 0.0001780558980697564, test mean loss [0.00018837 0.00016897 0.00018216 0.00021787 0.00017416 0.0001618
 0.00018683]
Model epoch 46: train total loss -64.8723305475331, train mean loss 0.00016651197760884345, test mean loss [0.00018492 0.00017167 0.00018135 0.00021076 0.00017562 0.00016338
 0.00018728]
Model epoch 47: train total loss -64.96012395261049, train mean loss 0.00017204977675135266, test mean loss [0.00019276 0.00017228 0.00018205 0.00019736 0.00017328 0.00016593
 0.00017968]
Model epoch 48: train total loss -65.08262347005811, train mean loss 0.00016739007410350006, test mean loss [0.00018824 0.00017451 0.00017958 0.00020356 0.00017623 0.00016156
 0.00017907]
Model epoch 49: train total loss -64.99547356540383, train mean loss 0.00017764529858012803, test mean loss [0.00018965 0.00017207 0.00017329 0.00020104 0.00017708 0.00016768
 0.00018392]
Model epoch 50: train total loss -64.9043009418606, train mean loss 0.00016480553321409502, test mean loss [0.00018912 0.00017123 0.0001788  0.00019825 0.00018274 0.00017217
 0.00017762]
Model epoch 51: train total loss -64.85890530196528, train mean loss 0.00016782960933942279, test mean loss [0.00018574 0.00017108 0.00017435 0.00020882 0.00017661 0.00016345
 0.00017844]
Model epoch 52: train total loss -64.93934184211271, train mean loss 0.00017567231210226963, test mean loss [0.00018992 0.00018196 0.0001761  0.0002011  0.00017387 0.00016102
 0.00017518]
Model epoch 53: train total loss -64.92610037196376, train mean loss 0.0001706737451951438, test mean loss [0.00018497 0.00017958 0.00017663 0.00019195 0.00016911 0.00016608
 0.00017534]
Model epoch 54: train total loss -64.99565362133191, train mean loss 0.00016748977426606827, test mean loss [0.00018574 0.00017148 0.00017647 0.00020323 0.00017185 0.00016019
 0.00017359]
Model epoch 55: train total loss -64.98420397006164, train mean loss 0.0001650409861017555, test mean loss [0.00019084 0.00016842 0.00017128 0.00020267 0.00017187 0.00016428
 0.00017703]
Model epoch 56: train total loss -64.9524630160531, train mean loss 0.00016703009214005617, test mean loss [0.00018383 0.00017122 0.00017293 0.00019866 0.00016858 0.00015995
 0.00017812]
Model epoch 57: train total loss -65.07343504843304, train mean loss 0.0001654182413608776, test mean loss [0.00018131 0.00016482 0.0001804  0.00020423 0.00017499 0.00015891
 0.00016933]
Model epoch 58: train total loss -65.1875444615286, train mean loss 0.00016553783235950188, test mean loss [0.00018118 0.00016247 0.00017224 0.00020292 0.00016862 0.00016322
 0.00017769]
Model epoch 59: train total loss -64.79096490535505, train mean loss 0.00017029676227226282, test mean loss [0.00018639 0.00016163 0.00017388 0.0001947  0.00017009 0.00015744
 0.00019589]
Model epoch 60: train total loss -64.96851205676036, train mean loss 0.00016434829070448341, test mean loss [0.00019094 0.00017214 0.00017548 0.0001965  0.00016623 0.0001538
 0.00017961]
Model epoch 61: train total loss -64.99836373977799, train mean loss 0.00015836714743040425, test mean loss [0.00019125 0.00016603 0.00017481 0.00020125 0.00016793 0.00015381
 0.00017639]
Model epoch 62: train total loss -64.91490322542523, train mean loss 0.00016380659978173002, test mean loss [0.00018328 0.00017423 0.00017666 0.0002024  0.00017052 0.00015545
 0.00017343]
Model epoch 63: train total loss -65.08569145279833, train mean loss 0.00016714555901654762, test mean loss [0.00017798 0.00018207 0.00018331 0.00020746 0.00016714 0.00015828
 0.00017028]
Model epoch 64: train total loss -65.03042506740907, train mean loss 0.00016274352255141387, test mean loss [0.00018394 0.00016815 0.00017814 0.00019368 0.00016811 0.00015391
 0.0001709 ]
Model epoch 65: train total loss -64.87862595723409, train mean loss 0.00016197187118136707, test mean loss [0.000181   0.00016654 0.00017521 0.00019922 0.00017001 0.00016978
 0.00017799]
Model epoch 66: train total loss -65.00373214346452, train mean loss 0.0001562043057051918, test mean loss [0.00017975 0.00016074 0.00017671 0.00019423 0.00016608 0.00016283
 0.00017179]
Model epoch 67: train total loss -65.06563232571128, train mean loss 0.000154959866101409, test mean loss [0.00017908 0.00015946 0.0001771  0.00019063 0.00016775 0.00015816
 0.00017275]
Model epoch 68: train total loss -64.97852796789762, train mean loss 0.0001525076660781227, test mean loss [0.00019087 0.00016474 0.00017818 0.00019035 0.00017346 0.0001568
 0.00016897]
Model epoch 69: train total loss -64.97751857195259, train mean loss 0.00015330657576994124, test mean loss [0.00018344 0.00016454 0.0001752  0.00019044 0.00016597 0.00015381
 0.00016747]
Model epoch 70: train total loss -65.02195173600627, train mean loss 0.00015956414396268217, test mean loss [0.00017542 0.00015773 0.00016565 0.00019043 0.00016841 0.0001604
 0.00017064]
Model epoch 71: train total loss -64.85386162529608, train mean loss 0.0001620386045964023, test mean loss [0.00017753 0.0001602  0.00021635 0.00019116 0.00017591 0.00017666
 0.00016543]
Model epoch 72: train total loss -64.9347520142546, train mean loss 0.00015458308961686224, test mean loss [0.00017529 0.00016176 0.00019472 0.00018919 0.00016663 0.00015306
 0.0001661 ]
Model epoch 73: train total loss -65.09840379085544, train mean loss 0.00015516103114360336, test mean loss [0.00017481 0.00015893 0.00018167 0.0001962  0.00017162 0.00014989
 0.0001659 ]
Model epoch 74: train total loss -65.08994272980141, train mean loss 0.00015104252801893407, test mean loss [0.00017571 0.00015461 0.00017889 0.0001905  0.00016672 0.00014725
 0.00016661]
Model epoch 75: train total loss -64.75924190327446, train mean loss 0.00015576924871994573, test mean loss [0.00018781 0.00015993 0.0002024  0.00019318 0.00016582 0.00014999
 0.00016105]
Model epoch 76: train total loss -64.92080593680876, train mean loss 0.00016268243070911444, test mean loss [0.00018155 0.00016174 0.0001927  0.00018631 0.00017512 0.0001516
 0.00015888]
Model epoch 77: train total loss -64.685061894221, train mean loss 0.0001619001556969282, test mean loss [0.00017878 0.00016367 0.00018711 0.0001936  0.0001721  0.00014788
 0.00021645]
Model epoch 78: train total loss -65.03070542347518, train mean loss 0.00015754216571115667, test mean loss [0.00017659 0.00015456 0.0001773  0.00018814 0.00016082 0.00015165
 0.00018006]
Model epoch 79: train total loss -64.9832808146939, train mean loss 0.00016215907814044674, test mean loss [0.00021706 0.0001566  0.00017358 0.00018828 0.00016907 0.00015989
 0.0001622 ]
Model epoch 80: train total loss -64.95671297155731, train mean loss 0.00015902448415726966, test mean loss [0.00017653 0.00016497 0.00016404 0.00019214 0.00016156 0.00014926
 0.00015983]
Model epoch 81: train total loss -64.56004026913237, train mean loss 0.00017042783044803972, test mean loss [0.00018087 0.00015588 0.00017053 0.00019428 0.000162   0.00014309
 0.00032072]
Model epoch 82: train total loss -63.08909836413369, train mean loss 0.0010383970518402033, test mean loss [0.00017494 0.00016486 0.00018851 0.00018421 0.00016063 0.00014953
 0.00543616]
Model epoch 83: train total loss -63.65712918308838, train mean loss 0.0013495273845517586, test mean loss [0.00018071 0.00016019 0.00018275 0.00018921 0.00016517 0.00015273
 0.00588621]
Model epoch 84: train total loss -63.88212810466032, train mean loss 0.0008513752361408467, test mean loss [0.00018537 0.00017024 0.0001723  0.00021831 0.00016125 0.00015171
 0.00518937]
Model epoch 85: train total loss -64.16344185155347, train mean loss 0.0009898230304700992, test mean loss [0.00017919 0.00015625 0.00016547 0.00020149 0.00016079 0.00015442
 0.00418811]
Model epoch 86: train total loss -64.47803428850348, train mean loss 0.0008285031462776402, test mean loss [0.00017177 0.00016259 0.00016317 0.0001957  0.00016117 0.00014755
 0.00332746]
Model epoch 87: train total loss -64.62369842595957, train mean loss 0.0005583941200552465, test mean loss [0.00016828 0.00015934 0.00016351 0.0001953  0.00015572 0.0001548
 0.00266299]
Model epoch 88: train total loss -64.72289180999957, train mean loss 0.000577292122198501, test mean loss [0.00017639 0.00015424 0.00016893 0.00019394 0.00015987 0.00014903
 0.00218731]
Model epoch 89: train total loss -64.8148428234494, train mean loss 0.00046439012645796624, test mean loss [0.00017382 0.00015549 0.00016796 0.00017903 0.00016284 0.00014076
 0.00186988]
Model epoch 90: train total loss -64.83728612268902, train mean loss 0.00034200161650541614, test mean loss [0.00017582 0.00015958 0.00016643 0.00019386 0.00017285 0.00015775
 0.001655  ]
Model epoch 91: train total loss -64.69900372114289, train mean loss 0.00038497386796690743, test mean loss [0.00017101 0.00015467 0.00016089 0.00021353 0.00016807 0.00015082
 0.00150094]
Model epoch 92: train total loss -64.67300111604072, train mean loss 0.00040867094564247505, test mean loss [0.00016864 0.00015561 0.0001644  0.00019739 0.00015878 0.00014664
 0.00137598]
Model epoch 93: train total loss -64.76640431487894, train mean loss 0.0003005928392494053, test mean loss [0.0001724  0.0001579  0.00017449 0.00018709 0.00016696 0.00014692
 0.00124654]
Model epoch 94: train total loss -64.93981331400374, train mean loss 0.0002816674343676059, test mean loss [0.00017548 0.00015707 0.00017435 0.00018812 0.00016868 0.0001718
 0.00113889]
Model epoch 95: train total loss -65.04685069976442, train mean loss 0.00031632388082306187, test mean loss [0.00016726 0.00015479 0.00016579 0.00018582 0.00016064 0.00014539
 0.00102213]
Model epoch 96: train total loss -65.0549582307889, train mean loss 0.0003016963396604519, test mean loss [0.00017346 0.00016131 0.00016883 0.00018664 0.00015448 0.00014464
 0.00095259]
Model epoch 97: train total loss -65.12663965848623, train mean loss 0.0002698596149385258, test mean loss [0.00017767 0.00015469 0.00016879 0.00018393 0.00016935 0.0001437
 0.00089156]
Model trained in 98 epochs with 2000 transitions.
[2025-01-22 14:05:49,959][absl][INFO] - {'eval/walltime': 105.65230965614319, 'training/sps': 1.4338388886907105, 'training/walltime': 1919.5761749744415, 'training/model_train_time': 322.8659439086914, 'training/other_time': 373.6947212219238, 'training/model_horizon': 2, 'training/hallucination_updates_per_training_step': 257, 'training/env_buffer_size': Array(3000, dtype=int32), 'model/train_total_loss': Array(-65.12663966, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00026986, dtype=float64), 'model/test_total_loss': Array(-64.58579955, dtype=float64), 'model/test_mean_loss': Array(0.00026996, dtype=float64), 'model/train_epochs': 98, 'model/sec_per_epoch': 3.2756697888277015, 'sac/actor_loss': Array(-12.41168133, dtype=float64), 'sac/alpha': Array(0.23520331, dtype=float32), 'sac/alpha_loss': Array(1.99053239, dtype=float64), 'sac/buffer_current_size': Array(108129.18, dtype=float32), 'sac/critic_loss': Array(0.09465422, dtype=float64), 'eval/episode_forward_vel': Array(-189.23619024, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-11.24767863, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(50.80776239, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.37378883, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-81.39190978, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(51.51337478, dtype=float64), 'eval/episode_rew_roll': Array(48.88996057, dtype=float64), 'eval/episode_rew_side_motion': Array(39.84581696, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(46.78559366, dtype=float64), 'eval/episode_rew_yaw': Array(55.26369543, dtype=float64), 'eval/episode_rew_z_vel_change': Array(25.14359437, dtype=float64), 'eval/episode_reward': Array(226.10350812, dtype=float64), 'eval/episode_step_count': Array(499500., dtype=float64), 'eval/avg_episode_length': Array(1000., dtype=float64), 'eval/epoch_eval_time': 30.546037912368774, 'eval/sps': 32.73747000736477}
Steps / Eval:  3000.0
Reward is  226.10350811725942
Model horizon updated to 4.
Hallucination updates per training step updated to 505.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -30.849216290845522, train mean loss 0.02873797436433611, test mean loss [0.01696931 0.02786782 0.02205298 0.03176779 0.03229709 0.02701788
 0.02991498]
Model epoch 1: train total loss -37.1346711607418, train mean loss 0.02607436837186463, test mean loss [0.01465811 0.02828261 0.0203004  0.0321243  0.02812316 0.02499435
 0.02841985]
Model epoch 2: train total loss -40.95807562834738, train mean loss 0.02401607684129429, test mean loss [0.01247744 0.02601254 0.01633652 0.03128166 0.02601924 0.02217442
 0.02457192]
Model epoch 3: train total loss -44.59680145394153, train mean loss 0.021790494907797595, test mean loss [0.01065217 0.02394111 0.01419496 0.0275039  0.02439493 0.02062069
 0.02113612]
Model epoch 4: train total loss -47.0857481101826, train mean loss 0.019234090095005832, test mean loss [0.00962398 0.02178774 0.01212128 0.02488739 0.02240093 0.01718667
 0.01827932]
Model epoch 5: train total loss -49.257068383145565, train mean loss 0.016992911608090355, test mean loss [0.0088499  0.01896209 0.01082149 0.02283272 0.01918438 0.01454352
 0.01641463]
Model epoch 6: train total loss -51.43324437178522, train mean loss 0.013948273988328255, test mean loss [0.00810247 0.01615602 0.00967696 0.02047343 0.0162654  0.01271876
 0.01494041]
Model epoch 7: train total loss -52.80343894925306, train mean loss 0.012581576785378417, test mean loss [0.00774311 0.01439709 0.00898955 0.01786371 0.013456   0.01073455
 0.01354185]
Model epoch 8: train total loss -54.13109940469488, train mean loss 0.011135743692784179, test mean loss [0.00744193 0.01314021 0.00847768 0.01473044 0.01140375 0.00929328
 0.01219061]
Model epoch 9: train total loss -55.25734368862371, train mean loss 0.009763941929636078, test mean loss [0.00677984 0.01207586 0.0077153  0.01291029 0.01009451 0.00820642
 0.01108323]
Model epoch 10: train total loss -55.819929892746174, train mean loss 0.008880248335688064, test mean loss [0.00587273 0.01103976 0.00691359 0.01172812 0.00895191 0.00724213
 0.01006681]
Model epoch 11: train total loss -56.552887944842425, train mean loss 0.00797786910990513, test mean loss [0.00503471 0.00993001 0.00606493 0.01063282 0.00781888 0.00653017
 0.00934734]
Model epoch 12: train total loss -57.12907523266537, train mean loss 0.007320455563299454, test mean loss [0.00431072 0.00910235 0.00560412 0.00971948 0.00683614 0.00592295
 0.0086081 ]
Model epoch 13: train total loss -57.61219293158906, train mean loss 0.006450268513716256, test mean loss [0.00363802 0.00829671 0.00500648 0.00873671 0.00615398 0.00539149
 0.00798574]
Model epoch 14: train total loss -58.059759829597624, train mean loss 0.006171280682230811, test mean loss [0.00314779 0.00758139 0.00451778 0.00808298 0.00560611 0.00463342
 0.00733493]
Model epoch 15: train total loss -58.328311743168555, train mean loss 0.005570441158366102, test mean loss [0.00263584 0.00684748 0.00408001 0.00728375 0.00521199 0.00401075
 0.00686033]
Model epoch 16: train total loss -58.68956278232772, train mean loss 0.004630112107607029, test mean loss [0.00218202 0.00620879 0.00354686 0.00660825 0.0048334  0.00336355
 0.00632197]
Model epoch 17: train total loss -58.81158762293249, train mean loss 0.004232031216732983, test mean loss [0.00184961 0.00571717 0.00308758 0.00602913 0.00441566 0.00296986
 0.00583765]
Model epoch 18: train total loss -59.01799214115276, train mean loss 0.004025878063976787, test mean loss [0.00153316 0.0053419  0.00278312 0.00545198 0.00416358 0.0024757
 0.00524949]
Model epoch 19: train total loss -59.53038728170298, train mean loss 0.0033807906840975744, test mean loss [0.00124635 0.00487412 0.00246426 0.00489181 0.00378334 0.00217958
 0.00479082]
Model epoch 20: train total loss -59.58973623479912, train mean loss 0.003163181526420337, test mean loss [0.00107123 0.00447958 0.00216895 0.00445409 0.0035523  0.00189151
 0.00437337]
Model epoch 21: train total loss -59.981443130612085, train mean loss 0.0027029148963473196, test mean loss [0.00098388 0.00404642 0.00189278 0.00390704 0.00331246 0.00161352
 0.00379679]
Model epoch 22: train total loss -60.131276940250906, train mean loss 0.002620372630403677, test mean loss [0.00091279 0.00366111 0.00166733 0.00352269 0.00311497 0.00139784
 0.00337618]
Model epoch 23: train total loss -60.348046818139984, train mean loss 0.00206260240684583, test mean loss [0.00088168 0.0032898  0.00152257 0.00296923 0.00295189 0.00130003
 0.00286771]
Model epoch 24: train total loss -60.427257716429686, train mean loss 0.0020847235314082817, test mean loss [0.00084871 0.00294587 0.00142709 0.00257497 0.00280867 0.00123387
 0.00245791]
Model epoch 25: train total loss -60.604777758566684, train mean loss 0.0017850222162165016, test mean loss [0.00081839 0.0026636  0.00127216 0.00223445 0.00259203 0.0011372
 0.00215399]
Model epoch 26: train total loss -60.80287985457929, train mean loss 0.0015277227750190574, test mean loss [0.00078763 0.00241007 0.00116699 0.00187456 0.00246185 0.00112398
 0.00188463]
Model epoch 27: train total loss -60.891793766100086, train mean loss 0.0015026135450915729, test mean loss [0.00075232 0.00217745 0.00110688 0.00169647 0.0022975  0.00105879
 0.00166764]
Model epoch 28: train total loss -61.177631236483336, train mean loss 0.001450752408841521, test mean loss [0.00073982 0.001994   0.00099226 0.00153084 0.00210561 0.00103973
 0.00141217]
Model epoch 29: train total loss -61.27787619078959, train mean loss 0.0011415324905879201, test mean loss [0.0007097  0.00181884 0.00095819 0.0013784  0.00198615 0.00099375
 0.0012519 ]
Model epoch 30: train total loss -61.19560399539902, train mean loss 0.0012184886859574846, test mean loss [0.00070372 0.00167592 0.00085985 0.00123287 0.00187453 0.00093154
 0.00117263]
Model epoch 31: train total loss -61.39811015599099, train mean loss 0.0010114253943229944, test mean loss [0.0006749  0.00154027 0.00082905 0.00114632 0.00178628 0.000944
 0.00109959]
Model epoch 32: train total loss -61.59808621925324, train mean loss 0.0009993725645769261, test mean loss [0.0006653  0.00141798 0.00078634 0.00104316 0.00163691 0.00090238
 0.00105835]
Model epoch 33: train total loss -61.777749754773616, train mean loss 0.0008872786041934016, test mean loss [0.00064561 0.00137206 0.00073455 0.00098794 0.00150997 0.00086249
 0.001016  ]
Model epoch 34: train total loss -61.79597354610849, train mean loss 0.000944305450148374, test mean loss [0.0006434  0.00127903 0.00070192 0.00097091 0.00141987 0.00083989
 0.00095145]
Model epoch 35: train total loss -61.9062115506198, train mean loss 0.0008647784033697592, test mean loss [0.00061587 0.00125655 0.00067389 0.00090999 0.00132589 0.00081486
 0.00092345]
Model epoch 36: train total loss -61.93735243479552, train mean loss 0.0007493136540559984, test mean loss [0.00059364 0.00119349 0.00063792 0.00087638 0.00126172 0.00079897
 0.00091448]
Model epoch 37: train total loss -62.08206495888442, train mean loss 0.0008260407408334268, test mean loss [0.00058517 0.00116039 0.00062835 0.00084172 0.00115651 0.00077317
 0.00087145]
Model epoch 38: train total loss -61.96419463260833, train mean loss 0.0007142987618739005, test mean loss [0.00058279 0.00109794 0.0006176  0.00082373 0.0010615  0.00075191
 0.00085698]
Model epoch 39: train total loss -62.21675303252452, train mean loss 0.000667462909799675, test mean loss [0.00056062 0.00106129 0.00061295 0.00078431 0.00102531 0.00074178
 0.00082311]
Model epoch 40: train total loss -62.25395968447124, train mean loss 0.0007270396347546367, test mean loss [0.00054063 0.00103301 0.00059131 0.00077188 0.00094049 0.000731
 0.00081192]
Model epoch 41: train total loss -62.238235201765235, train mean loss 0.0006184361631870613, test mean loss [0.00054602 0.00099313 0.00059639 0.00073754 0.00092413 0.00068774
 0.00080107]
Model epoch 42: train total loss -62.47198478920119, train mean loss 0.0005975764668881352, test mean loss [0.00053449 0.00098769 0.00057965 0.00074572 0.00082763 0.00067518
 0.00077552]
Model epoch 43: train total loss -62.52380651521095, train mean loss 0.0006357635894599979, test mean loss [0.000519   0.00095962 0.0005668  0.00072977 0.00080142 0.00067574
 0.00075892]
Model epoch 44: train total loss -62.458660509125, train mean loss 0.000647646857259724, test mean loss [0.00051087 0.00091289 0.00055476 0.00129183 0.00077142 0.00064373
 0.0007552 ]
Model epoch 45: train total loss -62.495799437590506, train mean loss 0.0006739838595196344, test mean loss [0.00050262 0.00091077 0.00054237 0.00098585 0.0007328  0.00062115
 0.00072553]
Model epoch 46: train total loss -62.71980827076559, train mean loss 0.0005236217735904036, test mean loss [0.0004992  0.00086695 0.00053624 0.00088541 0.00068869 0.00061945
 0.00072103]
Model epoch 47: train total loss -62.63770952794248, train mean loss 0.0005310369837077077, test mean loss [0.00047754 0.00085024 0.00052991 0.00080098 0.00068078 0.00059252
 0.00069497]
Model epoch 48: train total loss -62.55810366197206, train mean loss 0.0005653094865492571, test mean loss [0.00047369 0.00084443 0.00052987 0.00074775 0.00066604 0.00060225
 0.00068475]
Model epoch 49: train total loss -62.962527939001774, train mean loss 0.0005199305703171444, test mean loss [0.0004726  0.00082004 0.00050727 0.0006736  0.00063842 0.00059709
 0.00068008]
Model epoch 50: train total loss -62.75890897776958, train mean loss 0.0005568224557274331, test mean loss [0.00046556 0.00079786 0.00051999 0.00064288 0.0006081  0.00057322
 0.00065399]
Model epoch 51: train total loss -62.86451684200757, train mean loss 0.0004766722022939166, test mean loss [0.00046727 0.000777   0.00050562 0.0006328  0.00060068 0.00057977
 0.00064513]
Model epoch 52: train total loss -62.92429316994329, train mean loss 0.0004888977969457296, test mean loss [0.00046103 0.00076835 0.00049452 0.00064658 0.0005973  0.00054691
 0.00063334]
Model epoch 53: train total loss -63.178666379145156, train mean loss 0.000469895931708705, test mean loss [0.00045564 0.00075069 0.00048821 0.00060037 0.00059227 0.00055523
 0.00062809]
Model epoch 54: train total loss -62.79834194361444, train mean loss 0.0004912522791805611, test mean loss [0.0004469  0.00073492 0.00047677 0.00059342 0.00056483 0.00053898
 0.00062016]
Model epoch 55: train total loss -63.01983446486071, train mean loss 0.0004276424980601642, test mean loss [0.0004457  0.00071709 0.00047665 0.00057897 0.00056024 0.00053111
 0.00060868]
Model epoch 56: train total loss -63.069645606376916, train mean loss 0.0004116398562322989, test mean loss [0.0004291  0.00069931 0.00047511 0.00058122 0.00058453 0.00050725
 0.00059246]
Model epoch 57: train total loss -63.21221843449637, train mean loss 0.0004706291201879505, test mean loss [0.00042223 0.0006832  0.00047302 0.00055701 0.00055155 0.00049681
 0.00062806]
Model epoch 58: train total loss -63.14818827268239, train mean loss 0.0004851169540470242, test mean loss [0.0004232  0.0006668  0.00046163 0.00056127 0.00054799 0.00050046
 0.00057208]
Model epoch 59: train total loss -63.06952883956526, train mean loss 0.000453373968067445, test mean loss [0.00043863 0.00065839 0.00046096 0.00055548 0.0005231  0.00049235
 0.00056568]
Model epoch 60: train total loss -63.24501763386183, train mean loss 0.0004328100575119244, test mean loss [0.00042118 0.00064909 0.00045987 0.00054848 0.00052827 0.00048118
 0.00055929]
Model epoch 61: train total loss -63.141036920483515, train mean loss 0.0004069121162940486, test mean loss [0.00040979 0.00063739 0.00044373 0.00056113 0.00050177 0.00048346
 0.00055058]
Model epoch 62: train total loss -63.32188416243421, train mean loss 0.0004215413942806836, test mean loss [0.00040785 0.00062573 0.00044584 0.00054733 0.00049309 0.0004657
 0.00054415]
Model epoch 63: train total loss -63.32879089841233, train mean loss 0.000391872593496181, test mean loss [0.00040665 0.00061788 0.00044356 0.00052521 0.00048948 0.0004597
 0.00053753]
Model epoch 64: train total loss -63.13484888511035, train mean loss 0.0003803002691556147, test mean loss [0.00041472 0.00060132 0.00043191 0.00051903 0.00048584 0.00046738
 0.00053163]
Model epoch 65: train total loss -63.41301540228585, train mean loss 0.00034639776622116114, test mean loss [0.00039534 0.00059457 0.00042558 0.00050407 0.00047145 0.00044488
 0.00052094]
Model epoch 66: train total loss -63.483137314550184, train mean loss 0.00039337077476216315, test mean loss [0.00038904 0.00058581 0.00042391 0.00050264 0.00046373 0.00043901
 0.00052921]
Model epoch 67: train total loss -63.357480318446356, train mean loss 0.0004392820330065504, test mean loss [0.00038202 0.00057411 0.00042368 0.00049441 0.00047026 0.00044957
 0.00053193]
Model epoch 68: train total loss -63.43351925174924, train mean loss 0.0003972996131400733, test mean loss [0.00038009 0.00056533 0.00042215 0.00047904 0.00046311 0.00042902
 0.00049823]
Model epoch 69: train total loss -63.34977704616461, train mean loss 0.00035764530607561187, test mean loss [0.00037748 0.00055212 0.00040796 0.00048345 0.00045616 0.0004483
 0.00049853]
Model epoch 70: train total loss -63.64169029554786, train mean loss 0.00038069016496417767, test mean loss [0.00038745 0.00054417 0.00040031 0.00047181 0.00044738 0.00042377
 0.00049722]
Model epoch 71: train total loss -63.59212995048014, train mean loss 0.0003817614028646081, test mean loss [0.00038672 0.00054734 0.00041536 0.00046698 0.00043975 0.00041459
 0.00048813]
Model epoch 72: train total loss -63.45922629436645, train mean loss 0.0003685746377910167, test mean loss [0.00037535 0.00053136 0.000414   0.00046855 0.00044937 0.00042276
 0.0004809 ]
Model epoch 73: train total loss -63.466269271050535, train mean loss 0.0003448741021074449, test mean loss [0.00036309 0.00051844 0.00039383 0.00045459 0.00044246 0.00041501
 0.00048832]
Model epoch 74: train total loss -63.70814508079722, train mean loss 0.00034777448119212496, test mean loss [0.00035603 0.00053268 0.00040015 0.00045795 0.00042684 0.00040636
 0.00046484]
Model epoch 75: train total loss -63.62404574154804, train mean loss 0.0002876871549932757, test mean loss [0.00035648 0.00051695 0.00041312 0.00044366 0.00042748 0.00040809
 0.00046132]
Model epoch 76: train total loss -63.65089696714252, train mean loss 0.0003820505708371498, test mean loss [0.00036258 0.00048758 0.00038479 0.0004824  0.00042145 0.00039845
 0.00045437]
Model epoch 77: train total loss -63.693000927922704, train mean loss 0.00034857498903782466, test mean loss [0.00035159 0.00049457 0.00039851 0.00044391 0.00041414 0.00038961
 0.00045724]
Model epoch 78: train total loss -63.71228561418201, train mean loss 0.0003364103657165812, test mean loss [0.00035384 0.00048863 0.00038834 0.00043364 0.00041474 0.00038944
 0.00046025]
Model epoch 79: train total loss -63.88807012686492, train mean loss 0.00031497227330680455, test mean loss [0.00035533 0.00048491 0.0003761  0.00043311 0.00040526 0.00038474
 0.00045206]
Model epoch 80: train total loss -63.6611170601672, train mean loss 0.0003452590622949051, test mean loss [0.00034538 0.00048905 0.00037513 0.000421   0.00039326 0.00037768
 0.0004538 ]
Model epoch 81: train total loss -63.696225981828405, train mean loss 0.00030669193809847547, test mean loss [0.00035236 0.00047525 0.00037641 0.00041558 0.00039032 0.0003672
 0.00043468]
Model epoch 82: train total loss -63.74564843810059, train mean loss 0.0003473752909932817, test mean loss [0.00034462 0.0004584  0.00037143 0.00041725 0.00041472 0.00037219
 0.00043448]
Model epoch 83: train total loss -63.749144769712586, train mean loss 0.00033795212902761496, test mean loss [0.00033443 0.00045186 0.00037186 0.00040985 0.00039754 0.00035963
 0.00045477]
Model epoch 84: train total loss -63.97549020590586, train mean loss 0.0003105469415140346, test mean loss [0.00034429 0.00044794 0.00036417 0.00040388 0.00040313 0.00037704
 0.00043083]
Model epoch 85: train total loss -63.89105665327289, train mean loss 0.0002952800900742084, test mean loss [0.00033899 0.00045395 0.00036843 0.00039806 0.00038426 0.00035264
 0.00041429]
Model epoch 86: train total loss -64.07473134986896, train mean loss 0.0002687857458599437, test mean loss [0.00032603 0.00045235 0.00035839 0.00038754 0.00038357 0.00035198
 0.00042159]
Model epoch 87: train total loss -63.92480217094587, train mean loss 0.00029787861731279253, test mean loss [0.00032508 0.00045017 0.00035787 0.00039299 0.00037154 0.00035321
 0.00041335]
Model epoch 88: train total loss -63.987909398809094, train mean loss 0.0002554803582892318, test mean loss [0.00033192 0.00042988 0.00035673 0.00038676 0.0003743  0.00035289
 0.00041808]
Model epoch 89: train total loss -63.905858418332656, train mean loss 0.0003055522229262779, test mean loss [0.00032574 0.00043118 0.00035572 0.00038539 0.00036539 0.00035354
 0.00040996]
Model epoch 90: train total loss -63.88794937401634, train mean loss 0.0002929228429934272, test mean loss [0.00032469 0.00042846 0.00035881 0.00038241 0.00037137 0.00034221
 0.00040684]
Model epoch 91: train total loss -63.875982139485934, train mean loss 0.0002632107144331162, test mean loss [0.00032126 0.00042227 0.00036035 0.00037536 0.00036324 0.0003351
 0.0004047 ]
Model epoch 92: train total loss -63.923352759280505, train mean loss 0.00027971222491007553, test mean loss [0.00031321 0.00042555 0.00035036 0.00037586 0.00035688 0.00033201
 0.00039115]
Model epoch 93: train total loss -64.25214952413387, train mean loss 0.0002846123517987882, test mean loss [0.00031061 0.00041672 0.00034988 0.00037058 0.0003611  0.00033063
 0.00039571]
Model epoch 94: train total loss -64.01435188132469, train mean loss 0.00023503002361236245, test mean loss [0.0003165  0.00042169 0.00034851 0.00037586 0.00034933 0.00032975
 0.00039243]
Model epoch 95: train total loss -64.03326044436591, train mean loss 0.0002663615396939533, test mean loss [0.00031246 0.0004084  0.00033996 0.00036822 0.00035224 0.00033127
 0.00039389]
Model epoch 96: train total loss -64.09669420383335, train mean loss 0.00028223018279382116, test mean loss [0.00030425 0.00040297 0.00033796 0.00035656 0.0003513  0.0003218
 0.00038401]
Model epoch 97: train total loss -63.98386645611864, train mean loss 0.0002852494633653365, test mean loss [0.0003046  0.00040608 0.00034163 0.00035331 0.00034147 0.00031406
 0.00038233]
Model epoch 98: train total loss -64.23505466616504, train mean loss 0.00023753446562240564, test mean loss [0.0003188  0.00040497 0.00033615 0.00035658 0.00033775 0.00032239
 0.00038832]
Model epoch 99: train total loss -64.0213931382741, train mean loss 0.00026976525983820135, test mean loss [0.00030869 0.00040007 0.00033431 0.00036006 0.00033649 0.00031955
 0.00038341]
Model epoch 100: train total loss -64.01495017971789, train mean loss 0.0002850491178724159, test mean loss [0.00030935 0.00041442 0.00034049 0.00034456 0.00032639 0.00032012
 0.00036418]
Model epoch 101: train total loss -64.20488743792605, train mean loss 0.00022642999280942663, test mean loss [0.00030386 0.00039086 0.000333   0.000344   0.00034195 0.00031154
 0.00037258]
Model epoch 102: train total loss -64.10444788637484, train mean loss 0.00030896952794176857, test mean loss [0.00030369 0.0003796  0.00032577 0.00034806 0.00032408 0.00030538
 0.00036808]
Model epoch 103: train total loss -64.16069589858459, train mean loss 0.00026569528150322154, test mean loss [0.00029745 0.00039292 0.0003265  0.00035769 0.00032928 0.00030632
 0.00036928]
Model epoch 104: train total loss -64.1470508544379, train mean loss 0.00025800208160167313, test mean loss [0.00030251 0.00037673 0.00033626 0.00032931 0.00032206 0.000296
 0.00036978]
Model epoch 105: train total loss -64.26281472490723, train mean loss 0.00027166573992446814, test mean loss [0.00029786 0.00036969 0.00031972 0.00032916 0.00032734 0.00029684
 0.00036584]
Model epoch 106: train total loss -64.43317071116871, train mean loss 0.0002451172653066683, test mean loss [0.00030894 0.00037162 0.00032429 0.00033798 0.00031831 0.00029401
 0.00035154]
Model epoch 107: train total loss -64.24261037360758, train mean loss 0.00027582942045004897, test mean loss [0.00028784 0.00036256 0.00032249 0.00033128 0.00032012 0.00030091
 0.00036545]
Model epoch 108: train total loss -64.30825773209787, train mean loss 0.00023505619526555447, test mean loss [0.00029489 0.00035995 0.00031439 0.00032409 0.00032072 0.00028683
 0.00035966]
Model epoch 109: train total loss -64.0679751656852, train mean loss 0.00028945166835104853, test mean loss [0.00029549 0.00036567 0.00031853 0.00032728 0.00031754 0.0002951
 0.00035121]
Model epoch 110: train total loss -64.20471148177111, train mean loss 0.000269709891425673, test mean loss [0.00029043 0.00035432 0.00031443 0.00031622 0.00033676 0.00029261
 0.00034549]
Model epoch 111: train total loss -64.31425725401824, train mean loss 0.00023783448528609622, test mean loss [0.00028486 0.00035573 0.00032147 0.00033152 0.00031306 0.00028674
 0.00035047]
Model epoch 112: train total loss -64.15243556223268, train mean loss 0.0002757061347457118, test mean loss [0.00028216 0.00034889 0.00032101 0.00032757 0.00030919 0.00029106
 0.0003467 ]
Model epoch 113: train total loss -64.35342945834437, train mean loss 0.00025803877958395, test mean loss [0.00029567 0.00034161 0.00030951 0.00031427 0.00030348 0.00027865
 0.00034779]
Model epoch 114: train total loss -64.41558117881515, train mean loss 0.0002581993369150866, test mean loss [0.00028784 0.00034129 0.00030546 0.00031767 0.00029637 0.00027971
 0.00034073]
Model epoch 115: train total loss -64.44313449676801, train mean loss 0.00022191379997781984, test mean loss [0.00028655 0.00033956 0.00030869 0.00031332 0.00029491 0.00027983
 0.00033291]
Model epoch 116: train total loss -64.43020118407087, train mean loss 0.00023085116461488757, test mean loss [0.00027388 0.00034161 0.00030469 0.00030795 0.0002969  0.00027754
 0.00034182]
Model epoch 117: train total loss -64.52363632023396, train mean loss 0.0002575189628341397, test mean loss [0.00026952 0.00033678 0.00029455 0.00031139 0.00029587 0.00027413
 0.00033563]
Model epoch 118: train total loss -64.47597368197604, train mean loss 0.00023393421979617856, test mean loss [0.00027723 0.00033351 0.00029573 0.00030246 0.00029599 0.00027448
 0.00032985]
Model epoch 119: train total loss -64.37023205298995, train mean loss 0.0002700839096193958, test mean loss [0.00028011 0.0003344  0.00029846 0.00030305 0.00028626 0.00028828
 0.00033078]
Model epoch 120: train total loss -64.48970826619461, train mean loss 0.00022649806571216027, test mean loss [0.00027314 0.00033227 0.00030689 0.00030158 0.00029365 0.00029349
 0.00032855]
Model epoch 121: train total loss -64.42860058090125, train mean loss 0.00024582994175945116, test mean loss [0.00027318 0.00032969 0.00029531 0.00030343 0.00028202 0.00027312
 0.00032521]
Model epoch 122: train total loss -64.24212804921063, train mean loss 0.00023915951835166722, test mean loss [0.00027709 0.00032048 0.00029862 0.00029963 0.00028714 0.00026681
 0.00032386]
Model epoch 123: train total loss -64.44638237577574, train mean loss 0.0002282340574892914, test mean loss [0.00028182 0.00031785 0.0002878  0.0002996  0.00028582 0.00027431
 0.00031806]
Model epoch 124: train total loss -64.36286049605785, train mean loss 0.00021068754643754437, test mean loss [0.00026914 0.00031205 0.00029339 0.00029515 0.00029462 0.00026514
 0.00032267]
Model epoch 125: train total loss -64.52426249042765, train mean loss 0.00019145733547649472, test mean loss [0.00027892 0.00031626 0.00029007 0.00029617 0.00027299 0.00026704
 0.00032129]
Model epoch 126: train total loss -64.43711497509273, train mean loss 0.00022534955923776676, test mean loss [0.00026844 0.00031953 0.00028984 0.00028944 0.00027526 0.00027136
 0.00031298]
Model epoch 127: train total loss -64.5424957188805, train mean loss 0.00022261423853405532, test mean loss [0.00026455 0.00031896 0.00028287 0.00029755 0.00029738 0.0002746
 0.00030785]
Model epoch 128: train total loss -64.5325229118904, train mean loss 0.00024822500113861733, test mean loss [0.00025873 0.0003074  0.00028414 0.00028632 0.00027738 0.00025892
 0.00031578]
Model epoch 129: train total loss -64.59360386780322, train mean loss 0.00019784827038988136, test mean loss [0.00025738 0.00030738 0.00028594 0.0002801  0.00027451 0.00026392
 0.00031101]
Model epoch 130: train total loss -64.54951367234017, train mean loss 0.00019570463192545727, test mean loss [0.00025356 0.00030371 0.00029275 0.00028241 0.00028132 0.00024898
 0.00030454]
Model epoch 131: train total loss -64.72629789531051, train mean loss 0.00021807741204166875, test mean loss [0.00025927 0.00030355 0.00028051 0.00027603 0.00027322 0.00026059
 0.00030414]
Model epoch 132: train total loss -64.61328157884417, train mean loss 0.0002060766836266388, test mean loss [0.00025901 0.00030316 0.00028328 0.00028377 0.00028797 0.00025404
 0.00029768]
Model epoch 133: train total loss -64.61208132367547, train mean loss 0.00020525346540786133, test mean loss [0.00025945 0.0002983  0.00028449 0.00027254 0.00027057 0.00025615
 0.00030398]
Model epoch 134: train total loss -64.6504707748951, train mean loss 0.00020292751989587387, test mean loss [0.00025592 0.00029753 0.00028119 0.00027676 0.00027139 0.00025329
 0.00029883]
Model epoch 135: train total loss -64.50040738393257, train mean loss 0.00023657319545413534, test mean loss [0.00025428 0.00028963 0.0002764  0.0002887  0.0002694  0.00025129
 0.00030376]
Model epoch 136: train total loss -64.61490648345254, train mean loss 0.00021530468583141494, test mean loss [0.00025411 0.00029133 0.00027226 0.00028019 0.00026309 0.00024941
 0.00029609]
Model epoch 137: train total loss -64.69113873739036, train mean loss 0.00019903589540743092, test mean loss [0.00025683 0.00028473 0.00027208 0.0002821  0.00026    0.00025134
 0.00030057]
Model epoch 138: train total loss -64.74704005827788, train mean loss 0.00020240144146049425, test mean loss [0.00025455 0.00028182 0.00028    0.00027254 0.00025956 0.00024533
 0.00029706]
Model epoch 139: train total loss -64.41459282007665, train mean loss 0.0001984039529628671, test mean loss [0.00024628 0.0002878  0.00027359 0.00027206 0.00026471 0.00024757
 0.00029403]
Model epoch 140: train total loss -64.62160642046035, train mean loss 0.00019895603628156778, test mean loss [0.00024892 0.00028156 0.00027517 0.00026343 0.00027318 0.00025121
 0.00030154]
Model epoch 141: train total loss -64.64648745182873, train mean loss 0.00019004501404931546, test mean loss [0.00024518 0.000277   0.00027018 0.00026404 0.00025903 0.00023899
 0.00028132]
Model epoch 142: train total loss -64.7355533200828, train mean loss 0.00018721457727070658, test mean loss [0.00024453 0.00028723 0.00026339 0.00025967 0.00026412 0.00024216
 0.00028137]
Model epoch 143: train total loss -64.92724731087523, train mean loss 0.00022306382435912262, test mean loss [0.00025256 0.0002791  0.00026753 0.00026843 0.00025473 0.00023744
 0.00028383]
Model epoch 144: train total loss -64.80907884407206, train mean loss 0.0002383026056082667, test mean loss [0.00024408 0.00027469 0.00026655 0.00026023 0.00025477 0.000238
 0.00028792]
Model epoch 145: train total loss -64.70125305770483, train mean loss 0.00019318582673666596, test mean loss [0.00024744 0.00028749 0.00026678 0.00026    0.00025494 0.00024147
 0.00028118]
Model epoch 146: train total loss -64.77128554185832, train mean loss 0.0001897341756553401, test mean loss [0.00023776 0.00026878 0.00026289 0.00026114 0.00025235 0.00023118
 0.00027603]
Model epoch 147: train total loss -64.80130020005383, train mean loss 0.00016854920578853307, test mean loss [0.00024688 0.00028134 0.00026881 0.00026529 0.00025037 0.00023004
 0.0002776 ]
Model epoch 148: train total loss -64.69807128254834, train mean loss 0.00019584315321181147, test mean loss [0.00024623 0.0002672  0.00025636 0.00025484 0.00024855 0.00023411
 0.00027736]
Model epoch 149: train total loss -64.86456562565539, train mean loss 0.0002003062647496347, test mean loss [0.00026197 0.00027106 0.00026019 0.00025579 0.0002515  0.00023462
 0.00027663]
Model epoch 150: train total loss -64.7904528415564, train mean loss 0.00017133791100397444, test mean loss [0.00023748 0.00026882 0.00025817 0.00025133 0.0002484  0.00023396
 0.00027464]
Model epoch 151: train total loss -64.69581451756538, train mean loss 0.00018878317079541507, test mean loss [0.00024424 0.00027148 0.00026252 0.00024785 0.00024678 0.00022972
 0.00027844]
Model epoch 152: train total loss -64.61319570251099, train mean loss 0.00021111114721409749, test mean loss [0.00024443 0.00026914 0.00025715 0.00027152 0.00024809 0.00023616
 0.0002732 ]
Model epoch 153: train total loss -64.91419762147815, train mean loss 0.0001641494385159059, test mean loss [0.00024046 0.00025503 0.00025526 0.00024565 0.00024403 0.00023128
 0.0002693 ]
Model epoch 154: train total loss -64.88427738058215, train mean loss 0.00017981991418260462, test mean loss [0.0002309  0.00026579 0.00025603 0.00024749 0.00024337 0.00022474
 0.00027037]
Model epoch 155: train total loss -64.73424047079598, train mean loss 0.00017088933122518906, test mean loss [0.0002328  0.00025645 0.00025125 0.00024339 0.00024631 0.00022753
 0.0002712 ]
Model epoch 156: train total loss -64.68274486412153, train mean loss 0.00018889634461385232, test mean loss [0.00023825 0.00026415 0.00026053 0.000251   0.00023893 0.0002271
 0.00026375]
Model epoch 157: train total loss -64.70189115612814, train mean loss 0.0001921413144402806, test mean loss [0.00022521 0.00026099 0.00025386 0.00023621 0.00025733 0.00022947
 0.00026249]
Model epoch 158: train total loss -64.85236801915606, train mean loss 0.0001981772859867978, test mean loss [0.0002328  0.00025259 0.00025484 0.00024062 0.00024251 0.00022365
 0.00025256]
Model epoch 159: train total loss -64.91301436961727, train mean loss 0.00017508534704901643, test mean loss [0.00024016 0.00025887 0.000252   0.00023896 0.00024068 0.00022157
 0.00025661]
Model epoch 160: train total loss -64.8957357385775, train mean loss 0.00018612593745307327, test mean loss [0.00022229 0.00025715 0.00025305 0.0002408  0.00024139 0.00022652
 0.0002623 ]
Model epoch 161: train total loss -64.8116724870431, train mean loss 0.000209088154878849, test mean loss [0.00023165 0.00026606 0.00024634 0.00023865 0.00024449 0.0002143
 0.00025772]
Model epoch 162: train total loss -64.75906477298388, train mean loss 0.0001788277362514377, test mean loss [0.00022825 0.00025392 0.00025071 0.00024011 0.00023212 0.00021733
 0.00027268]
Model epoch 163: train total loss -64.87304202068209, train mean loss 0.00021248267504258563, test mean loss [0.00022508 0.00024701 0.00025569 0.00023655 0.00023272 0.00021929
 0.00025687]
Model epoch 164: train total loss -64.80492944850509, train mean loss 0.00020443548205591408, test mean loss [0.00022114 0.00024777 0.00025702 0.00023983 0.00023621 0.00021813
 0.00026729]
Model epoch 165: train total loss -64.87117568902984, train mean loss 0.00018734167986061813, test mean loss [0.00021874 0.00024589 0.00024836 0.00023534 0.00023539 0.00021175
 0.0002591 ]
Model epoch 166: train total loss -64.9553502924122, train mean loss 0.00016158704683917505, test mean loss [0.00023121 0.00024515 0.00024955 0.00022609 0.00022598 0.00021642
 0.00024682]
Model epoch 167: train total loss -64.99814771701368, train mean loss 0.00016276277024607935, test mean loss [0.00023325 0.00023939 0.00024057 0.00023923 0.00023139 0.00022791
 0.00024589]
Model epoch 168: train total loss -65.02100614756276, train mean loss 0.00016336013794473263, test mean loss [0.00022393 0.00023892 0.00024438 0.00022867 0.00023223 0.00021104
 0.00024323]
Model epoch 169: train total loss -65.1281785009838, train mean loss 0.00019701075802152555, test mean loss [0.00022317 0.00024292 0.00023943 0.00022891 0.00022704 0.0002139
 0.00024348]
Model epoch 170: train total loss -64.83468285148726, train mean loss 0.00020309449208750065, test mean loss [0.00024112 0.00024302 0.00024761 0.00022739 0.00022116 0.00021889
 0.00025173]
Model epoch 171: train total loss -64.86049968492998, train mean loss 0.00020849310299940062, test mean loss [0.00022293 0.00024328 0.00024391 0.00022796 0.00022198 0.00020553
 0.0002477 ]
Model epoch 172: train total loss -64.92196577346252, train mean loss 0.00017715599907202275, test mean loss [0.00021858 0.00024766 0.00024193 0.00022954 0.0002334  0.00020786
 0.0002437 ]
Model epoch 173: train total loss -65.01856282202982, train mean loss 0.00018890627019036132, test mean loss [0.00021773 0.00023358 0.00024736 0.00022217 0.00022085 0.00021489
 0.00023807]
Model epoch 174: train total loss -65.11913143271701, train mean loss 0.00015300801330201923, test mean loss [0.00021289 0.00023872 0.00024605 0.00021937 0.00021899 0.00021175
 0.00024251]
Model epoch 175: train total loss -65.04093310495627, train mean loss 0.0001864684699662755, test mean loss [0.00021717 0.00022877 0.00023756 0.00022206 0.00022047 0.00020717
 0.00024401]
Model epoch 176: train total loss -65.10257822466662, train mean loss 0.00019089832557168447, test mean loss [0.00021694 0.00022838 0.00023751 0.00021814 0.00022085 0.00019954
 0.00023585]
Model epoch 177: train total loss -65.19690248370742, train mean loss 0.00014578056233688472, test mean loss [0.00021704 0.00023613 0.00024248 0.00021755 0.000219   0.00021169
 0.00023138]
Model epoch 178: train total loss -65.0172117829913, train mean loss 0.00015355945419447855, test mean loss [0.00020924 0.00022806 0.00023313 0.00022162 0.00021649 0.00021793
 0.00023479]
Model epoch 179: train total loss -65.06857659336983, train mean loss 0.00015707623867008738, test mean loss [0.00021361 0.00023049 0.00023352 0.00021615 0.00022292 0.00021384
 0.0002333 ]
Model epoch 180: train total loss -64.78647750807292, train mean loss 0.0001939163310791729, test mean loss [0.00021455 0.00023896 0.00023169 0.00022011 0.00022213 0.00020549
 0.00027978]
Model epoch 181: train total loss -64.9977064929018, train mean loss 0.00018120440003601708, test mean loss [0.00021376 0.000229   0.0002435  0.00021975 0.00022103 0.00019927
 0.00024633]
Model epoch 182: train total loss -64.66052566241838, train mean loss 0.00016220692971400047, test mean loss [0.00021139 0.00022998 0.00023755 0.00022311 0.00021781 0.00020626
 0.00025455]
Model epoch 183: train total loss -64.97743690191948, train mean loss 0.0001650273583599305, test mean loss [0.00021034 0.00024373 0.00023544 0.00021446 0.00021741 0.0001987
 0.00024692]
Model epoch 184: train total loss -65.08633274424257, train mean loss 0.00017363393517795794, test mean loss [0.00020911 0.000242   0.00023268 0.00020987 0.00021129 0.00019437
 0.00023436]
Model epoch 185: train total loss -64.99420871060916, train mean loss 0.00017893548438951536, test mean loss [0.000215   0.00022275 0.00023297 0.00021401 0.00021253 0.0001946
 0.00022973]
Model epoch 186: train total loss -64.89307967316091, train mean loss 0.000159030509666311, test mean loss [0.00020832 0.00022828 0.00023034 0.00021493 0.0002093  0.00019695
 0.00022917]
Model epoch 187: train total loss -65.23378988330849, train mean loss 0.00016804019304028327, test mean loss [0.0002166  0.00022758 0.00022737 0.00021154 0.00020737 0.00019361
 0.00022686]
Model epoch 188: train total loss -65.21950774313446, train mean loss 0.00014983912973978527, test mean loss [0.00020945 0.00022953 0.00022732 0.00020456 0.00021879 0.00019163
 0.00022093]
Model epoch 189: train total loss -65.0419595362961, train mean loss 0.00016413919736835486, test mean loss [0.00020923 0.00022976 0.00023119 0.00020622 0.00020917 0.0001908
 0.00022549]
Model epoch 190: train total loss -65.232153109517, train mean loss 0.00016605103821734749, test mean loss [0.00021414 0.00021533 0.00022858 0.00022439 0.00021291 0.00019728
 0.00022317]
Model epoch 191: train total loss -65.16958582622365, train mean loss 0.00016037451433526982, test mean loss [0.00020687 0.00021961 0.00023339 0.00020971 0.00020405 0.00019959
 0.00022207]
Model epoch 192: train total loss -65.16306883148452, train mean loss 0.00016147123768283245, test mean loss [0.00020992 0.00022172 0.00022257 0.00020677 0.00020388 0.00019773
 0.00022024]
Model epoch 193: train total loss -65.19424562358643, train mean loss 0.0001775043251608254, test mean loss [0.00020188 0.0002173  0.00022648 0.00021271 0.00021001 0.00019129
 0.00022223]
Model epoch 194: train total loss -65.03251371490585, train mean loss 0.00015233508858925504, test mean loss [0.00020448 0.00022139 0.00022478 0.00020778 0.00021014 0.00018839
 0.00022208]
Model epoch 195: train total loss -65.08871701544204, train mean loss 0.0001705095197023006, test mean loss [0.00020409 0.00021539 0.00022366 0.0002227  0.00020656 0.00019232
 0.00022059]
Model epoch 196: train total loss -65.10796109455455, train mean loss 0.0001505489154743473, test mean loss [0.00020323 0.00021549 0.00023241 0.00020119 0.0002103  0.00019519
 0.0002134 ]
Model epoch 197: train total loss -65.18165517269222, train mean loss 0.00015074834690669337, test mean loss [0.0001975  0.00021521 0.00022201 0.0001981  0.00020603 0.0001913
 0.00022085]
Model epoch 198: train total loss -65.23838150136837, train mean loss 0.00014849612179718055, test mean loss [0.0002062  0.00021114 0.00022302 0.00020056 0.00020438 0.00019522
 0.00021261]
Model epoch 199: train total loss -65.12222698901482, train mean loss 0.00015127792433405833, test mean loss [0.00020057 0.00021347 0.00022222 0.0001988  0.00019954 0.00019088
 0.00021988]
Model epoch 200: train total loss -65.251041365851, train mean loss 0.00015017721926866308, test mean loss [0.00019327 0.00021527 0.00021866 0.0002028  0.00020647 0.00018896
 0.00021504]
Model epoch 201: train total loss -65.19310723690462, train mean loss 0.00016787874489740756, test mean loss [0.0002249  0.00021093 0.00023677 0.00020545 0.00020356 0.00018209
 0.00020779]
Model epoch 202: train total loss -65.05284728015582, train mean loss 0.00014453951073446672, test mean loss [0.00020928 0.00020977 0.00022189 0.00020545 0.00020615 0.00018033
 0.0002153 ]
Model epoch 203: train total loss -65.41395296666575, train mean loss 0.0001571871840811564, test mean loss [0.00019582 0.00020737 0.00021873 0.00019632 0.00019962 0.000182
 0.0002116 ]
Model epoch 204: train total loss -64.97589641869394, train mean loss 0.00016627769034311185, test mean loss [0.00020966 0.00020274 0.00021856 0.00020176 0.00019842 0.00018625
 0.00022214]
Model epoch 205: train total loss -65.29535684336082, train mean loss 0.00016449307330746997, test mean loss [0.00019903 0.00021231 0.00021689 0.00019722 0.0002004  0.00018087
 0.00021452]
Model epoch 206: train total loss -65.23866500197629, train mean loss 0.0001736984583721443, test mean loss [0.00019457 0.00020277 0.00021934 0.00020767 0.00019626 0.00018062
 0.00022611]
Model epoch 207: train total loss -65.08252463007666, train mean loss 0.00017775171913564082, test mean loss [0.00020092 0.00020712 0.00022027 0.00020165 0.00019784 0.00018263
 0.00021146]
Model epoch 208: train total loss -65.3373359995672, train mean loss 0.00017386321732922638, test mean loss [0.00019857 0.00021122 0.0002134  0.00019562 0.00019407 0.00018025
 0.00020814]
Model epoch 209: train total loss -65.39840820609979, train mean loss 0.00014867250393734647, test mean loss [0.00019123 0.00021864 0.00022285 0.00019906 0.00019964 0.00017672
 0.00020311]
Model epoch 210: train total loss -65.21076169012274, train mean loss 0.0001671946647799038, test mean loss [0.00019535 0.00020731 0.00021968 0.00019692 0.00020053 0.00018407
 0.00020357]
Model epoch 211: train total loss -65.20452700393, train mean loss 0.00014412153539482582, test mean loss [0.00019287 0.00020692 0.00021233 0.00020107 0.00020023 0.00017116
 0.00021304]
Model epoch 212: train total loss -65.34588494940657, train mean loss 0.00015341066620058464, test mean loss [0.0001903  0.00019811 0.00021288 0.00019104 0.00019712 0.00017528
 0.00019935]
Model epoch 213: train total loss -65.24920465202986, train mean loss 0.00014922004588376015, test mean loss [0.00019623 0.00020468 0.00021292 0.00019873 0.00019733 0.00017401
 0.00021364]
Model epoch 214: train total loss -65.24796000355468, train mean loss 0.00014723993926830684, test mean loss [0.00018962 0.00021304 0.00020722 0.00019456 0.00019249 0.00017838
 0.00019909]
Model epoch 215: train total loss -65.42917874380419, train mean loss 0.0001709901806221067, test mean loss [0.00019942 0.0001951  0.00021987 0.0001906  0.00018852 0.00017593
 0.00020265]
Model epoch 216: train total loss -65.34759451977884, train mean loss 0.0001428059520688836, test mean loss [0.00019169 0.00020478 0.00021716 0.00018927 0.00019381 0.00017711
 0.00020353]
Model epoch 217: train total loss -65.4548187870381, train mean loss 0.0001292004086775918, test mean loss [0.00018612 0.00019606 0.00021589 0.00019225 0.00018904 0.00018005
 0.00020318]
Model epoch 218: train total loss -65.33195694550572, train mean loss 0.00014316319284238727, test mean loss [0.00018904 0.00019394 0.00021023 0.0001914  0.00019973 0.00017826
 0.00019797]
Model epoch 219: train total loss -65.37992409054377, train mean loss 0.00014686217779060273, test mean loss [0.00018835 0.00020167 0.00020716 0.00018361 0.00018908 0.00018647
 0.00020506]
Model epoch 220: train total loss -65.3285921870347, train mean loss 0.00014727141809848626, test mean loss [0.00019187 0.00019451 0.00021902 0.00019308 0.00018755 0.00018463
 0.00020327]
Model epoch 221: train total loss -65.38805135081338, train mean loss 0.0001509057181319392, test mean loss [0.00018656 0.0001949  0.00020932 0.00018964 0.000187   0.00017619
 0.00019963]
Model epoch 222: train total loss -65.34727787674755, train mean loss 0.0001511520998783095, test mean loss [0.00018087 0.00019732 0.00020795 0.00018726 0.00018736 0.00017097
 0.00020303]
Model epoch 223: train total loss -65.43733546973056, train mean loss 0.0001433822043674401, test mean loss [0.0001871  0.00019347 0.00022078 0.00018703 0.0001909  0.00017284
 0.00019369]
Model epoch 224: train total loss -65.51261792462603, train mean loss 0.00014394339333208698, test mean loss [0.0001821  0.00019244 0.00020905 0.00018696 0.00018813 0.00016749
 0.00019766]
Model epoch 225: train total loss -65.54029838211837, train mean loss 0.000148268316919442, test mean loss [0.00018381 0.00019056 0.00021135 0.00018388 0.00018416 0.00016892
 0.00019416]
Model epoch 226: train total loss -65.22005047358898, train mean loss 0.00013496471188078477, test mean loss [0.00017843 0.00019771 0.00020812 0.0001864  0.00020535 0.00016734
 0.00019165]
Model epoch 227: train total loss -65.34596248459216, train mean loss 0.00013188283511358258, test mean loss [0.00018142 0.00019699 0.00020686 0.00018765 0.00018617 0.00017174
 0.00021059]
Model epoch 228: train total loss -65.44326538755526, train mean loss 0.00013101816081483698, test mean loss [0.00018009 0.00018814 0.00020727 0.00018388 0.00018522 0.00016969
 0.00019729]
Model epoch 229: train total loss -65.42617868038941, train mean loss 0.00013445831210764637, test mean loss [0.00018133 0.00018295 0.00020089 0.00018473 0.00019055 0.00017712
 0.00019164]
Model epoch 230: train total loss -65.3358792761094, train mean loss 0.00013316506928673025, test mean loss [0.00017815 0.00018944 0.00020929 0.00018741 0.00018654 0.00016893
 0.00018749]
Model epoch 231: train total loss -65.34619913738227, train mean loss 0.00015044527428590218, test mean loss [0.00017665 0.00018321 0.0002101  0.00018493 0.00017961 0.00016465
 0.00019372]
Model epoch 232: train total loss -65.45319942241538, train mean loss 0.00013018132029902417, test mean loss [0.00017906 0.00018297 0.00020693 0.00018569 0.00018337 0.00015806
 0.00018656]
Model epoch 233: train total loss -65.59106827269864, train mean loss 0.00013390155509173144, test mean loss [0.00017858 0.00018471 0.00020363 0.00018804 0.0001954  0.00017104
 0.00018541]
Model epoch 234: train total loss -65.47926944610977, train mean loss 0.0001317098635579425, test mean loss [0.00017895 0.00019322 0.00019852 0.00018567 0.00018553 0.00016687
 0.00019174]
Model epoch 235: train total loss -65.4936429002886, train mean loss 0.00013096817281587248, test mean loss [0.00017518 0.00018229 0.0002003  0.0001849  0.00018427 0.00017134
 0.00019048]
Model epoch 236: train total loss -65.20168390806572, train mean loss 0.00013303732648765377, test mean loss [0.00016851 0.00018433 0.00019824 0.00018152 0.00019362 0.00016843
 0.00018687]
Model epoch 237: train total loss -65.43191133072814, train mean loss 0.00013329387497390741, test mean loss [0.00017474 0.00019103 0.00019287 0.00017924 0.00017954 0.00015576
 0.00018758]
Model epoch 238: train total loss -65.44491170170778, train mean loss 0.00014304654107316023, test mean loss [0.00018871 0.0001845  0.00019677 0.00017614 0.00017994 0.00016579
 0.00018645]
Model epoch 239: train total loss -65.2855566091385, train mean loss 0.00013676902183504033, test mean loss [0.00018182 0.00018999 0.00019888 0.00017915 0.00017486 0.00017358
 0.00018657]
Model epoch 240: train total loss -65.3944674258892, train mean loss 0.00014445111031255976, test mean loss [0.00019209 0.00018351 0.0001971  0.00017664 0.00018036 0.00016591
 0.00018538]
Model epoch 241: train total loss -65.43650489025276, train mean loss 0.00012507969290641307, test mean loss [0.0001846  0.00018567 0.00019908 0.00017145 0.00018237 0.00016482
 0.00018688]
Model epoch 242: train total loss -65.63461171567343, train mean loss 0.00013163572153598803, test mean loss [0.00018283 0.00018667 0.00019335 0.00017408 0.00017839 0.0001585
 0.00017887]
Model epoch 243: train total loss -65.4312135983897, train mean loss 0.0001412639362897487, test mean loss [0.00017452 0.00018296 0.00018815 0.0001735  0.00017369 0.00015973
 0.00019436]
Model epoch 244: train total loss -65.40469437631741, train mean loss 0.00013922878180511392, test mean loss [0.00017901 0.00018466 0.00019593 0.00018162 0.0001749  0.00016759
 0.00018629]
Model epoch 245: train total loss -65.46032062797445, train mean loss 0.00014199326118649353, test mean loss [0.0001728  0.00018337 0.00018679 0.00017128 0.00018589 0.0001678
 0.00019203]
Model epoch 246: train total loss -65.58564492258496, train mean loss 0.00015279051769626084, test mean loss [0.00017613 0.00017688 0.00019285 0.00016969 0.00018102 0.0001688
 0.00018339]
Model epoch 247: train total loss -65.57652184308091, train mean loss 0.00013774477826440244, test mean loss [0.00017288 0.00017739 0.00019197 0.00017266 0.00017545 0.000156
 0.00018294]
Model epoch 248: train total loss -65.55469336942879, train mean loss 0.00013481741531124735, test mean loss [0.00017671 0.00017881 0.00020663 0.00017404 0.00017448 0.00016576
 0.00018459]
Model epoch 249: train total loss -65.41774822177611, train mean loss 0.00014432927782069292, test mean loss [0.00017068 0.00017952 0.00019119 0.00017483 0.00017082 0.00016175
 0.00017945]
Model epoch 250: train total loss -65.57557025664995, train mean loss 0.0001275787003038265, test mean loss [0.00016693 0.00018223 0.00018921 0.00016719 0.00017372 0.00016808
 0.00017817]
Model epoch 251: train total loss -65.5810804453381, train mean loss 0.0001253784064120374, test mean loss [0.00017312 0.00018386 0.00018201 0.00017387 0.00017284 0.0001632
 0.00018773]
Model epoch 252: train total loss -65.48658333496248, train mean loss 0.00013815393513621804, test mean loss [0.00016747 0.00017943 0.00018224 0.00016926 0.00016616 0.0001711
 0.00017633]
Model epoch 253: train total loss -65.64936811755577, train mean loss 0.00012282069087084116, test mean loss [0.00016966 0.0001761  0.00018507 0.00017054 0.00016637 0.00015759
 0.00017766]
Model epoch 254: train total loss -65.36279076356226, train mean loss 0.0001339039296659652, test mean loss [0.0001866  0.00017544 0.00018746 0.00017292 0.00017469 0.00015618
 0.0001758 ]
Model epoch 255: train total loss -65.38517266288993, train mean loss 0.00013014703200054758, test mean loss [0.00017348 0.00017723 0.00018402 0.00017625 0.00017562 0.00015594
 0.00017961]
Model epoch 256: train total loss -65.48394732526714, train mean loss 0.00012935469341332948, test mean loss [0.00017323 0.00017488 0.0001938  0.00017327 0.00016729 0.00015478
 0.00017425]
Model epoch 257: train total loss -65.59417551930639, train mean loss 0.00014267693525703263, test mean loss [0.00017212 0.00017078 0.00019419 0.00016357 0.00017774 0.00015089
 0.00018224]
Model epoch 258: train total loss -65.58655420295368, train mean loss 0.00013733290773594595, test mean loss [0.00016212 0.0001734  0.00018404 0.00016796 0.00017196 0.00015376
 0.00017871]
Model epoch 259: train total loss -65.58104426683124, train mean loss 0.00012167659442693247, test mean loss [0.00017457 0.00016874 0.00019228 0.00016751 0.00017543 0.00015522
 0.00016957]
Model epoch 260: train total loss -65.66737145142487, train mean loss 0.00014185623698455654, test mean loss [0.00016855 0.00017597 0.00018242 0.00016707 0.0001765  0.00015677
 0.00017322]
Model epoch 261: train total loss -65.70960711922615, train mean loss 0.00013183758791903775, test mean loss [0.00016452 0.00017364 0.0001778  0.00016209 0.00017348 0.00015176
 0.00017061]
Model epoch 262: train total loss -65.74558569366515, train mean loss 0.00013725612090729466, test mean loss [0.00016626 0.00016921 0.00018051 0.00016363 0.00017016 0.00014996
 0.00017118]
Model epoch 263: train total loss -65.59223365570652, train mean loss 0.00013695968310581475, test mean loss [0.00016654 0.00017417 0.00017981 0.00016918 0.00017012 0.00015421
 0.00017425]
Model epoch 264: train total loss -65.74131227544764, train mean loss 0.00012341973664139788, test mean loss [0.00016759 0.00017119 0.00018243 0.00016521 0.00016228 0.00015022
 0.00017113]
Model epoch 265: train total loss -65.6811775643234, train mean loss 0.00011999610483881608, test mean loss [0.00016306 0.00017962 0.00018599 0.00016751 0.00016668 0.00015177
 0.00016902]
Model epoch 266: train total loss -65.39674939120708, train mean loss 0.0001382875012589002, test mean loss [0.00015923 0.0001705  0.00018326 0.00016623 0.00016706 0.00014412
 0.00018978]
Model epoch 267: train total loss -65.59262315508353, train mean loss 0.00014001717395942245, test mean loss [0.00016147 0.0001642  0.00018299 0.00016142 0.00017407 0.00015303
 0.00017375]
Model epoch 268: train total loss -65.2828919784603, train mean loss 0.00015261366290426938, test mean loss [0.00017143 0.00016782 0.00019127 0.00016482 0.00017153 0.00014957
 0.00017236]
Model epoch 269: train total loss -65.48906011005934, train mean loss 0.0001372683490454283, test mean loss [0.00016461 0.0001653  0.00018553 0.0001662  0.00016463 0.00015248
 0.00016692]
Model epoch 270: train total loss -65.58385939180012, train mean loss 0.0001370132161037554, test mean loss [0.00017294 0.00016319 0.00020129 0.00016621 0.00017306 0.00014601
 0.00016708]
Model epoch 271: train total loss -65.48151344815368, train mean loss 0.0001440400527272182, test mean loss [0.00016459 0.00016775 0.00018061 0.00016843 0.00016792 0.00015351
 0.00017236]
Model epoch 272: train total loss -65.6745127759565, train mean loss 0.00012985318704322586, test mean loss [0.00016637 0.0001645  0.00018455 0.00016468 0.00016609 0.00014824
 0.0001696 ]
Model epoch 273: train total loss -65.51041211398396, train mean loss 0.0001359706625417278, test mean loss [0.00016434 0.00016973 0.0001765  0.00015905 0.00016416 0.00015172
 0.00016926]
Model epoch 274: train total loss -65.64210571634933, train mean loss 0.00012701585293029162, test mean loss [0.00016467 0.00016957 0.00017501 0.00015894 0.00016183 0.00015287
 0.00016822]
Model epoch 275: train total loss -65.75968150325639, train mean loss 0.00011751327711487988, test mean loss [0.00016214 0.00017101 0.0001839  0.00015726 0.00016841 0.00014815
 0.00016442]
Model epoch 276: train total loss -65.57817592690633, train mean loss 0.00012799563618560137, test mean loss [0.0001562  0.00016733 0.00017652 0.00015556 0.00017231 0.00015028
 0.00016814]
Model epoch 277: train total loss -65.6861399680752, train mean loss 0.00012232498990542233, test mean loss [0.00015794 0.00016016 0.00017482 0.00016042 0.00016843 0.0001499
 0.00017198]
Model epoch 278: train total loss -65.80158240897764, train mean loss 0.00012381515235000945, test mean loss [0.00015543 0.00017155 0.00017755 0.00016121 0.00016257 0.00014727
 0.00016986]
Model epoch 279: train total loss -65.68051229468065, train mean loss 0.0001274080407342513, test mean loss [0.00015977 0.00016963 0.00018757 0.0001639  0.00016394 0.00014966
 0.00016397]
Model epoch 280: train total loss -65.67522096473239, train mean loss 0.00011388142142669679, test mean loss [0.0001569  0.00016861 0.00017872 0.00016119 0.00016247 0.00015051
 0.00015616]
Model epoch 281: train total loss -65.79282587011015, train mean loss 0.00012105464180500195, test mean loss [0.00015691 0.00016337 0.00017893 0.00015459 0.00015942 0.00015025
 0.00016152]
Model epoch 282: train total loss -65.7153713208423, train mean loss 0.00012231445838086028, test mean loss [0.00015765 0.00017031 0.00017773 0.00016213 0.00016096 0.00014873
 0.00016208]
Model epoch 283: train total loss -65.6681996079571, train mean loss 0.0001300164740252444, test mean loss [0.00015802 0.00016671 0.00017185 0.00016223 0.00015944 0.00015269
 0.00016642]
Model epoch 284: train total loss -65.70591909691422, train mean loss 0.00013508706548019504, test mean loss [0.00015573 0.00016432 0.00017566 0.00016541 0.00016888 0.00014222
 0.00016652]
Model epoch 285: train total loss -65.55191947309375, train mean loss 0.00013196230528904253, test mean loss [0.00015935 0.00015689 0.00017531 0.00015842 0.00016216 0.00015042
 0.00017193]
Model epoch 286: train total loss -65.53280215646804, train mean loss 0.00013115656126718884, test mean loss [0.00016036 0.00016123 0.00017224 0.00016046 0.00015698 0.00015675
 0.00016495]
Model epoch 287: train total loss -65.7568787210433, train mean loss 0.00012623334300300467, test mean loss [0.00015534 0.00015729 0.00017399 0.00016229 0.00015725 0.0001477
 0.00016931]
Model epoch 288: train total loss -65.69989703488454, train mean loss 0.00012447797853507887, test mean loss [0.00016353 0.00016494 0.00017404 0.00016699 0.00015993 0.00015027
 0.0001693 ]
Model epoch 289: train total loss -65.59401715064948, train mean loss 0.00012930284451101914, test mean loss [0.00015671 0.00016088 0.00017465 0.00016065 0.00015853 0.00014613
 0.00017178]
Model epoch 290: train total loss -65.71840571559224, train mean loss 0.00012088509723040575, test mean loss [0.00016387 0.00015546 0.00017457 0.00015321 0.00015762 0.00014496
 0.00016531]
Model epoch 291: train total loss -65.44622288365659, train mean loss 0.00013443314557491445, test mean loss [0.00015392 0.00017665 0.00017439 0.00015447 0.00015969 0.00013918
 0.00016651]
Model epoch 292: train total loss -65.55403132276909, train mean loss 0.0001311852844302165, test mean loss [0.00015484 0.00016355 0.0001702  0.00015182 0.00016475 0.00014918
 0.00016025]
Model epoch 293: train total loss -65.85810168493, train mean loss 0.00011525684537112618, test mean loss [0.00015927 0.00015966 0.00016927 0.00015468 0.00015648 0.00014703
 0.00015783]
Model epoch 294: train total loss -65.39798490066593, train mean loss 0.00012867267268987302, test mean loss [0.00015435 0.00016211 0.00017298 0.00016149 0.0001583  0.00013889
 0.00016035]
Model epoch 295: train total loss -65.75626697913634, train mean loss 0.0001280031802282045, test mean loss [0.00014689 0.00016314 0.00016725 0.00015577 0.00015467 0.00014324
 0.00016231]
Model epoch 296: train total loss -65.68028166876374, train mean loss 0.00013119850869936728, test mean loss [0.00016159 0.00016144 0.00016704 0.00015929 0.0001558  0.00014797
 0.00015573]
Model epoch 297: train total loss -65.59818046383978, train mean loss 0.00011916372901925635, test mean loss [0.0001533  0.00015321 0.00017907 0.00014861 0.00015629 0.00014459
 0.00018191]
Model epoch 298: train total loss -65.69203221867046, train mean loss 0.00011415776424332269, test mean loss [0.00015498 0.00015815 0.00017572 0.00015403 0.00016419 0.00014241
 0.00015925]
Model epoch 299: train total loss -65.75812948602781, train mean loss 0.00011121234638887095, test mean loss [0.00015636 0.00015603 0.00016663 0.00015397 0.0001529  0.00014044
 0.00016198]
Model epoch 300: train total loss -65.63215001860337, train mean loss 0.00012080411565265425, test mean loss [0.00015581 0.00015404 0.00017331 0.00014779 0.00015712 0.00014332
 0.00016951]
Model epoch 301: train total loss -65.86356259333441, train mean loss 0.00012649892321170268, test mean loss [0.00014889 0.00015736 0.00017135 0.00015476 0.00016258 0.00014102
 0.00015951]
Model epoch 302: train total loss -65.77148215223136, train mean loss 0.0001309065109677411, test mean loss [0.00015215 0.00015846 0.00016546 0.00015532 0.00015581 0.00015669
 0.00016275]
Model epoch 303: train total loss -65.81196986995354, train mean loss 0.0001119047704417093, test mean loss [0.00015187 0.0001681  0.00016551 0.0001493  0.00015733 0.00014147
 0.00016113]
Model epoch 304: train total loss -65.82619977488484, train mean loss 0.0001232103075679926, test mean loss [0.00015677 0.00015213 0.00017106 0.00015383 0.00015647 0.00015355
 0.00017029]
Model epoch 305: train total loss -65.85681091656652, train mean loss 0.00010961335559088036, test mean loss [0.00014867 0.00015435 0.00016872 0.00014872 0.0001512  0.00013895
 0.00015523]
Model epoch 306: train total loss -65.7516687043002, train mean loss 0.00012528083218246364, test mean loss [0.00015326 0.00015061 0.00016571 0.00014821 0.00014953 0.00013974
 0.0001587 ]
Model epoch 307: train total loss -65.87372139121082, train mean loss 0.00012325007551732258, test mean loss [0.00015088 0.0001534  0.00016898 0.00015115 0.00015413 0.00013878
 0.00016003]
Model epoch 308: train total loss -65.73701113294015, train mean loss 0.00012512525718441015, test mean loss [0.00015131 0.00015261 0.00016757 0.00015097 0.00015806 0.00013863
 0.0001657 ]
Model epoch 309: train total loss -65.75058643214649, train mean loss 0.00011406015231353273, test mean loss [0.00015048 0.00015107 0.00016252 0.0001506  0.0001572  0.00014407
 0.00014995]
Model epoch 310: train total loss -65.8416645934787, train mean loss 0.00012569593675219791, test mean loss [0.00015098 0.00015058 0.00016985 0.00014697 0.00014888 0.00014689
 0.00015495]
Model epoch 311: train total loss -65.72880102601586, train mean loss 0.00011677254081585372, test mean loss [0.0001455  0.00015314 0.00016128 0.00016479 0.00015112 0.00014068
 0.00015337]
Model epoch 312: train total loss -65.7254775732543, train mean loss 0.0001161497143496711, test mean loss [0.00016991 0.0001509  0.00016379 0.00015272 0.00014908 0.00014075
 0.00015659]
Model epoch 313: train total loss -65.90161357787937, train mean loss 0.00011182168254326638, test mean loss [0.00015062 0.00015357 0.00015851 0.00014795 0.00015738 0.00014456
 0.00015617]
Model epoch 314: train total loss -65.77480681518122, train mean loss 0.00012002301740926083, test mean loss [0.00015548 0.00015518 0.00016736 0.00014745 0.00015197 0.00014177
 0.00015935]
Model epoch 315: train total loss -65.7814482695998, train mean loss 0.00011273681372741393, test mean loss [0.00015068 0.00015161 0.00015613 0.00014412 0.0001497  0.00014024
 0.00015473]
Model epoch 316: train total loss -65.80986267820036, train mean loss 0.00010999334154128369, test mean loss [0.00014857 0.00015061 0.00016229 0.00014974 0.00016283 0.00013764
 0.00015344]
Model epoch 317: train total loss -65.74686853383942, train mean loss 0.0001266960672411387, test mean loss [0.00015386 0.00014873 0.00015813 0.00014724 0.00014803 0.00013287
 0.00015242]
Model epoch 318: train total loss -65.79227423389425, train mean loss 0.00011634275166839843, test mean loss [0.00014463 0.0001548  0.00015927 0.00014557 0.00015725 0.00014045
 0.00014748]
Model epoch 319: train total loss -65.66035368158462, train mean loss 0.0001180459299954079, test mean loss [0.00014905 0.00015659 0.00016419 0.00014821 0.00015447 0.00013695
 0.0001522 ]
Model epoch 320: train total loss -65.72654514786115, train mean loss 0.00010966369223884876, test mean loss [0.00014074 0.00015329 0.00016088 0.00014477 0.00015936 0.00013656
 0.00015231]
Model epoch 321: train total loss -65.69231305178272, train mean loss 0.00011884412851939703, test mean loss [0.00015482 0.00014836 0.00015437 0.00014842 0.00015644 0.00015632
 0.0001521 ]
Model epoch 322: train total loss -65.84193166502153, train mean loss 0.0001306311573329997, test mean loss [0.00014887 0.00015657 0.00016016 0.00014854 0.00014889 0.00013785
 0.00015278]
Model epoch 323: train total loss -65.97454123817776, train mean loss 0.00010755825676455561, test mean loss [0.00014815 0.0001489  0.00015395 0.0001512  0.00014988 0.00013573
 0.00014942]
Model epoch 324: train total loss -65.94119636692595, train mean loss 0.00011479112944183731, test mean loss [0.00014579 0.00014805 0.00016094 0.00014627 0.00014719 0.00013543
 0.00015293]
Model epoch 325: train total loss -65.92798298654441, train mean loss 0.00011579635588287697, test mean loss [0.000145   0.00014984 0.00015764 0.00014526 0.00015296 0.00013547
 0.00014912]
Model epoch 326: train total loss -65.96847416397146, train mean loss 0.00011030787178308775, test mean loss [0.00014344 0.00015129 0.00016677 0.00015082 0.00014674 0.00013489
 0.00014903]
Model epoch 327: train total loss -65.7146003790115, train mean loss 0.00012128331614788662, test mean loss [0.00015432 0.00014571 0.00015477 0.00015347 0.00015457 0.00014075
 0.00014227]
Model epoch 328: train total loss -65.73561434387383, train mean loss 0.00011568620130774443, test mean loss [0.00014744 0.00014966 0.00016001 0.00015041 0.00015139 0.00014208
 0.00015511]
Model epoch 329: train total loss -66.01540215194446, train mean loss 0.00010440210275356842, test mean loss [0.00014138 0.00014819 0.00015989 0.00014855 0.00015168 0.00013135
 0.00014971]
Model epoch 330: train total loss -65.69137268558065, train mean loss 0.00011470455420995555, test mean loss [0.00015029 0.00014647 0.00015842 0.00014706 0.00014634 0.00013445
 0.0001503 ]
Model epoch 331: train total loss -65.90534389146409, train mean loss 0.00010949375992635741, test mean loss [0.00014368 0.00014496 0.00015385 0.00014769 0.00015141 0.00013153
 0.00014618]
Model epoch 332: train total loss -65.78507861270748, train mean loss 0.00011579508935967358, test mean loss [0.00014996 0.00015176 0.0001524  0.00014754 0.00014901 0.00013541
 0.00014492]
Model epoch 333: train total loss -65.56970907762675, train mean loss 0.00012067519374302704, test mean loss [0.00014489 0.00015614 0.00015973 0.00013892 0.00015003 0.00013697
 0.00014653]
Model epoch 334: train total loss -65.91297927732697, train mean loss 0.00010898159642493195, test mean loss [0.00014463 0.0001498  0.00015428 0.00014516 0.00015077 0.000136
 0.00014654]
Model epoch 335: train total loss -65.90549101566442, train mean loss 0.00011737734401700275, test mean loss [0.00014717 0.00014582 0.00015127 0.00014125 0.00014274 0.00012932
 0.00014928]
Model epoch 336: train total loss -65.96170880852634, train mean loss 0.0001124965180414204, test mean loss [0.00014937 0.00014452 0.00014935 0.00014172 0.00014619 0.0001342
 0.00015223]
Model epoch 337: train total loss -65.92144259478162, train mean loss 0.00011574129210390008, test mean loss [0.00014469 0.00014223 0.00015199 0.00014319 0.00014975 0.00013027
 0.00014384]
Model epoch 338: train total loss -65.99881003994237, train mean loss 0.00010857860165287111, test mean loss [0.00014857 0.000147   0.00015421 0.00014531 0.00014605 0.00012804
 0.00014169]
Model epoch 339: train total loss -65.92338591998015, train mean loss 0.00011335776232568666, test mean loss [0.00014527 0.00014661 0.00015678 0.00014066 0.000153   0.00013277
 0.00014537]
Model epoch 340: train total loss -65.9264927885718, train mean loss 0.00011095175850064501, test mean loss [0.00014838 0.00014056 0.0001565  0.00014212 0.00014844 0.00013418
 0.0001452 ]
Model epoch 341: train total loss -65.76499059812718, train mean loss 0.00012285730548499825, test mean loss [0.00014353 0.00015012 0.00015747 0.00014008 0.00014538 0.00014369
 0.00014857]
Model epoch 342: train total loss -65.96131233446883, train mean loss 0.00011623356797120952, test mean loss [0.00014442 0.00014797 0.00014734 0.00013943 0.00014611 0.0001317
 0.00015046]
Model epoch 343: train total loss -66.10919675433898, train mean loss 0.00010875070091990744, test mean loss [0.00014341 0.00014769 0.0001516  0.00014586 0.0001401  0.00013035
 0.00014262]
Model epoch 344: train total loss -65.9800224364285, train mean loss 0.0001145045444234369, test mean loss [0.00014104 0.00014149 0.00014983 0.00014303 0.00014832 0.00013527
 0.00014049]
Model epoch 345: train total loss -66.06447033193831, train mean loss 0.0001100902344965399, test mean loss [0.000141   0.00014402 0.00014992 0.00015045 0.00014471 0.00013229
 0.00014726]
Model epoch 346: train total loss -65.91453252607447, train mean loss 0.00011041602794886097, test mean loss [0.000145   0.00014103 0.00014933 0.00013648 0.00014307 0.00012892
 0.00014655]
Model epoch 347: train total loss -65.90232752164854, train mean loss 0.00011324260377737784, test mean loss [0.00013984 0.00014253 0.00015906 0.00014038 0.00015733 0.00013086
 0.00014329]
Model epoch 348: train total loss -66.06375704304122, train mean loss 0.00010185158250992262, test mean loss [0.00014229 0.00014371 0.00014547 0.00014381 0.00014877 0.00012625
 0.00013901]
Model epoch 349: train total loss -66.08691493040605, train mean loss 0.00010963066349617363, test mean loss [0.0001414  0.0001446  0.00014663 0.00014452 0.00014782 0.00013441
 0.00014712]
Model epoch 350: train total loss -66.06545468380416, train mean loss 0.0001104683185429998, test mean loss [0.00013804 0.00014063 0.00015439 0.0001423  0.00014784 0.00013373
 0.00014147]
Model epoch 351: train total loss -66.10760037837238, train mean loss 0.00011391940342934103, test mean loss [0.00014515 0.00014019 0.00015082 0.00014031 0.00014171 0.00014483
 0.00013855]
Model epoch 352: train total loss -65.98924964648339, train mean loss 0.00010810220705318187, test mean loss [0.00014807 0.00013846 0.00014627 0.00013991 0.00014611 0.0001295
 0.0001391 ]
Model epoch 353: train total loss -65.89834778434715, train mean loss 0.000111965471999254, test mean loss [0.00014567 0.0001504  0.00014922 0.00013911 0.00014513 0.00012945
 0.00014838]
Model epoch 354: train total loss -65.9065972282863, train mean loss 0.00010539921468380436, test mean loss [0.00014478 0.00014183 0.00014777 0.00013773 0.00014489 0.00013375
 0.0001399 ]
Model epoch 355: train total loss -66.02608675800313, train mean loss 0.00010190583256291078, test mean loss [0.00013454 0.00014375 0.00014861 0.00014372 0.00013854 0.00013102
 0.00014314]
Model epoch 356: train total loss -65.8385498927454, train mean loss 0.00010630568432769948, test mean loss [0.00013828 0.00014291 0.0001508  0.00014327 0.00015158 0.00012717
 0.00014706]
Model epoch 357: train total loss -65.77541776557152, train mean loss 0.00011518290481027863, test mean loss [0.00014093 0.0001453  0.0001502  0.00013445 0.00014645 0.00013771
 0.00015134]
Model epoch 358: train total loss -65.9441929814303, train mean loss 0.00011270376595526464, test mean loss [0.00013835 0.00014299 0.00014936 0.00014102 0.0001458  0.00012978
 0.00013946]
Model epoch 359: train total loss -66.09192833553888, train mean loss 0.00010415066190739067, test mean loss [0.0001354  0.00013892 0.00015074 0.00014188 0.00014608 0.00013019
 0.00013915]
Model epoch 360: train total loss -65.91746732072028, train mean loss 0.00010884900260976044, test mean loss [0.0001397  0.00013848 0.00015733 0.00014038 0.00014154 0.00013322
 0.00013898]
Model epoch 361: train total loss -66.03444107724165, train mean loss 0.00010934959954325138, test mean loss [0.00013413 0.00013661 0.00014749 0.00014296 0.00013991 0.00013219
 0.00013663]
Model epoch 362: train total loss -65.90334232516888, train mean loss 0.00011109106186202182, test mean loss [0.00013791 0.0001399  0.00014826 0.0001372  0.00014099 0.00013494
 0.00014422]
Model epoch 363: train total loss -65.86483056930877, train mean loss 0.00010925954277036317, test mean loss [0.00013685 0.00013568 0.00014731 0.00013816 0.00014163 0.00013005
 0.00013868]
Model epoch 364: train total loss -66.12398139668315, train mean loss 0.0001101006575502059, test mean loss [0.00013678 0.0001369  0.00014286 0.00013383 0.00014088 0.0001253
 0.00014174]
Model epoch 365: train total loss -65.85792035828123, train mean loss 0.00010954679982039952, test mean loss [0.00013414 0.00014084 0.00015047 0.00013321 0.00014482 0.00012626
 0.00013517]
Model epoch 366: train total loss -65.93965695768871, train mean loss 0.00010725857999759438, test mean loss [0.00013924 0.00013617 0.00015235 0.00013243 0.00013972 0.00012408
 0.00013414]
Model epoch 367: train total loss -65.99560144251043, train mean loss 0.00010917518963607973, test mean loss [0.00013411 0.00013548 0.00014268 0.00013377 0.00014551 0.00012771
 0.00013231]
Model epoch 368: train total loss -65.96370167859682, train mean loss 0.00011429120348947186, test mean loss [0.00013901 0.00014198 0.00014938 0.00014073 0.00014065 0.00012518
 0.00013999]
Model epoch 369: train total loss -66.13868563421144, train mean loss 0.0001040116887909969, test mean loss [0.00013296 0.00013435 0.00015028 0.00013331 0.00014016 0.00012695
 0.00013405]
Model epoch 370: train total loss -66.01632439762977, train mean loss 0.00010861450500728627, test mean loss [0.00014242 0.00014898 0.00014308 0.00013677 0.00013999 0.00012244
 0.00013513]
Model epoch 371: train total loss -65.9752306950885, train mean loss 0.00010859675850585765, test mean loss [0.00013368 0.00014098 0.00014664 0.00013457 0.00014364 0.0001244
 0.00013751]
Model epoch 372: train total loss -66.15261018561436, train mean loss 0.00010821688258711771, test mean loss [0.00013505 0.0001388  0.00013877 0.00013842 0.00013662 0.0001244
 0.00013956]
Model epoch 373: train total loss -66.13713105391615, train mean loss 0.000107342820537457, test mean loss [0.00014881 0.00013605 0.00014373 0.00013256 0.00013695 0.00012098
 0.00014351]
Model epoch 374: train total loss -66.13820989184262, train mean loss 0.00011536891733688844, test mean loss [0.0001369  0.00013162 0.00014319 0.00013301 0.00013724 0.00012255
 0.00013601]
Model epoch 375: train total loss -66.14361232603721, train mean loss 0.00011070790499564305, test mean loss [0.00013217 0.00013461 0.00013903 0.00013851 0.00013807 0.00012295
 0.00013112]
Model epoch 376: train total loss -66.05239568881649, train mean loss 0.00010620756201241491, test mean loss [0.00014063 0.00013322 0.00013696 0.00012811 0.00014231 0.00012607
 0.00013051]
Model epoch 377: train total loss -66.01603656395834, train mean loss 0.00010289095220596397, test mean loss [0.00013872 0.0001363  0.0001397  0.00013782 0.00013667 0.0001235
 0.00013519]
Model epoch 378: train total loss -66.10337147643229, train mean loss 0.00010906315297984337, test mean loss [0.00013289 0.00013177 0.0001384  0.00013025 0.0001417  0.00012546
 0.00013571]
Model epoch 379: train total loss -65.78613666590007, train mean loss 0.00011621319881963588, test mean loss [0.00014652 0.00016722 0.00013811 0.00013468 0.00013781 0.00012752
 0.00013824]
Model epoch 380: train total loss -66.06426172530111, train mean loss 0.00010659935825915262, test mean loss [0.00013292 0.00014474 0.00013568 0.00013173 0.00014513 0.00013022
 0.00013841]
Model epoch 381: train total loss -66.10446542266403, train mean loss 0.0001038500693865114, test mean loss [0.00013246 0.00014015 0.00014423 0.0001348  0.00013667 0.0001187
 0.00013745]
Model epoch 382: train total loss -65.92553721560239, train mean loss 0.00010715512460534091, test mean loss [0.00012977 0.00013476 0.00014448 0.00013299 0.00013994 0.00012285
 0.00013985]
Model epoch 383: train total loss -65.75276192700821, train mean loss 0.00011230542032489333, test mean loss [0.00013523 0.00013997 0.00015157 0.00013358 0.00014005 0.00012868
 0.00013482]
Model epoch 384: train total loss -65.74805186497373, train mean loss 0.00011405215124007453, test mean loss [0.00013239 0.00013648 0.00014241 0.00014299 0.00014659 0.00012637
 0.0001384 ]
Model epoch 385: train total loss -65.90493601898795, train mean loss 0.00010765472849083819, test mean loss [0.0001297  0.00013501 0.00014518 0.00013761 0.00013714 0.00012329
 0.00013583]
Model epoch 386: train total loss -65.93295772761098, train mean loss 0.0001051092226616043, test mean loss [0.00013315 0.00013828 0.00014242 0.00013845 0.00014981 0.0001296
 0.00013516]
Model epoch 387: train total loss -66.03528214117878, train mean loss 0.00011113276654212684, test mean loss [0.00012906 0.00012763 0.00014478 0.00013803 0.00013497 0.00012801
 0.00014364]
Model epoch 388: train total loss -65.94486815912343, train mean loss 0.00010913648500673293, test mean loss [0.00012815 0.00013127 0.00014343 0.00013245 0.00013953 0.00012702
 0.00013303]
Model epoch 389: train total loss -66.01034514985061, train mean loss 0.00010497313497227595, test mean loss [0.00012797 0.00013503 0.00014217 0.00013473 0.00013782 0.00012479
 0.00012639]
Model epoch 390: train total loss -66.11076325451207, train mean loss 0.000105667373550714, test mean loss [0.00012794 0.00013671 0.00014545 0.00013247 0.00013748 0.00012636
 0.00013777]
Model epoch 391: train total loss -66.06152242822222, train mean loss 0.00010659216166314686, test mean loss [0.00012986 0.00012837 0.00014055 0.00012785 0.00013596 0.00013523
 0.00013644]
Model epoch 392: train total loss -66.10529763676841, train mean loss 0.00010723676613889559, test mean loss [0.0001317  0.00013667 0.00013484 0.00012732 0.00013762 0.0001321
 0.00013462]
Model epoch 393: train total loss -66.11566608259804, train mean loss 0.00010387745569187419, test mean loss [0.00013143 0.00013198 0.00013531 0.00012827 0.00014216 0.00012924
 0.00013461]
Model epoch 394: train total loss -66.14600636596946, train mean loss 0.00010780464688068953, test mean loss [0.00014268 0.00013164 0.00013621 0.00013544 0.00013315 0.00012114
 0.00013474]
Model epoch 395: train total loss -65.95002449507945, train mean loss 0.0001022121833653223, test mean loss [0.00013191 0.00013043 0.00014201 0.00012994 0.00014191 0.00012315
 0.00013966]
Model epoch 396: train total loss -65.98255397799959, train mean loss 0.00010644401248883215, test mean loss [0.00012837 0.00013417 0.00013537 0.00013275 0.0001432  0.00013438
 0.0001286 ]
Model epoch 397: train total loss -66.1628902079896, train mean loss 0.00010507251953659328, test mean loss [0.00013097 0.00013459 0.00014086 0.00013182 0.00013412 0.00012613
 0.00012669]
Model epoch 398: train total loss -66.26469676321503, train mean loss 9.775339945406183e-05, test mean loss [0.00012963 0.00013279 0.0001394  0.00012959 0.00014134 0.00013147
 0.00012932]
Model epoch 399: train total loss -66.12365116705858, train mean loss 0.00010261437926844364, test mean loss [0.00013001 0.0001293  0.00014148 0.00013685 0.00013687 0.00012605
 0.00013181]
Model epoch 400: train total loss -66.16015581990881, train mean loss 0.00010796201366757389, test mean loss [0.00013108 0.00013242 0.00014398 0.00012717 0.00013551 0.00011783
 0.00012983]
Model trained in 401 epochs with 3000 transitions.
[2025-01-22 14:51:44,320][absl][INFO] - {'eval/walltime': 136.2448341846466, 'training/sps': 0.3671552334363771, 'training/walltime': 4643.2197701931, 'training/model_train_time': 1950.6026072502136, 'training/other_time': 772.1903922557831, 'training/model_horizon': 4, 'training/hallucination_updates_per_training_step': 505, 'training/env_buffer_size': Array(4000, dtype=int32), 'model/train_total_loss': Array(-66.16015582, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00010796, dtype=float64), 'model/test_total_loss': Array(-65.55737687, dtype=float64), 'model/test_mean_loss': Array(0.00013112, dtype=float64), 'model/train_epochs': 401, 'model/sec_per_epoch': 4.8588203973603665, 'sac/actor_loss': Array(-11.65850588, dtype=float64), 'sac/alpha': Array(0.03436523, dtype=float32), 'sac/alpha_loss': Array(0.00115977, dtype=float64), 'sac/buffer_current_size': Array(377045.56, dtype=float32), 'sac/critic_loss': Array(0.01475466, dtype=float64), 'eval/episode_forward_vel': Array(-36.70964655, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-3.9537667, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(5.2324167, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(6.9015952e-05, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-15.78909529, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(4.05246801, dtype=float64), 'eval/episode_rew_roll': Array(4.77320523, dtype=float64), 'eval/episode_rew_side_motion': Array(2.42354842, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(5.3908089, dtype=float64), 'eval/episode_rew_yaw': Array(6.91152408, dtype=float64), 'eval/episode_rew_z_vel_change': Array(2.30860525, dtype=float64), 'eval/episode_reward': Array(10.33196612, dtype=float64), 'eval/episode_step_count': Array(5778., dtype=float64), 'eval/avg_episode_length': Array(108., dtype=float64), 'eval/epoch_eval_time': 30.592524528503418, 'eval/sps': 32.68772405717247}
Steps / Eval:  4000.0
Reward is  10.331966119647403
Model horizon updated to 6.
Hallucination updates per training step updated to 752.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -28.580719003485832, train mean loss 0.03455389052075672, test mean loss [0.03474643 0.02973812 0.02918178 0.03074566 0.03166921 0.05461616
 0.03602392]
Model epoch 1: train total loss -33.35599584863253, train mean loss 0.03159451042119582, test mean loss [0.03047337 0.02703588 0.02894929 0.0262373  0.02436586 0.04009793
 0.02813023]
Model epoch 2: train total loss -37.88169339972664, train mean loss 0.026200061176998617, test mean loss [0.02641414 0.02303006 0.02665152 0.02678619 0.01943314 0.03005665
 0.02752266]
Model epoch 3: train total loss -41.81945349742005, train mean loss 0.023784727569348834, test mean loss [0.02445038 0.02282937 0.02470263 0.0269831  0.01857537 0.02842439
 0.02689443]
Model epoch 4: train total loss -45.31042299410078, train mean loss 0.023469833884528397, test mean loss [0.02208817 0.02175434 0.02319045 0.02462455 0.01860297 0.02753188
 0.02450044]
Model epoch 5: train total loss -48.16410801375268, train mean loss 0.02097522623300337, test mean loss [0.01936039 0.02105119 0.02161608 0.02241442 0.01836123 0.02513492
 0.02080054]
Model epoch 6: train total loss -49.841705077702066, train mean loss 0.01938110039172925, test mean loss [0.01635861 0.01983097 0.02003593 0.02000113 0.01644548 0.0213383
 0.01834319]
Model epoch 7: train total loss -51.39580065692584, train mean loss 0.017420457751420534, test mean loss [0.0148112  0.01925561 0.01816436 0.01766746 0.01446769 0.01887137
 0.01632151]
Model epoch 8: train total loss -52.86560874758159, train mean loss 0.014594384450846022, test mean loss [0.01315284 0.01762266 0.01612573 0.01595814 0.01260616 0.01695152
 0.01495784]
Model epoch 9: train total loss -53.47739449684156, train mean loss 0.014242820071300028, test mean loss [0.01201807 0.01613789 0.0141139  0.01412556 0.01094206 0.01498563
 0.01355638]
Model epoch 10: train total loss -54.37203421324465, train mean loss 0.011959941212132164, test mean loss [0.01086239 0.01473794 0.01255737 0.01276969 0.00953601 0.01403598
 0.01245747]
Model epoch 11: train total loss -54.94889073282406, train mean loss 0.010872392545218462, test mean loss [0.00980575 0.01365999 0.01128556 0.01142716 0.00854439 0.01265945
 0.01131816]
Model epoch 12: train total loss -55.548733518236624, train mean loss 0.009418168048401069, test mean loss [0.00871296 0.01270827 0.01030614 0.01029494 0.00764301 0.01151324
 0.01043603]
Model epoch 13: train total loss -55.82058724203617, train mean loss 0.008927679263869712, test mean loss [0.00797982 0.0119525  0.00953653 0.00915493 0.00691442 0.01055552
 0.00965301]
Model epoch 14: train total loss -56.35189998207189, train mean loss 0.008422384608118484, test mean loss [0.0073208  0.01104568 0.00849489 0.00841137 0.00628298 0.00957835
 0.00888589]
Model epoch 15: train total loss -56.73464227497656, train mean loss 0.0072406550091235556, test mean loss [0.006904   0.01007314 0.00799631 0.00760863 0.00583859 0.00865584
 0.00828994]
Model epoch 16: train total loss -57.34495036518913, train mean loss 0.006863814385638392, test mean loss [0.00648167 0.00938101 0.00738518 0.00673826 0.00541029 0.00803097
 0.00775798]
Model epoch 17: train total loss -57.126832398083835, train mean loss 0.007055292308237882, test mean loss [0.0060484  0.00857149 0.00676262 0.00630035 0.00515875 0.00724805
 0.00727766]
Model epoch 18: train total loss -57.66389119448684, train mean loss 0.0054218254874684605, test mean loss [0.00576395 0.00793671 0.0064279  0.00571888 0.00488908 0.00659075
 0.00689529]
Model epoch 19: train total loss -58.01542417495045, train mean loss 0.005223876266268107, test mean loss [0.00560451 0.00730448 0.00605149 0.00518318 0.00479278 0.00611813
 0.00667881]
Model epoch 20: train total loss -58.184683195900455, train mean loss 0.004842931285516885, test mean loss [0.00530711 0.00681076 0.00556674 0.00493492 0.00456297 0.00575026
 0.00638787]
Model epoch 21: train total loss -58.34713966879497, train mean loss 0.004476507965818557, test mean loss [0.00504305 0.00630166 0.00527915 0.00455665 0.00433831 0.00536331
 0.00608273]
Model epoch 22: train total loss -58.61028570789264, train mean loss 0.004319676327486317, test mean loss [0.00485106 0.00600968 0.00504753 0.00442001 0.00420197 0.00502421
 0.00570252]
Model epoch 23: train total loss -58.94107312920426, train mean loss 0.004682412643749989, test mean loss [0.00472476 0.0057186  0.0048525  0.00410022 0.00402873 0.00473585
 0.00540012]
Model epoch 24: train total loss -58.9057219889712, train mean loss 0.0040477004702481455, test mean loss [0.00456105 0.00547851 0.00457393 0.00391782 0.00387673 0.00450064
 0.0052229 ]
Model epoch 25: train total loss -59.221260319939894, train mean loss 0.003812191228230008, test mean loss [0.00435338 0.0052566  0.00444016 0.00376806 0.00376972 0.00437433
 0.00502965]
Model epoch 26: train total loss -59.20623126225387, train mean loss 0.00416461675093771, test mean loss [0.00421995 0.00504629 0.00422821 0.0036683  0.00366972 0.00412646
 0.00486195]
Model epoch 27: train total loss -59.435425712851476, train mean loss 0.0036495139061651885, test mean loss [0.00407593 0.00478481 0.00410842 0.003457   0.00354887 0.00402668
 0.00464318]
Model epoch 28: train total loss -59.4348656311229, train mean loss 0.003716197313173383, test mean loss [0.00400214 0.00467613 0.00397974 0.00335064 0.00343258 0.00385105
 0.00444565]
Model epoch 29: train total loss -59.86447277509418, train mean loss 0.003038224033041912, test mean loss [0.00381037 0.00470051 0.00386972 0.00321286 0.00336148 0.00373956
 0.00431229]
Model epoch 30: train total loss -59.5659930735632, train mean loss 0.0035652887884666208, test mean loss [0.00373555 0.00448812 0.00369326 0.00315125 0.00325931 0.00362013
 0.00417333]
Model epoch 31: train total loss -60.08720165557741, train mean loss 0.003086822965725336, test mean loss [0.00362926 0.00435516 0.003546   0.00304279 0.00317208 0.0034715
 0.00406524]
Model epoch 32: train total loss -59.65434115058535, train mean loss 0.003567167832659591, test mean loss [0.00351508 0.00424786 0.00338327 0.00292593 0.0031157  0.00332817
 0.00398352]
Model epoch 33: train total loss -60.061102309015055, train mean loss 0.003128300618691365, test mean loss [0.00341555 0.00404726 0.00330749 0.00285756 0.00300246 0.0032152
 0.00382219]
Model epoch 34: train total loss -60.28160797683911, train mean loss 0.0030277358824211875, test mean loss [0.00334141 0.00404511 0.00319228 0.00270712 0.00289605 0.00315002
 0.00369485]
Model epoch 35: train total loss -60.406659192491084, train mean loss 0.0026572785414203503, test mean loss [0.00322512 0.0038574  0.00306444 0.00278981 0.00286047 0.00306735
 0.00361938]
Model epoch 36: train total loss -60.58766888938859, train mean loss 0.0024704123199662514, test mean loss [0.00314137 0.00381726 0.00297814 0.00254437 0.00278335 0.00297171
 0.00344426]
Model epoch 37: train total loss -60.34785489774945, train mean loss 0.0027197625564809873, test mean loss [0.0030673  0.00373098 0.00290074 0.00248188 0.00271186 0.00282918
 0.00338073]
Model epoch 38: train total loss -60.57741136268919, train mean loss 0.0024537804241328296, test mean loss [0.00296885 0.00351897 0.00282828 0.00243498 0.00265581 0.00277666
 0.00322618]
Model epoch 39: train total loss -60.784338396790794, train mean loss 0.002262108528293828, test mean loss [0.00289626 0.00344445 0.00278535 0.00235059 0.00257489 0.00269281
 0.00315259]
Model epoch 40: train total loss -60.966932231238935, train mean loss 0.002412391701885796, test mean loss [0.00282359 0.00342408 0.00264713 0.00227475 0.00252541 0.00261236
 0.00307434]
Model epoch 41: train total loss -60.950504267054484, train mean loss 0.002132904200521517, test mean loss [0.00277512 0.00338466 0.0025544  0.002175   0.00244222 0.00258837
 0.00306955]
Model epoch 42: train total loss -60.992996081915756, train mean loss 0.0024111584629928962, test mean loss [0.00268333 0.00319892 0.00249734 0.00215194 0.00238605 0.00248707
 0.00302127]
Model epoch 43: train total loss -60.94204549867173, train mean loss 0.0021348681642638584, test mean loss [0.00266623 0.00310653 0.00242558 0.0020513  0.00238814 0.00244621
 0.00292401]
Model epoch 44: train total loss -61.195175107046545, train mean loss 0.002112222912868302, test mean loss [0.00258923 0.00298157 0.00236788 0.00202434 0.00231147 0.00240334
 0.00276343]
Model epoch 45: train total loss -61.34121249918634, train mean loss 0.0019724731743820854, test mean loss [0.00248598 0.00300664 0.00234167 0.00194874 0.00224495 0.00232566
 0.00267588]
Model epoch 46: train total loss -61.199026466862136, train mean loss 0.0021899468770847407, test mean loss [0.00247175 0.00296583 0.00225453 0.00190413 0.00221333 0.0022836
 0.00261939]
Model epoch 47: train total loss -61.461596441075095, train mean loss 0.0018564294384799025, test mean loss [0.00238785 0.0029479  0.00220492 0.00184752 0.00214607 0.00225791
 0.00261901]
Model epoch 48: train total loss -61.72091140128318, train mean loss 0.0019449785311232515, test mean loss [0.00233335 0.00283664 0.00219404 0.00183666 0.00215177 0.00217382
 0.0025021 ]
Model epoch 49: train total loss -61.65278852206711, train mean loss 0.0016341254147340483, test mean loss [0.00224415 0.00282714 0.00208586 0.00180232 0.00210964 0.00211545
 0.00255429]
Model epoch 50: train total loss -61.561093924617396, train mean loss 0.0017387671273018917, test mean loss [0.0022393  0.00272401 0.00205149 0.001713   0.00205843 0.00207715
 0.00239895]
Model epoch 51: train total loss -61.76025076483386, train mean loss 0.0015005380509816486, test mean loss [0.00217079 0.00271366 0.00198628 0.00171565 0.00202843 0.00200863
 0.00234568]
Model epoch 52: train total loss -61.81699075328512, train mean loss 0.0016562172935598717, test mean loss [0.00215515 0.00264898 0.00193282 0.00165051 0.00196206 0.00194724
 0.00230266]
Model epoch 53: train total loss -61.63245390996101, train mean loss 0.0018528848181144522, test mean loss [0.00207113 0.00257237 0.00186201 0.00161408 0.00197013 0.00198488
 0.00227403]
Model epoch 54: train total loss -61.80295773397679, train mean loss 0.001806844391000875, test mean loss [0.00202185 0.00257075 0.00182842 0.0015256  0.00186881 0.00191812
 0.00222809]
Model epoch 55: train total loss -61.87164242031513, train mean loss 0.0014460488284147768, test mean loss [0.00198841 0.00245859 0.00178962 0.00154674 0.0018293  0.00187474
 0.00213035]
Model epoch 56: train total loss -61.912840321724495, train mean loss 0.0016438006032707317, test mean loss [0.00199329 0.00241756 0.00179283 0.00150911 0.00178356 0.00180801
 0.0021211 ]
Model epoch 57: train total loss -62.102404416877896, train mean loss 0.001289835550936214, test mean loss [0.00192266 0.00243109 0.00172989 0.00143529 0.00176817 0.00177716
 0.00207347]
Model epoch 58: train total loss -61.98732859428091, train mean loss 0.0015669738552072277, test mean loss [0.00185992 0.00233327 0.00171896 0.00144829 0.00175118 0.00174515
 0.00205889]
Model epoch 59: train total loss -62.049217267553736, train mean loss 0.001592361774997919, test mean loss [0.00182182 0.00225927 0.00171898 0.00141145 0.0017335  0.00172361
 0.00205322]
Model epoch 60: train total loss -62.27760248541385, train mean loss 0.0014557907631686936, test mean loss [0.0018261  0.00222016 0.00161035 0.00138159 0.00168441 0.00169625
 0.00197108]
Model epoch 61: train total loss -62.17467149699594, train mean loss 0.0013222370359694303, test mean loss [0.00181764 0.00234088 0.00159188 0.00133397 0.00163275 0.0016498
 0.0020237 ]
Model epoch 62: train total loss -62.376345764935174, train mean loss 0.0015152184209031657, test mean loss [0.00172278 0.00219652 0.00159218 0.00128387 0.00162167 0.00165477
 0.00189842]
Model epoch 63: train total loss -62.219931526647436, train mean loss 0.0014768503551350078, test mean loss [0.00177169 0.00210319 0.00151413 0.00127006 0.00157456 0.00158417
 0.00193148]
Model epoch 64: train total loss -62.47779381334733, train mean loss 0.0010676203345281318, test mean loss [0.00170209 0.00213484 0.00154693 0.00122092 0.00156587 0.00156937
 0.00190781]
Model epoch 65: train total loss -62.33929065645223, train mean loss 0.0012734628633151936, test mean loss [0.00164344 0.0020395  0.00147342 0.00118292 0.00153404 0.00154129
 0.00186922]
Model epoch 66: train total loss -62.70623296227491, train mean loss 0.001016388833966478, test mean loss [0.00164006 0.0019733  0.00143214 0.00118367 0.00156185 0.00146881
 0.00179616]
Model epoch 67: train total loss -62.380747197257456, train mean loss 0.0011748434516664164, test mean loss [0.0016322  0.00195573 0.00141485 0.00115394 0.00150082 0.00145006
 0.00171985]
Model epoch 68: train total loss -62.644742292380805, train mean loss 0.0011948540544062252, test mean loss [0.00158512 0.00197229 0.00138618 0.00112532 0.00146127 0.00142451
 0.0017168 ]
Model epoch 69: train total loss -62.46952423772023, train mean loss 0.0011433872615194205, test mean loss [0.00158423 0.00194868 0.00130014 0.00111562 0.00142958 0.00141629
 0.00172974]
Model epoch 70: train total loss -62.4992813585099, train mean loss 0.0011706156020833457, test mean loss [0.0015091  0.00202738 0.00131803 0.00109267 0.00142734 0.00138283
 0.00163564]
Model epoch 71: train total loss -62.608104525573005, train mean loss 0.0010355845936647708, test mean loss [0.00154855 0.00196446 0.00132419 0.00105259 0.00139129 0.00130488
 0.00164297]
Model epoch 72: train total loss -62.62486693489557, train mean loss 0.0009974294581794089, test mean loss [0.0015073  0.00181245 0.00127215 0.00102503 0.00134064 0.00132253
 0.00165269]
Model epoch 73: train total loss -62.58323791302808, train mean loss 0.0011697583706933468, test mean loss [0.00144494 0.00183539 0.00124145 0.00099326 0.00134666 0.00130983
 0.00153412]
Model epoch 74: train total loss -62.52449863212666, train mean loss 0.000991052014578822, test mean loss [0.0014988  0.00177626 0.00122633 0.00101734 0.00131759 0.00126527
 0.00154852]
Model epoch 75: train total loss -62.92654890942338, train mean loss 0.000898614082535515, test mean loss [0.00142061 0.00175293 0.00119669 0.00097022 0.0013132  0.00124936
 0.00158571]
Model epoch 76: train total loss -62.648049014039586, train mean loss 0.0010701027253312205, test mean loss [0.00139983 0.00170426 0.00116331 0.00095879 0.00128756 0.00122711
 0.0016534 ]
Model epoch 77: train total loss -62.781768490876814, train mean loss 0.0010872365203511225, test mean loss [0.00139016 0.0017346  0.00116365 0.00096414 0.00128661 0.00119635
 0.00152546]
Model epoch 78: train total loss -62.68644571769734, train mean loss 0.0010110505187913956, test mean loss [0.00130267 0.00164806 0.00115322 0.00097335 0.00122999 0.00115983
 0.00157721]
Model epoch 79: train total loss -63.11589787778332, train mean loss 0.0009274100096655534, test mean loss [0.00132466 0.00164364 0.00111067 0.00088547 0.00125743 0.0011629
 0.00143954]
Model epoch 80: train total loss -62.76133321598732, train mean loss 0.0011166144308955783, test mean loss [0.00134541 0.00167665 0.00106775 0.00094859 0.00120608 0.0011066
 0.00142598]
Model epoch 81: train total loss -62.84032103968163, train mean loss 0.001053762785778567, test mean loss [0.00130978 0.00159105 0.00108155 0.00088882 0.0011955  0.00108927
 0.00138432]
Model epoch 82: train total loss -63.12980901889385, train mean loss 0.0008850466238978506, test mean loss [0.00124552 0.00154201 0.00106116 0.00086167 0.00118167 0.00106352
 0.00133836]
Model epoch 83: train total loss -63.10206047675114, train mean loss 0.0008867364861105653, test mean loss [0.00129593 0.00153312 0.00103471 0.00087451 0.00116771 0.00107652
 0.00132371]
Model epoch 84: train total loss -63.11167371899188, train mean loss 0.0008424580829042314, test mean loss [0.00122535 0.00159864 0.0010248  0.00081658 0.00113076 0.00103561
 0.00136353]
Model epoch 85: train total loss -62.89421875113309, train mean loss 0.0009908561117269417, test mean loss [0.00122905 0.00153646 0.00098908 0.0008344  0.00115685 0.00102829
 0.0012748 ]
Model epoch 86: train total loss -63.172217338699, train mean loss 0.0008641057398885607, test mean loss [0.00126714 0.0014627  0.00096891 0.00078708 0.00112542 0.00099587
 0.00129549]
Model epoch 87: train total loss -63.353216633255336, train mean loss 0.0007629079523343088, test mean loss [0.00124006 0.001477   0.00095873 0.00082847 0.00107605 0.00098234
 0.00128317]
Model epoch 88: train total loss -63.177437423926676, train mean loss 0.0009049588758480989, test mean loss [0.00116597 0.00141698 0.00094558 0.00077278 0.00109307 0.00099432
 0.00124343]
Model epoch 89: train total loss -63.32742633108649, train mean loss 0.0008339175789021031, test mean loss [0.0011092  0.0014046  0.00094565 0.00080593 0.00103689 0.00095394
 0.00120323]
Model epoch 90: train total loss -63.27639580040772, train mean loss 0.0008748779600071563, test mean loss [0.0011888  0.00137946 0.00092267 0.0007511  0.00104012 0.00093886
 0.00120762]
Model epoch 91: train total loss -63.31532684990455, train mean loss 0.0008352333137942255, test mean loss [0.00113256 0.00137769 0.00089833 0.00078357 0.00103705 0.00093479
 0.00117021]
Model epoch 92: train total loss -63.209893544691816, train mean loss 0.0008039691755712954, test mean loss [0.00106377 0.00131747 0.00087844 0.00077702 0.00102853 0.0009008
 0.00119983]
Model epoch 93: train total loss -63.241530592305324, train mean loss 0.0007794364615204994, test mean loss [0.00108626 0.0013337  0.00085467 0.00072209 0.00100335 0.00090625
 0.00116896]
Model epoch 94: train total loss -63.48331600171209, train mean loss 0.0006931533944399007, test mean loss [0.00112735 0.00132316 0.00084785 0.00072143 0.00098837 0.00087179
 0.00113309]
Model epoch 95: train total loss -63.2532191974672, train mean loss 0.0006386544803378889, test mean loss [0.00109258 0.00130343 0.00086151 0.00070074 0.00097577 0.00087568
 0.00113085]
Model epoch 96: train total loss -63.56286317476574, train mean loss 0.000893709192023443, test mean loss [0.00103231 0.00126322 0.00084715 0.00067758 0.00099971 0.00084779
 0.00109591]
Model epoch 97: train total loss -63.27656663640304, train mean loss 0.0006704215252711841, test mean loss [0.00102579 0.00124414 0.00084652 0.00067571 0.00100802 0.00083483
 0.00110041]
Model epoch 98: train total loss -63.37909479575161, train mean loss 0.0006787679923994832, test mean loss [0.00102976 0.00123688 0.00081719 0.00067775 0.00093151 0.00081681
 0.00106394]
Model epoch 99: train total loss -63.187791626938086, train mean loss 0.000703320619551089, test mean loss [0.00102021 0.00126162 0.00080822 0.0006999  0.00092152 0.00083497
 0.00103939]
Model epoch 100: train total loss -63.27848725200997, train mean loss 0.0009424089816026018, test mean loss [0.0010089  0.00128556 0.00079562 0.00064704 0.00090586 0.00082802
 0.00102754]
Model epoch 101: train total loss -63.3803258904791, train mean loss 0.0007368720102562921, test mean loss [0.00100052 0.00119312 0.000794   0.00062893 0.00088426 0.00078204
 0.00104201]
Model epoch 102: train total loss -63.52563966419285, train mean loss 0.0005264684630614419, test mean loss [0.00100342 0.00115496 0.00080784 0.00062192 0.00092784 0.00077058
 0.00100228]
Model epoch 103: train total loss -63.36491810553995, train mean loss 0.0006948537046312053, test mean loss [0.00097974 0.00118598 0.00075663 0.00060599 0.00087829 0.00078214
 0.00097456]
Model epoch 104: train total loss -63.530779151198914, train mean loss 0.000599123302573049, test mean loss [0.00091686 0.00112307 0.00075118 0.0005937  0.00087878 0.00075474
 0.00098103]
Model epoch 105: train total loss -63.656056304889404, train mean loss 0.0006157487865251077, test mean loss [0.00094501 0.00115083 0.00075335 0.00059772 0.00086405 0.0007437
 0.00101849]
Model epoch 106: train total loss -63.55079931366881, train mean loss 0.0006907089429558427, test mean loss [0.00097945 0.00111473 0.00075188 0.00059816 0.00084851 0.00073863
 0.00099835]
Model epoch 107: train total loss -63.60792037547564, train mean loss 0.0006135365299594658, test mean loss [0.00092608 0.00111291 0.00074897 0.00058763 0.00083388 0.00071759
 0.00095196]
Model epoch 108: train total loss -63.466388802889774, train mean loss 0.000666707406617104, test mean loss [0.00091512 0.00107576 0.0007357  0.00057309 0.00085634 0.00071291
 0.00092781]
Model epoch 109: train total loss -63.73667088071729, train mean loss 0.0006290445786461127, test mean loss [0.00090717 0.00113831 0.00069388 0.00056243 0.00082704 0.00070004
 0.00091821]
Model epoch 110: train total loss -63.623528230284315, train mean loss 0.0005606890880068121, test mean loss [0.0008797  0.00107944 0.00067906 0.00055731 0.00081837 0.00069939
 0.00091513]
Model epoch 111: train total loss -63.65126903252352, train mean loss 0.000619217911864242, test mean loss [0.00091728 0.00103757 0.00067034 0.00054992 0.00081249 0.00067063
 0.00093334]
Model epoch 112: train total loss -63.849808933133474, train mean loss 0.0006038800671147194, test mean loss [0.00085418 0.00100595 0.00067824 0.00054498 0.00078893 0.00083092
 0.00092678]
Model epoch 113: train total loss -63.75445682450722, train mean loss 0.000624056323441264, test mean loss [0.00084377 0.00099551 0.00067745 0.00053245 0.00077415 0.00068845
 0.00088777]
Model epoch 114: train total loss -63.53239121232605, train mean loss 0.0005588253623280884, test mean loss [0.00080446 0.00098372 0.00066334 0.00052711 0.00079163 0.00065974
 0.00087189]
Model epoch 115: train total loss -63.47825963037705, train mean loss 0.0006084555712221585, test mean loss [0.00095455 0.0010144  0.0006857  0.00052108 0.00074617 0.00065206
 0.00086975]
Model epoch 116: train total loss -63.78227287740354, train mean loss 0.0006116595665753448, test mean loss [0.00081723 0.00099042 0.00063738 0.000528   0.0007512  0.00063415
 0.00088645]
Model epoch 117: train total loss -63.88748782186609, train mean loss 0.0006724627346485792, test mean loss [0.00081725 0.00100089 0.00063541 0.00052684 0.0007594  0.00062923
 0.00083283]
Model epoch 118: train total loss -63.96175047646975, train mean loss 0.000506811399087976, test mean loss [0.00085208 0.00095561 0.00063378 0.00054815 0.00075004 0.00060847
 0.000866  ]
Model epoch 119: train total loss -63.93276049409305, train mean loss 0.0005685881935639169, test mean loss [0.00096248 0.00093937 0.00062436 0.00050156 0.00074302 0.00060851
 0.00083274]
Model epoch 120: train total loss -63.79713710817981, train mean loss 0.0005134778035714686, test mean loss [0.00075641 0.00093327 0.00059537 0.00051657 0.00072694 0.00061399
 0.00082626]
Model epoch 121: train total loss -63.75813732204872, train mean loss 0.0006399022359025622, test mean loss [0.00080014 0.00092884 0.00060864 0.00050673 0.0007428  0.00061023
 0.000813  ]
Model epoch 122: train total loss -63.91991175203947, train mean loss 0.0004475854044372867, test mean loss [0.0007649  0.00092924 0.00059535 0.00051969 0.00073249 0.00058565
 0.00085205]
Model epoch 123: train total loss -63.99658323615628, train mean loss 0.0005101624822071355, test mean loss [0.00074783 0.00092498 0.00058598 0.00049666 0.00071098 0.00059709
 0.00080438]
Model epoch 124: train total loss -63.99177233015509, train mean loss 0.000575521156045044, test mean loss [0.00072976 0.00088182 0.00066703 0.00048165 0.00071793 0.00058013
 0.00077716]
Model epoch 125: train total loss -63.827681226917186, train mean loss 0.0005194772352521223, test mean loss [0.00077385 0.00088011 0.0005816  0.00048465 0.00068962 0.00057698
 0.00076078]
Model epoch 126: train total loss -63.891148924692054, train mean loss 0.0005244045456545708, test mean loss [0.00072596 0.00087484 0.00057871 0.00046217 0.0007     0.00054934
 0.00077015]
Model epoch 127: train total loss -63.74363846846463, train mean loss 0.0005129900168426185, test mean loss [0.00071618 0.00086718 0.0005653  0.00047204 0.00069147 0.00055855
 0.00073453]
Model epoch 128: train total loss -64.03000342621239, train mean loss 0.0003954963334851307, test mean loss [0.00072504 0.00087144 0.00055767 0.00048005 0.00069912 0.00055119
 0.00074265]
Model epoch 129: train total loss -64.17039706948017, train mean loss 0.0005252054638749916, test mean loss [0.00069835 0.00085555 0.00056008 0.00046719 0.00068741 0.00054007
 0.00072805]
Model epoch 130: train total loss -64.05884032975656, train mean loss 0.0004719009015315331, test mean loss [0.00068132 0.00083934 0.00056456 0.00045079 0.00064993 0.00053281
 0.00073054]
Model epoch 131: train total loss -64.06955885489779, train mean loss 0.00047822232896983487, test mean loss [0.00070779 0.00083201 0.00054555 0.00047625 0.00064576 0.00052722
 0.00070581]
Model epoch 132: train total loss -63.933109925659174, train mean loss 0.0005909038026302339, test mean loss [0.00079817 0.0008235  0.00063621 0.00044966 0.0006608  0.00053396
 0.00071935]
Model epoch 133: train total loss -63.97525458434402, train mean loss 0.0004940000624271417, test mean loss [0.0006669  0.00082413 0.00053413 0.00043439 0.0006593  0.00052103
 0.00071578]
Model epoch 134: train total loss -63.99563766167071, train mean loss 0.0005657699271129024, test mean loss [0.00066958 0.00082951 0.00053403 0.00042878 0.00063467 0.00052378
 0.00070258]
Model epoch 135: train total loss -64.19697982555834, train mean loss 0.00043072692532837386, test mean loss [0.00066263 0.00081619 0.00053138 0.00043265 0.00062318 0.00052679
 0.00068569]
Model epoch 136: train total loss -64.193987403087, train mean loss 0.00045287025539922154, test mean loss [0.00063812 0.00083013 0.00051294 0.00042553 0.00062523 0.00050898
 0.00072937]
Model epoch 137: train total loss -64.03029316209438, train mean loss 0.0004099550749023607, test mean loss [0.000633   0.0007877  0.0005039  0.000422   0.00062636 0.00048361
 0.00069981]
Model epoch 138: train total loss -64.33936180594081, train mean loss 0.0003840120374872916, test mean loss [0.0006582  0.000778   0.00049387 0.00042406 0.00060576 0.00049351
 0.00066757]
Model epoch 139: train total loss -64.10629982583231, train mean loss 0.0004918574604505517, test mean loss [0.0006558  0.00085448 0.00048409 0.00040048 0.00060477 0.00050148
 0.00065194]
Model epoch 140: train total loss -64.27108713434059, train mean loss 0.00041761524874712986, test mean loss [0.00062859 0.00082008 0.00049815 0.00041644 0.0006181  0.00047584
 0.00064501]
Model epoch 141: train total loss -64.34107287104308, train mean loss 0.0005295433248353941, test mean loss [0.00062913 0.00078615 0.00049754 0.00040069 0.00058361 0.00047395
 0.00065061]
Model epoch 142: train total loss -64.14493501798158, train mean loss 0.0004120667490763448, test mean loss [0.00061419 0.00075767 0.00048028 0.00041303 0.00057971 0.0004785
 0.00066201]
Model epoch 143: train total loss -64.22535229937677, train mean loss 0.0005153794550128563, test mean loss [0.00065092 0.00077642 0.00049556 0.00039523 0.00059151 0.00048119
 0.00064639]
Model epoch 144: train total loss -64.31872466551916, train mean loss 0.000498694947627993, test mean loss [0.00061601 0.00076214 0.00048424 0.00038361 0.00057865 0.00045542
 0.0006435 ]
Model epoch 145: train total loss -64.11639686237014, train mean loss 0.0004368649338460886, test mean loss [0.00057616 0.00075373 0.00047745 0.00039096 0.00058081 0.00046418
 0.0006328 ]
Model epoch 146: train total loss -64.19755351224383, train mean loss 0.0004249436054514042, test mean loss [0.00062551 0.00077486 0.0004727  0.00040902 0.0005797  0.00045059
 0.00060013]
Model epoch 147: train total loss -64.10452927154155, train mean loss 0.00042482829859290033, test mean loss [0.00055876 0.00072298 0.00047101 0.00038863 0.00056812 0.00047953
 0.00064221]
Model epoch 148: train total loss -64.40765967100099, train mean loss 0.0004086399931135954, test mean loss [0.00058279 0.00068509 0.00044797 0.00037778 0.00055371 0.0004518
 0.00062078]
Model epoch 149: train total loss -64.25647198222809, train mean loss 0.0003724184186142343, test mean loss [0.00054868 0.00070401 0.00046967 0.00041789 0.00058644 0.0004343
 0.00059816]
Model epoch 150: train total loss -64.30138661808662, train mean loss 0.0003478096468909771, test mean loss [0.00056156 0.00069814 0.00043717 0.0003709  0.00054856 0.00043691
 0.00059556]
Model epoch 151: train total loss -64.25940569028091, train mean loss 0.00045384372280348135, test mean loss [0.00061035 0.00069454 0.00045324 0.00037764 0.00056196 0.00042559
 0.00060605]
Model epoch 152: train total loss -64.18537472070845, train mean loss 0.0004330204117216232, test mean loss [0.00053822 0.00069577 0.00045517 0.00035797 0.00054131 0.00043047
 0.00058745]
Model epoch 153: train total loss -64.32491788992002, train mean loss 0.00041091024327958876, test mean loss [0.00053066 0.00067124 0.00043835 0.00036404 0.0005594  0.00042898
 0.00059369]
Model epoch 154: train total loss -64.29138471025256, train mean loss 0.00041375659797055945, test mean loss [0.00053652 0.00066931 0.00042787 0.00037668 0.00052881 0.0004191
 0.00058616]
Model epoch 155: train total loss -64.30758206994743, train mean loss 0.0003235038417219778, test mean loss [0.00055879 0.00074692 0.00044055 0.0003678  0.0005439  0.00041424
 0.00057618]
Model epoch 156: train total loss -64.58136145236244, train mean loss 0.0003006719006285784, test mean loss [0.00051433 0.00067007 0.00043915 0.00038957 0.00051949 0.00042524
 0.00059583]
Model epoch 157: train total loss -64.45119749222616, train mean loss 0.00037786790837900493, test mean loss [0.00053818 0.00068954 0.00043601 0.00036364 0.00053788 0.00040681
 0.00056557]
Model epoch 158: train total loss -64.17056841377098, train mean loss 0.00039904480295318954, test mean loss [0.0005666  0.00067028 0.0004413  0.00036684 0.00051626 0.00039893
 0.00057357]
Model epoch 159: train total loss -64.52433492550223, train mean loss 0.0003687956957362918, test mean loss [0.00050486 0.00064336 0.0004178  0.00036706 0.00050283 0.000405
 0.00053988]
Model epoch 160: train total loss -64.33049365169744, train mean loss 0.000351308274163982, test mean loss [0.00051878 0.00062977 0.00042237 0.00037268 0.00050556 0.00043194
 0.00056276]
Model epoch 161: train total loss -64.53550110723593, train mean loss 0.0004048583560083717, test mean loss [0.00050514 0.00067299 0.00040712 0.00037253 0.00050517 0.00039322
 0.00058789]
Model epoch 162: train total loss -64.44550428762963, train mean loss 0.000374161543782413, test mean loss [0.00050093 0.00065951 0.00041647 0.00036028 0.00049387 0.00040673
 0.00053881]
Model epoch 163: train total loss -64.34376691099779, train mean loss 0.0003930969544868136, test mean loss [0.00048741 0.00066499 0.00041036 0.00035606 0.00049786 0.00040479
 0.00055708]
Model epoch 164: train total loss -64.3241303915658, train mean loss 0.00048079822503248044, test mean loss [0.00048958 0.00069022 0.000399   0.00035773 0.00048437 0.00040145
 0.000522  ]
Model epoch 165: train total loss -64.58123400828279, train mean loss 0.0003983249372523018, test mean loss [0.00047548 0.00060701 0.0003801  0.00034592 0.00048337 0.00038819
 0.00054657]
Model epoch 166: train total loss -64.54263716216761, train mean loss 0.0003575406441753282, test mean loss [0.00049242 0.00060738 0.00040288 0.00034883 0.00046892 0.00037771
 0.00050473]
Model epoch 167: train total loss -64.51038097898561, train mean loss 0.0002664171379221859, test mean loss [0.00046902 0.00060163 0.00038089 0.00034911 0.00049438 0.00038547
 0.00053405]
Model epoch 168: train total loss -64.44058097952636, train mean loss 0.00036280321037966836, test mean loss [0.0004621  0.00058597 0.00037488 0.00034871 0.00046678 0.00038029
 0.00054674]
Model epoch 169: train total loss -64.47976376012791, train mean loss 0.0003649361741009723, test mean loss [0.00046128 0.00061375 0.00039416 0.00033205 0.00048398 0.00038167
 0.00050397]
Model epoch 170: train total loss -64.5876190097632, train mean loss 0.00036556878123881494, test mean loss [0.00045703 0.00059661 0.00039382 0.0003357  0.00047658 0.00037746
 0.00051061]
Model epoch 171: train total loss -64.56155944711388, train mean loss 0.00039360530932462656, test mean loss [0.00044894 0.00056113 0.00039494 0.00033761 0.00046566 0.0003651
 0.00049962]
Model epoch 172: train total loss -64.63398323706875, train mean loss 0.0003644206240439488, test mean loss [0.00047027 0.00055643 0.00039227 0.00033133 0.00047021 0.00036976
 0.00050728]
Model epoch 173: train total loss -64.54509463313352, train mean loss 0.00032114225046339537, test mean loss [0.00044129 0.00055109 0.00037153 0.00033306 0.00045437 0.00036057
 0.00050865]
Model epoch 174: train total loss -64.53278527511009, train mean loss 0.00036627323424819546, test mean loss [0.0004454  0.00057703 0.00037996 0.00032573 0.00044532 0.00040117
 0.00048855]
Model epoch 175: train total loss -64.6088366152649, train mean loss 0.00031325423012873405, test mean loss [0.00045484 0.00055467 0.0003796  0.00032418 0.000453   0.00036188
 0.00049859]
Model epoch 176: train total loss -64.60993313356408, train mean loss 0.0003104102418099049, test mean loss [0.00043423 0.00056664 0.00037039 0.00032146 0.00043933 0.00036367
 0.0004991 ]
Model epoch 177: train total loss -64.57131734156673, train mean loss 0.0003247964398979636, test mean loss [0.00042067 0.00054615 0.0003703  0.00032882 0.00044614 0.00036015
 0.00047046]
Model epoch 178: train total loss -64.45742021958752, train mean loss 0.0003390159596773692, test mean loss [0.00043839 0.0005565  0.00035685 0.00033087 0.00044936 0.00035839
 0.0004812 ]
Model epoch 179: train total loss -64.77985397125036, train mean loss 0.00028738508620311195, test mean loss [0.00042009 0.00052184 0.00036557 0.00031725 0.00050054 0.00036336
 0.00046308]
Model epoch 180: train total loss -64.55943226678994, train mean loss 0.00032665310418608477, test mean loss [0.00041343 0.00055222 0.00036441 0.00031666 0.00044455 0.00033858
 0.00045376]
Model epoch 181: train total loss -64.72409327108406, train mean loss 0.00034289899942322783, test mean loss [0.0004132  0.00050855 0.00036586 0.00030702 0.00043138 0.00034215
 0.0004695 ]
Model epoch 182: train total loss -64.50898452337331, train mean loss 0.00040327683087269394, test mean loss [0.00041128 0.00051539 0.0003672  0.00032397 0.00042415 0.00034174
 0.00045413]
Model epoch 183: train total loss -64.60693117159055, train mean loss 0.0003310646315677814, test mean loss [0.00041214 0.0005078  0.00036153 0.00032467 0.00041871 0.00034473
 0.00047331]
Model epoch 184: train total loss -64.68930588960876, train mean loss 0.0003423640800253527, test mean loss [0.00040604 0.00051695 0.00035376 0.00030699 0.00049822 0.00034852
 0.00045374]
Model epoch 185: train total loss -64.52881241903923, train mean loss 0.00032402254682929396, test mean loss [0.00040067 0.00051544 0.00035289 0.00031714 0.00041801 0.00034099
 0.00045173]
Model epoch 186: train total loss -64.59040376666997, train mean loss 0.00032049984470820244, test mean loss [0.00040003 0.00048114 0.00035609 0.00030029 0.00042067 0.00034102
 0.00045405]
Model epoch 187: train total loss -64.78456577938721, train mean loss 0.0002900666768151324, test mean loss [0.00043057 0.00050647 0.00034535 0.00030465 0.00041785 0.00033449
 0.00046179]
Model epoch 188: train total loss -64.58996077566357, train mean loss 0.0003406840759393103, test mean loss [0.00039623 0.00048216 0.00033456 0.00029488 0.00041536 0.00033072
 0.00043953]
Model epoch 189: train total loss -64.74620075219065, train mean loss 0.0003224058892190952, test mean loss [0.00039458 0.00048754 0.00033333 0.00028631 0.00040914 0.00032608
 0.0004395 ]
Model epoch 190: train total loss -64.75171555055192, train mean loss 0.0003251010536193435, test mean loss [0.0003894  0.0005981  0.00032685 0.00032169 0.00043234 0.00033674
 0.00043739]
Model epoch 191: train total loss -64.61861610427697, train mean loss 0.00030055302867740757, test mean loss [0.00038672 0.00048401 0.00034215 0.00030218 0.00040612 0.00031779
 0.00044691]
Model epoch 192: train total loss -64.67712651785662, train mean loss 0.00028818144541309295, test mean loss [0.00036728 0.00047706 0.00036454 0.00029916 0.00042807 0.00031306
 0.00046446]
Model epoch 193: train total loss -64.71999981284013, train mean loss 0.00031553246066242735, test mean loss [0.00036882 0.00047431 0.0003366  0.00029808 0.00040169 0.00032832
 0.00044648]
Model epoch 194: train total loss -64.94635588925466, train mean loss 0.00026451833586710154, test mean loss [0.00037191 0.00049323 0.00032763 0.00030507 0.00039577 0.00033038
 0.0004388 ]
Model epoch 195: train total loss -64.9334145398042, train mean loss 0.0003265735692357855, test mean loss [0.00036521 0.00050699 0.00033073 0.00028884 0.00041939 0.00031655
 0.00042957]
Model epoch 196: train total loss -64.62113378542803, train mean loss 0.00027140880990982405, test mean loss [0.00036655 0.00047256 0.00032096 0.00032154 0.00039932 0.00034703
 0.00042603]
Model epoch 197: train total loss -64.66217195439994, train mean loss 0.00030374090530526645, test mean loss [0.00036735 0.00046507 0.00032794 0.00029013 0.00039465 0.00034955
 0.00040278]
Model epoch 198: train total loss -64.79831642352374, train mean loss 0.0002794036880740677, test mean loss [0.00035564 0.00050955 0.00032025 0.00030318 0.00038819 0.00030702
 0.00052006]
Model epoch 199: train total loss -64.83710169624747, train mean loss 0.000247213397846032, test mean loss [0.00036678 0.00044737 0.00034617 0.00028712 0.00041834 0.00030931
 0.00041664]
Model epoch 200: train total loss -64.8195151001305, train mean loss 0.0002523148249353376, test mean loss [0.00036048 0.00045997 0.00031948 0.00028786 0.00037564 0.00031556
 0.0004141 ]
Model epoch 201: train total loss -64.74092125751048, train mean loss 0.00031107627812864113, test mean loss [0.00035622 0.0004275  0.00031751 0.00029195 0.00038225 0.00030811
 0.00058338]
Model epoch 202: train total loss -64.82352528083453, train mean loss 0.0002569477603800735, test mean loss [0.00034781 0.00043547 0.00031643 0.00028745 0.00039924 0.00030117
 0.00046803]
Model epoch 203: train total loss -64.8245188809123, train mean loss 0.0003260567205150516, test mean loss [0.00034908 0.00043535 0.00031987 0.00029611 0.00038133 0.00031498
 0.00041331]
Model epoch 204: train total loss -64.77787447955369, train mean loss 0.00029820378937967825, test mean loss [0.00035031 0.00043455 0.0003128  0.00027268 0.0003725  0.00030009
 0.00040096]
Model epoch 205: train total loss -64.82461018209848, train mean loss 0.00025448852388900177, test mean loss [0.00033974 0.00047775 0.00030709 0.00027865 0.00036856 0.00031232
 0.00043788]
Model epoch 206: train total loss -64.75241464869434, train mean loss 0.0003097660146131142, test mean loss [0.00035269 0.00043692 0.00029605 0.00028043 0.00045054 0.00029477
 0.00040373]
Model epoch 207: train total loss -64.91072814297455, train mean loss 0.0002622078586144322, test mean loss [0.00034842 0.00042381 0.0003004  0.00029837 0.00040186 0.00030852
 0.00039664]
Model epoch 208: train total loss -64.68680091351236, train mean loss 0.00025689821845046543, test mean loss [0.00033832 0.00043087 0.00030494 0.00029296 0.00039202 0.00029898
 0.00040287]
Model epoch 209: train total loss -64.66231245847023, train mean loss 0.0002895534633578624, test mean loss [0.00034454 0.00040876 0.00032094 0.00027094 0.00036966 0.00030756
 0.00039194]
Model epoch 210: train total loss -64.84396999189644, train mean loss 0.0002966954134974547, test mean loss [0.00032913 0.00040916 0.00031244 0.00028818 0.00036125 0.00028753
 0.00039068]
Model epoch 211: train total loss -64.82353423891021, train mean loss 0.0002833776995277932, test mean loss [0.00033082 0.00043298 0.00035584 0.00026775 0.00041494 0.0002974
 0.0004066 ]
Model epoch 212: train total loss -64.73476817265856, train mean loss 0.00028789642020870447, test mean loss [0.00035479 0.00041516 0.00029711 0.0002662  0.000359   0.00031266
 0.00038737]
Model epoch 213: train total loss -64.79245912554458, train mean loss 0.00023213291659807632, test mean loss [0.00034118 0.0004153  0.00031046 0.00027094 0.00035334 0.00028967
 0.00039374]
Model epoch 214: train total loss -64.7333795161254, train mean loss 0.0002512805290062969, test mean loss [0.00033642 0.00038792 0.00031016 0.00025784 0.00034867 0.00029979
 0.00037753]
Model epoch 215: train total loss -64.96734791154776, train mean loss 0.000280954760089472, test mean loss [0.00032609 0.00040922 0.00031097 0.00026163 0.00036746 0.00027739
 0.00037044]
Model epoch 216: train total loss -65.0266500602167, train mean loss 0.00026373696920559397, test mean loss [0.00033789 0.00041238 0.00032103 0.0002685  0.00036498 0.00028907
 0.00037887]
Model epoch 217: train total loss -64.90623588056503, train mean loss 0.00026912388361304663, test mean loss [0.00032305 0.00043545 0.00029474 0.00026234 0.00035274 0.00028268
 0.00037518]
Model epoch 218: train total loss -64.76505312822209, train mean loss 0.00025093199357497536, test mean loss [0.00032077 0.00041455 0.00033006 0.00026116 0.00035458 0.00027793
 0.00037881]
Model epoch 219: train total loss -64.81865236309608, train mean loss 0.00024352418375801646, test mean loss [0.00031774 0.00039271 0.00029127 0.00026451 0.00034469 0.00030643
 0.00037431]
Model epoch 220: train total loss -64.93728111572587, train mean loss 0.00026113879679750494, test mean loss [0.00031466 0.00039479 0.00030158 0.00026104 0.00034904 0.00041627
 0.00038291]
Model epoch 221: train total loss -64.90496948897788, train mean loss 0.00022071319029456265, test mean loss [0.00032499 0.00037088 0.00032817 0.00026032 0.00034531 0.00037358
 0.00038584]
Model epoch 222: train total loss -64.7993038171634, train mean loss 0.00021092515932371824, test mean loss [0.00030759 0.00036708 0.00028883 0.00028502 0.00033384 0.0002929
 0.00038844]
Model epoch 223: train total loss -64.92755359646434, train mean loss 0.0002455063903479459, test mean loss [0.00032048 0.00040637 0.0002776  0.00027555 0.00032917 0.00027651
 0.00038763]
Model epoch 224: train total loss -65.07456438468876, train mean loss 0.0002542630782601083, test mean loss [0.00030488 0.00039142 0.0002821  0.00026293 0.00038928 0.0002728
 0.00038389]
Model epoch 225: train total loss -65.04708831259916, train mean loss 0.0002476249590472495, test mean loss [0.00030642 0.00036579 0.00029903 0.00026021 0.0003315  0.00027706
 0.00037286]
Model epoch 226: train total loss -64.84763910330281, train mean loss 0.00024184071715870113, test mean loss [0.00030014 0.00037906 0.00029234 0.00026555 0.00032636 0.00025742
 0.00036698]
Model epoch 227: train total loss -64.97526360094022, train mean loss 0.0003013533384045194, test mean loss [0.00032356 0.00038277 0.00027406 0.00027022 0.00033842 0.00026496
 0.00036511]
Model epoch 228: train total loss -64.87133765187072, train mean loss 0.0002338136231245223, test mean loss [0.00030306 0.00036789 0.00028785 0.0002506  0.00031915 0.00027616
 0.00036936]
Model epoch 229: train total loss -65.08254148050703, train mean loss 0.0002422670864703149, test mean loss [0.00029722 0.00038098 0.00027285 0.00026186 0.00031164 0.00027722
 0.00038743]
Model epoch 230: train total loss -65.05398812642873, train mean loss 0.00023629596533908536, test mean loss [0.00030165 0.00035269 0.00027359 0.00026679 0.00037046 0.00026112
 0.00037385]
Model epoch 231: train total loss -64.94811012646777, train mean loss 0.0002422032456230556, test mean loss [0.00029104 0.00035394 0.00029039 0.00025011 0.00031514 0.00027269
 0.00034887]
Model epoch 232: train total loss -65.00439909948662, train mean loss 0.00025566911880441605, test mean loss [0.00028365 0.00036923 0.00027679 0.000252   0.00030251 0.00028364
 0.00035859]
Model epoch 233: train total loss -65.06191910247418, train mean loss 0.00019751655387560674, test mean loss [0.00029284 0.00035989 0.00028771 0.00025513 0.00032643 0.00025946
 0.00033613]
Model epoch 234: train total loss -64.92987277624576, train mean loss 0.0002514289489096712, test mean loss [0.00029069 0.00035965 0.00027619 0.00026223 0.0003133  0.00028977
 0.00036111]
Model epoch 235: train total loss -64.94624502364734, train mean loss 0.00025127797505571786, test mean loss [0.00031851 0.00037452 0.00028719 0.00024348 0.00032793 0.00027764
 0.0003597 ]
Model epoch 236: train total loss -65.05535239412879, train mean loss 0.00023230050717093468, test mean loss [0.00028929 0.00034177 0.00027222 0.00024923 0.00031273 0.00027064
 0.0003383 ]
Model epoch 237: train total loss -65.15039789591887, train mean loss 0.00022416667475643232, test mean loss [0.00028662 0.00036267 0.00026897 0.0002444  0.00030991 0.00026026
 0.000343  ]
Model epoch 238: train total loss -65.00204878927578, train mean loss 0.00020011614025991132, test mean loss [0.00029696 0.0003331  0.00025612 0.00023228 0.0003117  0.00025147
 0.00033069]
Model epoch 239: train total loss -65.07304456371931, train mean loss 0.0002211221440330262, test mean loss [0.00029096 0.00034346 0.00027645 0.00024864 0.00029762 0.00026374
 0.000337  ]
Model epoch 240: train total loss -65.06336772554262, train mean loss 0.00024901753343649363, test mean loss [0.00028574 0.00033785 0.00025882 0.00024647 0.00033028 0.00025015
 0.0003295 ]
Model epoch 241: train total loss -65.06721239219593, train mean loss 0.00019721508656211272, test mean loss [0.00028588 0.00032785 0.00027304 0.00023557 0.00029835 0.00026732
 0.00037333]
Model epoch 242: train total loss -65.06419148932771, train mean loss 0.0002004297068831155, test mean loss [0.0002895  0.00032591 0.00026127 0.00024464 0.00029102 0.00024976
 0.00034064]
Model epoch 243: train total loss -64.91682363217683, train mean loss 0.00024754672364062644, test mean loss [0.00026917 0.00033132 0.00026779 0.00025019 0.00029752 0.00026306
 0.00032753]
Model epoch 244: train total loss -64.99473566135646, train mean loss 0.00022886573778676427, test mean loss [0.00027277 0.00036324 0.00026291 0.00025535 0.00033489 0.00024648
 0.00032593]
Model epoch 245: train total loss -65.23239273527929, train mean loss 0.0002093861675042624, test mean loss [0.00027932 0.00033692 0.00025225 0.00024495 0.00030673 0.00024839
 0.00032928]
Model epoch 246: train total loss -65.13197505968583, train mean loss 0.00024396511129013386, test mean loss [0.00030956 0.00033681 0.00024995 0.00026261 0.00031064 0.00024783
 0.00034499]
Model epoch 247: train total loss -65.13608557915973, train mean loss 0.0002043617977964882, test mean loss [0.0002769  0.00033474 0.00025898 0.00025719 0.0002886  0.00024871
 0.0003156 ]
Model epoch 248: train total loss -65.16930470865346, train mean loss 0.00019663008436215853, test mean loss [0.0002748  0.00032452 0.00025515 0.00024619 0.00029355 0.00024642
 0.00033199]
Model epoch 249: train total loss -65.09177140843423, train mean loss 0.00019581232958420277, test mean loss [0.00030497 0.00032189 0.00028043 0.00024405 0.00029641 0.00028638
 0.00033857]
Model epoch 250: train total loss -64.88247853868194, train mean loss 0.0001939604338748989, test mean loss [0.00027459 0.00033959 0.00025842 0.00024447 0.00029871 0.00024866
 0.00032206]
Model epoch 251: train total loss -65.15582439161321, train mean loss 0.00022415573116343708, test mean loss [0.00026747 0.00032272 0.00024842 0.00024458 0.00028061 0.0002401
 0.00031457]
Model epoch 252: train total loss -65.07672871377873, train mean loss 0.00023098595769111192, test mean loss [0.00027848 0.00032118 0.00025477 0.00022593 0.00028408 0.00024317
 0.00038382]
Model epoch 253: train total loss -64.99156847695916, train mean loss 0.0002101294558597037, test mean loss [0.00027178 0.0003638  0.00025652 0.00022711 0.00028614 0.00025116
 0.00032601]
Model epoch 254: train total loss -65.12927170641237, train mean loss 0.0002140967634845611, test mean loss [0.00026511 0.00031403 0.00027307 0.00024101 0.00031977 0.00023912
 0.00032776]
Model epoch 255: train total loss -65.0759420318121, train mean loss 0.0002418879117212614, test mean loss [0.00026479 0.00031143 0.00024709 0.00024137 0.00031535 0.00024379
 0.00031567]
Model epoch 256: train total loss -65.13067915164274, train mean loss 0.00024629665644941876, test mean loss [0.00026529 0.00032992 0.00024104 0.00022407 0.0002767  0.00024566
 0.00031599]
Model epoch 257: train total loss -65.20613401762091, train mean loss 0.00024018893703210063, test mean loss [0.00027508 0.0003136  0.00024651 0.0002283  0.0002911  0.0002511
 0.00030622]
Model epoch 258: train total loss -65.13154942000891, train mean loss 0.00021615439047843526, test mean loss [0.0002651  0.00033668 0.00024624 0.00023334 0.00027612 0.00024526
 0.00030784]
Model epoch 259: train total loss -65.20484781289045, train mean loss 0.00020355276430558485, test mean loss [0.00026815 0.00031896 0.00025192 0.00022776 0.00027583 0.00024142
 0.00032919]
Model epoch 260: train total loss -65.28204843427845, train mean loss 0.00019229325809359092, test mean loss [0.00027419 0.00033402 0.00024571 0.00022899 0.00029851 0.00023761
 0.00031494]
Model epoch 261: train total loss -65.21331619239682, train mean loss 0.00021407295236056229, test mean loss [0.00027191 0.00030924 0.00025118 0.0002424  0.00027225 0.00023056
 0.00030388]
Model epoch 262: train total loss -65.31433411855257, train mean loss 0.00014709604256423435, test mean loss [0.00025155 0.00030615 0.0002441  0.00026433 0.00027826 0.00023649
 0.00032508]
Model epoch 263: train total loss -65.14938975393072, train mean loss 0.00021848805995208607, test mean loss [0.00027186 0.00034504 0.0002551  0.00022998 0.00026105 0.0002255
 0.00030457]
Model epoch 264: train total loss -65.20677188480177, train mean loss 0.00023405764367425742, test mean loss [0.00026484 0.00029218 0.0002396  0.00023258 0.00026835 0.00022975
 0.00030729]
Model epoch 265: train total loss -65.2574252635544, train mean loss 0.00021696673409546136, test mean loss [0.00027079 0.00030146 0.00026034 0.00022537 0.00028103 0.00025249
 0.00031021]
Model epoch 266: train total loss -65.13954745071892, train mean loss 0.0002569192764552714, test mean loss [0.00024826 0.00028616 0.0002394  0.00023045 0.00026642 0.00025567
 0.00033269]
Model epoch 267: train total loss -65.25415131794648, train mean loss 0.0002289928346158361, test mean loss [0.00026017 0.00030169 0.00024737 0.0002285  0.00026777 0.00022909
 0.00029933]
Model epoch 268: train total loss -65.19010602420896, train mean loss 0.0002535983158786202, test mean loss [0.00025966 0.00031432 0.00023105 0.00021837 0.0002634  0.00025537
 0.00032477]
Model epoch 269: train total loss -65.34948125454551, train mean loss 0.00020366318691158474, test mean loss [0.00024965 0.00030082 0.00022815 0.00021266 0.00025573 0.00023364
 0.00029726]
Model epoch 270: train total loss -65.19566575795086, train mean loss 0.00019052332858803585, test mean loss [0.00024859 0.00030544 0.00024372 0.00025578 0.00025657 0.00022791
 0.00029593]
Model epoch 271: train total loss -65.27052455536565, train mean loss 0.0001727551956782852, test mean loss [0.00027353 0.00028818 0.00024806 0.00022077 0.00026228 0.00023356
 0.00028901]
Model epoch 272: train total loss -65.06585287750157, train mean loss 0.00023443495623076322, test mean loss [0.00027569 0.00028444 0.00024377 0.00022938 0.00027037 0.00025782
 0.00032086]
Model epoch 273: train total loss -65.36081005444177, train mean loss 0.00019181500782442513, test mean loss [0.00024561 0.00029273 0.0002435  0.00023194 0.00028219 0.00023514
 0.00029823]
Model epoch 274: train total loss -65.22970293419301, train mean loss 0.00019351066585753042, test mean loss [0.00026577 0.00030292 0.00024225 0.00022098 0.00025664 0.00023742
 0.00029886]
Model epoch 275: train total loss -65.25372257182678, train mean loss 0.00019707383571488917, test mean loss [0.00025244 0.00031956 0.00023251 0.00021707 0.00026221 0.00022698
 0.00029806]
Model epoch 276: train total loss -65.29469238094273, train mean loss 0.0002051531420153767, test mean loss [0.00024208 0.00037811 0.00023251 0.00020778 0.00027397 0.00022978
 0.00030902]
Model epoch 277: train total loss -65.07487674985727, train mean loss 0.00023048854876066838, test mean loss [0.00024403 0.00029186 0.00022874 0.00021147 0.00026577 0.00023467
 0.00029869]
Model epoch 278: train total loss -65.31798539861374, train mean loss 0.00016743070775820685, test mean loss [0.00024442 0.0002893  0.00024951 0.00021711 0.00025307 0.00021543
 0.0002923 ]
Model epoch 279: train total loss -65.07587029628726, train mean loss 0.00020988575017490208, test mean loss [0.00025055 0.00030528 0.00023124 0.00021755 0.00024866 0.00022461
 0.00030522]
Model epoch 280: train total loss -65.32770592217602, train mean loss 0.00016836645582457801, test mean loss [0.00024563 0.00029174 0.00022168 0.00021855 0.00026002 0.00023402
 0.00029686]
Model epoch 281: train total loss -65.34321179528031, train mean loss 0.00019129724389632482, test mean loss [0.0002425  0.00029143 0.00023511 0.00021723 0.00025293 0.00022639
 0.00028372]
Model epoch 282: train total loss -65.19712949648948, train mean loss 0.00019060766167931006, test mean loss [0.00023751 0.00027823 0.00021972 0.00021541 0.00024145 0.00021491
 0.00030996]
Model epoch 283: train total loss -65.26147614630175, train mean loss 0.0001769772615148236, test mean loss [0.00023602 0.00028486 0.00022422 0.00021005 0.00025026 0.00022216
 0.00029472]
Model epoch 284: train total loss -65.14008088411128, train mean loss 0.00019210746891575376, test mean loss [0.00023545 0.00027701 0.0002263  0.00021642 0.00024624 0.00023621
 0.00028387]
Model epoch 285: train total loss -65.3055530043685, train mean loss 0.00021250084784402322, test mean loss [0.00023836 0.00028064 0.0002241  0.00020686 0.00023865 0.00021945
 0.00029074]
Model epoch 286: train total loss -65.15284652748576, train mean loss 0.0001920372845479466, test mean loss [0.00023867 0.00028241 0.00022877 0.00021201 0.00024273 0.0002229
 0.00028786]
Model epoch 287: train total loss -65.36501979419245, train mean loss 0.00016687661255183515, test mean loss [0.00023499 0.0002645  0.00022906 0.00023031 0.00024749 0.00021637
 0.00027961]
Model epoch 288: train total loss -65.35794085851268, train mean loss 0.00017607771884618057, test mean loss [0.0002354  0.00028523 0.00022347 0.00021571 0.00023479 0.00024727
 0.00028737]
Model epoch 289: train total loss -65.3925800752806, train mean loss 0.0001755905446084775, test mean loss [0.00023318 0.00028984 0.00024918 0.00020467 0.00023941 0.0002354
 0.00028524]
Model epoch 290: train total loss -65.35779442533263, train mean loss 0.00016192599229348424, test mean loss [0.00023935 0.00026903 0.00022006 0.00020874 0.00024293 0.00023357
 0.00028516]
Model epoch 291: train total loss -65.41069183456007, train mean loss 0.0001753512547348773, test mean loss [0.00024216 0.00025804 0.00023224 0.000215   0.00023771 0.00021831
 0.00028283]
Model epoch 292: train total loss -65.28763459724877, train mean loss 0.00021477504475947475, test mean loss [0.00024743 0.00027801 0.0002226  0.000216   0.00023698 0.0002297
 0.00028056]
Model epoch 293: train total loss -65.38187745909521, train mean loss 0.00022473339752343262, test mean loss [0.00023568 0.00027234 0.00022619 0.00020479 0.0002393  0.00024333
 0.00028163]
Model epoch 294: train total loss -65.30302480504356, train mean loss 0.00021000166935859085, test mean loss [0.00023888 0.00026233 0.00022063 0.00021257 0.00025753 0.00021819
 0.00031426]
Model epoch 295: train total loss -65.43920804540699, train mean loss 0.00017812968408648946, test mean loss [0.00024096 0.00026751 0.00021774 0.00023569 0.00023336 0.00023129
 0.0002872 ]
Model epoch 296: train total loss -65.27333128336453, train mean loss 0.00023170991738092104, test mean loss [0.00024552 0.00027409 0.00021714 0.0002127  0.00024103 0.00021651
 0.00031797]
Model epoch 297: train total loss -65.44088360428384, train mean loss 0.0001943074929212578, test mean loss [0.00022817 0.0002525  0.00022011 0.00020825 0.00024893 0.00021033
 0.00029563]
Model epoch 298: train total loss -65.37410536707137, train mean loss 0.0001774100909977073, test mean loss [0.00024774 0.00027208 0.00022395 0.00020357 0.0002396  0.00021295
 0.00028124]
Model epoch 299: train total loss -65.20241347168455, train mean loss 0.00016979065852361765, test mean loss [0.00023349 0.00027526 0.00021568 0.00021467 0.00024419 0.00021195
 0.00027041]
Model epoch 300: train total loss -65.19687520822627, train mean loss 0.0001976961573508633, test mean loss [0.00024079 0.00026443 0.00021762 0.00020509 0.00024001 0.00021006
 0.00028666]
Model epoch 301: train total loss -65.1631179842115, train mean loss 0.00017391325941996808, test mean loss [0.00022418 0.00025918 0.00023062 0.00021608 0.00024195 0.00021094
 0.00027092]
Model epoch 302: train total loss -65.39932672605332, train mean loss 0.0002046156170153596, test mean loss [0.00024129 0.00027863 0.00022261 0.00020269 0.00023825 0.00020901
 0.00027461]
Model epoch 303: train total loss -65.45655570162582, train mean loss 0.00015994998166576663, test mean loss [0.00022674 0.00024396 0.00023789 0.00020686 0.00023521 0.00019822
 0.00027099]
Model epoch 304: train total loss -65.32086847835754, train mean loss 0.0001823822063048828, test mean loss [0.00023432 0.00026319 0.00022245 0.00020567 0.00023138 0.00021396
 0.00027763]
Model epoch 305: train total loss -65.40151209039806, train mean loss 0.00017821060965724498, test mean loss [0.00023711 0.00026279 0.00021146 0.00021007 0.00022938 0.00024284
 0.00029681]
Model epoch 306: train total loss -65.39631774513715, train mean loss 0.00018995709612693195, test mean loss [0.0002424  0.00025317 0.00020857 0.00019872 0.00022901 0.00024025
 0.00027443]
Model epoch 307: train total loss -65.12299873094094, train mean loss 0.00018328488519256427, test mean loss [0.0002275  0.00025247 0.00021565 0.00022978 0.00023126 0.00020513
 0.0002791 ]
Model epoch 308: train total loss -65.39581785475715, train mean loss 0.0001808252620200602, test mean loss [0.00022409 0.00025167 0.00022816 0.00019874 0.00022118 0.00020378
 0.00026737]
Model epoch 309: train total loss -65.53878353776702, train mean loss 0.00016307433446650387, test mean loss [0.00022439 0.00025601 0.00020492 0.00020162 0.00021805 0.00020543
 0.00026179]
Model epoch 310: train total loss -65.34381395091893, train mean loss 0.000206156807790713, test mean loss [0.00025529 0.00024861 0.00021108 0.00020134 0.00022828 0.00020965
 0.00027036]
Model epoch 311: train total loss -65.32770852530957, train mean loss 0.0001826622486946289, test mean loss [0.0002246  0.00024553 0.00020834 0.00021502 0.00022056 0.0002125
 0.00028147]
Model epoch 312: train total loss -65.38951029488803, train mean loss 0.00015746129690115025, test mean loss [0.00022666 0.0002473  0.00021122 0.00020229 0.00022829 0.00021044
 0.00026892]
Model epoch 313: train total loss -65.43984669667347, train mean loss 0.00018785570810715972, test mean loss [0.00021984 0.00023607 0.00021134 0.00019795 0.00023372 0.00020361
 0.00026465]
Model epoch 314: train total loss -65.35640856137927, train mean loss 0.0001928996374186918, test mean loss [0.0002239  0.00025547 0.00021371 0.00019929 0.00023647 0.00020659
 0.00027413]
Model epoch 315: train total loss -65.4970956795332, train mean loss 0.00015394563869195875, test mean loss [0.00022113 0.00023852 0.00020477 0.00019253 0.00021817 0.00020748
 0.00026904]
Model epoch 316: train total loss -65.53422922419003, train mean loss 0.00015307980275918777, test mean loss [0.00022681 0.00024037 0.00021148 0.00019558 0.00023923 0.00022658
 0.00025504]
Model epoch 317: train total loss -65.52207415026459, train mean loss 0.00017008871220187968, test mean loss [0.00022717 0.00024062 0.00020959 0.00020063 0.00021982 0.00020089
 0.00025686]
Model epoch 318: train total loss -65.5575206217994, train mean loss 0.0001565912858646688, test mean loss [0.00021754 0.0002377  0.0001991  0.00019026 0.00023223 0.0002224
 0.0002649 ]
Model epoch 319: train total loss -65.26598049850375, train mean loss 0.00017417828624412027, test mean loss [0.0002243  0.00024418 0.00020222 0.00020736 0.00021508 0.00021847
 0.00027205]
Model epoch 320: train total loss -65.48014527589275, train mean loss 0.0001618514160434243, test mean loss [0.00021591 0.00023607 0.00020941 0.00020062 0.00022197 0.00021379
 0.00025409]
Model epoch 321: train total loss -65.61733995096402, train mean loss 0.00015030415052146528, test mean loss [0.00022127 0.00024109 0.00020671 0.00020177 0.0002124  0.00020873
 0.00026481]
Model epoch 322: train total loss -65.52354590246061, train mean loss 0.0002034437251494553, test mean loss [0.00023042 0.0002539  0.0002118  0.00020978 0.00022091 0.00020117
 0.00029607]
Model epoch 323: train total loss -65.43132498126934, train mean loss 0.00017919062788135842, test mean loss [0.00022067 0.00023904 0.00020087 0.00021582 0.00021433 0.00020216
 0.00027402]
Model epoch 324: train total loss -65.17341013205458, train mean loss 0.00017379651841468004, test mean loss [0.00022111 0.00025158 0.00022407 0.00020828 0.00020911 0.00020799
 0.00026542]
Model epoch 325: train total loss -65.38837589970677, train mean loss 0.00018060945381386486, test mean loss [0.00021729 0.00024514 0.00020355 0.00020059 0.00022086 0.00020039
 0.00026566]
Model epoch 326: train total loss -65.40997498036506, train mean loss 0.0001823334113421459, test mean loss [0.00021577 0.00023817 0.00020584 0.00020195 0.00021793 0.00020449
 0.00026305]
Model epoch 327: train total loss -65.40055812694877, train mean loss 0.00016314178587885952, test mean loss [0.00022268 0.00022406 0.00020812 0.00019798 0.00021666 0.00020432
 0.00025847]
Model epoch 328: train total loss -65.48921492950618, train mean loss 0.00017639111227375905, test mean loss [0.00021605 0.00022941 0.00020581 0.0001935  0.00024212 0.00020206
 0.00025671]
Model epoch 329: train total loss -65.42592171987992, train mean loss 0.00015441893422833336, test mean loss [0.00021604 0.00023132 0.0002134  0.00018692 0.00022709 0.0001962
 0.00028367]
Model epoch 330: train total loss -65.5055999669391, train mean loss 0.00017125345819560907, test mean loss [0.00020348 0.00022333 0.00020823 0.00018281 0.0002107  0.00019949
 0.00027113]
Model epoch 331: train total loss -65.36164024074242, train mean loss 0.00015947748637506448, test mean loss [0.00020175 0.00026018 0.00020139 0.00018199 0.00020817 0.00021154
 0.00027436]
Model epoch 332: train total loss -65.50473162875703, train mean loss 0.00017539039681287446, test mean loss [0.00021435 0.0002385  0.00020821 0.00020442 0.00021426 0.00020533
 0.00024999]
Model epoch 333: train total loss -65.35928326540922, train mean loss 0.00020263216181204592, test mean loss [0.0002367  0.00023154 0.00019855 0.00020046 0.00020242 0.00020238
 0.00025744]
Model epoch 334: train total loss -65.49034979296705, train mean loss 0.00014727227524277196, test mean loss [0.00021024 0.00022259 0.0002041  0.00019131 0.00020705 0.00019528
 0.00024981]
Model epoch 335: train total loss -65.48280609856816, train mean loss 0.0001572912906621051, test mean loss [0.00020866 0.00022825 0.0002068  0.00019058 0.00021298 0.00020292
 0.00026041]
Model epoch 336: train total loss -65.46392889975999, train mean loss 0.0001763992487941894, test mean loss [0.00020758 0.00023301 0.00019539 0.00018947 0.00021174 0.00019697
 0.00025691]
Model epoch 337: train total loss -65.52406819316862, train mean loss 0.00018311665166628724, test mean loss [0.00020915 0.0002325  0.00019743 0.00018752 0.00020422 0.00020047
 0.00024773]
Model epoch 338: train total loss -65.54472832974096, train mean loss 0.00016756375475699155, test mean loss [0.00021611 0.000226   0.00019825 0.00019477 0.00021391 0.00019541
 0.00024174]
Model epoch 339: train total loss -65.47936640521357, train mean loss 0.00016314758217686413, test mean loss [0.00020677 0.00021958 0.00020811 0.0002287  0.00019347 0.00019796
 0.00025916]
Model epoch 340: train total loss -65.57045678116582, train mean loss 0.00017916796939530823, test mean loss [0.00020496 0.00021942 0.00019943 0.00019095 0.00019699 0.0001972
 0.0002528 ]
Model epoch 341: train total loss -65.50744687871159, train mean loss 0.00019330217529112885, test mean loss [0.00021708 0.00021891 0.00020805 0.00018808 0.00020633 0.00019445
 0.00026184]
Model epoch 342: train total loss -65.62955413863989, train mean loss 0.00018217223935899874, test mean loss [0.00022165 0.00022344 0.0001879  0.00020477 0.00020579 0.0001963
 0.00027494]
Model epoch 343: train total loss -65.52515679081702, train mean loss 0.0001645376397022614, test mean loss [0.00019878 0.0002121  0.00019209 0.00018888 0.00020639 0.00019405
 0.00025568]
Model epoch 344: train total loss -65.48765704943973, train mean loss 0.0001868575970657924, test mean loss [0.00020075 0.00021474 0.00019662 0.00019041 0.00021004 0.00020885
 0.00024686]
Model epoch 345: train total loss -65.36132985550162, train mean loss 0.00020086922269738566, test mean loss [0.00020753 0.00022979 0.0001968  0.00019028 0.00021614 0.00019979
 0.00024062]
Model epoch 346: train total loss -65.48917070943617, train mean loss 0.00015773916627297854, test mean loss [0.00020077 0.0002428  0.00018725 0.000197   0.00021802 0.00019571
 0.00024942]
Model epoch 347: train total loss -65.4893967378483, train mean loss 0.00014886043513247154, test mean loss [0.00020419 0.00023805 0.00019887 0.00019406 0.00021553 0.0001934
 0.00025156]
Model epoch 348: train total loss -65.52603416648036, train mean loss 0.00015896529845689825, test mean loss [0.00020572 0.00021117 0.00020518 0.00017976 0.00020678 0.00019672
 0.00025227]
Model epoch 349: train total loss -65.51860065703066, train mean loss 0.0001522980415347646, test mean loss [0.0002022  0.00021626 0.00019535 0.00018222 0.00022778 0.00019591
 0.00024457]
Model epoch 350: train total loss -65.42399879417111, train mean loss 0.00016358318221673847, test mean loss [0.00020067 0.00020389 0.00018788 0.0001845  0.00019708 0.00019722
 0.00025221]
Model epoch 351: train total loss -65.46659765677587, train mean loss 0.00018457227022902, test mean loss [0.00019836 0.00022474 0.00018541 0.00018747 0.00020993 0.00019918
 0.0002445 ]
Model epoch 352: train total loss -65.54262789506895, train mean loss 0.00015677199270551184, test mean loss [0.0002334  0.00020702 0.0001857  0.00018219 0.00019959 0.00020116
 0.00024826]
Model epoch 353: train total loss -65.51353115651617, train mean loss 0.00020217889160917661, test mean loss [0.00020507 0.00020556 0.00018168 0.0001853  0.00020663 0.00019255
 0.00024115]
Model epoch 354: train total loss -65.6361330166086, train mean loss 0.000213325495107934, test mean loss [0.00020301 0.00022441 0.00025605 0.00018108 0.00020709 0.00018943
 0.00023622]
Model epoch 355: train total loss -65.46881437751436, train mean loss 0.00017861967344454536, test mean loss [0.00019865 0.00021003 0.00019118 0.00019463 0.0002097  0.00019114
 0.00024569]
Model epoch 356: train total loss -65.33589736210268, train mean loss 0.00019873570881981053, test mean loss [0.00020031 0.00022287 0.00019041 0.00017952 0.00020681 0.00021195
 0.00024428]
Model epoch 357: train total loss -65.61010179235494, train mean loss 0.00016432866040779688, test mean loss [0.00020107 0.00021596 0.00018779 0.00018153 0.0002018  0.00018663
 0.00025401]
Model epoch 358: train total loss -65.63871069386128, train mean loss 0.00013683090275851841, test mean loss [0.0001983  0.00020642 0.00018827 0.00019128 0.00019548 0.00018546
 0.00024274]
Model epoch 359: train total loss -65.56394406430456, train mean loss 0.00014843107725906064, test mean loss [0.00019809 0.00021417 0.00018551 0.00018551 0.00021784 0.00019237
 0.00024653]
Model epoch 360: train total loss -65.70716396184831, train mean loss 0.0001566595008180228, test mean loss [0.00019552 0.00022609 0.000193   0.00018908 0.00020571 0.00017874
 0.00024459]
Model epoch 361: train total loss -65.61406060262674, train mean loss 0.0001305389362582823, test mean loss [0.00019582 0.00020542 0.0001871  0.0001785  0.00019262 0.00020356
 0.0002504 ]
Model epoch 362: train total loss -65.56914856392608, train mean loss 0.0001729282722849381, test mean loss [0.00020055 0.00020991 0.0001837  0.00018998 0.00020516 0.0001878
 0.00023262]
Model epoch 363: train total loss -65.44082930385572, train mean loss 0.0001493875153592611, test mean loss [0.00018886 0.00020367 0.00020007 0.00017652 0.00018784 0.00019314
 0.00024287]
Model epoch 364: train total loss -65.5360417606586, train mean loss 0.0001598018787313261, test mean loss [0.00019666 0.00020054 0.000186   0.00019181 0.00019591 0.00019698
 0.00023608]
Model epoch 365: train total loss -65.53464060798541, train mean loss 0.0001469177877778273, test mean loss [0.0001889  0.00020982 0.00018506 0.00018116 0.00019101 0.00019576
 0.00024029]
Model epoch 366: train total loss -65.62510363615645, train mean loss 0.00014174990938821562, test mean loss [0.0001878  0.00020867 0.00018259 0.00018737 0.00019474 0.00018899
 0.00024277]
Model epoch 367: train total loss -65.69546196500553, train mean loss 0.0001498908980481225, test mean loss [0.00019092 0.00020486 0.00019079 0.00017654 0.00020304 0.00018253
 0.00024023]
Model epoch 368: train total loss -65.66485211940024, train mean loss 0.00016670545129881484, test mean loss [0.00019805 0.00021594 0.0001875  0.00018994 0.00019573 0.00018004
 0.00024039]
Model epoch 369: train total loss -65.8165266988318, train mean loss 0.00012897647963765391, test mean loss [0.00019277 0.00018911 0.00018159 0.00017663 0.00023284 0.00018086
 0.0002263 ]
Model epoch 370: train total loss -65.62478525085103, train mean loss 0.0001643116273896562, test mean loss [0.00019541 0.00020214 0.00018698 0.00017752 0.00019446 0.0001855
 0.00024403]
Model epoch 371: train total loss -65.60050222033384, train mean loss 0.000157696799818141, test mean loss [0.00019275 0.00019693 0.00018105 0.00018609 0.00020939 0.00018601
 0.00023965]
Model epoch 372: train total loss -65.66618617245962, train mean loss 0.0001700126905503181, test mean loss [0.00019333 0.00022925 0.0001788  0.00018078 0.00018603 0.00021012
 0.00023709]
Model epoch 373: train total loss -65.74639159491504, train mean loss 0.0001633026906643282, test mean loss [0.00020198 0.0001952  0.00018255 0.00017817 0.00018686 0.00019035
 0.0002306 ]
Model epoch 374: train total loss -65.54781626288741, train mean loss 0.00015525112473548498, test mean loss [0.00019544 0.00021607 0.00017398 0.00018982 0.00018739 0.00018884
 0.00022829]
Model epoch 375: train total loss -65.71988135464643, train mean loss 0.0001587104517793683, test mean loss [0.00017871 0.00019802 0.00017903 0.0001826  0.00018788 0.00019303
 0.00023585]
Model epoch 376: train total loss -65.6529609803066, train mean loss 0.00014752268519174753, test mean loss [0.00018403 0.00019829 0.00019221 0.00019106 0.00019475 0.00018429
 0.00022661]
Model epoch 377: train total loss -65.43164239346798, train mean loss 0.00014497687460657372, test mean loss [0.0001906  0.00019648 0.00017809 0.00018014 0.00019203 0.00018791
 0.00022925]
Model epoch 378: train total loss -65.81260442628975, train mean loss 0.00012793702396520306, test mean loss [0.00019383 0.00020243 0.00017984 0.00017466 0.00020943 0.00018016
 0.00022504]
Model epoch 379: train total loss -65.6321211795513, train mean loss 0.00014804057721134705, test mean loss [0.00020072 0.00019514 0.00017731 0.00017957 0.0001867  0.00018543
 0.00023902]
Model epoch 380: train total loss -65.69107546541856, train mean loss 0.00015046190529185944, test mean loss [0.00018734 0.00019188 0.00017991 0.0001748  0.00019007 0.00020392
 0.00023644]
Model epoch 381: train total loss -65.66772754135168, train mean loss 0.00016964529294532444, test mean loss [0.00017488 0.00019033 0.00018734 0.00017042 0.00018779 0.00018185
 0.00024141]
Model epoch 382: train total loss -65.50033837258509, train mean loss 0.00014733765878062016, test mean loss [0.00019162 0.00019267 0.0001803  0.00018283 0.00019065 0.00017603
 0.00022714]
Model epoch 383: train total loss -65.60424765126353, train mean loss 0.0001834269200469446, test mean loss [0.00017848 0.00018517 0.00017715 0.00017677 0.00018596 0.0001786
 0.00023023]
Model epoch 384: train total loss -65.7740081550006, train mean loss 0.0001935048225892153, test mean loss [0.00017624 0.00019121 0.00017714 0.00017277 0.00017248 0.00019037
 0.00025275]
Model epoch 385: train total loss -65.6651680110267, train mean loss 0.00014178824745535631, test mean loss [0.00019369 0.00019058 0.00018427 0.00018263 0.00017745 0.00018393
 0.00022274]
Model epoch 386: train total loss -65.60393305398622, train mean loss 0.0001566187556070814, test mean loss [0.00018691 0.00020304 0.00017874 0.00018985 0.00019468 0.00018237
 0.00022987]
Model epoch 387: train total loss -65.59778110821769, train mean loss 0.00014456514548604588, test mean loss [0.00018233 0.0001871  0.00017064 0.00017738 0.00018438 0.00017334
 0.0002249 ]
Model epoch 388: train total loss -65.76912222992672, train mean loss 0.00014074514406998983, test mean loss [0.00018529 0.00019766 0.00018801 0.00017253 0.00018252 0.00017473
 0.0002356 ]
Model epoch 389: train total loss -65.68548060017616, train mean loss 0.00016169418446813075, test mean loss [0.00018363 0.00018984 0.00017397 0.00019328 0.00019544 0.00017644
 0.00021792]
Model epoch 390: train total loss -65.7771349555567, train mean loss 0.0001251988273419598, test mean loss [0.00017866 0.00019384 0.00016749 0.00017998 0.00018557 0.00018944
 0.00024273]
Model epoch 391: train total loss -65.67316034507618, train mean loss 0.0001239677263259045, test mean loss [0.00019158 0.00019274 0.00017203 0.00017443 0.00018445 0.00018829
 0.00022506]
Model epoch 392: train total loss -65.66308497489017, train mean loss 0.0001657442325411934, test mean loss [0.00018571 0.00023127 0.0001766  0.00017063 0.00017559 0.00017924
 0.000219  ]
Model epoch 393: train total loss -65.72301223531815, train mean loss 0.00013655664126731778, test mean loss [0.00018575 0.00021746 0.00016924 0.0001681  0.00022022 0.00021946
 0.0002246 ]
Model epoch 394: train total loss -65.66817914392938, train mean loss 0.00015253208187839844, test mean loss [0.00017747 0.00018733 0.00018232 0.00016433 0.00019467 0.00017823
 0.00021844]
Model epoch 395: train total loss -65.57746462250849, train mean loss 0.00014576462788180202, test mean loss [0.00018081 0.00018776 0.00016727 0.00017098 0.00017459 0.00017111
 0.00021978]
Model epoch 396: train total loss -65.74261572009398, train mean loss 0.0001561313610091705, test mean loss [0.00018712 0.00020787 0.00017645 0.00017804 0.00018824 0.00017432
 0.00022318]
Model epoch 397: train total loss -65.55845362114326, train mean loss 0.0001538923515418672, test mean loss [0.00017204 0.00019309 0.00016908 0.00016698 0.00017965 0.00018216
 0.00022199]
Model epoch 398: train total loss -65.53417574682176, train mean loss 0.00013449065149751256, test mean loss [0.00017557 0.00018603 0.00017563 0.00017213 0.00017261 0.00017861
 0.00024096]
Model epoch 399: train total loss -65.65944134862448, train mean loss 0.00014465063840325592, test mean loss [0.00017159 0.00017918 0.00017146 0.0001768  0.00017809 0.0001728
 0.00022748]
Model epoch 400: train total loss -65.70688817621199, train mean loss 0.0001315468228717047, test mean loss [0.00018364 0.00019156 0.000189   0.00017072 0.00018284 0.00017237
 0.00023916]
Model epoch 401: train total loss -65.76783393659281, train mean loss 0.00017246498834984315, test mean loss [0.00018363 0.00017745 0.00016606 0.00016409 0.00017733 0.00017349
 0.00021846]
Model epoch 402: train total loss -65.87348199165262, train mean loss 0.00014199831137578744, test mean loss [0.00018046 0.00018056 0.0001729  0.00017119 0.00018745 0.00017015
 0.00021581]
Model epoch 403: train total loss -65.68533322761081, train mean loss 0.0001443121884054103, test mean loss [0.00019318 0.00018629 0.00017369 0.00018166 0.00018787 0.00017726
 0.0002147 ]
Model epoch 404: train total loss -65.7391401939299, train mean loss 0.0001367094307378992, test mean loss [0.00017835 0.00017849 0.00017224 0.00017247 0.00018586 0.00017684
 0.00023311]
Model epoch 405: train total loss -65.72206233445097, train mean loss 0.0001533099115277846, test mean loss [0.00016861 0.00018756 0.00017733 0.0001682  0.00017513 0.00018075
 0.00021165]
Model epoch 406: train total loss -65.71629577889627, train mean loss 0.00014533478493678408, test mean loss [0.00017502 0.00018074 0.00017776 0.00018202 0.00017138 0.00017858
 0.00021531]
Model epoch 407: train total loss -65.8060921278736, train mean loss 0.00014635227780845063, test mean loss [0.00016901 0.00018242 0.00017935 0.00016891 0.00016853 0.00017155
 0.00023429]
Model epoch 408: train total loss -65.89421887230812, train mean loss 0.00014072552070251498, test mean loss [0.00017947 0.00017029 0.00016976 0.00017139 0.00018794 0.00017316
 0.00023201]
Model epoch 409: train total loss -65.7288935069927, train mean loss 0.00013478918470274899, test mean loss [0.00017498 0.00016998 0.00017076 0.00016836 0.00018832 0.00017591
 0.00023385]
Model epoch 410: train total loss -65.64111332059788, train mean loss 0.000141436933504098, test mean loss [0.000182   0.00017969 0.00016234 0.00016265 0.00018292 0.00017869
 0.00022969]
Model epoch 411: train total loss -65.61304777710704, train mean loss 0.000136975043376844, test mean loss [0.00018572 0.00018843 0.00016438 0.00017443 0.00016933 0.00017305
 0.00021706]
Model epoch 412: train total loss -65.71096548864702, train mean loss 0.0001354532088738835, test mean loss [0.0001772  0.00019394 0.0001799  0.00016946 0.00018389 0.00017817
 0.00022346]
Model epoch 413: train total loss -65.81233693528637, train mean loss 0.00012733534649282568, test mean loss [0.00017145 0.00017451 0.00017517 0.00016676 0.00017388 0.00017204
 0.00024496]
Model epoch 414: train total loss -65.82713846621363, train mean loss 0.00014429605285656608, test mean loss [0.00017864 0.00017534 0.00016682 0.00017589 0.00017656 0.0001715
 0.00021108]
Model epoch 415: train total loss -65.68492681038573, train mean loss 0.00014339998721142331, test mean loss [0.00017159 0.00017388 0.00017444 0.00016846 0.00017365 0.00017422
 0.00021563]
Model epoch 416: train total loss -65.87575283060491, train mean loss 0.00013174090381214325, test mean loss [0.00017135 0.00019284 0.00016406 0.0001635  0.00018172 0.00017188
 0.00020773]
Model epoch 417: train total loss -65.67919627714895, train mean loss 0.00012806358794661266, test mean loss [0.00017342 0.00017944 0.0001689  0.000173   0.00018811 0.00017244
 0.00021896]
Model epoch 418: train total loss -65.82544174184896, train mean loss 0.00015068700321073974, test mean loss [0.00017215 0.00019015 0.00016333 0.0001635  0.00016768 0.00019252
 0.00020447]
Model epoch 419: train total loss -65.76252276927477, train mean loss 0.00013639817492762802, test mean loss [0.00017049 0.00017732 0.00016894 0.00016736 0.00017363 0.00017006
 0.00021473]
Model epoch 420: train total loss -65.69371560973693, train mean loss 0.000140594522680875, test mean loss [0.00017627 0.00016875 0.00016749 0.00017055 0.00017735 0.00016975
 0.00021522]
Model epoch 421: train total loss -65.84506644246918, train mean loss 0.00013287556805143707, test mean loss [0.00018417 0.00017333 0.00016672 0.00016878 0.00017772 0.00019788
 0.0002089 ]
Model epoch 422: train total loss -65.64288098560284, train mean loss 0.00013651115918071095, test mean loss [0.00017215 0.0001738  0.00016928 0.00019049 0.00017051 0.00020582
 0.0002083 ]
Model epoch 423: train total loss -65.95286780546466, train mean loss 0.0001391545877327136, test mean loss [0.0001683  0.00016824 0.00016338 0.00016858 0.00017631 0.00016983
 0.00020641]
Model epoch 424: train total loss -65.99112912270091, train mean loss 0.00013422167851424104, test mean loss [0.00017031 0.00018679 0.00016732 0.00016056 0.00017187 0.00017149
 0.0002131 ]
Model epoch 425: train total loss -65.80640212055536, train mean loss 0.0001358986985520601, test mean loss [0.00016502 0.00016465 0.00016726 0.00016444 0.00018087 0.00017033
 0.00022551]
Model epoch 426: train total loss -65.78969779897336, train mean loss 0.00013772262182487865, test mean loss [0.0001727  0.00016888 0.00016725 0.00016089 0.00017222 0.00017112
 0.00021478]
Model epoch 427: train total loss -65.83467651425093, train mean loss 0.00012433840783540983, test mean loss [0.00017396 0.00017249 0.00016978 0.00017682 0.0001647  0.00017364
 0.00021151]
Model epoch 428: train total loss -65.66759295804967, train mean loss 0.0001494189593274828, test mean loss [0.00016887 0.00017244 0.00016834 0.00016501 0.00016456 0.00016153
 0.00021559]
Model epoch 429: train total loss -65.86892091220169, train mean loss 0.00013248160183103883, test mean loss [0.00016128 0.00017946 0.00016883 0.00016118 0.00017262 0.00017833
 0.00020964]
Model epoch 430: train total loss -65.8193587215363, train mean loss 0.00014845366780592926, test mean loss [0.00017221 0.00017002 0.00016637 0.00016991 0.00017436 0.00016438
 0.00021809]
Model epoch 431: train total loss -65.58614926281629, train mean loss 0.0001368833694011434, test mean loss [0.00017026 0.00017293 0.00016307 0.00016128 0.00017705 0.00016792
 0.00020888]
Model epoch 432: train total loss -65.77474471742197, train mean loss 0.0001502402840714598, test mean loss [0.00018003 0.00017586 0.00016533 0.000159   0.00016627 0.0001656
 0.00020554]
Model epoch 433: train total loss -65.96706454597371, train mean loss 0.0001345637416335048, test mean loss [0.00017469 0.00016354 0.00015819 0.00017708 0.00016702 0.00017567
 0.00020372]
Model epoch 434: train total loss -65.88802890556089, train mean loss 0.00014819343697466592, test mean loss [0.00016941 0.00017629 0.00016096 0.00016042 0.00017455 0.00017113
 0.00021143]
Model epoch 435: train total loss -65.70324034287255, train mean loss 0.0001262356486600994, test mean loss [0.00016658 0.00017481 0.00016442 0.0001648  0.00016753 0.00016655
 0.00021872]
Model epoch 436: train total loss -65.85705111851475, train mean loss 0.00013136024341099412, test mean loss [0.0001572  0.00016905 0.00016904 0.00015687 0.00019655 0.00018023
 0.00020106]
Model epoch 437: train total loss -65.74978266968985, train mean loss 0.0001362824814317005, test mean loss [0.00016851 0.00016184 0.0001636  0.00016595 0.00018917 0.00016403
 0.00020456]
Model epoch 438: train total loss -65.85758165685475, train mean loss 0.0001223198296629773, test mean loss [0.00017229 0.00016621 0.00016011 0.0001613  0.0001839  0.00016629
 0.00019912]
Model epoch 439: train total loss -65.90292182884463, train mean loss 0.0001492122795724276, test mean loss [0.00015814 0.00016279 0.00016522 0.00015331 0.000169   0.00017437
 0.00021369]
Model epoch 440: train total loss -65.77443499300347, train mean loss 0.00013416096354325278, test mean loss [0.00016235 0.00016525 0.00016677 0.00016787 0.00016634 0.00016849
 0.00020566]
Model epoch 441: train total loss -65.99147143996254, train mean loss 0.00012310042146639185, test mean loss [0.00016644 0.00016563 0.0001711  0.00016513 0.00017039 0.00016844
 0.00022737]
Model epoch 442: train total loss -65.86617754345974, train mean loss 0.0001387592131335175, test mean loss [0.00017311 0.00016011 0.00015954 0.00017053 0.00017362 0.00016974
 0.00020905]
Model epoch 443: train total loss -65.75605565197318, train mean loss 0.00013813819998314742, test mean loss [0.00016871 0.00016208 0.00017747 0.00015705 0.00017027 0.00016125
 0.00019827]
Model epoch 444: train total loss -65.81623327591367, train mean loss 0.00012550888258586402, test mean loss [0.00015965 0.00016323 0.00017072 0.00016254 0.00016454 0.00016145
 0.00020682]
Model epoch 445: train total loss -65.79738698200907, train mean loss 0.00013253970674470753, test mean loss [0.0001603  0.00015657 0.00015708 0.00019107 0.0001619  0.00016175
 0.00019928]
Model epoch 446: train total loss -65.67928996580044, train mean loss 0.00012946184489143761, test mean loss [0.00016124 0.0001678  0.00016612 0.00016007 0.00017197 0.00017146
 0.00019829]
Model epoch 447: train total loss -65.8902421738464, train mean loss 0.00013742739634821217, test mean loss [0.00016052 0.00018223 0.00015743 0.00015418 0.00016211 0.00016382
 0.00019976]
Model epoch 448: train total loss -65.84211289088617, train mean loss 0.00011678796124920524, test mean loss [0.00016586 0.0001685  0.00016419 0.00016058 0.00016181 0.0001647
 0.00020548]
Model epoch 449: train total loss -65.78056132135275, train mean loss 0.00012239285475380244, test mean loss [0.00017126 0.00016674 0.00016556 0.00015785 0.00017095 0.00016568
 0.0001996 ]
Model epoch 450: train total loss -65.82904662722929, train mean loss 0.00013613406225727187, test mean loss [0.00016658 0.00016976 0.00015457 0.00016836 0.00016481 0.0001609
 0.00020417]
Model epoch 451: train total loss -65.88940241985598, train mean loss 0.00013650331526932316, test mean loss [0.00016164 0.00016339 0.00016441 0.00016433 0.00016008 0.00016257
 0.00020333]
Model epoch 452: train total loss -65.82160843898262, train mean loss 0.0001375845541922278, test mean loss [0.00016504 0.00015985 0.00016744 0.00017131 0.00016612 0.0001714
 0.00020009]
Model epoch 453: train total loss -65.9283275653212, train mean loss 0.00012510516231921284, test mean loss [0.0001572  0.00016182 0.00015623 0.00017165 0.00017686 0.00016238
 0.00019396]
Model epoch 454: train total loss -65.72501989650611, train mean loss 0.00013632032916006823, test mean loss [0.00015977 0.00016595 0.00016273 0.00015545 0.00015735 0.00015587
 0.00019541]
Model epoch 455: train total loss -65.94891309972913, train mean loss 0.00012200453416959963, test mean loss [0.00015706 0.00015398 0.0001629  0.00016322 0.00016697 0.00015661
 0.00019261]
Model epoch 456: train total loss -65.71672961729435, train mean loss 0.00014790706509256238, test mean loss [0.00015333 0.00015941 0.00016151 0.00015276 0.0001718  0.0001595
 0.00020091]
Model epoch 457: train total loss -65.85646069104162, train mean loss 0.000136906211252547, test mean loss [0.00015659 0.00016789 0.00015798 0.00015073 0.00018076 0.00015392
 0.00020321]
Model epoch 458: train total loss -65.64692073816236, train mean loss 0.00016842588957167423, test mean loss [0.00016696 0.00016386 0.00016999 0.00015728 0.00017366 0.00015906
 0.00020079]
Model epoch 459: train total loss -65.64617121615267, train mean loss 0.00013113553757829058, test mean loss [0.00016403 0.00016815 0.00016236 0.00015654 0.00016216 0.00016698
 0.00021051]
Model epoch 460: train total loss -65.86258152461865, train mean loss 0.00012983106006102068, test mean loss [0.00016063 0.00016815 0.00016479 0.00015176 0.00016206 0.00016515
 0.00019461]
Model epoch 461: train total loss -65.79629208842896, train mean loss 0.00012492044785908135, test mean loss [0.00015985 0.00016318 0.00015693 0.00015973 0.00015864 0.00016476
 0.00020001]
Model epoch 462: train total loss -65.81167377250941, train mean loss 0.00015236103640855767, test mean loss [0.00015166 0.00015835 0.00015517 0.00015334 0.00016697 0.00015864
 0.00020639]
Model epoch 463: train total loss -65.84641469054495, train mean loss 0.00013417032352098997, test mean loss [0.0001597  0.00016476 0.00015821 0.00015715 0.00015832 0.00015524
 0.00020277]
Model epoch 464: train total loss -65.94731561708093, train mean loss 0.00012486525737516598, test mean loss [0.00015897 0.00015729 0.0001541  0.00015629 0.0001598  0.0001564
 0.00019942]
Model epoch 465: train total loss -65.87892121031926, train mean loss 0.0001245105490157295, test mean loss [0.00015329 0.00016607 0.00015358 0.00016105 0.00016272 0.00015644
 0.00019969]
Model epoch 466: train total loss -65.91960542694028, train mean loss 0.0001224189270137692, test mean loss [0.0001634  0.00015691 0.00015066 0.00016674 0.00015243 0.00016034
 0.00019694]
Model epoch 467: train total loss -65.8573332552182, train mean loss 0.00011826079070194405, test mean loss [0.00015525 0.0001534  0.00016276 0.00017627 0.00016201 0.00015344
 0.00020325]
Model epoch 468: train total loss -65.91009686975305, train mean loss 0.00012316056479515173, test mean loss [0.00015994 0.00015892 0.00016325 0.00015291 0.00015792 0.00015879
 0.00020847]
Model epoch 469: train total loss -65.87907760938042, train mean loss 0.00014456581885071554, test mean loss [0.00015508 0.00016763 0.0001644  0.00016127 0.00016661 0.00015891
 0.00019547]
Model epoch 470: train total loss -65.91848166829432, train mean loss 0.0001257854521570762, test mean loss [0.00017299 0.00015685 0.00015672 0.00015798 0.00015158 0.00015037
 0.00019251]
Model epoch 471: train total loss -65.92009548176028, train mean loss 0.00015081859455950562, test mean loss [0.00015337 0.00015563 0.00015298 0.00016522 0.00016118 0.00015917
 0.00019365]
Model epoch 472: train total loss -66.0057508060649, train mean loss 0.00012938798061671366, test mean loss [0.000152   0.00016278 0.00015053 0.00015339 0.00016809 0.00015846
 0.00019582]
Model epoch 473: train total loss -66.0515455082979, train mean loss 0.00013840740653485545, test mean loss [0.00014995 0.00015071 0.00015048 0.00015481 0.00015972 0.00016691
 0.00020018]
Model epoch 474: train total loss -66.01504570958241, train mean loss 0.00013065523372030965, test mean loss [0.00015236 0.0001535  0.00015209 0.00015334 0.00015669 0.00015796
 0.00020038]
Model epoch 475: train total loss -65.9521332253488, train mean loss 0.00011659316680874181, test mean loss [0.00016055 0.00016761 0.00014876 0.00015437 0.0001561  0.0001579
 0.00018957]
Model epoch 476: train total loss -65.85138472566162, train mean loss 0.00012015875049436148, test mean loss [0.0001549  0.0001711  0.00015788 0.00014587 0.00015306 0.00016314
 0.00019646]
Model epoch 477: train total loss -65.83589880021162, train mean loss 0.00012760493831651628, test mean loss [0.00015293 0.00015504 0.00015728 0.00015148 0.00015528 0.00015931
 0.00019209]
Model epoch 478: train total loss -65.83494282577526, train mean loss 0.00012389713779870445, test mean loss [0.00015051 0.00016032 0.00015224 0.00015879 0.00015891 0.00016321
 0.00018913]
Model epoch 479: train total loss -65.93879446118184, train mean loss 0.00013091409421894207, test mean loss [0.00015977 0.00015367 0.00016052 0.00015247 0.00016357 0.00016403
 0.00019181]
Model epoch 480: train total loss -65.84624415031831, train mean loss 0.00013523952970618367, test mean loss [0.00015404 0.00015659 0.00015242 0.00016172 0.00016546 0.00015601
 0.00018507]
Model epoch 481: train total loss -65.99152398065621, train mean loss 0.00012140495590478308, test mean loss [0.00016763 0.00015363 0.00015991 0.00015299 0.00016202 0.00015408
 0.0001978 ]
Model epoch 482: train total loss -65.89628285395212, train mean loss 0.00013799693572888547, test mean loss [0.0001598  0.00015407 0.0001547  0.00014361 0.0001601  0.00014736
 0.00019384]
Model epoch 483: train total loss -65.91088609399935, train mean loss 0.00012032553417058359, test mean loss [0.00015109 0.00015943 0.00016403 0.00015368 0.00019855 0.0001642
 0.00019006]
Model epoch 484: train total loss -65.96084976509253, train mean loss 0.00011706935713085013, test mean loss [0.00015163 0.00016225 0.00015957 0.00015173 0.00017113 0.00015628
 0.00020183]
Model epoch 485: train total loss -66.00458526712458, train mean loss 0.00013231269358807924, test mean loss [0.00014842 0.00015662 0.00014859 0.00014548 0.00016624 0.00015848
 0.0001907 ]
Model epoch 486: train total loss -65.99001912037207, train mean loss 0.00013397652467571534, test mean loss [0.00016281 0.00015691 0.00015381 0.00015147 0.00015114 0.00015898
 0.0001959 ]
Model epoch 487: train total loss -65.85972177392938, train mean loss 0.00013222994301922376, test mean loss [0.00015405 0.00015118 0.00015088 0.00014545 0.000153   0.00014965
 0.00019144]
Model epoch 488: train total loss -66.03075311242014, train mean loss 0.00011353470163744969, test mean loss [0.00015375 0.00016161 0.00015043 0.00015651 0.00015295 0.00015561
 0.00019479]
Model epoch 489: train total loss -65.98181874071093, train mean loss 0.00011676225492152865, test mean loss [0.00015148 0.00016335 0.00017975 0.00015447 0.00015442 0.00014631
 0.00019134]
Model epoch 490: train total loss -65.93046820673558, train mean loss 0.00012641426070539403, test mean loss [0.00014941 0.00015211 0.00015934 0.00015896 0.0001491  0.00015565
 0.00018884]
Model epoch 491: train total loss -65.88220757256374, train mean loss 0.0001257266735797435, test mean loss [0.00014672 0.00015545 0.00015059 0.00015761 0.00015948 0.00015932
 0.00018204]
Model epoch 492: train total loss -66.0031613371674, train mean loss 0.0001327496030021654, test mean loss [0.00015285 0.00014618 0.00015741 0.00015122 0.00015346 0.00015257
 0.00018322]
Model epoch 493: train total loss -65.9045068844262, train mean loss 0.0001244266348777177, test mean loss [0.00015058 0.00015233 0.00015428 0.00015772 0.00015406 0.00015162
 0.00019223]
Model epoch 494: train total loss -65.93791099307008, train mean loss 0.00012452404878571902, test mean loss [0.00015098 0.00015053 0.00014895 0.00015276 0.00015141 0.00015672
 0.00018148]
Model epoch 495: train total loss -65.9590514270971, train mean loss 0.0001348477416604984, test mean loss [0.00015378 0.00015086 0.0001521  0.00014756 0.00015058 0.00015592
 0.00019361]
Model epoch 496: train total loss -65.74364246562274, train mean loss 0.0001260562001482373, test mean loss [0.00014684 0.00016473 0.0001522  0.00014863 0.00015636 0.00016193
 0.00019062]
Model epoch 497: train total loss -65.90538839396861, train mean loss 0.00011799981698234295, test mean loss [0.0001523  0.00015087 0.00015198 0.0001443  0.00015934 0.00015403
 0.00019339]
Model epoch 498: train total loss -66.00792746297668, train mean loss 0.00011530041349575109, test mean loss [0.00015481 0.0001441  0.00016384 0.00014725 0.00015607 0.00015584
 0.00018407]
Model epoch 499: train total loss -66.01253985767983, train mean loss 0.0001283849421541632, test mean loss [0.00016858 0.00014842 0.00015618 0.00014904 0.00015364 0.00016335
 0.00018479]
Model epoch 500: train total loss -65.8234156619754, train mean loss 0.0001317689961417535, test mean loss [0.00014352 0.00015061 0.00016274 0.00014629 0.00016642 0.00015526
 0.00019421]
Model epoch 501: train total loss -65.87487564354906, train mean loss 0.00011641601079423785, test mean loss [0.00014531 0.00013992 0.00015934 0.00014842 0.00015465 0.00015815
 0.0001882 ]
Model epoch 502: train total loss -66.16323050588167, train mean loss 0.000143580641389813, test mean loss [0.00015603 0.00014435 0.00015209 0.00015017 0.00014809 0.00016225
 0.00018129]
Model epoch 503: train total loss -65.96930133785932, train mean loss 0.00011295879877581512, test mean loss [0.00014379 0.00014953 0.00015659 0.0001576  0.00015722 0.00015094
 0.00017957]
Model epoch 504: train total loss -65.99780577558644, train mean loss 0.00011178018113442817, test mean loss [0.00015568 0.00014394 0.00014539 0.00014993 0.00016048 0.00016019
 0.00018269]
Model epoch 505: train total loss -66.0080182749408, train mean loss 0.00012842571084452378, test mean loss [0.00017912 0.00016239 0.00014773 0.00015041 0.00017263 0.00014896
 0.0001834 ]
Model epoch 506: train total loss -66.06439974683543, train mean loss 0.00011696417462539936, test mean loss [0.00014986 0.00015698 0.00015325 0.00014417 0.000148   0.00015397
 0.00018407]
Model epoch 507: train total loss -65.98133111150939, train mean loss 0.00011317235321860334, test mean loss [0.00014721 0.00015896 0.00015048 0.00014419 0.00015421 0.00015353
 0.0001854 ]
Model epoch 508: train total loss -66.07734461997613, train mean loss 0.00011908317458561158, test mean loss [0.00016354 0.00014297 0.00014839 0.00014689 0.00015702 0.0001507
 0.00018832]
Model epoch 509: train total loss -66.01967934180786, train mean loss 0.00012904953269579544, test mean loss [0.00014299 0.00014916 0.00014374 0.00015633 0.00015668 0.0001455
 0.0001863 ]
Model epoch 510: train total loss -66.0697377409316, train mean loss 0.00012034582201493373, test mean loss [0.00015309 0.00014379 0.00014314 0.00015087 0.0001505  0.00014607
 0.00018499]
Model epoch 511: train total loss -66.06916162985569, train mean loss 0.00011869546945878824, test mean loss [0.00014455 0.00015202 0.00015195 0.00015117 0.00015175 0.00015518
 0.00018432]
Model epoch 512: train total loss -65.97677747416559, train mean loss 0.00011708769179239335, test mean loss [0.00014465 0.00015717 0.00014468 0.00014288 0.00015132 0.00014828
 0.00018544]
Model epoch 513: train total loss -65.88536114588933, train mean loss 0.00013838431117795617, test mean loss [0.00014498 0.00014751 0.00014326 0.00014485 0.00014869 0.0001473
 0.00018498]
Model epoch 514: train total loss -65.90196708096688, train mean loss 0.00015158774602076647, test mean loss [0.00014989 0.00014196 0.0001476  0.00015636 0.00014833 0.00014295
 0.00017967]
Model epoch 515: train total loss -66.06316385817439, train mean loss 0.00012178635873746832, test mean loss [0.00014551 0.00014351 0.00015293 0.00014223 0.00014918 0.00014937
 0.00018169]
Model epoch 516: train total loss -66.08901626455209, train mean loss 0.00011988439861087253, test mean loss [0.00015064 0.00014052 0.00015039 0.00014888 0.00014851 0.00015734
 0.00017677]
Model epoch 517: train total loss -66.04299698979548, train mean loss 0.00012092335258577838, test mean loss [0.00014556 0.00015385 0.00014656 0.00014203 0.00016632 0.00015545
 0.00017377]
Model epoch 518: train total loss -66.12517085252722, train mean loss 0.00011858938406670227, test mean loss [0.00014533 0.00015209 0.0001549  0.00014879 0.00017486 0.00014449
 0.00018569]
Model epoch 519: train total loss -66.17971706464931, train mean loss 0.00011884229329181283, test mean loss [0.00014432 0.00016432 0.00014474 0.0001447  0.00014925 0.00014283
 0.00018354]
Model epoch 520: train total loss -66.17829393256571, train mean loss 0.00012206784983156625, test mean loss [0.00014585 0.00014526 0.00016176 0.00014758 0.00014502 0.00014386
 0.00018634]
Model epoch 521: train total loss -65.99380273665469, train mean loss 0.00012297679708257628, test mean loss [0.00014317 0.00013712 0.00015016 0.00015444 0.00015192 0.00014645
 0.00018238]
Model epoch 522: train total loss -65.91213861497471, train mean loss 0.0001257602333390118, test mean loss [0.00015555 0.00014981 0.00014982 0.00014015 0.00014924 0.00014812
 0.00018053]
Model epoch 523: train total loss -65.70953209610732, train mean loss 0.0001332015805717728, test mean loss [0.00015041 0.00015332 0.00014671 0.00015098 0.0001469  0.00016212
 0.00017929]
Model epoch 524: train total loss -65.89295598507097, train mean loss 0.00011709641823348286, test mean loss [0.00014445 0.00014527 0.00014243 0.00013782 0.00015268 0.00014262
 0.00017681]
Model epoch 525: train total loss -66.00954217047993, train mean loss 0.00012982138500954927, test mean loss [0.00014638 0.0001474  0.00014396 0.00014687 0.00014908 0.0001508
 0.00017753]
Model epoch 526: train total loss -66.17162318625861, train mean loss 0.00011265839531874283, test mean loss [0.0001409  0.00014157 0.0001398  0.00014401 0.00014194 0.00016155
 0.00017368]
Model epoch 527: train total loss -66.16133426648393, train mean loss 0.00012030052152680655, test mean loss [0.00015543 0.00014064 0.0001506  0.00014662 0.00014664 0.00014862
 0.00018414]
Model epoch 528: train total loss -66.11078924672034, train mean loss 0.00012468454426066856, test mean loss [0.00014342 0.00014828 0.00014807 0.00014141 0.00014698 0.00014558
 0.00017397]
Model epoch 529: train total loss -65.89045497039697, train mean loss 0.00012487086159118725, test mean loss [0.00015131 0.00014233 0.00014974 0.00013676 0.00014685 0.00020955
 0.00018209]
Model epoch 530: train total loss -66.02667203512401, train mean loss 0.00011149305392626968, test mean loss [0.00013998 0.00013762 0.00015851 0.00015056 0.00014543 0.00015334
 0.00017893]
Model epoch 531: train total loss -66.11181546452642, train mean loss 0.00010998577357886272, test mean loss [0.00014059 0.00014532 0.0001574  0.00014111 0.0001415  0.0001559
 0.00016848]
Model epoch 532: train total loss -65.98158619134635, train mean loss 0.00011440217068215898, test mean loss [0.00014215 0.00014694 0.00014179 0.00014732 0.00015555 0.0001516
 0.00018016]
Model epoch 533: train total loss -66.1266284355305, train mean loss 0.00011740796043418963, test mean loss [0.0001406  0.00014722 0.00014128 0.00014513 0.00014421 0.00014129
 0.00017253]
Model epoch 534: train total loss -66.23144254334714, train mean loss 0.00010607331356912738, test mean loss [0.00013988 0.00015299 0.00014076 0.00014604 0.00014918 0.0001526
 0.00017098]
Model epoch 535: train total loss -66.14918181863624, train mean loss 0.0001227932628970747, test mean loss [0.0001398  0.00015057 0.00014065 0.00014436 0.00014665 0.00015199
 0.00017462]
Model epoch 536: train total loss -66.01755750121117, train mean loss 0.00011617659565465179, test mean loss [0.00013805 0.00014703 0.00013723 0.0001454  0.00014334 0.00013727
 0.00017451]
Model epoch 537: train total loss -66.1633253429212, train mean loss 0.00012303094846342173, test mean loss [0.00013744 0.00014879 0.00014915 0.00015984 0.00014892 0.00014966
 0.00017618]
Model epoch 538: train total loss -66.04973949673672, train mean loss 0.0001143794618169147, test mean loss [0.00014972 0.00015943 0.00014533 0.00014552 0.00015444 0.00015593
 0.00017797]
Model epoch 539: train total loss -66.14005398032276, train mean loss 0.00011332871346412449, test mean loss [0.00014563 0.00016248 0.00014571 0.00013996 0.00014826 0.00013848
 0.00017969]
Model epoch 540: train total loss -66.05589780842074, train mean loss 0.00011182652308375953, test mean loss [0.00013688 0.00014595 0.00014842 0.00013976 0.00016214 0.00015143
 0.0001782 ]
Model epoch 541: train total loss -65.99293428201285, train mean loss 0.00011980797551692467, test mean loss [0.00013657 0.00013993 0.00015202 0.00015136 0.00014575 0.00016019
 0.00017481]
Model epoch 542: train total loss -65.82016497615297, train mean loss 0.00011507437352878312, test mean loss [0.00014973 0.00014416 0.00014233 0.00014302 0.00015128 0.0001486
 0.00018211]
Model epoch 543: train total loss -66.1585138978999, train mean loss 0.00011016399283443615, test mean loss [0.00014302 0.00014065 0.00014127 0.00013959 0.00016016 0.00014821
 0.00019119]
Model epoch 544: train total loss -66.13083162048011, train mean loss 0.00010592654805962775, test mean loss [0.00013245 0.0001393  0.00013814 0.00014188 0.00014402 0.00014467
 0.00017284]
Model epoch 545: train total loss -66.11624726205623, train mean loss 0.00010390371545450281, test mean loss [0.00013999 0.0001327  0.00013968 0.00014249 0.00014375 0.00014682
 0.00017492]
Model epoch 546: train total loss -66.08015806796226, train mean loss 0.00010889350618582178, test mean loss [0.00013772 0.00014028 0.00013954 0.00013567 0.0001435  0.00014689
 0.00017095]
Model epoch 547: train total loss -66.13757530915919, train mean loss 0.00011079057033282913, test mean loss [0.0001433  0.0001512  0.00014042 0.00014508 0.00015075 0.00013928
 0.00017455]
Model epoch 548: train total loss -66.16495380902843, train mean loss 0.00011183377140448999, test mean loss [0.00013278 0.00014717 0.00014614 0.00013948 0.00014357 0.000151
 0.0001678 ]
Model epoch 549: train total loss -66.06724287549169, train mean loss 0.00011665115422237999, test mean loss [0.00014068 0.00014309 0.00014022 0.00013877 0.00014396 0.00015443
 0.00016806]
Model epoch 550: train total loss -65.91035688917073, train mean loss 0.0001237222460209711, test mean loss [0.00014109 0.00013832 0.00014651 0.00014491 0.0001468  0.00014727
 0.00017131]
Model epoch 551: train total loss -66.11133060904064, train mean loss 0.00011244523487712393, test mean loss [0.00013492 0.00014706 0.0001433  0.00014457 0.0001528  0.00014384
 0.00018327]
Model epoch 552: train total loss -66.13394270579722, train mean loss 0.00010200722340569421, test mean loss [0.00014031 0.00014408 0.00014382 0.00014468 0.00014772 0.00014899
 0.00017337]
Model trained in 553 epochs with 4000 transitions.
[2025-01-22 16:12:44,114][absl][INFO] - {'eval/walltime': 167.02121782302856, 'training/sps': 0.20708385084230183, 'training/walltime': 9472.181545495987, 'training/model_train_time': 3529.438048362732, 'training/other_time': 1298.670758485794, 'training/model_horizon': 6, 'training/hallucination_updates_per_training_step': 752, 'training/env_buffer_size': Array(5000, dtype=int32), 'model/train_total_loss': Array(-66.13394271, dtype=float64, weak_type=True), 'model/train_mean_loss': Array(0.00010201, dtype=float64), 'model/test_total_loss': Array(-65.27391185, dtype=float64), 'model/test_mean_loss': Array(0.00014899, dtype=float64), 'model/train_epochs': 553, 'model/sec_per_epoch': 6.378885442481981, 'sac/actor_loss': Array(-16.06904042, dtype=float64), 'sac/alpha': Array(0.02758814, dtype=float32), 'sac/alpha_loss': Array(5.43586845e-05, dtype=float64), 'sac/buffer_current_size': Array(400000., dtype=float32), 'sac/critic_loss': Array(0.02582282, dtype=float64), 'eval/episode_forward_vel': Array(-61.37629298, dtype=float64), 'eval/episode_penalty_torque_lim': Array(-1.1388185, dtype=float64), 'eval/episode_rew_action': Array(0., dtype=float64), 'eval/episode_rew_ang_change': Array(12.10086047, dtype=float64), 'eval/episode_rew_ang_vel': Array(0., dtype=float64), 'eval/episode_rew_cosmetic': Array(0., dtype=float64), 'eval/episode_rew_energy': Array(0.02496458, dtype=float64), 'eval/episode_rew_foot_z': Array(0., dtype=float64), 'eval/episode_rew_forward_vel': Array(-26.39840558, dtype=float64), 'eval/episode_rew_joint_acc': Array(0., dtype=float64), 'eval/episode_rew_joint_limits': Array(0., dtype=float64), 'eval/episode_rew_pitch': Array(12.79817056, dtype=float64), 'eval/episode_rew_roll': Array(11.54316674, dtype=float64), 'eval/episode_rew_side_motion': Array(9.94768813, dtype=float64), 'eval/episode_rew_torque_limits': Array(0., dtype=float64), 'eval/episode_rew_turn': Array(11.04490106, dtype=float64), 'eval/episode_rew_yaw': Array(17.6621975, dtype=float64), 'eval/episode_rew_z_vel_change': Array(6.23768365, dtype=float64), 'eval/episode_reward': Array(52.59724154, dtype=float64), 'eval/episode_step_count': Array(32640., dtype=float64), 'eval/avg_episode_length': Array(256., dtype=float64), 'eval/epoch_eval_time': 30.776383638381958, 'eval/sps': 32.492446537899156}
Steps / Eval:  5000.0
Reward is  52.597241535587
Model horizon updated to 8.
Hallucination updates per training step updated to 1000.
SAC buffer resized to 400000 samples.
Model epoch 0: train total loss -27.256473311104273, train mean loss 0.1275617562971891, test mean loss [0.18038018 0.05782871 0.08602188 0.06059572 0.07186972 0.06663045
 0.23242737]
Model epoch 1: train total loss -33.95433992165215, train mean loss 0.048480200918894295, test mean loss [0.04688702 0.03524063 0.03330295 0.02740034 0.0446485  0.04430895
 0.059847  ]
Model epoch 2: train total loss -38.73313883337579, train mean loss 0.029687054163941802, test mean loss [0.02696486 0.02935744 0.02418229 0.02333871 0.03085494 0.03112031
 0.02826268]
Model epoch 3: train total loss -42.78401137959383, train mean loss 0.02198321223139991, test mean loss [0.01837926 0.02689313 0.0225898  0.02161129 0.02253501 0.02747484
 0.02256695]
Model epoch 4: train total loss -45.838263138568266, train mean loss 0.020134990744732892, test mean loss [0.01546792 0.02345914 0.01994523 0.01994831 0.01789453 0.02708572
 0.02110627]
Model epoch 5: train total loss -48.64718839773154, train mean loss 0.01863193659002779, test mean loss [0.01267102 0.02043385 0.01752524 0.01708622 0.01692991 0.024098
 0.01988027]
Model epoch 6: train total loss -51.06366458158733, train mean loss 0.015155580126791102, test mean loss [0.01040469 0.01739822 0.01601541 0.0143247  0.01443009 0.02087383
 0.01760388]
Model epoch 7: train total loss -52.83076965998362, train mean loss 0.013756702909916062, test mean loss [0.00854047 0.01557337 0.01441012 0.01216996 0.01217418 0.01781728
 0.01652221]
Model epoch 8: train total loss -53.840960794857956, train mean loss 0.010183018052211917, test mean loss [0.00730689 0.01387541 0.01265523 0.01029681 0.01057959 0.01570018
 0.01461738]
Model epoch 9: train total loss -54.82136895670321, train mean loss 0.009369598608764304, test mean loss [0.00637129 0.01207847 0.0111512  0.00847972 0.00915345 0.01444451
 0.01292535]
Model epoch 10: train total loss -55.234032280499925, train mean loss 0.008905731825163927, test mean loss [0.00545423 0.01051396 0.00965145 0.007173   0.00786701 0.012661
 0.01164216]
Model epoch 11: train total loss -55.90593448151247, train mean loss 0.007975082559015665, test mean loss [0.00475592 0.00914238 0.0085972  0.00598013 0.00697266 0.01125658
 0.01046896]
Model epoch 12: train total loss -56.12247972145868, train mean loss 0.006910726150861302, test mean loss [0.00428909 0.0081485  0.00758704 0.00526402 0.00605767 0.01015317
 0.00930388]
Model epoch 13: train total loss -56.85361748756205, train mean loss 0.005729353358668282, test mean loss [0.00387273 0.00723011 0.00693919 0.00443434 0.00533387 0.00891274
 0.00838542]
Model epoch 14: train total loss -57.580301281425434, train mean loss 0.005231855273449446, test mean loss [0.00341882 0.00625619 0.00606477 0.00395212 0.00470415 0.00800963
 0.00734046]
Model epoch 15: train total loss -57.94377099487568, train mean loss 0.004590645030592407, test mean loss [0.00318666 0.00562569 0.00549466 0.00348326 0.00424869 0.00713386
 0.00671194]
Model epoch 16: train total loss -58.15549176071383, train mean loss 0.004526177414444348, test mean loss [0.00294369 0.00489221 0.00490156 0.00315892 0.00390813 0.00648878
 0.00601041]
Model epoch 17: train total loss -58.54882513896723, train mean loss 0.0034579699188498595, test mean loss [0.00276981 0.00432238 0.00453667 0.00291121 0.00349992 0.00570616
 0.00543699]
Model epoch 18: train total loss -58.44548349762901, train mean loss 0.003247360644540829, test mean loss [0.00263229 0.00385437 0.00415732 0.00269615 0.00323204 0.00514802
 0.00502701]
Model epoch 19: train total loss -58.82779469054963, train mean loss 0.003237116033176419, test mean loss [0.00248903 0.00348228 0.00380947 0.0025144  0.00296829 0.00462183
 0.00446053]
Model epoch 20: train total loss -59.54555918960679, train mean loss 0.002811026243158748, test mean loss [0.00232964 0.00326313 0.00353522 0.00237551 0.00277885 0.00421135
 0.00403637]
Model epoch 21: train total loss -59.436646395276945, train mean loss 0.0028009979367948313, test mean loss [0.00217727 0.00286494 0.00322925 0.00222843 0.00265789 0.00386276
 0.0037065 ]
Model epoch 22: train total loss -59.6580177012164, train mean loss 0.0021774654253770777, test mean loss [0.00206956 0.00266589 0.00292208 0.00209509 0.00244883 0.00346764
 0.00344353]
Model epoch 23: train total loss -60.08296800505698, train mean loss 0.0023050594687895405, test mean loss [0.00193324 0.00249081 0.00271459 0.00197943 0.00236741 0.00318307
 0.00322736]
Model epoch 24: train total loss -59.95377099424744, train mean loss 0.0020870426055068546, test mean loss [0.00192859 0.0023078  0.00248774 0.00188015 0.00221791 0.00301663
 0.00297767]
Model epoch 25: train total loss -60.239333860449875, train mean loss 0.0017451394505034264, test mean loss [0.00173111 0.00215689 0.00226487 0.00177328 0.00212164 0.00287585
 0.00270287]
Model epoch 26: train total loss -60.463022012084934, train mean loss 0.0018207263124906288, test mean loss [0.00165733 0.00210518 0.00205794 0.00166059 0.00202735 0.00267105
 0.00253129]
Model epoch 27: train total loss -60.57893333876321, train mean loss 0.0017071984223048884, test mean loss [0.00157766 0.0019641  0.00185351 0.00157867 0.00199654 0.00253776
 0.00239485]
Model epoch 28: train total loss -60.3886222784057, train mean loss 0.0017812210642940201, test mean loss [0.00147993 0.00172517 0.00169473 0.00147234 0.00180805 0.00242829
 0.00221706]
Model epoch 29: train total loss -61.16887848686809, train mean loss 0.0013815739432556065, test mean loss [0.001475   0.00167246 0.00163759 0.00141192 0.00176047 0.0023125
 0.00205947]
Model epoch 30: train total loss -61.10476550496204, train mean loss 0.0015585857335689737, test mean loss [0.00141232 0.00163457 0.00147463 0.00134845 0.00171276 0.00218547
 0.00189444]
Model epoch 31: train total loss -61.14812393064247, train mean loss 0.0013670387566239476, test mean loss [0.00140284 0.00145503 0.00137899 0.00128499 0.00161968 0.0020823
 0.00183557]
Model epoch 32: train total loss -60.992710223032454, train mean loss 0.0013176513628366015, test mean loss [0.00129802 0.00140169 0.00131603 0.00123334 0.00154462 0.00200178
 0.00167377]
Model epoch 33: train total loss -61.28506986230633, train mean loss 0.0011393421569561026, test mean loss [0.00123554 0.00137675 0.00126685 0.00117592 0.00147972 0.00191399
 0.00162698]
Model epoch 34: train total loss -61.38636320264339, train mean loss 0.0012523506235470397, test mean loss [0.00119051 0.00128909 0.00118345 0.00111597 0.00141299 0.00179683
 0.00155749]
Model epoch 35: train total loss -61.630510001359745, train mean loss 0.0012347150842992843, test mean loss [0.00112872 0.00124443 0.00115645 0.00107423 0.00140291 0.0017008
 0.0014382 ]
Model epoch 36: train total loss -61.53094703703457, train mean loss 0.0010623365460803215, test mean loss [0.00108737 0.00120262 0.00108911 0.00102016 0.00131255 0.00168609
 0.00136156]
Model epoch 37: train total loss -61.7285046168959, train mean loss 0.0009768332478233036, test mean loss [0.0010625  0.00112343 0.00141506 0.00099664 0.0012782  0.0015805
 0.00130778]
Model epoch 38: train total loss -61.69487699724469, train mean loss 0.0009835806634908779, test mean loss [0.00101989 0.00111183 0.00107811 0.00099348 0.00121069 0.00152084
 0.00130376]
Model epoch 39: train total loss -61.67651784249265, train mean loss 0.0010454495132106911, test mean loss [0.00101182 0.00106609 0.00099412 0.00094396 0.00115126 0.00150177
 0.00124245]
Traceback (most recent call last):
  File "/home/ant/ssrl/ssrl/scripts/go1_train.py", line 248, in <module>
    train_go1()
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/ant/miniforge3/envs/ssrl/lib/python3.9/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/ant/ssrl/ssrl/scripts/go1_train.py", line 199, in train_go1
    state = train_fn(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 263, in train
    env_state) = sim_training_epoch_with_timing(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 947, in sim_training_epoch_with_timing
    training_state, model_metrics = train_model(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 661, in train_model
    test_total_loss, test_mean_loss) = model_training_epoch(
  File "/home/ant/ssrl/ssrl/brax/training/agents/ssrl/train.py", line 745, in model_training_epoch
    test_total_losses, test_mean_losses) = model_training_epoch_jit(
  File "<string>", line 1, in <lambda>
KeyboardInterrupt